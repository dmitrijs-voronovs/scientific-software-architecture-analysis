id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/834:1247,Usability,learn,learn,1247,"Hi, . I tried to run `sc.tl.highly_variable_genes` with `flavor=CellRanger` and `n_top_genes = 2000`. I obtained the following error:; ```pytb; /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 280 n_top_genes=n_top_genes,; 281 n_bins=n_bins,; --> 282 flavor=flavor,; 283 ); 284 . /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 141 dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]; 142 dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower; --> 143 disp_cut_off = dispersion_norm[n_top_genes-1]; 144 gene_subset = np.nan_to_num(df['dispersions_norm'].values) >= disp_cut_off; 145 logg.debug(. IndexError: index 1999 is out of bounds for axis 0 with size 1898; ```. I run scanpy in Python 3.7 (linux machine) with the following versions:; ```; scanpy==1.4.5.dev114+gd69832a anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. I suggest to check if `n_top_genes` is larger than `len(dispersion_norm)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/834
https://github.com/scverse/scanpy/pull/835:6,Testability,test,test,6,TODO: test. Fixes #834,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/835
https://github.com/scverse/scanpy/issues/837:76,Availability,error,error,76,"I've tried running `sc.pp.neighbors` with only 1 feature, got the following error:. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-6-e652dbfa9fae> in <module>; 3 ; 4 adata = sc.datasets.paul15(); ----> 5 sc.pp.neighbors(adata[:, 0]). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 653 use_dense_distances = (metric == 'euclidean' and X.shape[0] < 8192) or knn == False; 654 if use_dense_distances:; --> 655 _distances = pairwise_distances(X, metric=metric, **metric_kwds); 656 knn_indices, knn_distances = get_indices_distances_from_dense_matrix(; 657 _distances, n_neighbors). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds); 1586 func = partial(distance.cdist, metric=metric, **kwds); 1587 ; -> 1588 return _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1589 ; 1590 . ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1204 ; 1205 if effective_n_jobs(n_jobs) == 1:; -> 1206 return func(X, Y, **kwds); 1207 ; 1208 # enforce a threading backend to prevent data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_dista",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:3013,Modifiability,flexible,flexible,3013," data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_distances : distances betweens pairs of elements of X and Y.; 231 """"""; --> 232 X, Y = check_pairwise_arrays(X, Y); 233 ; 234 # If norms are passed as float32, they are unused. If arrays are passed as. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype); 107 if Y is X or Y is None:; 108 X = Y = check_array(X, accept_sparse='csr', dtype=dtype,; --> 109 estimator=estimator); 110 else:; 111 X = check_array(X, accept_sparse='csr', dtype=dtype,. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 519 ""Reshape your data either using array.reshape(-1, 1) if ""; 520 ""your data has a single feature or array.reshape(1, -1) ""; --> 521 ""if it contains a single sample."".format(array)); 522 ; 523 # in the future np.flexible dtypes will be handled like object dtypes. ValueError: Expected 2D array, got 1D array instead:; array=[0. 0. 1. ... 0. 3. 0.].; Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.; ```. To reproduce:; ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.neighbors(adata[:, 0]); ```; Not using `.copy()` doesn't seem to be the cause of the problem, since I've tried that and it still crashes.; My versions are:; ```python; scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.8 numpy==1.16.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. When running `sc.pp.neighbors(adata[:, :2])`, it works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:2601,Security,validat,validation,2601,"metrics/pairwise.py in _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1204 ; 1205 if effective_n_jobs(n_jobs) == 1:; -> 1206 return func(X, Y, **kwds); 1207 ; 1208 # enforce a threading backend to prevent data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_distances : distances betweens pairs of elements of X and Y.; 231 """"""; --> 232 X, Y = check_pairwise_arrays(X, Y); 233 ; 234 # If norms are passed as float32, they are unused. If arrays are passed as. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype); 107 if Y is X or Y is None:; 108 X = Y = check_array(X, accept_sparse='csr', dtype=dtype,; --> 109 estimator=estimator); 110 else:; 111 X = check_array(X, accept_sparse='csr', dtype=dtype,. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 519 ""Reshape your data either using array.reshape(-1, 1) if ""; 520 ""your data has a single feature or array.reshape(1, -1) ""; --> 521 ""if it contains a single sample."".format(array)); 522 ; 523 # in the future np.flexible dtypes will be handled like object dtypes. ValueError: Expected 2D array, got 1D array instead:; array=[0. 0. 1. ... 0. 3. 0.].; Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.; ```. To reproduce:; ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.neighbors(adata[:, 0]); ```; Not using `.copy()` doesn't seem to be the cause of the problem, since I've tried that and it still crashes.; My versions are:; ```python; scanpy==1.4.4.post1 anndata==0.6.22.post1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:3653,Usability,learn,learn,3653," data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_distances : distances betweens pairs of elements of X and Y.; 231 """"""; --> 232 X, Y = check_pairwise_arrays(X, Y); 233 ; 234 # If norms are passed as float32, they are unused. If arrays are passed as. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype); 107 if Y is X or Y is None:; 108 X = Y = check_array(X, accept_sparse='csr', dtype=dtype,; --> 109 estimator=estimator); 110 else:; 111 X = check_array(X, accept_sparse='csr', dtype=dtype,. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 519 ""Reshape your data either using array.reshape(-1, 1) if ""; 520 ""your data has a single feature or array.reshape(1, -1) ""; --> 521 ""if it contains a single sample."".format(array)); 522 ; 523 # in the future np.flexible dtypes will be handled like object dtypes. ValueError: Expected 2D array, got 1D array instead:; array=[0. 0. 1. ... 0. 3. 0.].; Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.; ```. To reproduce:; ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.neighbors(adata[:, 0]); ```; Not using `.copy()` doesn't seem to be the cause of the problem, since I've tried that and it still crashes.; My versions are:; ```python; scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.8 numpy==1.16.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. When running `sc.pp.neighbors(adata[:, :2])`, it works as expected.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/840:294,Availability,error,errors,294,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840
https://github.com/scverse/scanpy/issues/840:344,Testability,log,logging,344,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840
https://github.com/scverse/scanpy/issues/840:1722,Usability,learn,learn,1722,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840
https://github.com/scverse/scanpy/pull/841:13,Testability,test,tests,13,TODO:. - [x] tests; - [x] go over changes if they’re good or the code should be changed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/841
https://github.com/scverse/scanpy/issues/842:605,Testability,test,test,605,"I get inconsistent results when I use the parameter groups in `rank_genes_groups`. What I want to achieve is to focus on some groups for the DE genes computation. However, the results I get using the parameter groups, to select a subset of groups, are the same, in terms of DE genes, with respect to using the full set of groups. For example, l get different results if I run the following two snippets of code (which should provide instead the same set of DE genes).; ``` python; # Subsetting should be done by method; sc.tl.rank_genes_groups(; adata=adata,; groupby='leiden',; use_raw=False,; method='t-test',; groups=['1', '2'],; ); ```. ``` python; # Explicit subsetting; adata_f = adata[adata.obs['leiden'].isin(['1','2'])].copy(); sc.tl.rank_genes_groups(; adata=adata_f,; groupby='leiden',; use_raw=False,; method='t-test',; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:824,Testability,test,test,824,"I get inconsistent results when I use the parameter groups in `rank_genes_groups`. What I want to achieve is to focus on some groups for the DE genes computation. However, the results I get using the parameter groups, to select a subset of groups, are the same, in terms of DE genes, with respect to using the full set of groups. For example, l get different results if I run the following two snippets of code (which should provide instead the same set of DE genes).; ``` python; # Subsetting should be done by method; sc.tl.rank_genes_groups(; adata=adata,; groupby='leiden',; use_raw=False,; method='t-test',; groups=['1', '2'],; ); ```. ``` python; # Explicit subsetting; adata_f = adata[adata.obs['leiden'].isin(['1','2'])].copy(); sc.tl.rank_genes_groups(; adata=adata_f,; groupby='leiden',; use_raw=False,; method='t-test',; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/pull/844:122,Availability,down,downside,122,"This simplifies `top_segment_proportions_sparse_csr` by using improvements in numba which allow cacheing parallel code. A downside of this is it takes a really long time to compile on first run, which might be off-putting. Side note: I accidentally ran formatting before committing, so some other lines got changed too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:96,Performance,cache,cacheing,96,"This simplifies `top_segment_proportions_sparse_csr` by using improvements in numba which allow cacheing parallel code. A downside of this is it takes a really long time to compile on first run, which might be off-putting. Side note: I accidentally ran formatting before committing, so some other lines got changed too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:5,Usability,simpl,simplifies,5,"This simplifies `top_segment_proportions_sparse_csr` by using improvements in numba which allow cacheing parallel code. A downside of this is it takes a really long time to compile on first run, which might be off-putting. Side note: I accidentally ran formatting before committing, so some other lines got changed too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/846:102,Availability,down,down,102,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846
https://github.com/scverse/scanpy/pull/846:21,Performance,concurren,concurrently,21,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846
https://github.com/scverse/scanpy/pull/846:39,Testability,test,tests,39,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846
https://github.com/scverse/scanpy/pull/846:116,Testability,test,test,116,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846
https://github.com/scverse/scanpy/pull/846:143,Testability,test,test,143,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846
https://github.com/scverse/scanpy/pull/847:71,Availability,down,down,71,"Default: lzf. see theislab/anndata#123. To review without being bogged down with whitespace changes, check: https://github.com/theislab/scanpy/pull/847/files?w=1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/issues/849:226,Integrability,depend,dependency,226,"As @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015, we have to wait until matplotlib/matplotlib#14298 is fixed. It seems to be in matplotlib’s 3.1.2 milestone, so maybe we can just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”. This originally came up in #663, and then later in e.g. #787",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/851:390,Availability,error,errors,390,"Hello, . I am using scanpy version 1.4 from bioconda. I am running one of the examples from the code to query datasets - . ```; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); print(pbmc); plotdf = sc.get.obs_df(; pbmc,; keys=[""CD8B"", ""n_genes""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); plotdf.plot.scatter(""X_umap0"", ""X_umap1"", c=""CD8B""); ```. the library can read the dataset but errors out saying `scanpy` has no attribute `get`. I even tried . ```File ""test.py"", line 2, in <module>; from scanpy.get import obs_df; ModuleNotFoundError: No module named 'scanpy.get'; ```. Did the API change for any of this ? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:465,Testability,test,test,465,"Hello, . I am using scanpy version 1.4 from bioconda. I am running one of the examples from the code to query datasets - . ```; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); print(pbmc); plotdf = sc.get.obs_df(; pbmc,; keys=[""CD8B"", ""n_genes""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); plotdf.plot.scatter(""X_umap0"", ""X_umap1"", c=""CD8B""); ```. the library can read the dataset but errors out saying `scanpy` has no attribute `get`. I even tried . ```File ""test.py"", line 2, in <module>; from scanpy.get import obs_df; ModuleNotFoundError: No module named 'scanpy.get'; ```. Did the API change for any of this ? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/853:135,Availability,down,downloaded,135,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:275,Availability,error,errors,275,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:388,Availability,error,error,388,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:430,Availability,error,error,430,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:554,Availability,error,error,554,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:150,Deployability,install,installed,150,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:436,Integrability,message,message,436,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/853:475,Integrability,message,message,475,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853
https://github.com/scverse/scanpy/issues/854:87,Deployability,toggle,toggleswitch,87,"Hi, thanks for this great library!. I was playing around with data simulated from the `toggleswitch` model and was very much surprised to see the result of running the `dpt` on my simulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854
https://github.com/scverse/scanpy/issues/854:269,Deployability,toggle,toggleswitch,269,"Hi, thanks for this great library!. I was playing around with data simulated from the `toggleswitch` model and was very much surprised to see the result of running the `dpt` on my simulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854
https://github.com/scverse/scanpy/issues/854:656,Deployability,toggle,toggleswitch,656,"Hi, thanks for this great library!. I was playing around with data simulated from the `toggleswitch` model and was very much surprised to see the result of running the `dpt` on my simulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854
https://github.com/scverse/scanpy/issues/854:2033,Testability,test,tests,2033,"mulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some extent, but after running some tests, I could still find very pathological situations. It would be great if someone could look into this, I was told to mention @falexwolf . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854
https://github.com/scverse/scanpy/issues/854:1899,Usability,intuit,intuition,1899,"mulated data. The script I am running is the following:; ```python; adata = sc.tl.sim('toggleswitch',; nrRealizations=5,; tmax=200,; branching=False). sc.pl.sim(adata). sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.diffmap(adata); adata.uns['iroot'] = 0; sc.tl.dpt(adata). sc.tl.umap(adata); sc.pl.umap(adata,; edges=True,; edges_width=1,; color=['louvain', 'dpt_pseudotime'],; legend_loc='on data'); ```. In short, I am simulating five realizations of the two-genes `toggleswitch` model with 200 time steps in each realization and allowing to have multiple realizations from the same branch (otherwise there would be only two possible realizations). The problem I face is that the result of the pseudo-time computation seems (and is, since I know how the data was generated) wrong. Here are the plots displayed when running this script:; ![image](https://user-images.githubusercontent.com/6624306/65698989-b0028600-e07d-11e9-94ec-1ef5ac690658.png); and ; ![image](https://user-images.githubusercontent.com/6624306/65698967-a6791e00-e07d-11e9-9202-8603e49c4675.png). As you can see, for some reason, there is like a ""jump"" being made between the two steady states of the system, resulting in a final time (t=1) being somewhere between the starting point and one steady state. Running the same simulation with `branching=True` and only two realizations doesn't seem to have this issue. Since I'm a working student at the ICB, I talked to some people here about it, and we found out the following:; - using `method='gauss'` in the `neighbors` call did help in some situations, but playing with more random datasets later on invalidated this hypothesis.; - using less data points (time steps per realization), the intuition was that the high density of points in similar region could have an impact, did work to some extent, but after running some tests, I could still find very pathological situations. It would be great if someone could look into this, I was told to mention @falexwolf . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/854
https://github.com/scverse/scanpy/issues/855:69,Availability,error,error,69,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855
https://github.com/scverse/scanpy/issues/855:617,Deployability,install,installed,617,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855
https://github.com/scverse/scanpy/issues/855:644,Deployability,install,install,644,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855
https://github.com/scverse/scanpy/issues/855:75,Integrability,message,message,75,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855
https://github.com/scverse/scanpy/issues/856:1308,Performance,load,loading,1308,"Hi team Scanpy,. Thanks for developing this awesome suite of library and above all actively maintaining it.; I found [this](https://scanpy.readthedocs.io/en/stable/tutorials.html) tutorial page very helpful to get started for exploring the world of single-cell in python, using one stop libraries of scanpy. I am curious if you are interested in adding some tutorials related to quantification of the RNA-seq data i.e. in scanpy world it would be preprocessing step to generate the cell-v-gene counts. I am one of the author of the tool [alevin](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1670-y), we developed for quantifying 3' droplet based single cell data, somewhat in the line of Cellranger, although ours is a principled approach to consume the gene multi-mapping reads instead of dropping them all together. I have been writing some of the tutorials myself [here](https://combine-lab.github.io/alevin-tutorial/) but was wondering is there a way of supporting them directly in scanpy. The default output format (cell-v-gene matrix) of alevin is a binary format but it would be interesting to check if we can directly dump or post process it to `annData`format. I have been doing some analysis comparing various output formats (h5, mtx, csv, loom Eds) through their disk size, loading time and memory usage [here](https://github.com/COMBINE-lab/EDS). Looking forward to hearing back.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/856
https://github.com/scverse/scanpy/issues/859:576,Deployability,integrat,integrate,576,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:627,Deployability,Integrat,IntegrateData,627,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:693,Deployability,integrat,integrated,693,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:829,Deployability,integrat,integrate,829,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:920,Deployability,integrat,integrated,920,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1180,Deployability,integrat,integrating,1180,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1304,Deployability,integrat,integrate,1304,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:576,Integrability,integrat,integrate,576,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:627,Integrability,Integrat,IntegrateData,627,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:693,Integrability,integrat,integrated,693,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:829,Integrability,integrat,integrate,829,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:920,Integrability,integrat,integrated,920,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1180,Integrability,integrat,integrating,1180,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1304,Integrability,integrat,integrate,1304,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:156,Performance,perform,perform,156,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:661,Performance,perform,perform,661,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:888,Performance,perform,perform,888,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1106,Performance,perform,perform,1106,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:1326,Performance,perform,perform,1326,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:717,Testability,test,test,717,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/859:943,Testability,test,test,943,"Hi, . First of all, I would like to thank the developers for this awesome tool! I am new to Scanpy. I am migrating from Seurat to Scanpy as I would like to perform trajectory analysis in my data. I have single cell sequencing data from 12 samples and 3 treatments (so 4 samples per treatment). I merged the samples from the same treatment in a single matrix using ‘cellranger’ software from 10x Genomics (so I have 3 matrixes from 3 different treatments to import to Scanpy). . In ‘Seurat’, I can read the data from my three treatments separated, do quality control, and then integrate them using ‘FindIntegrationAnchors’ and ‘IntegrateData’ functions. Then, I perform cluster analysis in the integrated dataset, and test the effect of treatment on the transcriptome of each cluster. . Is there a similar function in ‘Scanpy’ to integrate different datasets which are labeled in order to perform cluster analyses in the integrated dataset and test for the effect of treatment in the transcriptome of identified cell types? If so, is there a tutorial for that?. In ‘Scanpy’ I am able to import the data and perform quality control and cluster analysis. Thus, if there was a way of integrating the 3 different matrixes in one single object that would be helpful. Any suggestions on how I should proceed to integrate my data and perform differential gene expression analysis according to treatment and cell type?. Thank you very much!. Joao",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/859
https://github.com/scverse/scanpy/issues/863:35,Testability,log,log,35,"`filter_rank_genes_groups` handles log values differently than the `rank_genes_groups` function. The discrepancy gives different DE gene lists when filtering genes based on `log2fc_min=1` with `get.rank_genes_groups_df` vs `min_fold_change=2` with `tl.filter_rank_genes_groups`. In rank_genes_groups, `np.expm1` is used:; ```python; foldchanges = (np.expm1(means[imask]) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; ```python; rankings_gene_logfoldchanges.append(np.log2(foldchanges[global_indices])); ```. In filter_rank_genes_groups, `np.exp` is used:; ```python; if log:; fold_change_matrix.loc[:, cluster] = (np.exp(mean_obs.loc[True]) / np.exp(mean_obs.loc[False])).values; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863
https://github.com/scverse/scanpy/issues/863:569,Testability,log,log,569,"`filter_rank_genes_groups` handles log values differently than the `rank_genes_groups` function. The discrepancy gives different DE gene lists when filtering genes based on `log2fc_min=1` with `get.rank_genes_groups_df` vs `min_fold_change=2` with `tl.filter_rank_genes_groups`. In rank_genes_groups, `np.expm1` is used:; ```python; foldchanges = (np.expm1(means[imask]) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; ```python; rankings_gene_logfoldchanges.append(np.log2(foldchanges[global_indices])); ```. In filter_rank_genes_groups, `np.exp` is used:; ```python; if log:; fold_change_matrix.loc[:, cluster] = (np.exp(mean_obs.loc[True]) / np.exp(mean_obs.loc[False])).values; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863
https://github.com/scverse/scanpy/issues/864:66,Testability,log,logFC,66,"Hi!; I've noticed that the function `rank_genes_groups` calculate logFC differently than seurat. ; https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L207-L208. https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L223. Thus the equation is; `log(exp(mean(values))`. while in Seurat is; https://github.com/satijalab/seurat/blob/96d07d80bc4b6513b93e9c10d8a9d57ae7016f9f/R/differential_expression.R#L175-L179 . thus; `log(mean(exp(values)))`. I was thus wondering if this was intended, since it leads to different logFC values.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864
https://github.com/scverse/scanpy/issues/864:371,Testability,log,log,371,"Hi!; I've noticed that the function `rank_genes_groups` calculate logFC differently than seurat. ; https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L207-L208. https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L223. Thus the equation is; `log(exp(mean(values))`. while in Seurat is; https://github.com/satijalab/seurat/blob/96d07d80bc4b6513b93e9c10d8a9d57ae7016f9f/R/differential_expression.R#L175-L179 . thus; `log(mean(exp(values)))`. I was thus wondering if this was intended, since it leads to different logFC values.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864
https://github.com/scverse/scanpy/issues/864:544,Testability,log,log,544,"Hi!; I've noticed that the function `rank_genes_groups` calculate logFC differently than seurat. ; https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L207-L208. https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L223. Thus the equation is; `log(exp(mean(values))`. while in Seurat is; https://github.com/satijalab/seurat/blob/96d07d80bc4b6513b93e9c10d8a9d57ae7016f9f/R/differential_expression.R#L175-L179 . thus; `log(mean(exp(values)))`. I was thus wondering if this was intended, since it leads to different logFC values.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864
https://github.com/scverse/scanpy/issues/864:640,Testability,log,logFC,640,"Hi!; I've noticed that the function `rank_genes_groups` calculate logFC differently than seurat. ; https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L207-L208. https://github.com/theislab/scanpy/blob/5800db45dde0c2060ad0a9bed8ea931bd41da936/scanpy/tools/_rank_genes_groups.py#L223. Thus the equation is; `log(exp(mean(values))`. while in Seurat is; https://github.com/satijalab/seurat/blob/96d07d80bc4b6513b93e9c10d8a9d57ae7016f9f/R/differential_expression.R#L175-L179 . thus; `log(mean(exp(values)))`. I was thus wondering if this was intended, since it leads to different logFC values.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/864
https://github.com/scverse/scanpy/pull/865:157,Availability,down,downsampled,157,"Addressing https://github.com/theislab/scanpy/issues/435#issuecomment-538776417. This PR does two things:. 1. `downsample_counts` will convert the resulting downsampled matrix back to the initial dtype by default.; 2. `normalize_total` will now work with integer matrices. I think 2 should definitely be the case. 1 does have a performance cost, but it's close to @falexwolf's [suggestion](https://github.com/theislab/scanpy/issues/435#issuecomment-475999342) and removes a minor foot-gun.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865
https://github.com/scverse/scanpy/pull/865:328,Performance,perform,performance,328,"Addressing https://github.com/theislab/scanpy/issues/435#issuecomment-538776417. This PR does two things:. 1. `downsample_counts` will convert the resulting downsampled matrix back to the initial dtype by default.; 2. `normalize_total` will now work with integer matrices. I think 2 should definitely be the case. 1 does have a performance cost, but it's close to @falexwolf's [suggestion](https://github.com/theislab/scanpy/issues/435#issuecomment-475999342) and removes a minor foot-gun.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865
https://github.com/scverse/scanpy/issues/866:359,Testability,test,test,359,"Hi, I recently found that the parameter of filtering, n_genes, is determined arbitrarily. Hence, could we use the normal distribution and the threshold value (5% and 95%) to do the job?. The scanpy gives the violin plot for n_genes, but I really want a density plot (imagined as attached). Specifically, after the plot, it could automatically do the ""shapiro test"" to see if it fits the normal distribution and give the the threshold value of 5% and 95% respectively. And the users could decide whether they want to filter the data by these parameters through n_genes. ![imagine](https://user-images.githubusercontent.com/49429496/66399459-3752e080-ea12-11e9-8458-af332e620975.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/866
https://github.com/scverse/scanpy/pull/869:30,Availability,error,error,30,`sc.pl.paga` was throwing and error when the color list in `.uns` was not previously set. While fixing the error I realized that some functionality was duplicated between legacy scatter plots and the embedding plots and removed the code duplication.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869
https://github.com/scverse/scanpy/pull/869:107,Availability,error,error,107,`sc.pl.paga` was throwing and error when the color list in `.uns` was not previously set. While fixing the error I realized that some functionality was duplicated between legacy scatter plots and the embedding plots and removed the code duplication.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869
https://github.com/scverse/scanpy/issues/870:54,Testability,log,log,54,"Hi guys,. I am trying to get the gene expression raw, log, scaled for just a couple of genes from the anndata object but i have tried doesnt seem to work. I just want a simple dataframe with the gene names as colum indexes and row info of the cells. this is waht i used to do in seurat. I am sure there is an easy way to do this in scanpy but just havent figure out. . geneX_df=as.data.frame(as.matrix(GetAssayData(object = anndata, slot = ""data"")[""geneX"",])). Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/870
https://github.com/scverse/scanpy/issues/870:169,Usability,simpl,simple,169,"Hi guys,. I am trying to get the gene expression raw, log, scaled for just a couple of genes from the anndata object but i have tried doesnt seem to work. I just want a simple dataframe with the gene names as colum indexes and row info of the cells. this is waht i used to do in seurat. I am sure there is an easy way to do this in scanpy but just havent figure out. . geneX_df=as.data.frame(as.matrix(GetAssayData(object = anndata, slot = ""data"")[""geneX"",])). Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/870
https://github.com/scverse/scanpy/issues/871:48,Safety,avoid,avoid,48,"```; # normalize, by excluding frequent gene to avoid distorting data; sc.pp.normalize_total(d, exclude_highly_expressed=True, max_fraction=0.05, inplace=True); ```. I was trying to normalize_total and exclude highly expressed genes. But:; I got; TypeError: normalize_total() got an unexpected keyword argument 'exclude_highly_expressed'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/871
https://github.com/scverse/scanpy/issues/872:175,Performance,perform,perform,175,"Hi,. In the scanpy, has anyone tried implementing jackstraw using anndata? If anyone has written a code to find the significant PCs in scanpy, please do share or any guide to perform it would be greatly appreciated! Thanks so much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872
https://github.com/scverse/scanpy/issues/872:166,Usability,guid,guide,166,"Hi,. In the scanpy, has anyone tried implementing jackstraw using anndata? If anyone has written a code to find the significant PCs in scanpy, please do share or any guide to perform it would be greatly appreciated! Thanks so much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872
https://github.com/scverse/scanpy/issues/874:277,Availability,fault,fault,277,"This issue just came up recently when I tried re-running an older notebook of mine. Whenever I try and run my code in Jupyter notebook and execute any cell that uses scanpy.tl.tsne my kernel crashes. When I try and execute the same code from the terminal I get ; `Segmentation fault: 11`. . This is the code I used to reproducibly get the error:; ```; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. <img width=""629"" alt=""Screenshot 2019-10-16 at 14 39 09"" src=""https://user-images.githubusercontent.com/15019107/66920007-c2d7fd00-f022-11e9-93d6-560305d1cc50.png"">. Any ideas what the issue could be and how I can fix this? The function used to work fine for me. I am running scanpy in the following version:; `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874
https://github.com/scverse/scanpy/issues/874:339,Availability,error,error,339,"This issue just came up recently when I tried re-running an older notebook of mine. Whenever I try and run my code in Jupyter notebook and execute any cell that uses scanpy.tl.tsne my kernel crashes. When I try and execute the same code from the terminal I get ; `Segmentation fault: 11`. . This is the code I used to reproducibly get the error:; ```; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. <img width=""629"" alt=""Screenshot 2019-10-16 at 14 39 09"" src=""https://user-images.githubusercontent.com/15019107/66920007-c2d7fd00-f022-11e9-93d6-560305d1cc50.png"">. Any ideas what the issue could be and how I can fix this? The function used to work fine for me. I am running scanpy in the following version:; `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874
https://github.com/scverse/scanpy/issues/874:883,Usability,learn,learn,883,"This issue just came up recently when I tried re-running an older notebook of mine. Whenever I try and run my code in Jupyter notebook and execute any cell that uses scanpy.tl.tsne my kernel crashes. When I try and execute the same code from the terminal I get ; `Segmentation fault: 11`. . This is the code I used to reproducibly get the error:; ```; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. <img width=""629"" alt=""Screenshot 2019-10-16 at 14 39 09"" src=""https://user-images.githubusercontent.com/15019107/66920007-c2d7fd00-f022-11e9-93d6-560305d1cc50.png"">. Any ideas what the issue could be and how I can fix this? The function used to work fine for me. I am running scanpy in the following version:; `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874
https://github.com/scverse/scanpy/issues/875:428,Availability,error,error,428,"Hi Scanpy team,. A potentially silly question. I'm having problems changing vmax in sc.pl.scatter. I want to set 'dpt_pseudotime' vmax to 0.5, similar to how vmax and vmin can be changed, for example, in sc.pl.umap. I tried the following:. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', color='dpt_pseudotime', size=5, use_raw=False, ; color_map='RdYlBu_r', vmax=0.5). But get the following error:. ![image](https://user-images.githubusercontent.com/49629901/66955933-64fee180-f031-11e9-90c2-0f12a392786b.png). I read in the scanpy.pl.scatter documentation that kwargs can be used to set vmax. I tried this approach, but got the same result as above:. kwargs={'vmax':0.5}. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', ; color='dpt_pseudotime', size=5, use_raw=False, color_map='RdYlBu_r', **kwargs). I tried to find a solution online with no success. Any help/suggestions will be appreciated. P.S: This is my first post and I'm a huge fan of your package. Keep up the great work!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/875
https://github.com/scverse/scanpy/issues/876:40,Deployability,install,installed,40,I just noticed that matplotlib 3.1.1 is installed when using conda to install scanpy 1.4.4.; In your requirements you state that this breaks the scatter plot.; In the repodata from bioconda however it seems like there are very old dependencies that were not changed when new scanpy versions were included. So still the dependency there ist matplotlib>=2.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/876
https://github.com/scverse/scanpy/issues/876:70,Deployability,install,install,70,I just noticed that matplotlib 3.1.1 is installed when using conda to install scanpy 1.4.4.; In your requirements you state that this breaks the scatter plot.; In the repodata from bioconda however it seems like there are very old dependencies that were not changed when new scanpy versions were included. So still the dependency there ist matplotlib>=2.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/876
https://github.com/scverse/scanpy/issues/876:231,Integrability,depend,dependencies,231,I just noticed that matplotlib 3.1.1 is installed when using conda to install scanpy 1.4.4.; In your requirements you state that this breaks the scatter plot.; In the repodata from bioconda however it seems like there are very old dependencies that were not changed when new scanpy versions were included. So still the dependency there ist matplotlib>=2.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/876
https://github.com/scverse/scanpy/issues/876:319,Integrability,depend,dependency,319,I just noticed that matplotlib 3.1.1 is installed when using conda to install scanpy 1.4.4.; In your requirements you state that this breaks the scatter plot.; In the repodata from bioconda however it seems like there are very old dependencies that were not changed when new scanpy versions were included. So still the dependency there ist matplotlib>=2.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/876
https://github.com/scverse/scanpy/issues/883:553,Availability,error,error,553,"Hi - excellent software, thanks! - . but I do have a problem. If i load a disk backed dataset, I cannot run `sc.tl.score_genes`. Given these two sets:; ```py; ad = sc.read_h5ad('scdataset.h5ad', backed='r+'); ad2 = sc.read_h5ad('scdataset.h5ad'); ```; and; ```py; random_genes = list(ad.var_names.to_series().sample(100)); ```; this works perfectly:; ```py; sc.tl.score_genes(ad2, random, score_name=""random100"", random_state=42); ```; but, this:; ```py; sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42); ```; yields the following error:; ```pytb; -----------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-113-9cb28e089b25> in <module>; ----> 1 sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 90 else:; 91 obs_avg = pd.Series(; ---> 92 np.nanmean(_adata[:, gene_pool].X, axis=0), index=gene_pool) # average expression of genes; 93 ; 94 obs_avg = obs_avg[np.isfinite(obs_avg)] # Sometimes (and I don't know how) missing data may be there, with nansfor. <__array_function__ internals> in nanmean(*args, **kwargs). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in nanmean(a, axis, dtype, out, keepdims); 949 cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims); 950 tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims); --> 951 avg = _divide_by_count(tot, cnt, out=out); 952 ; 953 isbad = (cnt == 0). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in _divide_by_count(a, b, out); 216 else:; 217 if out is None:; --> 218 return a.dtype.type(a / b); 219 else:; 220 # This is questionable, but currently a numpy scalar can. ValueError: setting an array element with a sequence.; ```. thanks; Mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883
https://github.com/scverse/scanpy/issues/883:1457,Availability,mask,mask,1457,"Hi - excellent software, thanks! - . but I do have a problem. If i load a disk backed dataset, I cannot run `sc.tl.score_genes`. Given these two sets:; ```py; ad = sc.read_h5ad('scdataset.h5ad', backed='r+'); ad2 = sc.read_h5ad('scdataset.h5ad'); ```; and; ```py; random_genes = list(ad.var_names.to_series().sample(100)); ```; this works perfectly:; ```py; sc.tl.score_genes(ad2, random, score_name=""random100"", random_state=42); ```; but, this:; ```py; sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42); ```; yields the following error:; ```pytb; -----------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-113-9cb28e089b25> in <module>; ----> 1 sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 90 else:; 91 obs_avg = pd.Series(; ---> 92 np.nanmean(_adata[:, gene_pool].X, axis=0), index=gene_pool) # average expression of genes; 93 ; 94 obs_avg = obs_avg[np.isfinite(obs_avg)] # Sometimes (and I don't know how) missing data may be there, with nansfor. <__array_function__ internals> in nanmean(*args, **kwargs). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in nanmean(a, axis, dtype, out, keepdims); 949 cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims); 950 tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims); --> 951 avg = _divide_by_count(tot, cnt, out=out); 952 ; 953 isbad = (cnt == 0). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in _divide_by_count(a, b, out); 216 else:; 217 if out is None:; --> 218 return a.dtype.type(a / b); 219 else:; 220 # This is questionable, but currently a numpy scalar can. ValueError: setting an array element with a sequence.; ```. thanks; Mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883
https://github.com/scverse/scanpy/issues/883:67,Performance,load,load,67,"Hi - excellent software, thanks! - . but I do have a problem. If i load a disk backed dataset, I cannot run `sc.tl.score_genes`. Given these two sets:; ```py; ad = sc.read_h5ad('scdataset.h5ad', backed='r+'); ad2 = sc.read_h5ad('scdataset.h5ad'); ```; and; ```py; random_genes = list(ad.var_names.to_series().sample(100)); ```; this works perfectly:; ```py; sc.tl.score_genes(ad2, random, score_name=""random100"", random_state=42); ```; but, this:; ```py; sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42); ```; yields the following error:; ```pytb; -----------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-113-9cb28e089b25> in <module>; ----> 1 sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 90 else:; 91 obs_avg = pd.Series(; ---> 92 np.nanmean(_adata[:, gene_pool].X, axis=0), index=gene_pool) # average expression of genes; 93 ; 94 obs_avg = obs_avg[np.isfinite(obs_avg)] # Sometimes (and I don't know how) missing data may be there, with nansfor. <__array_function__ internals> in nanmean(*args, **kwargs). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in nanmean(a, axis, dtype, out, keepdims); 949 cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims); 950 tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims); --> 951 avg = _divide_by_count(tot, cnt, out=out); 952 ; 953 isbad = (cnt == 0). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in _divide_by_count(a, b, out); 216 else:; 217 if out is None:; --> 218 return a.dtype.type(a / b); 219 else:; 220 # This is questionable, but currently a numpy scalar can. ValueError: setting an array element with a sequence.; ```. thanks; Mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883
https://github.com/scverse/scanpy/issues/884:503,Availability,error,error,503,"I've been having some issues recently when trying to subset an anndata object after I save it to disk. Everything works perfectly, but after I save it to disk using `adata.write(filename, compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's relate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884
https://github.com/scverse/scanpy/issues/884:1562,Availability,error,error,1562," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884
https://github.com/scverse/scanpy/issues/884:1678,Deployability,install,installed,1678," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884
https://github.com/scverse/scanpy/issues/884:1537,Modifiability,variab,variables,1537," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884
https://github.com/scverse/scanpy/issues/884:1807,Usability,learn,learn,1807," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884
https://github.com/scverse/scanpy/pull/886:0,Usability,Feedback,Feedback,0,Feedback please!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/886
https://github.com/scverse/scanpy/issues/889:220,Availability,error,error,220,"I've been trying to export my data to SPRING using the external export feature. I do all my processing in Seurat and then export a loom file to be read in scanpy and export to SPRING. I've been however getting the below error. The notebook with the code and the loom file can be found here: https://github.com/tejas-j/seurat2spring. Is there a better way to achieve what I'm trying to do (data -> Seurat -> scanpy -> SPRING) . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-3b0044b18ade> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sce.exporting.spring_project(data, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); 4 print(time.time() - t0). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, overwrite); 157 # Write continuous colors; 158 continuous_extras['Uniform'] = np.zeros(E.shape[0]); --> 159 write_color_tracks(continuous_extras, subplot_dir / 'color_data_gene_sets.csv'); 160 ; 161 # Create and write a dictionary of color profiles to be used by the visualizer. ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in write_color_tracks(ctracks, fname); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in <listcomp>(.0); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). TypeError: must be real number, not numpy.str_; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889
https://github.com/scverse/scanpy/issues/889:995,Deployability,continuous,continuous,995,"I've been trying to export my data to SPRING using the external export feature. I do all my processing in Seurat and then export a loom file to be read in scanpy and export to SPRING. I've been however getting the below error. The notebook with the code and the loom file can be found here: https://github.com/tejas-j/seurat2spring. Is there a better way to achieve what I'm trying to do (data -> Seurat -> scanpy -> SPRING) . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-3b0044b18ade> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sce.exporting.spring_project(data, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); 4 print(time.time() - t0). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, overwrite); 157 # Write continuous colors; 158 continuous_extras['Uniform'] = np.zeros(E.shape[0]); --> 159 write_color_tracks(continuous_extras, subplot_dir / 'color_data_gene_sets.csv'); 160 ; 161 # Create and write a dictionary of color profiles to be used by the visualizer. ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in write_color_tracks(ctracks, fname); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in <listcomp>(.0); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). TypeError: must be real number, not numpy.str_; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889
https://github.com/scverse/scanpy/pull/893:437,Testability,test,test,437,"Fix issue related to #890 and the reordering of stacked_violin_plots when `swap_axes=False` and for the case when `dendrogram` and `order` are given, in which case dendrogram order takes precedence. . Fix issue #891, now if `groups` is set for an embedding, the cells belonging to those groups are plotted on top. I also added missing documentation, pointing that the marker size could be a list of per-cell size. ; Added a new plotting test for the groups option.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/893
https://github.com/scverse/scanpy/issues/895:5,Availability,error,error,5,This error appears when using DESC autoencoder (github: eleozzr/desc) under scanpy 1.4.4. This was not an issue with earlier versions of scanpy. Is there a work-around available?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895
https://github.com/scverse/scanpy/issues/895:168,Availability,avail,available,168,This error appears when using DESC autoencoder (github: eleozzr/desc) under scanpy 1.4.4. This was not an issue with earlier versions of scanpy. Is there a work-around available?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895
https://github.com/scverse/scanpy/issues/897:276,Deployability,update,updated,276,"Continuation from #805, cc @gokceneraslan @falexwolf . > Why do we change Matplotlib ""font.sans-serif"" anyway?. Alex started replacing fonts from the beginning:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. He then updated them to the stack we have now:. https://github.com/theislab/scanpy/blob/6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2/scanpy/plotting.py#L763-L767. There’s some known [metrically compatible](https://wiki.archlinux.org/index.php/Metric-compatible_fonts) fonts, but our stack doesn’t reflect that, as e.g. DejaVu Sans isn’t metrically compatible to Arial and Helvetica. Is the [default matplotlib stack](https://github.com/matplotlib/matplotlib/blob/90fba030f534b3d7068e536fcfc4a2dc8d459eeb/lib/matplotlib/rcsetup.py#L1125-L1129) better or can we at least gain inspiration from it? What would be a safe stack to use on most OSs (even if that means fiddling with our plots if we change the stack to not-Helvetica-like)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/897
https://github.com/scverse/scanpy/issues/897:875,Safety,safe,safe,875,"Continuation from #805, cc @gokceneraslan @falexwolf . > Why do we change Matplotlib ""font.sans-serif"" anyway?. Alex started replacing fonts from the beginning:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. He then updated them to the stack we have now:. https://github.com/theislab/scanpy/blob/6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2/scanpy/plotting.py#L763-L767. There’s some known [metrically compatible](https://wiki.archlinux.org/index.php/Metric-compatible_fonts) fonts, but our stack doesn’t reflect that, as e.g. DejaVu Sans isn’t metrically compatible to Arial and Helvetica. Is the [default matplotlib stack](https://github.com/matplotlib/matplotlib/blob/90fba030f534b3d7068e536fcfc4a2dc8d459eeb/lib/matplotlib/rcsetup.py#L1125-L1129) better or can we at least gain inspiration from it? What would be a safe stack to use on most OSs (even if that means fiddling with our plots if we change the stack to not-Helvetica-like)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/897
https://github.com/scverse/scanpy/pull/898:181,Modifiability,inherit,inherit-requirements,181,"To not repeat ourselves @ivirshup (I think) suggested this. Let’s see if readthedocs supports this. If so, this should soon be visible: https://icb-scanpy.readthedocs-hosted.com/en/inherit-requirements/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/898
https://github.com/scverse/scanpy/issues/900:1332,Modifiability,Layers,LayersBase,1332,"ns, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silence_errors(); 35 ; ---> 36 from ._conv import register_converters as _register_converters; 37 _register_converters(); 38 . h5py\h5r.pxd in init h5py._conv(). h5py\_objects.pxd in init h5py.h5r(). h5py\_objects.pyx in init h5py._objects(). ImportError: DLL load failed: The specified procedure could not be found.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:1344,Modifiability,Layers,Layers,1344,"ns, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silence_errors(); 35 ; ---> 36 from ._conv import register_converters as _register_converters; 37 _register_converters(); 38 . h5py\h5r.pxd in init h5py._conv(). h5py\_objects.pxd in init h5py.h5r(). h5py\_objects.pyx in init h5py._objects(). ImportError: DLL load failed: The specified procedure could not be found.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:2256,Performance,load,load,2256,"ns, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silence_errors(); 35 ; ---> 36 from ._conv import register_converters as _register_converters; 37 _register_converters(); 38 . h5py\h5r.pxd in init h5py._conv(). h5py\_objects.pxd in init h5py.h5r(). h5py\_objects.pyx in init h5py._objects(). ImportError: DLL load failed: The specified procedure could not be found.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:588,Testability,log,logging,588,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:599,Testability,log,logg,599,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:792,Testability,log,logging,792,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:810,Testability,log,logging,810,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:912,Testability,log,logging,912,"ImportError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/issues/900:996,Testability,log,logging,996,"tError Traceback (most recent call last); <ipython-input-1-b6c916879140> in <module>(); 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc. ~\Anaconda3-6\lib\site-packages\scanpy\__init__.py in <module>(); 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~\Anaconda3-6\lib\site-packages\scanpy\utils.py in <module>(); 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~\Anaconda3-6\lib\site-packages\scanpy\_settings.py in <module>(); 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~\Anaconda3-6\lib\site-packages\scanpy\logging.py in <module>(); 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~\Anaconda3-6\lib\site-packages\anndata\__init__.py in <module>(); ----> 1 from .core.anndata import AnnData, Raw; 2 from .readwrite import (; 3 read_h5ad, read_loom, read_hdf,; 4 read_excel, read_umi_tools,; 5 read_csv, read_text, read_mtx,. ~\Anaconda3-6\lib\site-packages\anndata\core\anndata.py in <module>(); 46 LayersBase, Layers; 47 ); ---> 48 from .. import h5py; 49 from .views import ArrayView, SparseCSRView, SparseCSCView, DictView, DataFrameView; 50 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\__init__.py in <module>(); 22 SparseDataset; 23 """"""; ---> 24 from .h5sparse import File, Group, SparseDataset, _load_h5_dataset_as_sparse; 25 from h5py import Dataset, special_dtype; 26 . ~\Anaconda3-6\lib\site-packages\anndata\h5py\h5sparse.py in <module>(); 4 from typing import Optional, Union, KeysView, NamedTuple; 5 ; ----> 6 import h5py; 7 import numpy as np; 8 import scipy.sparse as ss. ~\Anaconda3-6\lib\site-packages\h5py\__init__.py in <module>(); 34 _errors.silence_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/900
https://github.com/scverse/scanpy/pull/903:26,Deployability,integrat,integrate,26,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/pull/903:420,Energy Efficiency,power,powerful,420,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/pull/903:26,Integrability,integrat,integrate,26,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/pull/903:199,Modifiability,variab,variability,199,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/pull/903:263,Testability,benchmark,benchmarking,263,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/pull/903:645,Testability,test,test,645,This is a pull request to integrate the Self-Assembling Manifold (SAM) algorithm into scanpy. A brief summary of the method:; SAM iteratively rescales the expressions of genes based on their spatial variability along the intrinsic manifold of the data. Extensive benchmarking has shown this approach to improve dimensionality reduction and feature selection for both 'easy' and 'challenging' datasets. SAM is especially powerful when analyzing datasets with only subtle differences in gene expression between cell types. More information can be found in the eLife publication: https://elifesciences.org/articles/48994. I still need to write the test script as well as ensure that the added code follows the BLACK coding style. Please let me know if there are any other issues I should fix prior to merging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/903
https://github.com/scverse/scanpy/issues/905:1265,Deployability,pipeline,pipelines,1265,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:1280,Deployability,pipeline,pipeline,1280,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:350,Modifiability,variab,variable,350,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:919,Performance,perform,performed,919,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:857,Safety,detect,detected,857,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:422,Testability,log,log,422,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:564,Testability,log,log,564,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:590,Testability,log,log,590,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:615,Testability,log,log,615,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/issues/905:1107,Testability,log,log,1107,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905
https://github.com/scverse/scanpy/pull/910:208,Testability,test,test,208,Paga plotting had some half-finished support for supplying a root by its label. This is supposed to finish this. Fixes #909. @falexwolf needs to say if this corresponds to his intentions and we need to add a test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/910
https://github.com/scverse/scanpy/issues/913:3669,Performance,bottleneck,bottleneck,3669,"anceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""../../../../../opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/umap/nndescent.py"", line 47:; @numba.njit(parallel=True); def nn_descent(; ^. self.func_ir.loc)); ```. when I run; ```; from joblib import parallel_backend; with parallel_backend('threading', n_jobs=15):; sc.pp.neighbors(adata, n_neighbors=100, n_pcs=12); ```. as suggested in #659, it takes 1 min 28 seconds, empirically mostly uses 1 cpu, and gives the following warning. ```; /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/numba/compiler.py:602: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""../../../../../opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/umap/rp_tree.py"", line 135:; @numba.njit(fastmath=True, nogil=True, parallel=True); def euclidean_random_projection_split(data, indices, rng_state):; ^. self.func_ir.loc)); /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/numba/compiler.py:602: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""../../../../../opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/umap/nndescent.py"", line 47:; @numba.njit(parallel=True); def nn_descent(; ^. self.func_ir.loc)); ```. Are there any tips on how I can benefit from parallelization in these nearest neighbor computations? This is the bottleneck in my work flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913
https://github.com/scverse/scanpy/pull/915:434,Availability,avail,available,434,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:679,Availability,avail,available,679,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:733,Availability,avail,available,733,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:763,Integrability,interface,interfaces,763,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:1900,Integrability,wrap,wrapping,1900,"rical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki page](https://en.wikipedia.org/wiki/Geary%27s_C)). Calculates autocorrelation on a measure on a network. Used in [VISION](https://doi.org/10.1038/s41467-019-12235-0) for ranking gene sets. This is useful for finding out whether some per-cell measure is correlated with the structure of a connectivity graph. In practice, I've found it useful for identifying features that look good on a UMAP:. ```python; import numpy as np; pbmc.layers[""logcounts""] = pbmc.raw.X. %time gearys_c = sc.metrics.gearys_c(pbmc, layer=""logcounts""); # CPU times: user 496 ms, sys: 3.88 ms, total: 500 ms; # Wall time: 74.9 ms; to_plot = pbmc.var_names[np.argsort(gearys_c)[:4]]; sc.pl.umap(pbmc, color=to_plot, ncols=2); ```. ![image](https://user-images.githubusercontent.com/8238804/68736833-e304d700-0635-11ea-87f4-ac066f3e270c.png). It can also be useful to rank components of dimensionality reduct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:2428,Modifiability,layers,layers,2428,"turns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki page](https://en.wikipedia.org/wiki/Geary%27s_C)). Calculates autocorrelation on a measure on a network. Used in [VISION](https://doi.org/10.1038/s41467-019-12235-0) for ranking gene sets. This is useful for finding out whether some per-cell measure is correlated with the structure of a connectivity graph. In practice, I've found it useful for identifying features that look good on a UMAP:. ```python; import numpy as np; pbmc.layers[""logcounts""] = pbmc.raw.X. %time gearys_c = sc.metrics.gearys_c(pbmc, layer=""logcounts""); # CPU times: user 496 ms, sys: 3.88 ms, total: 500 ms; # Wall time: 74.9 ms; to_plot = pbmc.var_names[np.argsort(gearys_c)[:4]]; sc.pl.umap(pbmc, color=to_plot, ncols=2); ```. ![image](https://user-images.githubusercontent.com/8238804/68736833-e304d700-0635-11ea-87f4-ac066f3e270c.png). It can also be useful to rank components of dimensionality reductions (example with ICA: https://github.com/theislab/scanpy/issues/767#issuecomment-552756716).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:2436,Testability,log,logcounts,2436,"turns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki page](https://en.wikipedia.org/wiki/Geary%27s_C)). Calculates autocorrelation on a measure on a network. Used in [VISION](https://doi.org/10.1038/s41467-019-12235-0) for ranking gene sets. This is useful for finding out whether some per-cell measure is correlated with the structure of a connectivity graph. In practice, I've found it useful for identifying features that look good on a UMAP:. ```python; import numpy as np; pbmc.layers[""logcounts""] = pbmc.raw.X. %time gearys_c = sc.metrics.gearys_c(pbmc, layer=""logcounts""); # CPU times: user 496 ms, sys: 3.88 ms, total: 500 ms; # Wall time: 74.9 ms; to_plot = pbmc.var_names[np.argsort(gearys_c)[:4]]; sc.pl.umap(pbmc, color=to_plot, ncols=2); ```. ![image](https://user-images.githubusercontent.com/8238804/68736833-e304d700-0635-11ea-87f4-ac066f3e270c.png). It can also be useful to rank components of dimensionality reductions (example with ICA: https://github.com/theislab/scanpy/issues/767#issuecomment-552756716).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:2512,Testability,log,logcounts,2512,"turns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki page](https://en.wikipedia.org/wiki/Geary%27s_C)). Calculates autocorrelation on a measure on a network. Used in [VISION](https://doi.org/10.1038/s41467-019-12235-0) for ranking gene sets. This is useful for finding out whether some per-cell measure is correlated with the structure of a connectivity graph. In practice, I've found it useful for identifying features that look good on a UMAP:. ```python; import numpy as np; pbmc.layers[""logcounts""] = pbmc.raw.X. %time gearys_c = sc.metrics.gearys_c(pbmc, layer=""logcounts""); # CPU times: user 496 ms, sys: 3.88 ms, total: 500 ms; # Wall time: 74.9 ms; to_plot = pbmc.var_names[np.argsort(gearys_c)[:4]]; sc.pl.umap(pbmc, color=to_plot, ncols=2); ```. ![image](https://user-images.githubusercontent.com/8238804/68736833-e304d700-0635-11ea-87f4-ac066f3e270c.png). It can also be useful to rank components of dimensionality reductions (example with ICA: https://github.com/theislab/scanpy/issues/767#issuecomment-552756716).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/915:1819,Usability,feedback,feedback,1819,"fusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki page](https://en.wikipedia.org/wiki/Geary%27s_C)). Calculates autocorrelation on a measure on a network. Used in [VISION](https://doi.org/10.1038/s41467-019-12235-0) for ranking gene sets. This is useful for finding out whether some per-cell measure is correlated with the structure of a connectivity graph. In practice, I've found it useful for identifying features that look good on a UMAP:. ```python; import numpy as np; pbmc.layers[""logcounts""] = pbmc.raw.X. %time gearys_c = sc.metrics.gearys_c(pbmc, layer=""logcounts""); # CPU times: user 496 ms, sys: 3.88 ms, total: 500 ms; # Wall time: 74.9 ms; to_plot = pbmc.var_names[np.argsort(gearys_c)[:4]]; sc.pl.umap(pbmc, color=to_plot, ncols=2); ```. ![image](https://user-images.githubusercontent.com/8238804/68736833-e304d700-0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915
https://github.com/scverse/scanpy/pull/917:62,Deployability,release,released,62,"This should not be merged until Scanpy uses UMAP 0.4 (not yet released). It allows UMAP to take advantage of multiple cores by setting the random state to `None`:. ```python; sc.tl.umap(adata, random_state=None); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/917
https://github.com/scverse/scanpy/issues/918:422,Availability,Error,Error,422,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918
https://github.com/scverse/scanpy/issues/918:511,Availability,error,error,511,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918
https://github.com/scverse/scanpy/issues/918:561,Testability,log,logging,561,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918
https://github.com/scverse/scanpy/issues/918:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918
https://github.com/scverse/scanpy/issues/918:690,Usability,learn,learn,690,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918
https://github.com/scverse/scanpy/issues/919:52,Testability,test,test,52,"Hi!. Is it possible to do two-sided (or two-tailed) test in rank_genes_groups?. It seems like the tests you can choose from for now (t-test, wilcoxon etc.) are one-sided in that comparing group A to group B produces a list of DE genes that is not the same as in comparison of B to A. Thank you. Sincerely,; Anna Arutyunyan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919
https://github.com/scverse/scanpy/issues/919:98,Testability,test,tests,98,"Hi!. Is it possible to do two-sided (or two-tailed) test in rank_genes_groups?. It seems like the tests you can choose from for now (t-test, wilcoxon etc.) are one-sided in that comparing group A to group B produces a list of DE genes that is not the same as in comparison of B to A. Thank you. Sincerely,; Anna Arutyunyan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919
https://github.com/scverse/scanpy/issues/919:135,Testability,test,test,135,"Hi!. Is it possible to do two-sided (or two-tailed) test in rank_genes_groups?. It seems like the tests you can choose from for now (t-test, wilcoxon etc.) are one-sided in that comparing group A to group B produces a list of DE genes that is not the same as in comparison of B to A. Thank you. Sincerely,; Anna Arutyunyan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919
https://github.com/scverse/scanpy/issues/921:3294,Availability,down,down,3294," Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` takes 334s, while Dask with `scipy.sparse` takes 138s, a 2.4x speedup. That's a significant speedup, but I'm not sure that it justifies the code overhead. I'd be interested to hear what others think. . ### Other notes. #### Code; See this branch: https://github.com/theislab/scanpy/compare/master...tomwhite:sparse-dask. #### CuPy and GPUs; I also wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_cupy_sparse.py) around the GPU equivalent of `scipy.sparse`, [`cupyx.scipy.sparse`](https://docs-cupy.chainer.org/en/stable/reference/sparse.html). Many operations work, however `cupyx.scipy.sparse` has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:; * `multiply` - not implemented by `cupyx.scipy.sparse.csr.csr_matrix`; * `mean` - no method on `cupyx.scipy.sparse.csr.csr_matrix` (note that it does have `sum`); * column subset not supported, e.g. `xs[:, 1:3]` (note that row subset is); * boolean indexing, i.e. `xs[:, subset]`, where `subset` is e.g. `np.array([True, False, True, False, True])`; note this fails for rows too. #### NumPy 1.16 vs NumPy 1.17; I used NumPy 1.16 for the above experiments. However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921
https://github.com/scverse/scanpy/issues/921:693,Integrability,wrap,wrapper,693,"Can we use Dask to speed up the preprocessing phase of Scanpy by taking advantage of multiple CPUs (or GPUs)?. **TLDR**: Dask can speed up Zheng17, but it needs lots of cores and a rewritten implementation. CuPy (for GPUs) has missing operations required by Zheng17, so more work is needed for Dask with GPUs. ### Investigation. Dask is mainly used with dense arrays, however the arrays in Scanpy are sparse (for most of the preprocessing phase at least). I tried looking at [pydata sparse](https://sparse.pydata.org/en/latest/) with Dask, but it ran a lot slower than regular [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html) (which is what Scanpy uses). So I wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_scipy_sparse.py) around `scipy.sparse` to implement NumPy's `__array_function__` protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular `scipy.sparse`. However, when I first tried running the whole Zheng17 recipe, `scipy.sparse` was always faster than Dask with `scipy.sparse`, even with many cores (e.g. 64). It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` tak",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921
https://github.com/scverse/scanpy/issues/921:855,Integrability,protocol,protocol,855,"Can we use Dask to speed up the preprocessing phase of Scanpy by taking advantage of multiple CPUs (or GPUs)?. **TLDR**: Dask can speed up Zheng17, but it needs lots of cores and a rewritten implementation. CuPy (for GPUs) has missing operations required by Zheng17, so more work is needed for Dask with GPUs. ### Investigation. Dask is mainly used with dense arrays, however the arrays in Scanpy are sparse (for most of the preprocessing phase at least). I tried looking at [pydata sparse](https://sparse.pydata.org/en/latest/) with Dask, but it ran a lot slower than regular [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html) (which is what Scanpy uses). So I wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_scipy_sparse.py) around `scipy.sparse` to implement NumPy's `__array_function__` protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular `scipy.sparse`. However, when I first tried running the whole Zheng17 recipe, `scipy.sparse` was always faster than Dask with `scipy.sparse`, even with many cores (e.g. 64). It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` tak",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921
https://github.com/scverse/scanpy/issues/921:2355,Integrability,wrap,wrapper,2355,"late the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` takes 334s, while Dask with `scipy.sparse` takes 138s, a 2.4x speedup. That's a significant speedup, but I'm not sure that it justifies the code overhead. I'd be interested to hear what others think. . ### Other notes. #### Code; See this branch: https://github.com/theislab/scanpy/compare/master...tomwhite:sparse-dask. #### CuPy and GPUs; I also wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_cupy_sparse.py) around the GPU equivalent of `scipy.sparse`, [`cupyx.scipy.sparse`](https://docs-cupy.chainer.org/en/stable/reference/sparse.html). Many operations work, however `cupyx.scipy.sparse` has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:; * `multiply` - not implemented by `cupyx.scipy.sparse.csr.csr_matrix`; * `mean` - no method on `cupyx.scipy.sparse.csr.csr_matrix` (note that it does have `sum`); * column subset not supported, e.g. `xs[:, 1:3]` (note that row subset is); * boolean indexing, i.e. `xs[:, subset]`, where `subset` is e.g. `np.array([True, False, True, False, True])`; note this fails for rows too. #### NumPy 1.16 vs NumPy 1.17; I used NumPy 1.16 for the above experiments. However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921
https://github.com/scverse/scanpy/issues/921:1585,Safety,avoid,avoid,1585," a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_scipy_sparse.py) around `scipy.sparse` to implement NumPy's `__array_function__` protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular `scipy.sparse`. However, when I first tried running the whole Zheng17 recipe, `scipy.sparse` was always faster than Dask with `scipy.sparse`, even with many cores (e.g. 64). It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` takes 334s, while Dask with `scipy.sparse` takes 138s, a 2.4x speedup. That's a significant speedup, but I'm not sure that it justifies the code overhead. I'd be interested to hear what others think. . ### Other notes. #### Code; See this branch: https://github.com/theislab/scanpy/compare/master...tomwhite:sparse-dask. #### CuPy and GPUs; I also wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_cupy_sparse.py) around the GPU equivalent of `scipy.sparse`, [`cupyx.scipy.sparse`](https://docs-cupy.chainer.org/en/stable/reference/sparse.html). Many operations work, however `cupyx.scipy.sparse` has a number of missing features that mean it can’t be ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921
https://github.com/scverse/scanpy/issues/924:460,Availability,error,error,460,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:2271,Availability,Mask,MaskedArray,2271,"as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). ~\AppData\Local\Continuum\anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:921,Modifiability,layers,layers,921,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:928,Modifiability,layers,layers,928,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:1101,Modifiability,layers,layers,1101,"om_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:1173,Modifiability,layers,layers,1173,"om_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:1180,Modifiability,layers,layers,1180,"om_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:1481,Modifiability,layers,layers,1481,"-------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:269,Security,validat,validate,269,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:414,Security,validat,validate,414,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/924:718,Security,validat,validate,718,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924
https://github.com/scverse/scanpy/issues/925:204,Availability,error,error,204,"Hi,. To have a depth understanding, I wanted to set the resolution high for louvain clustering, but now I cannot merge subclusters. When I try to rename the categories with same cluster name, it gives an error about not having unique names. Yet, I could not find a functional merge_clusters function. Is there anyone having the same issue as me? I would appreciate any help. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/925
https://github.com/scverse/scanpy/issues/929:502,Energy Efficiency,adapt,adapt,502,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:502,Modifiability,adapt,adapt,502,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:52,Testability,log,log,52,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:86,Testability,log,logarithm,86,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:158,Testability,log,log,158,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:224,Testability,log,log,224,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/929:307,Usability,simpl,simple,307,"`log2(TP10K+1)` values are more interpretable than `log(TP10K+1)`, which uses natural logarithm, therefore it'd be great to have an option on the base of the log. It's one of the requests also here #45 . Since neither of np.log or np.log1p accepts any base arguments(isn't this unbelievable), I did it with simple numba functions here: . https://nbviewer.ipython.org/gist/gokceneraslan/2744cfeda702fb9b9e48d0216427372c?flush_cache=true. I won't have time to send a PR, but feel free to pursue further, adapt the notebook and merge (if you have time). PS: Also see https://github.com/numpy/numpy/issues/14969.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/929
https://github.com/scverse/scanpy/issues/933:2502,Availability,avail,available,2502,"_3', 'ClusterMarkers_0_sub_30', 'ClusterMarkers_0_sub_31', 'ClusterMarkers_0_sub_32', 'ClusterMarkers_0_sub_33', 'ClusterMarkers_0_sub_34', 'ClusterMarkers_0_sub_35', 'ClusterMarkers_0_sub_36', 'ClusterMarkers_0_sub_37', 'ClusterMarkers_0_sub_38', 'ClusterMarkers_0_sub_39', 'ClusterMarkers_0_sub_4', 'ClusterMarkers_0_sub_40', 'ClusterMarkers_0_sub_41', 'ClusterMarkers_0_sub_42', 'ClusterMarkers_0_sub_43', 'ClusterMarkers_0_sub_44', 'ClusterMarkers_0_sub_45', 'ClusterMarkers_0_sub_46', 'ClusterMarkers_0_sub_47', 'ClusterMarkers_0_sub_48', 'ClusterMarkers_0_sub_49', 'ClusterMarkers_0_sub_5', 'ClusterMarkers_0_sub_50', 'ClusterMarkers_0_sub_51', 'ClusterMarkers_0_sub_52', 'ClusterMarkers_0_sub_53', 'ClusterMarkers_0_sub_54', 'ClusterMarkers_0_sub_55', 'ClusterMarkers_0_sub_56', 'ClusterMarkers_0_sub_57', 'ClusterMarkers_0_sub_58', 'ClusterMarkers_0_sub_59', 'ClusterMarkers_0_sub_6', 'ClusterMarkers_0_sub_60', 'ClusterMarkers_0_sub_61', 'ClusterMarkers_0_sub_62', 'ClusterMarkers_0_sub_63', 'ClusterMarkers_0_sub_64', 'ClusterMarkers_0_sub_65', 'ClusterMarkers_0_sub_66', 'ClusterMarkers_0_sub_67', 'ClusterMarkers_0_sub_68', 'ClusterMarkers_0_sub_69', 'ClusterMarkers_0_sub_7', 'ClusterMarkers_0_sub_70', 'ClusterMarkers_0_sub_71', 'ClusterMarkers_0_sub_72', 'ClusterMarkers_0_sub_8', 'ClusterMarkers_0_sub_9', 'ClusterMarkers_1', 'ClusterMarkers_2', 'ClusterMarkers_3', 'ClusterMarkers_4', 'ClusterMarkers_5', 'ClusterMarkers_6', 'ClusterMarkers_7', 'Regulons'; obsm: 'ClusterID'. This is from publicaly available data. so what i would like to do is plot their published tsne or umap and compare a few things from it. If I simply run sc.pl.tsne(loom_file, color=['louvain']) I get error msg: ValueError: no field of name X_tsne. This makes sense as there is not X_tsne on the object. How could I get pass this without re-clustering myself? At the moment I am only interested in pulling out 2 of their annotated clusters... if there is an easy way to do this via scanpy please let me know.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/933
https://github.com/scverse/scanpy/issues/933:2679,Availability,error,error,2679,"_3', 'ClusterMarkers_0_sub_30', 'ClusterMarkers_0_sub_31', 'ClusterMarkers_0_sub_32', 'ClusterMarkers_0_sub_33', 'ClusterMarkers_0_sub_34', 'ClusterMarkers_0_sub_35', 'ClusterMarkers_0_sub_36', 'ClusterMarkers_0_sub_37', 'ClusterMarkers_0_sub_38', 'ClusterMarkers_0_sub_39', 'ClusterMarkers_0_sub_4', 'ClusterMarkers_0_sub_40', 'ClusterMarkers_0_sub_41', 'ClusterMarkers_0_sub_42', 'ClusterMarkers_0_sub_43', 'ClusterMarkers_0_sub_44', 'ClusterMarkers_0_sub_45', 'ClusterMarkers_0_sub_46', 'ClusterMarkers_0_sub_47', 'ClusterMarkers_0_sub_48', 'ClusterMarkers_0_sub_49', 'ClusterMarkers_0_sub_5', 'ClusterMarkers_0_sub_50', 'ClusterMarkers_0_sub_51', 'ClusterMarkers_0_sub_52', 'ClusterMarkers_0_sub_53', 'ClusterMarkers_0_sub_54', 'ClusterMarkers_0_sub_55', 'ClusterMarkers_0_sub_56', 'ClusterMarkers_0_sub_57', 'ClusterMarkers_0_sub_58', 'ClusterMarkers_0_sub_59', 'ClusterMarkers_0_sub_6', 'ClusterMarkers_0_sub_60', 'ClusterMarkers_0_sub_61', 'ClusterMarkers_0_sub_62', 'ClusterMarkers_0_sub_63', 'ClusterMarkers_0_sub_64', 'ClusterMarkers_0_sub_65', 'ClusterMarkers_0_sub_66', 'ClusterMarkers_0_sub_67', 'ClusterMarkers_0_sub_68', 'ClusterMarkers_0_sub_69', 'ClusterMarkers_0_sub_7', 'ClusterMarkers_0_sub_70', 'ClusterMarkers_0_sub_71', 'ClusterMarkers_0_sub_72', 'ClusterMarkers_0_sub_8', 'ClusterMarkers_0_sub_9', 'ClusterMarkers_1', 'ClusterMarkers_2', 'ClusterMarkers_3', 'ClusterMarkers_4', 'ClusterMarkers_5', 'ClusterMarkers_6', 'ClusterMarkers_7', 'Regulons'; obsm: 'ClusterID'. This is from publicaly available data. so what i would like to do is plot their published tsne or umap and compare a few things from it. If I simply run sc.pl.tsne(loom_file, color=['louvain']) I get error msg: ValueError: no field of name X_tsne. This makes sense as there is not X_tsne on the object. How could I get pass this without re-clustering myself? At the moment I am only interested in pulling out 2 of their annotated clusters... if there is an easy way to do this via scanpy please let me know.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/933
https://github.com/scverse/scanpy/issues/933:2621,Usability,simpl,simply,2621,"_3', 'ClusterMarkers_0_sub_30', 'ClusterMarkers_0_sub_31', 'ClusterMarkers_0_sub_32', 'ClusterMarkers_0_sub_33', 'ClusterMarkers_0_sub_34', 'ClusterMarkers_0_sub_35', 'ClusterMarkers_0_sub_36', 'ClusterMarkers_0_sub_37', 'ClusterMarkers_0_sub_38', 'ClusterMarkers_0_sub_39', 'ClusterMarkers_0_sub_4', 'ClusterMarkers_0_sub_40', 'ClusterMarkers_0_sub_41', 'ClusterMarkers_0_sub_42', 'ClusterMarkers_0_sub_43', 'ClusterMarkers_0_sub_44', 'ClusterMarkers_0_sub_45', 'ClusterMarkers_0_sub_46', 'ClusterMarkers_0_sub_47', 'ClusterMarkers_0_sub_48', 'ClusterMarkers_0_sub_49', 'ClusterMarkers_0_sub_5', 'ClusterMarkers_0_sub_50', 'ClusterMarkers_0_sub_51', 'ClusterMarkers_0_sub_52', 'ClusterMarkers_0_sub_53', 'ClusterMarkers_0_sub_54', 'ClusterMarkers_0_sub_55', 'ClusterMarkers_0_sub_56', 'ClusterMarkers_0_sub_57', 'ClusterMarkers_0_sub_58', 'ClusterMarkers_0_sub_59', 'ClusterMarkers_0_sub_6', 'ClusterMarkers_0_sub_60', 'ClusterMarkers_0_sub_61', 'ClusterMarkers_0_sub_62', 'ClusterMarkers_0_sub_63', 'ClusterMarkers_0_sub_64', 'ClusterMarkers_0_sub_65', 'ClusterMarkers_0_sub_66', 'ClusterMarkers_0_sub_67', 'ClusterMarkers_0_sub_68', 'ClusterMarkers_0_sub_69', 'ClusterMarkers_0_sub_7', 'ClusterMarkers_0_sub_70', 'ClusterMarkers_0_sub_71', 'ClusterMarkers_0_sub_72', 'ClusterMarkers_0_sub_8', 'ClusterMarkers_0_sub_9', 'ClusterMarkers_1', 'ClusterMarkers_2', 'ClusterMarkers_3', 'ClusterMarkers_4', 'ClusterMarkers_5', 'ClusterMarkers_6', 'ClusterMarkers_7', 'Regulons'; obsm: 'ClusterID'. This is from publicaly available data. so what i would like to do is plot their published tsne or umap and compare a few things from it. If I simply run sc.pl.tsne(loom_file, color=['louvain']) I get error msg: ValueError: no field of name X_tsne. This makes sense as there is not X_tsne on the object. How could I get pass this without re-clustering myself? At the moment I am only interested in pulling out 2 of their annotated clusters... if there is an easy way to do this via scanpy please let me know.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/933
https://github.com/scverse/scanpy/issues/935:251,Modifiability,variab,variable,251,"I ran the newest Scanpy package's ; ```; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.05,; batch_key='batch'); ```. It indeed gave me information about highly_variable_nbatches etc. But all the genes were labelled as not variable ('False'). Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935
https://github.com/scverse/scanpy/issues/936:173,Availability,error,error,173,"This may be related to this issue:; https://github.com/theislab/scanpy/issues/918#issue-522668041. I was running:. `sc.tl.umap(bdata, init_pos='paga')`. But it gave me this error:. ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)); [2] During: typing of call at /usr/local/lib/python3.6/dist-packages/umap/umap_.py (795). File ""../../usr/local/lib/python3.6/dist-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936
https://github.com/scverse/scanpy/issues/936:223,Deployability,pipeline,pipeline,223,"This may be related to this issue:; https://github.com/theislab/scanpy/issues/918#issue-522668041. I was running:. `sc.tl.umap(bdata, init_pos='paga')`. But it gave me this error:. ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)); [2] During: typing of call at /usr/local/lib/python3.6/dist-packages/umap/umap_.py (795). File ""../../usr/local/lib/python3.6/dist-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936
https://github.com/scverse/scanpy/issues/936:476,Modifiability,parameteriz,parameterized,476,"This may be related to this issue:; https://github.com/theislab/scanpy/issues/918#issue-522668041. I was running:. `sc.tl.umap(bdata, init_pos='paga')`. But it gave me this error:. ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)); [2] During: typing of call at /usr/local/lib/python3.6/dist-packages/umap/umap_.py (795). File ""../../usr/local/lib/python3.6/dist-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936
https://github.com/scverse/scanpy/issues/937:492,Availability,error,error,492,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:684,Availability,error,error,684,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:1714,Availability,ERROR,ERROR,1714,"st numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:1747,Availability,Error,Error,1747,"ve already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:121,Deployability,install,install,121,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2187,Performance,cache,cache,2187,"raph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2351,Performance,cache,cache,2351,"raph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2357,Performance,cache,cache,2357,"raph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2565,Performance,cache,cache,2565,"]['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2914,Performance,load,load,2914,"input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key +",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:1299,Testability,test,test,1299," I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_colu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:1650,Testability,test,test,1650," some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:2727,Testability,log,logg,2727,"]['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:4649,Testability,log,logging,4649,"n read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 542 return key, value; 543 ; --> 544 key, value = postprocess_reading(key, value); 545 d[key_write] = value; 546 return. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in postprocess_reading(key, value); 539 new_dtype = [((dt[0], 'U{}'.format(int(int(dt[1][2:])/4))); 540 if dt[1][1] == 'S' else dt) for dt in value.dtype.descr]; --> 541 value = value.astype(new_dtype); 542 return key, value; 543 . ValueError: invalid shape in fixed-type tuple.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.3 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/937:4785,Usability,learn,learn,4785,"n read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 542 return key, value; 543 ; --> 544 key, value = postprocess_reading(key, value); 545 d[key_write] = value; 546 return. ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in postprocess_reading(key, value); 539 new_dtype = [((dt[0], 'U{}'.format(int(int(dt[1][2:])/4))); 540 if dt[1][1] == 'S' else dt) for dt in value.dtype.descr]; --> 541 value = value.astype(new_dtype); 542 return key, value; 543 . ValueError: invalid shape in fixed-type tuple.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.3 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937
https://github.com/scverse/scanpy/issues/938:711,Availability,error,error-prone,711,"We have a weird temporary global variable called `sc.pl._utils._tmp_cluster_pos`. We use it for storing the positions of cluster centroids (actually the centroids of any categorical variable for any sort of embedding). The weird part is that it's set in scatterplot functions (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L468 and https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L809) and used only by `sc.pl.paga_compare` (https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L119). First, it's not obvious where paga_compare finds centroids (it was a mystery to me until recently). Second, the current design is error-prone (see a corner case https://github.com/theislab/scanpy/issues/686). Therefore, there should be a better place to store cluster centroids :). I'm not following the discussion about the future of AnnData, but maybe having something like `adata.uns['obs_category_leiden']` and storing colors and centroids in it e.g. `adata.uns['obs_category_leiden']['colors']` and `adata.uns['obs_category_leiden']['centroids']['X_umap']` would be more structured.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/938
https://github.com/scverse/scanpy/issues/938:33,Modifiability,variab,variable,33,"We have a weird temporary global variable called `sc.pl._utils._tmp_cluster_pos`. We use it for storing the positions of cluster centroids (actually the centroids of any categorical variable for any sort of embedding). The weird part is that it's set in scatterplot functions (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L468 and https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L809) and used only by `sc.pl.paga_compare` (https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L119). First, it's not obvious where paga_compare finds centroids (it was a mystery to me until recently). Second, the current design is error-prone (see a corner case https://github.com/theislab/scanpy/issues/686). Therefore, there should be a better place to store cluster centroids :). I'm not following the discussion about the future of AnnData, but maybe having something like `adata.uns['obs_category_leiden']` and storing colors and centroids in it e.g. `adata.uns['obs_category_leiden']['colors']` and `adata.uns['obs_category_leiden']['centroids']['X_umap']` would be more structured.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/938
https://github.com/scverse/scanpy/issues/938:182,Modifiability,variab,variable,182,"We have a weird temporary global variable called `sc.pl._utils._tmp_cluster_pos`. We use it for storing the positions of cluster centroids (actually the centroids of any categorical variable for any sort of embedding). The weird part is that it's set in scatterplot functions (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L468 and https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L809) and used only by `sc.pl.paga_compare` (https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L119). First, it's not obvious where paga_compare finds centroids (it was a mystery to me until recently). Second, the current design is error-prone (see a corner case https://github.com/theislab/scanpy/issues/686). Therefore, there should be a better place to store cluster centroids :). I'm not following the discussion about the future of AnnData, but maybe having something like `adata.uns['obs_category_leiden']` and storing colors and centroids in it e.g. `adata.uns['obs_category_leiden']['colors']` and `adata.uns['obs_category_leiden']['centroids']['X_umap']` would be more structured.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/938
https://github.com/scverse/scanpy/pull/939:220,Deployability,release,release,220,We use Graph.node attributes (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L776) which are removed in networkx 2.X. More details here: https://networkx.github.io/documentation/stable/release/migration_guide_from_1.x_to_2.0.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/939
https://github.com/scverse/scanpy/pull/941:267,Availability,error,errors,267,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:756,Modifiability,variab,variable,756,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:655,Testability,benchmark,benchmark,655,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:560,Usability,learn,learn,560,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:573,Usability,learn,learn,573,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:617,Usability,learn,learn,617,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/pull/941:630,Usability,learn,learn,630,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941
https://github.com/scverse/scanpy/issues/942:389,Availability,Error,Error,389,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942
https://github.com/scverse/scanpy/issues/942:783,Testability,log,log,783,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942
https://github.com/scverse/scanpy/issues/942:1536,Testability,log,logging,1536,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942
https://github.com/scverse/scanpy/issues/942:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942
https://github.com/scverse/scanpy/issues/942:1662,Usability,learn,learn,1662,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942
https://github.com/scverse/scanpy/issues/944:764,Usability,learn,learn,764,"Especially when using `standard_scale = 'var'`, the scale values obscure each other if values are '0' and '1'. Is there a way to allow for off-center plotting of the scale values? Minimizing the font size helps somewhat but is far from ideal.; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.settings.set_figure_params(dpi=150); sc.pl.stacked_violin(adata, marker_genes, groupby='louvain', rotation = 90, standard_scale = 'var'; ...; ```; Output:; <img width=""734"" alt=""image"" src=""https://user-images.githubusercontent.com/36309128/70078263-5dd76700-15d0-11ea-8c6d-2d809f4a2f7c.png"">. #### Versions:; <scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.15.4 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/944
https://github.com/scverse/scanpy/issues/947:881,Integrability,wrap,wraps,881,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:1017,Modifiability,flexible,flexible,1017,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:1055,Modifiability,variab,variables,1055,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:291,Performance,cache,cache,291,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:502,Performance,cache,cache,502,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:695,Performance,cache,cached,695,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:821,Performance,Cache,Cache,821,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:1049,Performance,cache,cache,1049,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/947:1445,Performance,cache,cached,1445,"Hi all! I wanted to make you aware of a caching extension for scanpy and scvelo that @michalk8 and myself have developed called [scachepy](https://github.com/theislab/scachepy) and to kick off a discussion about caching in scanpy. From my point of view, there are currently two main ways to cache your results in scanpy, please correct me if I'm wrong:; - write the AnnData object; - manually write the attributes, e.g. adata.X to file, e.g. pickle. The idea of scachepy is to offer the possibility to cache all fields of an AnnData object associated with a certain function call, e.g. `sc.pp.pca`. It allows you to globally define a caching directory and a backend (default is pickle) that the cached objects will be written to. In the case of PCA, this would amount to calling. ```python; import scachepy; c = scachepy.Cache(<directory>) ; c.pp.pca(adata); ```; where `c.pp.pca` wraps around `sc.pp.pca` but takes additional caching arguments like `force`. So in short, our aim with scachepy is to....; - ...have a flexible and easy to use way to cache variables associated with scanpy/scvelo function calls.; - ... speed up individual steps in a scanpy/scvelo analysis by caching them, without having to save the entire AnnData object; - ... be able to share jupyter notebooks with someone else who can run them on a different machine, possibly on a different OS and yet get the exactly the same results because the critical computations are cached. @michalk8 is the main developer and will be able to tell you much more about it. I would appreciate any input, and would love to discuss caching in scanpy/scvelo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/947
https://github.com/scverse/scanpy/issues/948:322,Availability,error,error,322,"Hi,. I'm trying to follow the [Dahlin18 PAGA tutorial](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:1086,Availability,error,errors,1086,"b/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:2140,Availability,error,errors,2140,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:2331,Availability,error,error,2331,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:1130,Deployability,pipeline,pipeline,1130,"error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please rep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:1935,Deployability,release,release,1935,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:328,Integrability,message,message,328,"Hi,. I'm trying to follow the [Dahlin18 PAGA tutorial](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:2337,Integrability,message,message,2337,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/issues/948:1383,Modifiability,parameteriz,parameterized,1383,"error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please rep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948
https://github.com/scverse/scanpy/pull/951:172,Deployability,release,releases,172,- [x] reordered existing ones; - [ ] added new ones. With the new structure we don’t even need `:noteversion:` anymore and should just make the headers links to the GitHub releases.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/951
https://github.com/scverse/scanpy/issues/953:167,Availability,error,error,167,"<!-- Please give a clear and concise description of what the bug is: -->. Hi,; I run scanpy in Python 3.7, matplotlib=3.1.1 - `sc.pl.paga_path` gives me the following error(s). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.dpt(adata); sc.tl.paga(adata, groups='paul15_clusters'); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:529,Availability,Error,Error,529,"<!-- Please give a clear and concise description of what the bug is: -->. Hi,; I run scanpy in Python 3.7, matplotlib=3.1.1 - `sc.pl.paga_path` gives me the following error(s). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.dpt(adata); sc.tl.paga(adata, groups='paul15_clusters'); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:2982,Availability,error,error,2982,"da3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `adata.X` to sparse matrix format, I have the following error:; ```python; adata.X = sci.sparse.csr_matrix(adata.X); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-29-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:1756,Integrability,wrap,wrapper,1756,"ule>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:1953,Integrability,wrap,wrapper,1953,"ath(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:2037,Integrability,wrap,wrapper,2037,"left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `adata.X` to sparse matrix format, I have the following error:; ```python; adata.X = sci.sparse.csr_matrix(adata.X); sc.pl.paga_pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:2234,Integrability,wrap,wrapper,2234,"heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `adata.X` to sparse matrix format, I have the following error:; ```python; adata.X = sci.sparse.csr_matrix(adata.X); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. ```pytb; ---------------------------------------------------------------------------; Typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:4271,Integrability,wrap,wrapper,4271,"ule>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:4468,Integrability,wrap,wrapper,4468,"ath(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} cannot be converted to ""; --> 685 ""float"".format(self._A.dtype)); 686 ; 687 if not (self._A.ndim == 2. TypeError: Image data of dtype object cannot be conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:4552,Integrability,wrap,wrapper,4552,"left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} cannot be converted to ""; --> 685 ""float"".format(self._A.dtype)); 686 ; 687 if not (self._A.ndim == 2. TypeError: Image data of dtype object cannot be converted to float; ```; Plotting a heatmap with `sc.pl.heatmap` works. #### Versions:; <!-- Output of scanpy.logging.print_versions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:4749,Integrability,wrap,wrapper,4749,"heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} cannot be converted to ""; --> 685 ""float"".format(self._A.dtype)); 686 ; 687 if not (self._A.ndim == 2. TypeError: Image data of dtype object cannot be converted to float; ```; Plotting a heatmap with `sc.pl.heatmap` works. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.5.dev137+ge46f89b anndata==0.6.22.post2.dev73+g00b4b91 umap==0.3.8 numpy==1.17.3 scipy==1.2.1 pandas==0.25.2 scikit-learn==0.20.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:5549,Testability,log,logging,5549,"mg = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} cannot be converted to ""; --> 685 ""float"".format(self._A.dtype)); 686 ; 687 if not (self._A.ndim == 2. TypeError: Image data of dtype object cannot be converted to float; ```; Plotting a heatmap with `sc.pl.heatmap` works. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.5.dev137+ge46f89b anndata==0.6.22.post2.dev73+g00b4b91 umap==0.3.8 numpy==1.17.3 scipy==1.2.1 pandas==0.25.2 scikit-learn==0.20.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->. Hi,; I run scanpy in Python 3.7, matplotlib=3.1.1 - `sc.pl.paga_path` gives me the following error(s). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.dpt(adata); sc.tl.paga(adata, groups='paul15_clusters'); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/953:5712,Usability,learn,learn,5712,"mg = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 683 not np.can_cast(self._A.dtype, float, ""same_kind"")):; 684 raise TypeError(""Image data of dtype {} cannot be converted to ""; --> 685 ""float"".format(self._A.dtype)); 686 ; 687 if not (self._A.ndim == 2. TypeError: Image data of dtype object cannot be converted to float; ```; Plotting a heatmap with `sc.pl.heatmap` works. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.5.dev137+ge46f89b anndata==0.6.22.post2.dev73+g00b4b91 umap==0.3.8 numpy==1.17.3 scipy==1.2.1 pandas==0.25.2 scikit-learn==0.20.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953
https://github.com/scverse/scanpy/issues/954:510,Deployability,continuous,continuous,510,"<!-- What kind of feature would you like to request? -->; [x ] Additional function parameters / changed functionality / changed defaults?; <!-- Please describe your wishes below: -->; When we have discrete colors for clusters or samples, scatter plots (and therefore umap, tsne plots etc.) using a command like this `sc.pl.scatter(adata, color='sample', groups=['A'])` can help emphasize them by plotting only selected colors and all other cells in gray (see attached). This is very useful. But much like with continuous coloring, the order of colors matters. And particularly here, it would be most useful if all cells with selected colors are ""in front"" of all gray cells. Currently some colored selected cells are often invisible behind gray cells, like in the attached example.; [umap-example.pdf](https://github.com/theislab/scanpy/files/3965139/umap-example.pdf)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/954
https://github.com/scverse/scanpy/issues/955:1210,Testability,test,test,1210,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:1258,Testability,test,test,1258,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:1281,Testability,test,test,1281,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:1299,Testability,test,test,1299,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:1330,Testability,test,test,1330,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:582,Usability,simpl,simple,582,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/955:1626,Usability,simpl,simple,1626,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey @fidelram !. I just wrote something to create small multiples to plot cells in a clustering category. Pretty simple and very useful if you have too many clusters. What do you think of this:; ```; def cluster_small_multiples(adata, clust_key, size=60, frameon=False, legend_loc=None, **kwargs):; tmp = adata.copy(). for i,clust in enumerate(adata.obs[clust_key].cat.categories):; tmp.obs[clust] = adata.obs[clust_key].isin([clust]).astype('category'); tmp.uns[clust+'_colors'] = ['#d3d3d3', adata.uns[clust_key+'_colors'][i]]. sc.pl.umap(tmp, groups=tmp.obs[clust].cat.categories[1:].values, color=adata.obs[clust_key].cat.categories.tolist(), size=size, frameon=frameon, legend_loc=legend_loc, **kwargs); ```. Example output from:; ```; test = sc.datasets.pbmc68k_reduced(); sc.pp.pca(test); sc.pp.neighbors(test); sc.tl.umap(test); cluster_small_multiples(test, 'bulk_labels'); ```. ![umap_bulk_lab_sm](https://user-images.githubusercontent.com/13019956/70931843-a19e8780-2038-11ea-8549-2f7820636c41.png). Could generalize this to different bases via `sc.pl.scatter()`. Or is this already implemented somewhere that I'm not aware of? Or maybe it's too simple to have as a small helper function?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955
https://github.com/scverse/scanpy/issues/956:472,Energy Efficiency,reduce,reduce,472,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. To reduce the number of arguments that are passed to plotting functions and to agrupate them by type I was considering the following example syntax:; ```PYTHON; sc.pl.umap(adata, color='clusters').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1); ```; or . ```; sc.pl.dotplot(adata, ['gene1', 'gene2'], groupby='clusters'); .add_dendrogram(width=0.4,color='grey'); .swap_axes(); .dot_size_legend(title='fraction', location='left'); ```. Any comments? ; (I am not sure how to implement something like this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/956
https://github.com/scverse/scanpy/issues/956:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. To reduce the number of arguments that are passed to plotting functions and to agrupate them by type I was considering the following example syntax:; ```PYTHON; sc.pl.umap(adata, color='clusters').scatter_outline(width=0.1); .legend(loc='on data', outline=1); .add_edges(color='black', width=0.1); ```; or . ```; sc.pl.dotplot(adata, ['gene1', 'gene2'], groupby='clusters'); .add_dendrogram(width=0.4,color='grey'); .swap_axes(); .dot_size_legend(title='fraction', location='left'); ```. Any comments? ; (I am not sure how to implement something like this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/956
https://github.com/scverse/scanpy/pull/960:8,Deployability,release,release,8,"Prepare release 1.4.5 with docs, logging, default parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/960
https://github.com/scverse/scanpy/pull/960:33,Testability,log,logging,33,"Prepare release 1.4.5 with docs, logging, default parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/960
https://github.com/scverse/scanpy/issues/961:1341,Availability,avail,available,1341,"t); <ipython-input-13-a0665160cba0> in <module>; 1 import anndata; ----> 2 import scanpy as sc; 3 import igraph; 4 ; 5 C6665_new = anndata.AnnData(C6665_encoded). ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\__init__.py in <module>; 30 # the actual API; 31 from ._settings import settings, Verbosity # start with settings as several tools are using it; ---> 32 from . import tools as tl; 33 from . import preprocessing as pp; 34 from . import plotting as pl. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\__init__.py in <module>; 8 from ._rank_genes_groups import rank_genes_groups, filter_rank_genes_groups; 9 from ._dpt import dpt; ---> 10 from ._leiden import leiden; 11 from ._louvain import louvain; 12 from ._sim import sim. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\_leiden.py in <module>; 13 ; 14 try:; ---> 15 from leidenalg.VertexPartition import MutableVertexPartition; 16 except ImportError:; 17 class MutableVertexPartition: pass. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\__init__.py in <module>; 33 not immediately available in :func:`leidenalg.find_partition`.; 34 """"""; ---> 35 from .functions import ALL_COMMS; 36 from .functions import ALL_NEIGH_COMMS; 37 from .functions import RAND_COMM. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\functions.py in <module>; 21 return graph.__graph_as_cobject(); 22 ; ---> 23 from .VertexPartition import *; 24 from .Optimiser import *; 25 . ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\VertexPartition.py in <module>; 6 PY3 = (sys.version > '3'); 7 ; ----> 8 class MutableVertexPartition(_ig.VertexClustering):; 9 """""" Contains a partition of graph, derives from :class:`ig.VertexClustering`.; 10 . AttributeError: module 'igraph' has no attribute 'VertexClustering'`. ```; I might be wrong, but looks like Scanpy is directly calling igraph.vertexclustering, while vertex clustering is a module under clustering. Shouldn't it be referred as ig.clustering.vertexclustering?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961
https://github.com/scverse/scanpy/pull/963:230,Availability,error,error,230,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963
https://github.com/scverse/scanpy/pull/963:462,Availability,error,error,462,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963
https://github.com/scverse/scanpy/pull/963:585,Testability,log,logic,585,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963
https://github.com/scverse/scanpy/pull/963:648,Testability,test,test,648,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963
https://github.com/scverse/scanpy/issues/967:1073,Availability,error,error,1073,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:172,Testability,log,log-transformed,172,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:399,Testability,log,log-transformed,399,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:434,Testability,test,test,434,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:543,Testability,log,log-transform,543,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:1039,Testability,log,log,1039,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:1300,Testability,log,logging,1300,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:525,Usability,undo,undo,525,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:1136,Usability,guid,guide,1136,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/967:1436,Usability,learn,learn,1436,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967
https://github.com/scverse/scanpy/issues/969:387,Testability,log,log-transformed,387,"It appears that in the cell ranger code, the dispersion is calculated using the negative binomial relationship between mean and dispersion, see. https://github.com/10XGenomics/cellranger/blob/5f5a6293bbc067e1965e50f0277286914b96c908/lib/python/cellranger/analysis/stats.py#L44. Furthermore, these summary statistics are calculated on the count matrix normalized by library size, but not log-transformed. https://github.com/10XGenomics/cellranger/blob/5f5a6293bbc067e1965e50f0277286914b96c908/lib/python/cellranger/analysis/pca.py#L91-L95. As a follow-up, the ""Seurat"" flavor seems to be no longer used in Seurat. Any plans to implement their ""vst"" method?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/969
https://github.com/scverse/scanpy/issues/970:321,Testability,test,test,321,"Hi islab,. I was wondering if there is a way to get statistical significance for a given gene expression between 2 groups on a violin plot or make a calculation separately?. for example:; here is the expression of GZMB between 2 groups and O would like to see if the difference is statistical significant with a simple t-test. <img width=""164"" alt=""image"" src=""https://user-images.githubusercontent.com/29153026/71746338-7631e000-2e21-11ea-95db-0aef5fe6dba7.png"">. Thank you fore your help,; Shen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/970
https://github.com/scverse/scanpy/issues/970:312,Usability,simpl,simple,312,"Hi islab,. I was wondering if there is a way to get statistical significance for a given gene expression between 2 groups on a violin plot or make a calculation separately?. for example:; here is the expression of GZMB between 2 groups and O would like to see if the difference is statistical significant with a simple t-test. <img width=""164"" alt=""image"" src=""https://user-images.githubusercontent.com/29153026/71746338-7631e000-2e21-11ea-95db-0aef5fe6dba7.png"">. Thank you fore your help,; Shen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/970
https://github.com/scverse/scanpy/issues/973:2174,Testability,log,logging,2174," ~/miniconda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```; sce.pp.mnn_correct(*[scdata[scdata.obs['batch']==batch] for batch in batch_]); #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.4.5 anndata==0.7rc1 umap==0.3.7 numpy==1.18.0 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/973
https://github.com/scverse/scanpy/issues/973:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; IndexError Traceback (most recent call last); <ipython-input-22-408c81d5d845> in <module>; 1 t1 = time.time(); ----> 2 corrected = sce.pp.mnn_correct(scdata[scdata.obs['batch']==batch_[0]],scdata[scdata.obs['batch']==batch_[1]]); 3 t2 = time.time(); 4 print('Took '+str(timedelta(seconds=t2-t1))). ~/miniconda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. <!-- Put a minimal reproducible example that reproduces the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/973
https://github.com/scverse/scanpy/issues/973:2302,Usability,learn,learn,2302," ~/miniconda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```; sce.pp.mnn_correct(*[scdata[scdata.obs['batch']==batch] for batch in batch_]); #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.4.5 anndata==0.7rc1 umap==0.3.7 numpy==1.18.0 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/973
https://github.com/scverse/scanpy/issues/974:2250,Testability,log,logging,2250,"conda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; corrected = sce.pp.mnn_correct(*[scdata[scdata.obs['batch']==batch] for batch in batch_]); ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5 anndata==0.7rc1 umap==0.3.7 numpy==1.18.0 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/974
https://github.com/scverse/scanpy/issues/974:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ```pytb; -----------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-22-408c81d5d845> in <module>; 1 t1 = time.time(); ----> 2 corrected = sce.pp.mnn_correct(scdata[scdata.obs['batch']==batch_[0]],scdata[scdata.obs['batch']==batch_[1]]); 3 t2 = time.time(); 4 print('Took '+str(timedelta(seconds=t2-t1))). ~/miniconda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/974
https://github.com/scverse/scanpy/issues/974:2373,Usability,learn,learn,2373,"conda3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. ~/miniconda3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; corrected = sce.pp.mnn_correct(*[scdata[scdata.obs['batch']==batch] for batch in batch_]); ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5 anndata==0.7rc1 umap==0.3.7 numpy==1.18.0 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/974
https://github.com/scverse/scanpy/issues/977:306,Performance,cache,cache,306,"Hi all,. I am analysing some 10x samples generated in my lab and I noticed that there could be some problems with your `read_10x_mtx` function. So, I opened 4 times the `pbmc3k` dataset used in your tutorial by using the following lines of code:. `adata = sc.read_10x_mtx(sample, var_names='gene_symbols', cache=True)`; `adata.var_names_make_unique()`; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; `mito_genes = adata.var_names.str.startswith('MT-')`; `adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1`; `adata.obs['n_counts'] = adata.X.sum(axis=1).A1`. I generated the violin plots showing the `n_genes`, `n_counts`, and `percent_mito` for each test and they are different in each test (see attached picture). ![Tests](https://user-images.githubusercontent.com/38785099/72088802-d7b2ec80-3302-11ea-91cd-db9d95698c00.gif). Do you have any suggestions to solve this problem?. Thank you in advance,; Simone",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977
https://github.com/scverse/scanpy/issues/977:737,Testability,test,test,737,"Hi all,. I am analysing some 10x samples generated in my lab and I noticed that there could be some problems with your `read_10x_mtx` function. So, I opened 4 times the `pbmc3k` dataset used in your tutorial by using the following lines of code:. `adata = sc.read_10x_mtx(sample, var_names='gene_symbols', cache=True)`; `adata.var_names_make_unique()`; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; `mito_genes = adata.var_names.str.startswith('MT-')`; `adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1`; `adata.obs['n_counts'] = adata.X.sum(axis=1).A1`. I generated the violin plots showing the `n_genes`, `n_counts`, and `percent_mito` for each test and they are different in each test (see attached picture). ![Tests](https://user-images.githubusercontent.com/38785099/72088802-d7b2ec80-3302-11ea-91cd-db9d95698c00.gif). Do you have any suggestions to solve this problem?. Thank you in advance,; Simone",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977
https://github.com/scverse/scanpy/issues/977:773,Testability,test,test,773,"Hi all,. I am analysing some 10x samples generated in my lab and I noticed that there could be some problems with your `read_10x_mtx` function. So, I opened 4 times the `pbmc3k` dataset used in your tutorial by using the following lines of code:. `adata = sc.read_10x_mtx(sample, var_names='gene_symbols', cache=True)`; `adata.var_names_make_unique()`; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; `mito_genes = adata.var_names.str.startswith('MT-')`; `adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1`; `adata.obs['n_counts'] = adata.X.sum(axis=1).A1`. I generated the violin plots showing the `n_genes`, `n_counts`, and `percent_mito` for each test and they are different in each test (see attached picture). ![Tests](https://user-images.githubusercontent.com/38785099/72088802-d7b2ec80-3302-11ea-91cd-db9d95698c00.gif). Do you have any suggestions to solve this problem?. Thank you in advance,; Simone",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977
https://github.com/scverse/scanpy/issues/977:804,Testability,Test,Tests,804,"Hi all,. I am analysing some 10x samples generated in my lab and I noticed that there could be some problems with your `read_10x_mtx` function. So, I opened 4 times the `pbmc3k` dataset used in your tutorial by using the following lines of code:. `adata = sc.read_10x_mtx(sample, var_names='gene_symbols', cache=True)`; `adata.var_names_make_unique()`; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; `mito_genes = adata.var_names.str.startswith('MT-')`; `adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1`; `adata.obs['n_counts'] = adata.X.sum(axis=1).A1`. I generated the violin plots showing the `n_genes`, `n_counts`, and `percent_mito` for each test and they are different in each test (see attached picture). ![Tests](https://user-images.githubusercontent.com/38785099/72088802-d7b2ec80-3302-11ea-91cd-db9d95698c00.gif). Do you have any suggestions to solve this problem?. Thank you in advance,; Simone",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/977
https://github.com/scverse/scanpy/issues/978:61,Availability,error,error,61,"Hi, I was trying to use the most recent version but saw this error in 1.4.5 and above. ```; scanpy==1.4.5 anndata==0.7rc2 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0rc1 python-igraph==0.7.1; ```. ```; adata = sc.datasets.pbmc3k(); sc.pp.calculate_qc_metrics(adata, inplace=True); ```; output:; ```; ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-5-0d8cf2779f18> in <module>; 1 adata = sc.datasets.pbmc3k(); ----> 2 sc.pp.calculate_qc_metrics(adata, inplace=True). ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:1841,Availability,error,errors,1841,"lel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:3011,Availability,error,error,3011,"sue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:4918,Availability,error,errors,4918,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:5109,Availability,error,error,5109,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:5265,Availability,error,error,5265,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:2414,Deployability,pipeline,pipeline,2414," mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:2478,Deployability,pipeline,pipeline,2478," mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:4713,Deployability,release,release,4713,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:5115,Integrability,message,message,5115,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:2609,Modifiability,parameteriz,parameterized,2609," mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/978:184,Usability,learn,learn,184,"Hi, I was trying to use the most recent version but saw this error in 1.4.5 and above. ```; scanpy==1.4.5 anndata==0.7rc2 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0rc1 python-igraph==0.7.1; ```. ```; adata = sc.datasets.pbmc3k(); sc.pp.calculate_qc_metrics(adata, inplace=True); ```; output:; ```; ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-5-0d8cf2779f18> in <module>; 1 adata = sc.datasets.pbmc3k(); ----> 2 sc.pp.calculate_qc_metrics(adata, inplace=True). ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978
https://github.com/scverse/scanpy/issues/979:249,Modifiability,enhance,enhance,249,"In the scanpy documentation for sc.pl.dotplot, it indicates that it returns a list of matplotlib.axes.Axes. However, this is not true, it returns a gridspec object instead. I noticed this because I wanted to make some subtle edits to the results to enhance the figure such as changing axis labels, adding overlapping lines to delineate the marker genes for each cell type, etc. But I am struggling to do so. I am wondering how the API intends for us to interact with the gridspec object returned to modify the figure. If I edit the code to return the figure object as well as the gridspec, I can access the axis like so. ```; ax = fig.add_subplot(gs[1,0]); ```. but I can't seem to overwrite the default axis labels or add new lines as commands like; ```; ax.set_ylabel('new label'); ```. Don't change the figure at all. This is all Scanpy 1.4.5.post1 but it was the same for 1.4.4.post1. Thanks!. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.17.2 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. but the same things happened with scanpy==1.4.4.post1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979
https://github.com/scverse/scanpy/issues/979:596,Security,access,access,596,"In the scanpy documentation for sc.pl.dotplot, it indicates that it returns a list of matplotlib.axes.Axes. However, this is not true, it returns a gridspec object instead. I noticed this because I wanted to make some subtle edits to the results to enhance the figure such as changing axis labels, adding overlapping lines to delineate the marker genes for each cell type, etc. But I am struggling to do so. I am wondering how the API intends for us to interact with the gridspec object returned to modify the figure. If I edit the code to return the figure object as well as the gridspec, I can access the axis like so. ```; ax = fig.add_subplot(gs[1,0]); ```. but I can't seem to overwrite the default axis labels or add new lines as commands like; ```; ax.set_ylabel('new label'); ```. Don't change the figure at all. This is all Scanpy 1.4.5.post1 but it was the same for 1.4.4.post1. Thanks!. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.17.2 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. but the same things happened with scanpy==1.4.4.post1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979
https://github.com/scverse/scanpy/issues/979:936,Testability,log,logging,936,"In the scanpy documentation for sc.pl.dotplot, it indicates that it returns a list of matplotlib.axes.Axes. However, this is not true, it returns a gridspec object instead. I noticed this because I wanted to make some subtle edits to the results to enhance the figure such as changing axis labels, adding overlapping lines to delineate the marker genes for each cell type, etc. But I am struggling to do so. I am wondering how the API intends for us to interact with the gridspec object returned to modify the figure. If I edit the code to return the figure object as well as the gridspec, I can access the axis like so. ```; ax = fig.add_subplot(gs[1,0]); ```. but I can't seem to overwrite the default axis labels or add new lines as commands like; ```; ax.set_ylabel('new label'); ```. Don't change the figure at all. This is all Scanpy 1.4.5.post1 but it was the same for 1.4.4.post1. Thanks!. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.17.2 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. but the same things happened with scanpy==1.4.4.post1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979
https://github.com/scverse/scanpy/issues/979:1069,Usability,learn,learn,1069,"In the scanpy documentation for sc.pl.dotplot, it indicates that it returns a list of matplotlib.axes.Axes. However, this is not true, it returns a gridspec object instead. I noticed this because I wanted to make some subtle edits to the results to enhance the figure such as changing axis labels, adding overlapping lines to delineate the marker genes for each cell type, etc. But I am struggling to do so. I am wondering how the API intends for us to interact with the gridspec object returned to modify the figure. If I edit the code to return the figure object as well as the gridspec, I can access the axis like so. ```; ax = fig.add_subplot(gs[1,0]); ```. but I can't seem to overwrite the default axis labels or add new lines as commands like; ```; ax.set_ylabel('new label'); ```. Don't change the figure at all. This is all Scanpy 1.4.5.post1 but it was the same for 1.4.4.post1. Thanks!. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.17.2 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. but the same things happened with scanpy==1.4.4.post1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/979
https://github.com/scverse/scanpy/issues/984:569,Availability,avail,available,569,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When testing for differential genes among groups with `rank_genes_groups` function, two options are available for `reference`: `'rest'` or any other single group. It would be helpful to have the possibility to choose different groups as reference (`reference: Union[Literal['rest'], Iterable[str]] = 'rest'`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/984
https://github.com/scverse/scanpy/issues/984:474,Testability,test,testing,474,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When testing for differential genes among groups with `rank_genes_groups` function, two options are available for `reference`: `'rest'` or any other single group. It would be helpful to have the possibility to choose different groups as reference (`reference: Union[Literal['rest'], Iterable[str]] = 'rest'`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/984
https://github.com/scverse/scanpy/issues/984:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When testing for differential genes among groups with `rank_genes_groups` function, two options are available for `reference`: `'rest'` or any other single group. It would be helpful to have the possibility to choose different groups as reference (`reference: Union[Literal['rest'], Iterable[str]] = 'rest'`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/984
https://github.com/scverse/scanpy/issues/985:262,Deployability,integrat,integrated,262,"Hi. After I performed ingest, I need to concatenate the two datasets. But when followed the tutorial, used concatenated but this function doesn't;t concatenate the .obsm, therefore the UMAP coordinates are not merged. How did you manage to performed UMAP on the integrated/concatenated dataset?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/985
https://github.com/scverse/scanpy/issues/985:262,Integrability,integrat,integrated,262,"Hi. After I performed ingest, I need to concatenate the two datasets. But when followed the tutorial, used concatenated but this function doesn't;t concatenate the .obsm, therefore the UMAP coordinates are not merged. How did you manage to performed UMAP on the integrated/concatenated dataset?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/985
https://github.com/scverse/scanpy/issues/985:12,Performance,perform,performed,12,"Hi. After I performed ingest, I need to concatenate the two datasets. But when followed the tutorial, used concatenated but this function doesn't;t concatenate the .obsm, therefore the UMAP coordinates are not merged. How did you manage to performed UMAP on the integrated/concatenated dataset?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/985
https://github.com/scverse/scanpy/issues/985:240,Performance,perform,performed,240,"Hi. After I performed ingest, I need to concatenate the two datasets. But when followed the tutorial, used concatenated but this function doesn't;t concatenate the .obsm, therefore the UMAP coordinates are not merged. How did you manage to performed UMAP on the integrated/concatenated dataset?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/985
https://github.com/scverse/scanpy/issues/987:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Related to scanpy.pp.subsample, it would be useful to have a subsampling tool that subsamples based on the key of an observations grouping. E.g., if I have an observation key 'MyGroup' with possible values ['A', 'B'], and there are 10,000 cells of type 'A' and 2,000 cells of type 'B' and I want only max 5,000 cells of each type, then this function would subsample 5,000 cells of type 'A' but retain all 2,000 cells of type 'B'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987
https://github.com/scverse/scanpy/pull/988:53,Deployability,update,updated,53,Changeset:; * added new MAGIC parameter `knn_max`; * updated MAGIC default parameters to match KrishnaswamyLab/MAGIC; * added tests to check MAGIC implementation interacts with AnnData object correctly; * increased required version of `magic-impute` to 2.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988
https://github.com/scverse/scanpy/pull/988:126,Testability,test,tests,126,Changeset:; * added new MAGIC parameter `knn_max`; * updated MAGIC default parameters to match KrishnaswamyLab/MAGIC; * added tests to check MAGIC implementation interacts with AnnData object correctly; * increased required version of `magic-impute` to 2.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988
https://github.com/scverse/scanpy/pull/989:208,Testability,test,tested,208,Example of this kind of bug in https://github.com/theislab/anndata/issues/293. * Now `read_10x_mtx` does not set an integer name for obs_name/ var_name indices; * Additionally improved code re-use and things tested in 10x reading tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989
https://github.com/scverse/scanpy/pull/989:230,Testability,test,tests,230,Example of this kind of bug in https://github.com/theislab/anndata/issues/293. * Now `read_10x_mtx` does not set an integer name for obs_name/ var_name indices; * Additionally improved code re-use and things tested in 10x reading tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989
https://github.com/scverse/scanpy/issues/990:9,Deployability,install,install,9,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:453,Safety,abort,abort,453,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:904,Usability,learn,learn,904,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:943,Usability,learn,learn,943,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1602,Usability,learn,learn,1602,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1639,Usability,learn,learn,1639,"I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy ; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:; scanpy -> numba[version='>=0.41.0']; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package h5py conflicts for:; scanpy -> h5py!=2.10.0; Package networkx conflicts for:; scanpy -> networkx; Package scipy conflicts for:; scanpy -> scipy[version='<1.3|>=1.3']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package joblib conflicts for:; scanpy -> joblib; Package natsort conflicts for:; scanpy -> natsort; Package seaborn conflicts for:; scanpy -> seaborn; Package setuptools conflicts for:; scanpy -> setuptools; Package pytables conflicts for:; scanpy -> pytables; Package anndata conflicts for:; scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']; Package importlib-metadata conflicts for:; scanpy -> importlib-metadata; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; Package tqdm conflicts for:; scanpy -> tqdm; Package pandas conflicts for:; scanpy -> pandas[version='>=0.21']; Package umap-learn conflicts for:; scanpy -> umap-learn[version='>=0.3.0']; Package patsy conflicts for:; scanpy -> patsy; Package louvain conflicts for:; scanpy -> louvain; Package python conflicts for:; scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']; Package python-igraph conflicts for:; scanpy -> python-igraph; Package statsmodels conflicts for:; scanpy -> statsmodels[version='>=0.10.0rc2']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/993:96,Testability,test,tests,96,"I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python; import statsmodels.api as sm; def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):; norm_gene_vars = []; del_batch = False; if ""batch"" not in adata.obs_keys():; del_batch = True; adata.obs[""batch""] = np.zeros((adata.X.shape[0])); for b in np.unique(adata.obs[""batch""]):; var = adata[adata.obs[""batch""] == b].X.var(0); print(var.shape); mean = adata[adata.obs[""batch""] == b].X.mean(0); estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var); x = np.log10(mean); if use_lowess is True:; lowess = sm.nonparametric.lowess; # output is sorted by x; v = lowess(y, x, frac=0.15); estimat_var[np.argsort(x)] = v[:, 1]; else:; estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var); # as in seurat paper, clip max values; norm_values = np.clip(; norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)); ); norm_gene_var = norm_values.var(0); norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0); ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1); median_norm_gene_vars = np.median(norm_gene_vars, axis=0); median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(; ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0; ); df = pd.DataFrame(index=np.array(adata.var_names)); df[""highly_variable_n_batches""] = num_batches_high_var; df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars; df.sort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:212,Testability,log,log-transformed,212,"I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python; import statsmodels.api as sm; def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):; norm_gene_vars = []; del_batch = False; if ""batch"" not in adata.obs_keys():; del_batch = True; adata.obs[""batch""] = np.zeros((adata.X.shape[0])); for b in np.unique(adata.obs[""batch""]):; var = adata[adata.obs[""batch""] == b].X.var(0); print(var.shape); mean = adata[adata.obs[""batch""] == b].X.mean(0); estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var); x = np.log10(mean); if use_lowess is True:; lowess = sm.nonparametric.lowess; # output is sorted by x; v = lowess(y, x, frac=0.15); estimat_var[np.argsort(x)] = v[:, 1]; else:; estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var); # as in seurat paper, clip max values; norm_values = np.clip(; norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)); ); norm_gene_var = norm_values.var(0); norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0); ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1); median_norm_gene_vars = np.median(norm_gene_vars, axis=0); median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(; ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0; ); df = pd.DataFrame(index=np.array(adata.var_names)); df[""highly_variable_n_batches""] = num_batches_high_var; df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars; df.sort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/995:230,Deployability,install,installs,230,"This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```; >>> import scanpy; >>> scanpy.__version__; <Version('1.4.5.post2')>; >>> scanpy.datasets.pbmc68k_reduced(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced; return read(filename); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read; **kwargs,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read; return read_h5ad(filename, backed=backed); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad; constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad; f = h5py.File(filename, 'r'); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__; **kwds,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__; fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid; fid = h5f.open(name, flags, fapl=fapl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1792,Integrability,wrap,wrapper,1792,"This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```; >>> import scanpy; >>> scanpy.__version__; <Version('1.4.5.post2')>; >>> scanpy.datasets.pbmc68k_reduced(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced; return read(filename); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read; **kwargs,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read; return read_h5ad(filename, backed=backed); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad; constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad; f = h5py.File(filename, 'r'); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__; **kwds,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__; fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid; fid = h5f.open(name, flags, fapl=fapl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1863,Integrability,wrap,wrapper,1863,"This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```; >>> import scanpy; >>> scanpy.__version__; <Version('1.4.5.post2')>; >>> scanpy.datasets.pbmc68k_reduced(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced; return read(filename); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read; **kwargs,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read; return read_h5ad(filename, backed=backed); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad; constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad; f = h5py.File(filename, 'r'); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__; **kwds,; File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__; fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr); File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid; fid = h5f.open(name, flags, fapl=fapl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/996:768,Deployability,integrat,integrate,768,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:831,Deployability,integrat,integrating,831,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:743,Integrability,wrap,wrapping,743,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:768,Integrability,integrat,integrate,768,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:831,Integrability,integrat,integrating,831,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Hi!. We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves?. Thanks!. Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/pull/997:8,Deployability,install,install,8,To make install from source tarball work. Fixes #995. @falexwolf can you check if it works for you now?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/997
https://github.com/scverse/scanpy/issues/998:558,Usability,learn,learn,558,"In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; matplotlib==3.0.3; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/999:587,Availability,Error,Error,587,"<!-- Please give a clear and concise description of what the bug is: -->; I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; #what works:; marker_genes = ['NCAM1']; ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:; subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:781,Testability,log,logging,781,"<!-- Please give a clear and concise description of what the bug is: -->; I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; #what works:; marker_genes = ['NCAM1']; ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:; subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; #what works:; marker_genes = ['NCAM1']; ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:; subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/1000:525,Testability,assert,assert,525,"Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made; bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]; # This line triggers a copy being made:; sc.pl.umap(bcells); # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual.; # ""Initializing view as actual."", ImplicitModificationWarning,; assert not bcells.is_view; ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python; from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]; assert_equal(bcells, bcells_view, exact=True); ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:687,Testability,test,tests,687,"Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made; bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]; # This line triggers a copy being made:; sc.pl.umap(bcells); # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual.; # ""Initializing view as actual."", ImplicitModificationWarning,; assert not bcells.is_view; ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python; from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]; assert_equal(bcells, bcells_view, exact=True); ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1001:96,Availability,error,error,96,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:86,Deployability,install,installed,86,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:202,Deployability,install,installed,202,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:51,Testability,test,tests,51,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:112,Testability,test,tests,112,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/pull/1002:151,Deployability,release,release,151,"When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view; * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:97,Testability,test,tests,97,"When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view; * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:167,Testability,test,tests,167,"When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view; * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1004:40,Integrability,rout,routines,40,This. - moves all the external plotting routines to `scanpy/external/pl.py`; - adds one for harmony; - Fixes a plotting bug this triggered; - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:211,Testability,test,test,211,This. - moves all the external plotting routines to `scanpy/external/pl.py`; - adds one for harmony; - Fixes a plotting bug this triggered; - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1005:36,Deployability,install,install,36,"It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:85,Testability,test,tests,85,"It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1007:25,Testability,test,test,25,"Suggested changes to the test function, and harmony_timeseries",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1007
https://github.com/scverse/scanpy/issues/1009:340,Availability,down,downstream,340,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:123,Deployability,pipeline,pipeline,123,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2595,Modifiability,variab,variability,2595,"tion=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine; ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers; ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:; Mine; ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers; ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:616,Usability,learn,learn,616,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1010:283,Availability,Error,Error,283,"AxisError was encountered while executing the regress_out function following the pbmc3k tutorial ; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; regressing out ['n_counts', 'percent_mito']; sparse input is densified and may lead to high memory use; ---------------------------------------------------------------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2089,Integrability,wrap,wrap,2089,"------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2171,Integrability,wrap,wrap,2171,"------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2332,Testability,log,logging,2332,"------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2461,Usability,learn,learn,2461,"------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1011:108,Usability,learn,learn,108,"If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.neighbors(adata, metric='hellinger'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-5-e2c66b650fd3> in <module>; 2 ; 3 adata = sc.datasets.paul15(); ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 109 method=method, metric=metric, metric_kwds=metric_kwds,; --> 110 random_state=random_state,; 111 ); 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 686 # non-euclidean case and approx nearest neighbors; 687 if X.shape[0] < 4096:; --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds); 689 metric = 'precomputed'; 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds); 1550 raise ValueError(""Unknown metric %s. ""; 1551 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1552 ""callable"" % (metric, _VALID_METRICS)); 1553 ; 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/pull/1015:21,Testability,test,tests,21,- [x] leiden/louvain tests are fixed by 71fbae4 circumventing pandas-dev/pandas#31499; - [x] `test_read_10x[mtx_path1-h5_path1]` fixed by theislab/anndata#313; - [x] `test_plotting.test_clustermap` is caused by seaborn mwaskom/seaborn#1953,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015
https://github.com/scverse/scanpy/issues/1016:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1017:59,Availability,error,error,59,"sc.tl.louvain() works fine in pandas==0.25.3; but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017
https://github.com/scverse/scanpy/pull/1020:85,Deployability,update,update,85,"Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |; | ---- | -- |; | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/issues/1021:334,Availability,avail,available,334,"Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 104 if adata.isview: # we shouldn't need this here...; 105 adata._init_as_actual(adata.copy()); --> 106 neighbors = Neighbors(adata); 107 neighbors.compute_neighbors(; 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs); 527 self._number_connected_components = self._connected_components[0]; 528 if 'X_diffmap' in adata.obsm_keys():; --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata); 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata); 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata); 395 return np.r_[1, adata.uns['diffmap_evals']]; 396 else:; --> 397 return adata.uns['diffmap_evals']; 398 ; 399 . KeyError: 'diffmap_evals'; ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/pull/1022:475,Availability,Ping,Ping,475,"Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master); --------|--------------------------|--------------; `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs; 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/issues/1027:178,Availability,error,error,178,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:864,Availability,Error,Error,864,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:709,Deployability,install,install,709,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1233,Deployability,install,install,1233,"ata' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:950,Modifiability,Variab,Variable,950,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:74,Performance,Load,Loading,74,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1970,Testability,log,logging,1970,"ata' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2121,Usability,learn,learn,2121,"ata' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1028:75,Availability,error,error,75,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:172,Availability,error,error,172,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1624,Deployability,install,installed,1624,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1465,Security,hash,hashtable,1465,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/pull/1029:389,Security,access,accessor,389,"Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it.; Prior to this PR, the below ""works"":; ```python; sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'); ```; i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now; it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/issues/1030:465,Availability,error,error,465,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1154,Integrability,rout,routinely,1154,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1452,Safety,avoid,avoid,1452,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1785,Security,access,accessible,1785,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1032:133,Availability,down,downstream,133,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:785,Availability,error,error,785,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:822,Availability,Error,Error,822,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2630,Availability,error,error,2630,"rn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2948,Modifiability,variab,variable,2948,"tion/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3184,Modifiability,variab,variable,3184,"tion/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2109,Security,validat,validation,2109,"a_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3162,Testability,log,logg,3162,"tion/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3656,Testability,log,logging,3656,"tion/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3785,Usability,learn,learn,3785,"tion/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1033:304,Testability,log,log,304,"Came across this while investigating #1032. . ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k_processed(); sc.pp.highly_variable_genes(pbmc, inplace=False); ```. ```pytb; /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-36b7cb4d9c0f> in <module>; 1 import scanpy as sc; 2 pbmc = sc.datasets.pbmc3k_processed(); ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 347 ('highly_variable_intersection', np.bool_),; 348 ]); --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 615 ; 616 if dtype is not None:; --> 617 descr = sb.dtype(dtype); 618 _names = descr.names; 619 else:. TypeError: data type not understood; ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:325,Testability,log,log,325,"Came across this while investigating #1032. . ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k_processed(); sc.pp.highly_variable_genes(pbmc, inplace=False); ```. ```pytb; /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-36b7cb4d9c0f> in <module>; 1 import scanpy as sc; 2 pbmc = sc.datasets.pbmc3k_processed(); ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 347 ('highly_variable_intersection', np.bool_),; 348 ]); --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 615 ; 616 if dtype is not None:; --> 617 descr = sb.dtype(dtype); 618 _names = descr.names; 619 else:. TypeError: data type not understood; ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/pull/1034:0,Deployability,Update,Update,0,"Update:; * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview); * addressed #1027 by changing requirements; * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:147,Deployability,pipeline,pipelines,147,"Update:; * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview); * addressed #1027 by changing requirements; * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/issues/1035:363,Testability,test,test,363,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use ; sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False); sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. ; Thank you for helping me with this issue!. -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1036:70,Availability,error,errors,70,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:188,Availability,avail,available,188,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:35,Deployability,release,release,35,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:99,Testability,test,tests,99,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:1029,Testability,test,tests,1029," release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_initialisations' from 'umap.nndescen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/pull/1037:5,Deployability,update,update,5,Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1038:42,Deployability,release,release,42,This should fix the problems with the new release candidate of umap.; https://github.com/theislab/scanpy/issues/1036,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1038
https://github.com/scverse/scanpy/issues/1039:191,Availability,error,error,191,"<!-- Please give a clear and concise description of what the bug is: -->; When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:; ```; >>> sc.pl.umap(post_adata, color=['XKR4']); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap; return embedding(adata, 'umap', **kwargs); File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1398,Modifiability,variab,variable,1398,"plotting\_tools\scatterplots.py"", line 542, in umap; return embedding(adata, 'umap', **kwargs); File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'; var: 'gene_id'; uns: 'neighbors', 'louvain', 'louvain_colors'; obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']); ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. #### Versions:; scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:; ```; >>> sc.pl.umap(post_adata, color=['XKR4']); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap; return embedding(adata, 'umap', **kwargs); File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2402,Usability,learn,learn,2402,"\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'; var: 'gene_id'; uns: 'neighbors', 'louvain', 'louvain_colors'; obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']); ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. #### Versions:; scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/pull/1042:61,Deployability,release,release,61,"@falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself?. - major version (x.0) bumps for vast breaking changes; - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes; - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:168,Deployability,release,release,168,"@falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself?. - major version (x.0) bumps for vast breaking changes; - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes; - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:390,Deployability,patch,patch,390,"@falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself?. - major version (x.0) bumps for vast breaking changes; - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes; - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/issues/1043:1014,Availability,Error,Error,1014,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1134,Availability,error,error,1134,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:418,Testability,Assert,AssertionError,418,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1100,Testability,Assert,AssertionError,1100,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:457,Usability,simpl,simply,457,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:696,Usability,simpl,simple,696,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:741,Usability,simpl,simply,741,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1274,Usability,learn,learn,1274,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1051:385,Availability,Error,Error,385,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1275,Testability,log,logging,1275,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1432,Usability,learn,learn,1432,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1053:577,Availability,avail,available,577,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:125,Deployability,release,release,125,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:206,Integrability,depend,depend,206,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:351,Usability,simpl,simpler,351,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1057:310,Availability,avail,available,310,"<details>; <summary> Traceback from readthedocs: </summary>. ```pytb; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:634,Availability,error,errors,634,"<details>; <summary> Traceback from readthedocs: </summary>. ```pytb; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:687,Availability,error,errors,687,"<details>; <summary> Traceback from readthedocs: </summary>. ```pytb; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3072,Availability,error,errors,3072,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3330,Availability,error,error,3330,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3055,Integrability,message,message,3055,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2125,Testability,log,logging,2125,"(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2188,Testability,log,logger,2188,".6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2315,Testability,log,logging,2315,"home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomSt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2350,Testability,log,logger,2350,"/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2426,Testability,log,logging,2426," line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2550,Testability,log,logging,2550,"uilds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2674,Testability,log,logging,2674,"l(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2796,Testability,log,logging,2796,"ages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2984,Testability,log,logging,2984,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1059:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True); sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']); sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```; ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1061:74,Availability,error,error,74,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:437,Safety,avoid,avoid,437,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:31,Testability,test,tested,31,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:749,Testability,test,tested,749,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/pull/1062:1443,Availability,error,error,1443,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1504,Availability,error,error,1504,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:22,Safety,avoid,avoid,22,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:174,Testability,log,log,174,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1066:145,Deployability,integrat,integrate,145,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1251,Deployability,integrat,integrate,1251,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:145,Integrability,integrat,integrate,145,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1251,Integrability,integrat,integrate,1251,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:511,Performance,perform,performs,511,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:563,Performance,perform,performing,563,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:551,Testability,benchmark,benchmarks,551,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1049,Testability,benchmark,benchmarks,1049,"I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/issues/1067:1481,Availability,error,errors,1481,"54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2643,Availability,down,downgrading,2643,"e, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Union etc. are not valid as type arguments; 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.; ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:20,Deployability,install,installed,20,"Hi all,. I recently installed the newest version of scanpy:; ```; scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1; ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb; TypeError Traceback (most recent call last); <ipython-input-54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:162,Usability,learn,learn,162,"Hi all,. I recently installed the newest version of scanpy:; ```; scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1; ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb; TypeError Traceback (most recent call last); <ipython-input-54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/pull/1069:240,Testability,test,test,240,"Fixes issue #979 . Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set `show=False`:. ```; fig,ax = sc.pl.dotplot(adata,var_names,show=False); ax.set_xlabel('test'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069
https://github.com/scverse/scanpy/issues/1072:162,Deployability,integrat,integration,162,"Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, ; Romain; <!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:162,Integrability,integrat,integration,162,"Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, ; Romain; <!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/pull/1073:89,Integrability,depend,depends,89,"This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329; I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/issues/1074:712,Testability,log,logging,712,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using; ```; adata = sc.read_loom(""seu.loom""); ```; I get the following:; ```; /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal; nonzeros = np.where(vals != 0); ```; I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using; ```; adata = sc.read_loom(""seu.loom""); ```; I get the following:; ```; /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal; nonzeros = np.where(vals != 0); ```; I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:847,Usability,learn,learn,847,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using; ```; adata = sc.read_loom(""seu.loom""); ```; I get the following:; ```; /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal; nonzeros = np.where(vals != 0); ```; I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1077:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/pull/1080:3,Deployability,update,updated,3,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:15,Deployability,release,release,15,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:225,Deployability,update,updates,225,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:366,Deployability,update,updated,366,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:135,Safety,detect,detection,135,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:298,Testability,test,testing,298,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:326,Testability,test,tests,326,"An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/issues/1082:65,Availability,error,error,65,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:135,Availability,error,error,135,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:273,Availability,Error,Error,273,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:688,Availability,down,downloaded,688,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:431,Security,access,accession,431,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1083:721,Availability,Error,Error,721,"<!-- Please give a clear and concise description of what the bug is: -->; I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_cells(adata, min_counts=300); sc.pp.filter_genes(adata, min_counts=1); sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'); sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'); sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells; print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; True; False; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24.; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:864,Testability,log,logging,864,"<!-- Please give a clear and concise description of what the bug is: -->; I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_cells(adata, min_counts=300); sc.pp.filter_genes(adata, min_counts=1); sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'); sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'); sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells; print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; True; False; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24.; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_cells(adata, min_counts=300); sc.pp.filter_genes(adata, min_counts=1); sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'); sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'); sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells; print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; True; False; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24.; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/pull/1085:210,Usability,learn,learned,210,"Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/issues/1086:18,Testability,test,test,18,"Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? ; e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/pull/1087:147,Availability,error,error,147,"Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:75,Testability,test,test,75,"Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1088:0,Availability,Ping,Ping,0,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:580,Deployability,pipeline,pipelines,580,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:523,Testability,test,test,523,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/issues/1089:141,Performance,perform,perform,141,"We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data?. Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:691,Security,access,access,691,"We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data?. Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/pull/1090:842,Availability,down,down,842,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:80,Deployability,update,update,80,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:201,Deployability,update,update,201,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:52,Testability,test,tests,52,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1091:0,Deployability,Update,Update,0,Update to `sce.external.tl._harmony_timeseries.py`.; Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/issues/1092:452,Availability,error,error,452,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:84,Deployability,integrat,integrate,84,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:965,Deployability,install,installing,965,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:84,Integrability,integrat,integrate,84,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:869,Usability,learn,learn,869,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1094:99,Availability,error,error,99,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:177,Availability,error,error,177,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1054,Availability,Error,Error,1054,"r: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:751,Testability,log,logging,751,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3293,Testability,log,logging,3293,"r, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2536,Usability,simpl,simplefilter,2536,"r, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3415,Usability,learn,learn,3415,"r, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1095:199,Availability,error,error,199,"Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):; File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>; sc.pl.umap(adata); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap; return embedding(adata, 'umap', **kwargs); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding; data_points, components_list = _get_data_points(adata, basis, projection, components); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points; f""Could not find entry in `obsm` for '{basis}'.\n""; KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata; Out[34]: ; AnnData object with n_obs × n_vars = 1858 × 366 ; obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'; var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; uns: 'log1p', 'pca', 'neighbors', 'leiden'; obsm: 'X_pca'; varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:65,Deployability,pipeline,pipeline,65,"Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):; File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>; sc.pl.umap(adata); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap; return embedding(adata, 'umap', **kwargs); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding; data_points, components_list = _get_data_points(adata, basis, projection, components); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points; f""Could not find entry in `obsm` for '{basis}'.\n""; KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata; Out[34]: ; AnnData object with n_obs × n_vars = 1858 × 366 ; obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'; var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; uns: 'log1p', 'pca', 'neighbors', 'leiden'; obsm: 'X_pca'; varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1096:0,Availability,Down,Downstream,0,"Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python; import scanpy as sc; from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000); adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) ; sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/pull/1102:20,Availability,down,downloading,20,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:252,Availability,down,downloaded,252,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:175,Security,access,accessing,175,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:331,Testability,test,tested,331,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:385,Testability,test,testing,385,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/issues/1103:1000,Testability,log,logging,1000,"<!-- Please give a clear and concise description of what the bug is: -->; Hey!; The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">; <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hey!; The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">; <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1124,Usability,learn,learn,1124,"<!-- Please give a clear and concise description of what the bug is: -->; Hey!; The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">; <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1104:145,Availability,error,error,145,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:346,Availability,Error,Error,346,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:808,Availability,error,error,808,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:875,Availability,ERROR,ERROR,875,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:890,Availability,error,errored,890,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:267,Deployability,install,install,267,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:956,Testability,log,logs,956,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/pull/1105:361,Availability,Recover,Recover,361,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:321,Deployability,pipeline,pipelines,321,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:1143,Modifiability,variab,variable,1143,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:361,Safety,Recover,Recover,361,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/issues/1107:653,Deployability,integrat,integrative,653,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:653,Integrability,integrat,integrative,653,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:719,Modifiability,layers,layers,719,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:787,Modifiability,layers,layers,787,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1088,Modifiability,config,configurable,1088,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1146,Modifiability,enhance,enhancement,1146,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:623,Performance,perform,perform,623,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:842,Performance,perform,perform,842,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:934,Testability,test,tested,934,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. ; We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1108:404,Availability,error,error,404,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:223,Deployability,integrat,integration,223,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:223,Integrability,integrat,integration,223,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:197,Performance,perform,performing,197,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/pull/1109:194,Availability,error,errors,194,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:774,Modifiability,layers,layers,774,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:189,Testability,test,test,189,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:680,Testability,assert,assert,680,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:911,Testability,assert,assert,911,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:44,Usability,simpl,simplification,44,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1110:7,Modifiability,config,configurable,7,"It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`.; As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1110
https://github.com/scverse/scanpy/pull/1111:7,Modifiability,config,configurable,7,"It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`.; As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111
https://github.com/scverse/scanpy/pull/1113:210,Performance,cache,caches,210,"https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. I’ll set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches …",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/issues/1114:139,Availability,error,errors,139,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:234,Availability,error,errors,234,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:789,Availability,error,error,789,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:877,Availability,Error,Error,877,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1968,Availability,error,error,1968,"----------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 3114 else:; 3115 # set column; -> 3116 self._set_item(key, value); 3117 ; 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 3188 """"""; 3189 ; -> 3190 self._ensure_valid_index(value); 3191 value = self._sanitize_column(key, value); 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:82,Deployability,update,update,82,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3330,Testability,log,logging,3330,"1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 3114 else:; 3115 # set column; -> 3116 self._set_item(key, value); 3117 ; 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 3188 """"""; 3189 ; -> 3190 self._ensure_valid_index(value); 3191 value = self._sanitize_column(key, value); 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3170 value = Series(value); 3171 except:; -> 3172 raise ValueError('Cannot set a frame with no defined index '; 3173 'and a value that cannot be converted to a '; 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1; scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3455,Usability,learn,learn,3455,"1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 3114 else:; 3115 # set column; -> 3116 self._set_item(key, value); 3117 ; 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 3188 """"""; 3189 ; -> 3190 self._ensure_valid_index(value); 3191 value = self._sanitize_column(key, value); 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3170 value = Series(value); 3171 except:; -> 3172 raise ValueError('Cannot set a frame with no defined index '; 3173 'and a value that cannot be converted to a '; 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1; scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/pull/1117:70,Integrability,depend,dependency,70,"This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.); * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1118:157,Testability,test,test,157,"It is now possible to have several neighbors graphs in adata. For example,. ```py; sc.pp.neighbors(adata); sc.pp.neighbors(adata, use_rep='some', key_added='test'); sc.pp.neighbors(adata, use_rep='some1', key_added='test1'); sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'); sc.tl.diffmap(adata, neighbors_key='test1'); ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/pull/1118:301,Testability,test,test,301,"It is now possible to have several neighbors graphs in adata. For example,. ```py; sc.pp.neighbors(adata); sc.pp.neighbors(adata, use_rep='some', key_added='test'); sc.pp.neighbors(adata, use_rep='some1', key_added='test1'); sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'); sc.tl.diffmap(adata, neighbors_key='test1'); ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/issues/1121:721,Availability,error,error,721,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:822,Availability,error,error,822,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:882,Deployability,install,installing,882,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:282,Integrability,depend,dependency,282,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:979,Integrability,depend,dependecies,979,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:508,Performance,perform,performing,508,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:677,Performance,load,load,677,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:193,Usability,learn,learn,193,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:238,Usability,learn,learn,238,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:251,Usability,learn,learn,251,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:900,Usability,learn,learn,900,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:966,Usability,learn,learn,966,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1122:58,Availability,error,error,58,"Hi all!; I want to use ingest after BBKNN but it gives an error related to the metric.; If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/pull/1123:264,Performance,perform,performance,264,"Hi everyone,; at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25.; This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers.; I've tested the performance; ```python; foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}; sc.pl.paga(adata, color=foo, colorbar=False); ```; ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,; ~4s, but I consider that the worst-case scenario.; More importantly, current version doesn't produce a correct plot, see below:; ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:536,Performance,Perform,Performancewise,536,"Hi everyone,; at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25.; This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers.; I've tested the performance; ```python; foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}; sc.pl.paga(adata, color=foo, colorbar=False); ```; ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,; ~4s, but I consider that the worst-case scenario.; More importantly, current version doesn't produce a correct plot, see below:; ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:253,Testability,test,tested,253,"Hi everyone,; at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25.; This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers.; I've tested the performance; ```python; foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}; sc.pl.paga(adata, color=foo, colorbar=False); ```; ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,; ~4s, but I consider that the worst-case scenario.; More importantly, current version doesn't produce a correct plot, see below:; ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/issues/1125:341,Availability,Error,Error,341,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:600,Availability,error,error,600,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:827,Availability,Error,Error,827,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:264,Deployability,release,release,264,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:347,Integrability,message,message,347,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:606,Integrability,message,message,606,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1308,Testability,log,logg,1308,"clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1804,Testability,log,logging,1804,"clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1950,Usability,learn,learn,1950,"clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/pull/1127:719,Deployability,update,update,719,"This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:; * Colorbar and dot size legends had been improved. Now is also possible to set a title for them.; * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted.; * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter.; * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted.; * `swap_axes` has been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1793,Deployability,Update,Update,1793,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2626,Deployability,Update,Update,2626,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2651,Deployability,Update,Update,2651,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2671,Deployability,Update,Update,2671,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2398,Energy Efficiency,Adapt,Adapt,2398,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2442,Energy Efficiency,Adapt,Adapt,2442,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2479,Energy Efficiency,Adapt,Adapt,2479,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2398,Modifiability,Adapt,Adapt,2398,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2442,Modifiability,Adapt,Adapt,2442,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2479,Modifiability,Adapt,Adapt,2479,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:758,Safety,avoid,avoid,758,"This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:; * Colorbar and dot size legends had been improved. Now is also possible to set a title for them.; * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted.; * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter.; * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted.; * `swap_axes` has been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1601,Testability,log,logfoldchange,1601,"re and in general any parameter from `sc.rank_genes_groups` can be plotted.; * `swap_axes` has been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2150,Testability,log,log,2150,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2658,Testability,test,tests,2658,"been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1713,Usability,feedback,feedback,1713," `swap_axes` has been added.; * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:; * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting.; * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved.; * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**; The following is now possible (notice the method chaining):. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}; sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \; .add_totals(sort='descending', size=1.2) \; .legend(color_title='log(UMI count+1)', width=1.6)\; .style(color_map='RdBu_r', dot_min=0.3)\; .show(); ```; ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:; - [x] Remove small secondary ticks; - [x] Adapt matrixplot to new object model; - [ ] Adapt heatmap to object model; - [x] Adapt stackedviolin to object model; - [ ] Incorporate modifications from #1116 ; - [x] Fix call from rank_genes_groups; - [x] 'black' code; - [x] Update docstrings; - [ ] Update tests; - [ ] Update tutoria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/issues/1128:40,Deployability,integrat,integrate,40,"Hi all,. I am trying to use `ingest` to integrate different datasets.; I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance.; Best,; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:40,Integrability,integrat,integrate,40,"Hi all,. I am trying to use `ingest` to integrate different datasets.; I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance.; Best,; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/pull/1130:2311,Availability,down,download,2311,"1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2442,Availability,down,download,2442,"et, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:86,Deployability,install,installed,86,"Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. ; The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python; import scanpy as sc; sc.datasets.moignard15(); ```. Output: ; ```; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 97 else: # No total? Show info style bar with no progress tqdm status; ---> 98 pbar = IProgress(min=0, max=1); 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-5-ec5b1e8cd660> in <module>; ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(); 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'; 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'; --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url); 111 # filter out 4 genes as in Haghverdi et al. (2016); 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3269,Deployability,update,update,3269,"url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3403,Deployability,update,update,3403,"url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:167,Integrability,depend,dependency,167,"Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. ; The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python; import scanpy as sc; sc.datasets.moignard15(); ```. Output: ; ```; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 97 else: # No total? Show info style bar with no progress tqdm status; ---> 98 pbar = IProgress(min=0, max=1); 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-5-ec5b1e8cd660> in <module>; ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(); 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'; 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'; --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url); 111 # filter out 4 genes as in Haghverdi et al. (2016); 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1509,Performance,cache,cache,1509," = IProgress(min=0, max=1); 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-5-ec5b1e8cd660> in <module>; ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(); 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'; 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'; --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url); 111 # filter out 4 genes as in Haghverdi et al. (2016); 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1914,Performance,cache,cache,1914,"108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'; 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'; --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url); 111 # filter out 4 genes as in Haghverdi et al. (2016); 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:10,Usability,progress bar,progress bar,10,"Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. ; The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python; import scanpy as sc; sc.datasets.moignard15(); ```. Output: ; ```; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 97 else: # No total? Show info style bar with no progress tqdm status; ---> 98 pbar = IProgress(min=0, max=1); 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-5-ec5b1e8cd660> in <module>; ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(); 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'; 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'; --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url); 111 # filter out 4 genes as in Haghverdi et al. (2016); 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filena",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/issues/1131:365,Availability,error,error,365,"```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); pbmc.write(""tmp.h5ad'); ```. ```pytb; NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>; <summary> Full traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 187 try:; --> 188 return func(elem, key, val, *args, **kwargs); 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs); 144 raise NotImplementedError(; --> 145 f""Failed to write value for {key}, ""; 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5342,Availability,error,error,5342,"pe({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 193 f""Above error raised while writing key {key!r} of {type(elem)}""; 194 f"" from {parent}.""; --> 195 ) from e; 196 ; 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5651,Availability,error,error,5651,"pe({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 193 f""Above error raised while writing key {key!r} of {type(elem)}""; 194 f"" from {parent}.""; --> 195 ) from e; 196 ; 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2408,Integrability,wrap,wrapper,2408," (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs); 113 if adata.isbacked:; 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3220,Integrability,wrap,wrapper,3220,"ed:; 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4032,Integrability,wrap,wrapper,4032,"taset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4844,Integrability,wrap,wrapper,4844,"pe({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 193 f""Above error raised while writing key {key!r} of {type(elem)}""; 194 f"" from {parent}.""; --> 195 ) from e; 196 ; 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2111,Modifiability,layers,layers,2111," for {key}, ""; 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs); 113 if adata.isbacked:; 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2126,Modifiability,layers,layers,2126,"nted yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs); 113 if adata.isbacked:; 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1133:111,Performance,perform,performs,111,"Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path?. 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input?. Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:465,Performance,perform,perform,465,"Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path?. 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input?. Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/pull/1135:193,Usability,simpl,simplify,193,"This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/issues/1136:207,Availability,Error,Error,207,"<!-- Please give a clear and concise description of what the bug is: -->; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:341,Testability,log,logging,341,"<!-- Please give a clear and concise description of what the bug is: -->; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/pull/1137:37,Testability,test,tests,37,Fix uns structure in read visium and tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1137
https://github.com/scverse/scanpy/issues/1139:561,Availability,error,error,561,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; ...; It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1141:569,Usability,guid,guidance,569,"Hi,; I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##; `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`; ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png); `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`; `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`; ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##; `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`; ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png); `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`; `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`; ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,; Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1840,Usability,learn,learn,1840,"Hi,; I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##; `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`; ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png); `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`; `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`; ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##; `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`; ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png); `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`; `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`; ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,; Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1142:960,Availability,error,error,960,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1660,Availability,error,error,1660,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:201,Deployability,install,install,201,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:904,Deployability,install,installed,904,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1820,Deployability,install,installed,1820,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1957,Deployability,install,installed,1957,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:357,Modifiability,flexible,flexible,357,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:603,Modifiability,flexible,flexible,603,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1164,Modifiability,flexible,flexible,1164,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1410,Modifiability,flexible,flexible,1410,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:744,Safety,abort,abort,744,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1551,Safety,abort,abort,1551,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1143:293,Availability,error,error,293,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1128,Availability,Error,Error,1128,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:310,Testability,Assert,AssertionError,310,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1243,Testability,log,logging,1243,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1144:262,Availability,error,error,262,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:403,Availability,error,error,403,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:538,Availability,error,error,538,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:577,Availability,error,error,577,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1147:238,Availability,error,error,238,"<!-- Please give a clear and concise description of what the bug is: -->; (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:449,Availability,down,down,449,"<!-- Please give a clear and concise description of what the bug is: -->; (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:974,Availability,Error,Error,974,"vice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1221,Availability,error,errors,1221,"vice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4911,Availability,error,error,4911,"k(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(pe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5049,Availability,error,error,5049,"e, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5074,Availability,error,error,5074,"e, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6803,Availability,error,errors,6803,"s, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7327,Availability,error,errors,7327,"se:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7793,Availability,error,errors,7793,"tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8087,Availability,error,error,8087,", **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9140,Availability,avail,available,9140,"de is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12521,Availability,error,errors,12521,"orLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self); 271 bb = self.blkmap[offset]; 272 self.builder.position_at_end(bb); --> 273 self.lower_block(block); 274 ; 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13071,Availability,error,error,13071,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13096,Availability,error,error,13096,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2353,Deployability,pipeline,pipeline,2353," try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1168 flags,; -> 1169 locals); 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 615 lifted_from=lifted_from); 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 340 FixupArgs().run_pass(self.state); --> 341 return self._compile_ir(); 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self); 399 assert self.state.func_ir is not None; --> 400 return self._compile_core(); 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 372 if is_final_pipeline:; --> 373 raise e; 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4144,Deployability,pipeline,pipeline,4144,"; 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4993,Deployability,pipeline,pipeline,4993,"e, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8343,Deployability,pipeline,pipeline,8343,"rg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8455,Deployability,pipeline,pipeline,8455,"rg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9150,Deployability,pipeline,pipelines,9150,"de is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10862,Deployability,pipeline,pipeline,10862,"Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 300 mutated |= check(pss.run_initialization, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:; 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 273 ; 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):; 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 405 ; 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']; 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 347 lower = lowering.Lower(targetctx, library, fndesc, interp,; 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:; 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 193 if self.generator_info is None:; 194 self.genlower = None; --> 195 self.lower_normal_function(self.fndesc); 196 else:; 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12951,Deployability,pipeline,pipeline,12951,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13015,Deployability,pipeline,pipeline,13015,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14299,Deployability,install,installing,14299,"om numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399); ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14365,Deployability,install,installing,14365,"om numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399); ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6502,Modifiability,config,config,6502,", percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12598,Modifiability,config,config,12598,"ower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self); 271 bb = self.blkmap[offset]; 272 self.builder.position_at_end(bb); --> 273 self.lower_block(block); 274 ; 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtrac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12636,Modifiability,config,config,12636,"lues; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self); 271 bb = self.blkmap[offset]; 272 self.builder.position_at_end(bb); --> 273 self.lower_block(block); 274 ; 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2698,Testability,assert,assert,2698,"ba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1168 flags,; -> 1169 locals); 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 615 lifted_from=lifted_from); 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 340 FixupArgs().run_pass(self.state); --> 341 return self._compile_ir(); 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self); 399 assert self.state.func_ir is not None; --> 400 return self._compile_core(); 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 372 if is_final_pipeline:; --> 373 raise e; 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8839,Testability,assert,assert,8839,"elf._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14427,Testability,log,logging,14427,"om numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399); ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3698,Usability,Simpl,SimpleTimer,3698," assert self.state.func_ir is not None; --> 400 return self._compile_core(); 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 372 if is_final_pipeline:; --> 373 raise e; 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3792,Usability,Simpl,SimpleTimer,3792,"3\lib\site-packages\numba\compiler.py in _compile_core(self); 372 if is_final_pipeline:; --> 373 raise e; 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\ll",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10277,Usability,Simpl,SimpleTimer,10277,"un(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 300 mutated |= check(pss.run_initialization, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:; 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 273 ; 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):; 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 405 ; 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']; 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 347 lower = lowering.Lower(targetctx, library, fndesc, interp,; 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:; 351 lower.create_cpython_wrapper(flags.release_gi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10371,Usability,Simpl,SimpleTimer,10371,"ompiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state); 300 mutated |= check(pss.run_initialization, internal_state); 301 with SimpleTimer() as pass_time:; --> 302 mutated |= check(pss.run_pass, internal_state); 303 with SimpleTimer() as finalize_time:; 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state); 273 ; 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):; 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 405 ; 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']; 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 347 lower = lowering.Lower(targetctx, library, fndesc, interp,; 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:; 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 193 if self.generator_info is N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14549,Usability,learn,learn,14549,"om numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399); ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1148:516,Usability,learn,learn,516,"sc.pl.spatial plots vertically flipped spots when `sc.pl.spatial(..., img_key=None)`. Try comparing these in your lymph node demo notebook.; ```python; # Plot orientation correct; sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',; color=['total_counts', 'n_genes_by_counts']). # Now spots are flipped; sc.pl.spatial(adata, img_key = None, cmap='magma',; color=['total_counts', 'n_genes_by_counts']); ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1148
https://github.com/scverse/scanpy/issues/1150:612,Deployability,install,installed,612,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:935,Integrability,wrap,wrap,935,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1250,Integrability,wrap,wrapper,1250,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:730,Security,expose,exposed,730,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper?. Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1151:307,Availability,Error,Error,307,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:840,Testability,log,logic,840,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1203,Testability,log,logging,1203,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1152:362,Modifiability,parameteriz,parameterization,362,"https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:284,Testability,log,logfoldchanges,284,"https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1153:97,Availability,error,error,97,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:266,Availability,error,error,266,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:879,Availability,Error,Error,879,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:904,Availability,Error,Error,904,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1261,Availability,error,error,1261,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:51,Performance,perform,performing,51,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:177,Testability,log,logarithmizing,177,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:677,Testability,test,test,677,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1954,Usability,learn,learn,1954,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1154:518,Availability,Error,Error,518,"<!-- Please give a clear and concise description of what the bug is: -->; 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; # neighborhood graph of cells (determine optimal number of PCs here); sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); # compute UMAP; sc.tl.umap(adata); # tSNE; tsne = TSNE( n_jobs=20 ); adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ); adata.write( f_anndata_path ); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2203,Testability,log,logging,2203,"s code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ...; Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; # neighborhood graph of cells (determine optimal number of PCs here); sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); # compute UMAP; sc.tl.umap(adata); # tSNE; tsne = TSNE( n_jobs=20 ); adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ); adata.write( f_anndata_path ); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2335,Usability,learn,learn,2335,"s code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ...; Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1157:378,Availability,error,error,378,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1083,Availability,Error,Error,1083," on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose); 216 projection=projection,; 217 sparse_pca=sparse_pca,; --> 218 verbose=verbose,; 219 ); 220 . ~/anaconda3/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:108,Deployability,integrat,integration,108,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:242,Deployability,integrat,integrated,242,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:484,Deployability,integrat,integrate,484,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:108,Integrability,integrat,integration,108,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:242,Integrability,integrat,integrated,242,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:484,Integrability,integrat,integrate,484,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3399,Testability,log,logging,3399,"; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose); 216 projection=projection,; 217 sparse_pca=sparse_pca,; --> 218 verbose=verbose,; 219 ); 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs); 1014 ; 1015 W, wPCA_data, EDM, = self.calculate_nnm(; -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,; 1017 ); 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold); 1117 ; 1118 if update_manifold:; -> 1119 edm = ut.calc_nnm(g_weighted, k, distance); 1120 self.adata.uns[""nnm""] = edm; 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance); 448 if g_weighted.shape[0] > 8000:; 449 # only uses cosine; --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance); 451 EDM = gen_sparse_knn(nnm, dists); 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory); 175 leaf_array=leaf_array,; 176 n_iters=n_iters,; --> 177 verbose=False,; 178 ); 179 . TypeError: some keyword arguments unexpected; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1158:511,Availability,down,download,511,"I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python; fig, ax = plt.subplots(1,3, figsize=(20,6)); sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False); sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False); sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False); plt.tight_layout(pad=3.0); plt.show(); ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1163:676,Deployability,integrat,integration,676,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:812,Deployability,integrat,integration,812,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:676,Integrability,integrat,integration,676,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:812,Integrability,integrat,integration,812,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:125,Usability,learn,learn,125,"Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are; * extension to BCR data; * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks; * integration with epitope databases. Let me know what you think! . Best, ; Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1164:105,Availability,error,errors,105,"<!-- Please give a clear and concise description of what the bug is: -->; Console outputs a long list of errors/warnings when running scanpy.pp.combat().; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataCombat = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:445,Availability,Error,Error,445,"<!-- Please give a clear and concise description of what the bug is: -->; Console outputs a long list of errors/warnings when running scanpy.pp.combat().; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataCombat = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4561,Testability,log,logging,4561,"ackages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; change = 1; count = 0; ^. self.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide; b_prior[i],; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Console outputs a long list of errors/warnings when running scanpy.pp.combat().; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataCombat = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4696,Usability,learn,learn,4696,"ackages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; change = 1; count = 0; ^. self.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide; b_prior[i],; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1166:209,Availability,error,error,209,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:421,Availability,Error,Error,421,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:81,Deployability,upgrade,upgraded,81,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:150,Performance,load,load,150,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1167:162,Availability,error,error,162,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataMNN = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:745,Availability,Error,Error,745,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataMNN = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1804,Availability,error,error,1804,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4248,Availability,error,error,4248,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6692,Availability,error,error,6692,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9136,Availability,error,error,9136,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11580,Availability,error,error,11580,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14024,Availability,error,error,14024,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16468,Availability,error,error,16468,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18912,Availability,error,error,18912,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22624,Energy Efficiency,schedul,scheduled,22624,"def find_mutual_nn(data1, data2, k1, k2, n_jobs):; <source elided>; mutual_2 = []; for index_2 in range(data2.shape[0]):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:; def find_mutual_nn(data1, data2, k1, k2, n_jobs):; <source elided>; mutual_2 = []; for index_2 in range(data2.shape[0]):; ^. state.func_ir.loc)); Computing correction vectors...; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: ; Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1410,Modifiability,parameteriz,parameterized,1410,"sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3854,Modifiability,parameteriz,parameterized,3854,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6298,Modifiability,parameteriz,parameterized,6298,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8742,Modifiability,parameteriz,parameterized,8742,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11186,Modifiability,parameteriz,parameterized,11186,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13630,Modifiability,parameteriz,parameterized,13630,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16074,Modifiability,parameteriz,parameterized,16074,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18518,Modifiability,parameteriz,parameterized,18518,"rning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2887,Safety,detect,detected,2887,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5331,Safety,detect,detected,5331,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7775,Safety,detect,detected,7775,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10219,Safety,detect,detected,10219,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12663,Safety,detect,detected,12663,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15107,Safety,detect,detected,15107,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17551,Safety,detect,detected,17551,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19995,Safety,detect,detected,19995,"gument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); Starting MNN correct iteration. Reference batch: 0; Step 1 of 11: processing batch 1; Looking for MNNs...; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21996,Safety,detect,detected,21996,"ype pyobject; [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:; def find_mutual_nn(data1, data2, k1, k2, n_jobs):; <source elided>; mutual_2 = []; for index_2 in range(data2.shape[0]):; ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:; def find_mutual_nn(data1, data2, k1, k2, n_jobs):; <source elided>; mutual_2 = []; for index_2 in range(data2.shape[0]):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:; def find_mutual_nn(data1, data2, k1, k2, n_jobs):; <source elided>; mutual_2 = []; for index_2 in range(data2.shape[0]):; ^. state.func_ir.loc)); Computing correction vectors...; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: ; Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/util",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24774,Safety,detect,detected,24774," vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107); @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); Adjusting variance...; Applying correction...; Step 2 of 11: processing batch 2; Looking for MNNs...; Computing correction vectors...; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject; [1] During: typing of argument at /home/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26923,Safety,detect,detected,26923,"utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>; batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct; **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct; svd_mode=svd_mode, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28169,Testability,log,logging,28169,"iled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>; batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct; **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct; svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct; new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataMNN = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28289,Usability,learn,learn,28289,"iled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:; def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):; <source elided>; vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32); for index, ve in zip(mnn2, vect):; ^. state.func_ir.loc)); Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>; batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct; **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct; svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct; new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1168:170,Availability,error,error,170,"Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.; pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1169:226,Availability,mainten,maintenance,226,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:706,Deployability,Update,Update,706,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:215,Energy Efficiency,reduce,reduce,215,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:473,Testability,test,tests,473,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:611,Testability,test,tests,611,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:773,Testability,test,testing,773,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1170:124,Availability,error,errors,124,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:318,Availability,Error,Error,318,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1175,Testability,log,logging,1175,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1298,Usability,learn,learn,1298,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1171:159,Availability,error,error,159,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:874,Availability,Error,Error,874,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:285,Deployability,update,updated,285,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2340,Testability,log,logging,2340,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls; raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2461,Usability,learn,learn,2461,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls; raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1172:456,Availability,Error,Error,456,"<!-- Please give a clear and concise description of what the bug is: -->; After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:784,Availability,avail,available,784,"<!-- Please give a clear and concise description of what the bug is: -->; After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1442,Modifiability,variab,variables,1442,"`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>; sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=fl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2129,Modifiability,variab,variable,2129,"f six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>; sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3240,Testability,log,logging,3240,"s. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>; sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1311,Usability,learn,learn,1311," reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>; sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3361,Usability,learn,learn,3361,"s. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>; sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/pull/1173:347,Modifiability,refactor,refactor,347,"This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables; - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089; * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:697,Modifiability,variab,variables,697,"This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables; - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089; * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:198,Testability,test,testing,198,"This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables; - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089; * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/issues/1174:626,Availability,Error,Error,626,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1715,Testability,log,logging,1715,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1836,Usability,learn,learn,1836,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1175:375,Availability,error,errors,375,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:494,Availability,Error,Error,494,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:829,Availability,avail,available,829,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1487,Modifiability,variab,variables,1487," Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2015,Modifiability,variab,variable,2015,"ng: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3133,Testability,log,logging,3133,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1356,Usability,learn,learn,1356,"lysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/aues",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3253,Usability,learn,learn,3253,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes; flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut; duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1176:218,Performance,perform,performs,218,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python; conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']; adata.obsp[neighbor_key][conn_key]; ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:485,Security,access,access,485,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python; conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']; adata.obsp[neighbor_key][conn_key]; ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1177:153,Performance,perform,perform,153,"<!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:278,Usability,simpl,simply,278,"<!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:437,Usability,simpl,simple,437,"<!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1178:555,Usability,simpl,simple,555,"<!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1181:220,Availability,error,error,220,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:965,Availability,Error,Error,965,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:89,Deployability,integrat,integrate,89,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:89,Integrability,integrat,integrate,89,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:226,Integrability,message,message,226,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1653,Testability,log,logging,1653,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1774,Usability,learn,learn,1774,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/pull/1182:158,Availability,avail,available,158,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:366,Deployability,integrat,integrate,366,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:366,Integrability,integrat,integrate,366,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/issues/1183:66,Availability,error,error,66,"When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1184:320,Availability,Error,Error,320,"<!-- Please give a clear and concise description of what the bug is: -->; After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python; adata = sc.datasets.visium_sge(); ```; I get ; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'; ```; I figured it is because the intermediate folder ""/data"" is missing as well - . ```python; sample_dir.mkdir(exist_ok=True); ```; in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python; adata = sc.datasets.visium_sge(); ```; I get ; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'; ```; I figured it is because the intermediate folder ""/data"" is missing as well - . ```python; sample_dir.mkdir(exist_ok=True); ```; in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:945,Usability,learn,learn,945,"<!-- Please give a clear and concise description of what the bug is: -->; After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python; adata = sc.datasets.visium_sge(); ```; I get ; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'; ```; I figured it is because the intermediate folder ""/data"" is missing as well - . ```python; sample_dir.mkdir(exist_ok=True); ```; in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/pull/1186:21,Usability,guid,guide,21,Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:191,Usability,guid,guide,191,Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/issues/1187:4253,Availability,Error,Error,4253,"bors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). ```; This outputs the following. ```; 0; 134513; 37696; 0 659; 1 605; 2 398; 3 352; 4 342; 5 174; 6 118; 7 41; 8 11; Name: leiden, dtype: int64; 0 527; 1 484; 2 398; 3 324; 4 320; 5 301; 6 174; 7 109; 8 52; 9 11; Name: leiden, dtype: int64. 0; 134127; 37278; 0 646; 1 617; 2 382; 3 362; 4 334; 5 173; 6 129; 7 46; 8 11; Name: leiden, dtype: int64; 0 646; 1 631; 2 408; 3 349; 4 334; 5 170; 6 106; 7 45; 8 11; Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions(). -->; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1140,Performance,cache,cache,1140,"I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below.; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # First run on a machine with 8 CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2002,Performance,cache,cache,2002," CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4387,Testability,log,logging,4387,"bors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). ```; This outputs the following. ```; 0; 134513; 37696; 0 659; 1 605; 2 398; 3 352; 4 342; 5 174; 6 118; 7 41; 8 11; Name: leiden, dtype: int64; 0 527; 1 484; 2 398; 3 324; 4 320; 5 301; 6 174; 7 109; 8 52; 9 11; Name: leiden, dtype: int64. 0; 134127; 37278; 0 646; 1 617; 2 382; 3 362; 4 334; 5 173; 6 129; 7 46; 8 11; Name: leiden, dtype: int64; 0 646; 1 631; 2 408; 3 349; 4 334; 5 170; 6 106; 7 45; 8 11; Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions(). -->; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:505,Usability,learn,learn,505,"I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below.; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # First run on a machine with 8 CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4514,Usability,learn,learn,4514,"bors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). ```; This outputs the following. ```; 0; 134513; 37696; 0 659; 1 605; 2 398; 3 352; 4 342; 5 174; 6 118; 7 41; 8 11; Name: leiden, dtype: int64; 0 527; 1 484; 2 398; 3 324; 4 320; 5 301; 6 174; 7 109; 8 52; 9 11; Name: leiden, dtype: int64. 0; 134127; 37278; 0 646; 1 617; 2 382; 3 362; 4 334; 5 173; 6 129; 7 46; 8 11; Name: leiden, dtype: int64; 0 646; 1 631; 2 408; 3 349; 4 334; 5 170; 6 106; 7 45; 8 11; Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions(). -->; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1190:137,Availability,error,error,137,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:961,Availability,Avail,Available,961,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:86,Deployability,install,install,86,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:264,Deployability,install,install,264,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:420,Modifiability,flexible,flexible,420,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:666,Modifiability,flexible,flexible,666,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:808,Safety,abort,abort,808,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1191:119,Availability,error,error,119,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:629,Testability,log,logg,629,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1397,Testability,log,logging,1397,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1518,Usability,learn,learn,1518,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1192:209,Integrability,depend,dependencies,209,Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1193:112,Availability,error,error,112,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:145,Availability,fault,fault,145,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:151,Availability,error,error,151,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:255,Availability,error,error,255,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:790,Availability,error,errors,790,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:895,Availability,fault,fault,895,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:901,Availability,error,error,901,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1465,Availability,Error,Error,1465,"uces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2809,Availability,error,errors,2809,"rallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite; reraise(type(e), e, None); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4131,Availability,error,errors,4131,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4322,Availability,error,error,4322,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3932,Deployability,release,release,3932,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4328,Integrability,message,message,4328,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1090,Performance,load,load,1090," or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:841,Testability,log,logging,841,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4480,Testability,log,logging,4480,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4624,Usability,learn,learn,4624,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4686,Usability,learn,learn,4686,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/pull/1194:23,Testability,test,test,23,"bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/pull/1196:10,Safety,Avoid,Avoids,10,"In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box).; This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:330,Safety,avoid,avoided,330,"In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box).; This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1197:30,Deployability,update,updated,30,"API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/issues/1198:339,Availability,error,error,339,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:358,Availability,Error,Error,358,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:665,Availability,Error,Error,665,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:785,Testability,log,logging,785,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:88,Usability,clear,clear,88,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1199:141,Availability,error,error,141,"<!-- Please give a clear and concise description of what the bug is: -->; I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```; Exception Traceback (most recent call last); <ipython-input-195-8f87448845a3> in <module>; 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2440,Availability,Error,Error,2440,"a.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 480 elif subarr.ndim > 1:; 481 if isinstance(data, np.ndarray):; --> 482 raise Exception(""Data must be 1-dimensional""); 483 else:; 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2574,Testability,log,logging,2574,"a.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 480 elif subarr.ndim > 1:; 481 if isinstance(data, np.ndarray):; --> 482 raise Exception(""Data must be 1-dimensional""); 483 else:; 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```; Exception Traceback (most recent call last); <ipython-input-195-8f87448845a3> in <module>; 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2695,Usability,learn,learn,2695,"a.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 480 elif subarr.ndim > 1:; 481 if isinstance(data, np.ndarray):; --> 482 raise Exception(""Data must be 1-dimensional""); 483 else:; 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1201:173,Availability,avail,available,173,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:847,Availability,Error,Error,847,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1208,Testability,log,logging,1208,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1202:257,Availability,Error,Error,257,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:500,Testability,log,logging,500,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:610,Usability,learn,learn,610,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1203:64,Usability,user-friendly,user-friendly,64,"The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1203
https://github.com/scverse/scanpy/issues/1205:723,Deployability,integrat,integration,723,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:723,Integrability,integrat,integration,723,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:518,Usability,learn,learning,518,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:901,Usability,learn,learning,901,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this?. Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF); - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf); - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1207:19,Deployability,update,update,19,Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1208:438,Availability,Error,Error,438,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:795,Testability,log,logging,795,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:934,Usability,learn,learn,934,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/pull/1210:3808,Deployability,update,update,3808,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4082,Deployability,Update,Update,4082,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4102,Deployability,Update,Update,4102,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:524,Integrability,wrap,wrappers,524,"This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], ; 'myeloid': ['CST3', 'LYZ']}; dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True); dp.add_totals(size=1.2)\; .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\; .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\; .show(); ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2826,Performance,tune,tuned,2826," sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True); dp.add_totals(size=1.2)\; .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\; .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\; .show(); ```; All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:599,Security,Access,Accessing,599,"This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], ; 'myeloid': ['CST3', 'LYZ']}; dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True); dp.add_totals(size=1.2)\; .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\; .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\; .show(); ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:325,Testability,log,log,325,"This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], ; 'myeloid': ['CST3', 'LYZ']}; dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True); dp.add_totals(size=1.2)\; .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\; .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\; .show(); ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1856,Testability,log,log,1856,"d to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON; adata = sc.datasets.pbmc68k_reduced(); markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], ; 'myeloid': ['CST3', 'LYZ']}; dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True); dp.add_totals(size=1.2)\; .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\; .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\; .show(); ```; All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the tota",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3609,Testability,log,log,3609,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3766,Testability,log,log,3766,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4089,Testability,test,tests,4089,"each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:; **all figures**:; * Set a title to the image. ; * Pass an `axe` where to plot the image.; * Return a dictionary of axes for further manipulation; * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned.; * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns.; * legend can be removed; * `groupby` can be a list of categories. . **dotplot**; * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller.; * Plot genes in rows and categories in columns (swap_axes).; * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features; * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**; * added title for colorbar and positioned as in dotplot; * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**; * [update] violin colors can be colored based on average gene expression as in dotplots; * made the linewidth of the violin plots smaller.; * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:; - [x] Update tests; - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/issues/1213:476,Availability,Error,Error,476,"<!-- Please give a clear and concise description of what the bug is: -->; here is the code for marker filter; I think the 3 condition need to be OR instead of AND; gene_names = gene_names[; (fraction_in_cluster_matrix > min_in_group_fraction) &; (fraction_out_cluster_matrix < max_out_group_fraction) &; (fold_change_matrix > min_fold_change); ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:610,Testability,log,logging,610,"<!-- Please give a clear and concise description of what the bug is: -->; here is the code for marker filter; I think the 3 condition need to be OR instead of AND; gene_names = gene_names[; (fraction_in_cluster_matrix > min_in_group_fraction) &; (fraction_out_cluster_matrix < max_out_group_fraction) &; (fold_change_matrix > min_fold_change); ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; here is the code for marker filter; I think the 3 condition need to be OR instead of AND; gene_names = gene_names[; (fraction_in_cluster_matrix > min_in_group_fraction) &; (fraction_out_cluster_matrix < max_out_group_fraction) &; (fold_change_matrix > min_fold_change); ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/pull/1215:112,Testability,test,tests,112,Fixes #1170 by not requiring unique `obs_names` to run combat. I also ran formatting over combat and the combat tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1215
https://github.com/scverse/scanpy/pull/1218:30,Deployability,release,release,30,Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/issues/1220:267,Availability,error,error,267,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:18,Deployability,install,installation,18,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:86,Deployability,install,install,86,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1221:138,Availability,error,error,138,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:150,Availability,Error,Error,150,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:439,Availability,Error,Error,439,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:977,Availability,Down,Downloaded,977,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1525,Availability,down,downloaded,1525,"tput in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2442,Availability,error,error,2442,"881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2588,Availability,error,error,2588,"type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3420,Availability,Error,Error,3420,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2159,Integrability,protocol,protocol,2159,"ign"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(Ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1852,Safety,timeout,timeout,1852,"boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1969,Safety,timeout,timeout,1969,"ed {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2102,Safety,timeout,timeout,2102,"i_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:872,Security,access,accession,872,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:943,Security,access,accession,943,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:989,Security,access,accession,989,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1149,Security,access,accession,1149,"and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:965,Testability,log,logg,965,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3476,Testability,log,logging,3476,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3616,Usability,learn,learn,3616,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3801,Usability,learn,learn,3801,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1222:334,Availability,Error,Error,334,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:428,Availability,error,error,428,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1235,Testability,log,logging,1235,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1356,Usability,learn,learn,1356,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1223:520,Availability,Error,Error,520,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:622,Availability,fault,fault,622,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:272,Performance,cache,cache,272,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:729,Testability,log,logging,729,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1225:1387,Deployability,patch,patches,1387,"I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python; import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""); sc.pl.spatial(adata); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-1ffa4586cef4> in <module>; ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs); 785 bw=bw,; 786 library_id=library_id,; --> 787 **kwargs,; 788 ); 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 c=color_vector,; 398 rasterized=settings._vector_friendly,; --> 399 **kwargs,; 400 ); 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs); 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]; 1128 collection = PatchCollection(patches, **kwargs); -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):; 1130 collection.set_array(c); 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1464,Deployability,Patch,PatchCollection,1464,"I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python; import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""); sc.pl.spatial(adata); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-1ffa4586cef4> in <module>; ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs); 785 bw=bw,; 786 library_id=library_id,; --> 787 **kwargs,; 788 ); 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 c=color_vector,; 398 rasterized=settings._vector_friendly,; --> 399 **kwargs,; 400 ); 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs); 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]; 1128 collection = PatchCollection(patches, **kwargs); -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):; 1130 collection.set_array(c); 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1480,Deployability,patch,patches,1480,"I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python; import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""); sc.pl.spatial(adata); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-1ffa4586cef4> in <module>; ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs); 785 bw=bw,; 786 library_id=library_id,; --> 787 **kwargs,; 788 ); 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 c=color_vector,; 398 rasterized=settings._vector_friendly,; --> 399 **kwargs,; 400 ); 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs); 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]; 1128 collection = PatchCollection(patches, **kwargs); -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):; 1130 collection.set_array(c); 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1227:243,Availability,error,error,243,"I was running Scanpy 1.4.5.1 on Jupyter Notebook; My matplotlib version is 3.1.3. I ran paga using these commands:; ```; sc.tl.paga(bdata,groups='leiden'); sc.pl.paga(bdata, plot=False); sc.pl.paga(bdata); ````. The third command gave me this error:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-65-5027c99fe1bd> in <module>; ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2591,Availability,down,downgrade,2591,"nent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1596,Usability,simpl,simplefilter,1596,"ponent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1233:167,Availability,avail,available,167,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:308,Availability,down,downstream,308,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:213,Integrability,depend,depend,213,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:689,Usability,learn,learning,689,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1300,Usability,learn,learning,1300,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1237:300,Deployability,update,updated,300,"Hi,; Thanks for providing an amazing platform for single-cell data analysis. ; I was trying to use palantir in scanpy and I just reran the example data. However, ; d = sce.tl.palantir(adata) ; always return None for any kind of data. Could you please comment on this?; I am using scanpy 1.5 and have updated Palantir to 0.2.6; Thanks in advance,; Zeinab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1239:1046,Usability,learn,learn,1046,"I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:; import copy; Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ); sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50); sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40); sc.tl.umap(Tcells, min_dist=0.2, random_state=42); sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:; import copy; Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ; sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50); sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40); sc.tl.umap(Tcells, min_dist=0.2, random_state=42); sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:; scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/pull/1240:118,Testability,test,test,118,"Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:260,Testability,test,tests,260,"Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:560,Testability,test,test,560,"Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:613,Testability,test,tests,613,"Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/issues/1243:7,Deployability,install,install,7,leiden install via conda code is wrong in the current page. it should be:. ```; conda install -c conda-forge leidenalg ; ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:86,Deployability,install,install,86,leiden install via conda code is wrong in the current page. it should be:. ```; conda install -c conda-forge leidenalg ; ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1244:93,Deployability,install,installed,93,"When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash; conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4; conda activate test_scanpy_tqdm; python -c ""import scanpy as sc"" ; ```. ```pytb; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>; from . import datasets, logging, queries, external, get; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>; from ._datasets import (; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>; from tqdm.auto import tqdm; ModuleNotFoundError: No module named 'tqdm.auto'; ```. ### Suggested solution; Either ; * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or ; * require a minimal version of `tqdm>=4.29.1`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1034,Deployability,install,installed,1034,"When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash; conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4; conda activate test_scanpy_tqdm; python -c ""import scanpy as sc"" ; ```. ```pytb; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>; from . import datasets, logging, queries, external, get; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>; from ._datasets import (; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>; from tqdm.auto import tqdm; ModuleNotFoundError: No module named 'tqdm.auto'; ```. ### Suggested solution; Either ; * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or ; * require a minimal version of `tqdm>=4.29.1`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1178,Deployability,update,update-jupyter-an,1178,"When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash; conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4; conda activate test_scanpy_tqdm; python -c ""import scanpy as sc"" ; ```. ```pytb; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>; from . import datasets, logging, queries, external, get; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>; from ._datasets import (; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>; from tqdm.auto import tqdm; ModuleNotFoundError: No module named 'tqdm.auto'; ```. ### Suggested solution; Either ; * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or ; * require a minimal version of `tqdm>=4.29.1`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:501,Testability,log,logging,501,"When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash; conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4; conda activate test_scanpy_tqdm; python -c ""import scanpy as sc"" ; ```. ```pytb; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>; from . import datasets, logging, queries, external, get; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>; from ._datasets import (; File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>; from tqdm.auto import tqdm; ModuleNotFoundError: No module named 'tqdm.auto'; ```. ### Suggested solution; Either ; * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or ; * require a minimal version of `tqdm>=4.29.1`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/pull/1245:9,Deployability,update,updates,9,Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:61,Deployability,update,updated,61,Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:43,Integrability,wrap,wrapper,43,Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/issues/1246:581,Availability,Error,Error,581,"<!-- Please give a clear and concise description of what the bug is: -->; ...; ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png); with adata like this:; ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:; ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:715,Testability,log,logging,715,"<!-- Please give a clear and concise description of what the bug is: -->; ...; ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png); with adata like this:; ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:; ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ...; ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png); with adata like this:; ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:; ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1249:833,Availability,Error,Error,833,"<!-- Please give a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249
https://github.com/scverse/scanpy/issues/1249:405,Modifiability,variab,variable,405,"<!-- Please give a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249
https://github.com/scverse/scanpy/issues/1249:1814,Testability,log,logging,1814,"a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249
https://github.com/scverse/scanpy/issues/1249:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249
https://github.com/scverse/scanpy/issues/1249:1940,Usability,learn,learn,1940,"a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249
https://github.com/scverse/scanpy/pull/1250:30,Availability,down,downloading,30,"Sometimes, it can happen when downloading 10x files from e.g. GEO that they are not organized in; folders but instead, they have a sample-specific prefix. E.g. . ```console; sturm@zeus [SSH] processed % ll; total 156M; -rw-r--r-- 1 dbadmin dbadmin 29K May 21 2018 GSM3148575_BC09_TUMOR1_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148575_BC09_TUMOR1_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 34M May 21 2018 GSM3148575_BC09_TUMOR1_matrix.mtx.gz; -rw-r--r-- 1 dbadmin dbadmin 28K May 21 2018 GSM3148576_BC09_TUMOR2_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148576_BC09_TUMOR2_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 33M May 21 2018 GSM3148576_BC09_TUMOR2_matrix.mtx.gz; ```. This PR adds a keyword argument `prefix` to `read_10x_mtx` which enables to load these files ; without manual renaming and moving, e.g. ; ```python; adata = sc.read_10x_mtx(""path/to/files"", prefix=""GSM3148575_BC09_TUMOR1_""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:802,Performance,load,load,802,"Sometimes, it can happen when downloading 10x files from e.g. GEO that they are not organized in; folders but instead, they have a sample-specific prefix. E.g. . ```console; sturm@zeus [SSH] processed % ll; total 156M; -rw-r--r-- 1 dbadmin dbadmin 29K May 21 2018 GSM3148575_BC09_TUMOR1_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148575_BC09_TUMOR1_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 34M May 21 2018 GSM3148575_BC09_TUMOR1_matrix.mtx.gz; -rw-r--r-- 1 dbadmin dbadmin 28K May 21 2018 GSM3148576_BC09_TUMOR2_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148576_BC09_TUMOR2_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 33M May 21 2018 GSM3148576_BC09_TUMOR2_matrix.mtx.gz; ```. This PR adds a keyword argument `prefix` to `read_10x_mtx` which enables to load these files ; without manual renaming and moving, e.g. ; ```python; adata = sc.read_10x_mtx(""path/to/files"", prefix=""GSM3148575_BC09_TUMOR1_""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/issues/1251:233,Modifiability,variab,variable,233,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:365,Performance,perform,perform,365,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:157,Testability,log,log-transformed,157,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:270,Testability,log,log-transformed,270,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:393,Testability,log,log-transform,393,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:497,Testability,log,log-transformed,497,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.recipe_seurat and scanpy.pp.recipe_zheng17 indicate that they expect non log-transformed data. This leads both functions to do by default the highly variable gene (HVG) selection on non log-transformed data. This seems contrary to the scanpy and seurat clustering tutorials, which perform HVG selection after log-transform. It also seems contrary to the new function scanpy.pp.highly_variable_genes which expects log-transformed inputs. scanpy version : 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1252:768,Availability,error,error,768,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:269,Deployability,update,updated,269,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:305,Deployability,install,installed,305,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:774,Integrability,message,message,774,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:2336,Integrability,wrap,wrapper,2336," with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 else:. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 199 ; 200 output = _pca_with_sparse(; --> 201 X, n_comps, solver=svd_solver, random_state=random_state; 202 ); 203 # this is just a wrapper for the results. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in _pca_with_sparse(X, npcs, solver, mu, random_state); 298 shape=X.shape,; 299 rmatvec=rmatvec,; --> 300 rmatmat=rmatmat,; 301 ); 302 . /usr/local/anaconda/lib/python3.6/site-packages/scipy/sparse/linalg/interface.py in __new__(cls, *args, **kwargs); 131 if cls is LinearOperator:; 132 # Operate as _CustomLinearOperator factory.; --> 133 return _CustomLinearOperator(*args, **kwargs); 134 else:; 135 obj = super(LinearOperator, cls).__new__(cls). TypeError: __init__() got an unexpected keyword argument 'rmatmat'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:2632,Integrability,interface,interface,2632," with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 else:. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 199 ; 200 output = _pca_with_sparse(; --> 201 X, n_comps, solver=svd_solver, random_state=random_state; 202 ); 203 # this is just a wrapper for the results. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in _pca_with_sparse(X, npcs, solver, mu, random_state); 298 shape=X.shape,; 299 rmatvec=rmatvec,; --> 300 rmatmat=rmatmat,; 301 ); 302 . /usr/local/anaconda/lib/python3.6/site-packages/scipy/sparse/linalg/interface.py in __new__(cls, *args, **kwargs); 131 if cls is LinearOperator:; 132 # Operate as _CustomLinearOperator factory.; --> 133 return _CustomLinearOperator(*args, **kwargs); 134 else:; 135 obj = super(LinearOperator, cls).__new__(cls). TypeError: __init__() got an unexpected keyword argument 'rmatmat'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:602,Testability,log,logging,602,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1538,Testability,log,logg,1538,"ce question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 else:. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 199 ; 200 output = _pca_with_sparse(; --> 201 X, n_comps, solver=svd_solver, random_state=random_state; 202 ); 203 # this is just a wrapper for the results. ~/.local/lib/python3.6/site-packages/scanpy/preprocessing/_pca.py in _pca_with_sparse(X, npcs, solver, mu, rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:721,Usability,learn,learn,721,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1253:499,Usability,learn,learn,499,"Looks like the default values for plotting Visium spots are way outsized. Try this in your lymph node notebook:; ```python; sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',; color=['total_counts', 'n_genes_by_counts'],; gene_symbols='SYMBOL'); ```; This is what I get:; ...; ![image](https://user-images.githubusercontent.com/22567383/83098134-acf2e600-a0a1-11ea-9248-c611f7330547.png). #### Versions:; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1253
https://github.com/scverse/scanpy/issues/1254:476,Availability,error,error,476,"Does `scanpy==1.5.1` support multiple sections in one adata object? If I concatenate several anndata object I can't plot even with `sc.pl.spatial(img_key=None)`. Try concatenating 3 mouse brain adata object and plotting:; ```python; adata = adata1.concatenate([obj2, obj3], index_unique=None); sc.pl.spatial(adata[adata.obs[""sample""]==adata.obs[""sample""].unique()[0], :], ; color=[""Rorb"", ""Vip""], img_key=None,; vmin=0, cmap='magma',; gene_symbols='SYMBOL'); ```. This is the error I get:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-9-8c84185773ec> in <module>; 6 color=[""Rorb"", ""Vip""], img_key=None,; 7 vmin=0, cmap='magma', #vmax=3.8,; ----> 8 gene_symbols='SYMBOL'; 9 ). /nfs/team283/vk7/software/miniconda3farm5/envs/cellpymc/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, size, **kwargs); 765 """"""; 766 if library_id is _empty:; --> 767 library_id = next((i for i in adata.uns['spatial'].keys())); 768 else:; 769 if library_id not in adata.uns['spatial'].keys():. KeyError: 'spatial'; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:1289,Usability,learn,learn,1289,"Does `scanpy==1.5.1` support multiple sections in one adata object? If I concatenate several anndata object I can't plot even with `sc.pl.spatial(img_key=None)`. Try concatenating 3 mouse brain adata object and plotting:; ```python; adata = adata1.concatenate([obj2, obj3], index_unique=None); sc.pl.spatial(adata[adata.obs[""sample""]==adata.obs[""sample""].unique()[0], :], ; color=[""Rorb"", ""Vip""], img_key=None,; vmin=0, cmap='magma',; gene_symbols='SYMBOL'); ```. This is the error I get:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-9-8c84185773ec> in <module>; 6 color=[""Rorb"", ""Vip""], img_key=None,; 7 vmin=0, cmap='magma', #vmax=3.8,; ----> 8 gene_symbols='SYMBOL'; 9 ). /nfs/team283/vk7/software/miniconda3farm5/envs/cellpymc/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, size, **kwargs); 765 """"""; 766 if library_id is _empty:; --> 767 library_id = next((i for i in adata.uns['spatial'].keys())); 768 else:; 769 if library_id not in adata.uns['spatial'].keys():. KeyError: 'spatial'; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1256:409,Availability,error,error,409,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:943,Availability,error,error,943," I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:950,Availability,ERROR,ERROR,950," I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:965,Availability,error,errored,965," I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:2656,Availability,error,error,2656," (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:2782,Availability,down,downloads,2782,"d; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:2836,Availability,ERROR,ERROR,2836,"d; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3000,Availability,error,error,3000,".win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3007,Availability,ERROR,ERROR,3007,"md64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-am",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3022,Availability,error,errored,3022,"md64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-am",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:4860,Availability,error,error,4860,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:4986,Availability,down,downloads,4986,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5040,Availability,ERROR,ERROR,5040,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5055,Availability,error,errored,5055,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:25,Deployability,install,install,25,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:42,Deployability,install,install,42,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:262,Deployability,install,installed,262,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:350,Deployability,install,install,350,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:378,Deployability,install,install,378,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:396,Deployability,install,installation,396,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1176,Deployability,install,install-,1176,"ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.eg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1273,Deployability,install,install-,1273,"' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1587,Deployability,install,install-,1587,"a\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1639,Deployability,Install,Installing,1639,"a\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1722,Deployability,install,installed,1722,"(1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:1756,Deployability,install,install,1756,"satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:2927,Deployability,Install,Installing,2927,"> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is ins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:2980,Deployability,install,install,2980,"py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running insta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3233,Deployability,install,install-,3233,".egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3330,Deployability,install,install-,3330,"st file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3528,Deployability,install,install,3528,"2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3601,Deployability,install,install-record,3601,"2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3669,Deployability,install,install-headers,3669,"io.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3795,Deployability,install,install-,3795,"io.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3847,Deployability,Install,Installing,3847,"io.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3930,Deployability,install,installed,3930,"talling collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3964,Deployability,install,install,3964,"a2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:3982,Deployability,install,install,3982,"mmand errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5256,Deployability,install,install-,5256,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5353,Deployability,install,install-,5353,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5551,Deployability,install,install,5551,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5624,Deployability,install,install-record,5624,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5692,Deployability,install,install-headers,5692,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:438,Performance,cache,cached,438,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:5783,Testability,log,logs,5783,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1258:2460,Availability,error,error,2460,"5cac3.png). Now the code that doesn't work:; ```python; sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); #sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:2488,Availability,Error,Error,2488,"bs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:199,Security,access,accessed,199,"<!-- Please give a clear and concise description of what the bug is: -->; When using `sc.pl.scatter()` and providing an existing axis object, the legend doesn't always appear correctly and cannot be accessed. ; This doesn't seem to happen with a categorial coloring however, only with a continous colormap. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; This code works as expected:; ```python; sc.pp.calculate_qc_metrics(adata_raw, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='batch', size = 10, ax=sc_ax1, show=False, title=""all counts""); sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='batch', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```; It creates some metrics and stores them in `adata_raw.obs`, then plots these metrics for all counts and for counts < 1000 on the two axes created by `plt.subplots()`. The legend from the first axis is then removed.; This is an example of this output:; ![image](https://user-images.githubusercontent.com/50995210/83322157-ac9b4c00-a255-11ea-9861-8974b535cac3.png). Now the code that doesn't work:; ```python; sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); #sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; Th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3325,Security,access,access,3325,",'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; >matplotlib==3.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3424,Testability,log,logging,3424,",'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; >matplotlib==3.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When using `sc.pl.scatter()` and providing an existing axis object, the legend doesn't always appear correctly and cannot be accessed. ; This doesn't seem to happen with a categorial coloring however, only with a continous colormap. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; This code works as expected:; ```python; sc.pp.calculate_qc_metrics(adata_raw, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='batch', size = 10, ax=sc_ax1, show=False, title=""all counts""); sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='batch', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```; It creates some metrics and stores them in `adata_raw.obs`, then plots these metrics for all counts and for counts < 1000 on the two axes created by `plt.subplots()`. The legend from the first axis is then removed.; This is an example of this output:; ![image](https://user-images.githubusercontent.com/50995210/83322157-ac9b4c00-a255-11ea-9861-8974b535cac3.png). Now the code that doesn't work:; ```python; sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); #sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; Th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3561,Usability,learn,learn,3561,",'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; >matplotlib==3.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1259:149,Availability,error,error,149,"Hello, everyone,. I am working om fly model. And I have met a problem when I was doing QC step use function pp.calculate_qc_metrics. I have got this error. Can anyone help me? Thanks. The code as follows: . ```python; adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-34-455e630e3278> in <module>; 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. ~\anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 51 return self._get_sliceXslice(row, col); 52 elif col.ndim == 1:; ---> 53 return self._get_sliceXarray(row, col); 54 raise IndexError('index results in >2 dimensions'); 55 elif row.ndim == 1:. ~\anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col); 314 ; 315 def _get_sliceXarray(self, row, col):; --> 316 return self._major_slice(row)._minor_index_fancy(col); 317 ; 318 def _get_arrayXint(self, row, col):. ~\anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx); 735 """"""; 736 idx_dtype = self.indices.dtype; --> 737 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1260:183,Availability,error,error,183,"<!-- Please give a clear and concise description of what the bug is: -->; First of all, thank you for your great platform! . When I try to export a SPRING project I get the following error (it seems that the class NeighborsView is not defined; I have a 'neighbors' key in .uns): . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1289,Availability,Error,Error,1289,"_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:1198,Modifiability,layers,layers,1198,"f all, thank you for your great platform! . When I try to export a SPRING project I get the following error (it seems that the class NeighborsView is not defined; I have a 'neighbors' key in .uns): . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite);",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:2743,Testability,log,logging,2743,"gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.0 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; First of all, thank you for your great platform! . When I try to export a SPRING project I get the following error (it seems that the class NeighborsView is not defined; I have a 'neighbors' key in .uns): . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/issues/1260:2864,Usability,learn,learn,2864,"gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.0 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260
https://github.com/scverse/scanpy/pull/1262:905,Testability,log,logg,905,"```py; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.neighbors(adata); sc.tl.diffmap(adata); sc.tl.diffmap(adata); ```. gives. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-6-f88b34870534> in <module>; 7 sc.pp.neighbors(adata); 8 sc.tl.diffmap(adata); ----> 9 sc.tl.diffmap(adata). ~/.anaconda3/lib/python3.7/site-packages/scanpy/tools/_diffmap.py in diffmap(adata, n_comps, neighbors_key, copy); 64 raise ValueError('Provide any value greater than 2 for `n_comps`. '); 65 adata = adata.copy() if copy else adata; ---> 66 _diffmap(adata, n_comps=n_comps, neighbors_key=neighbors_key); 67 return adata if copy else None. ~/.anaconda3/lib/python3.7/site-packages/scanpy/tools/_dpt.py in _diffmap(adata, n_comps, neighbors_key); 13 def _diffmap(adata, n_comps=15, neighbors_key=None):; 14 start = logg.info(f'computing Diffusion Maps using n_comps={n_comps}(=n_dcs)'); ---> 15 dpt = DPT(adata, neighbors_key); 16 dpt.compute_transitions(); 17 dpt.compute_eigen(n_comps=n_comps). ~/.anaconda3/lib/python3.7/site-packages/scanpy/tools/_dpt.py in __init__(self, adata, n_dcs, min_group_size, n_branchings, allow_kendall_tau_shift, neighbors_key); 184 def __init__(self, adata, n_dcs=None, min_group_size=0.01,; 185 n_branchings=0, allow_kendall_tau_shift=False, neighbors_key=None):; --> 186 super(DPT, self).__init__(adata, n_dcs=n_dcs, neighbors_key=neighbors_key); 187 self.flavor = 'haghverdi16'; 188 self.n_branchings = n_branchings. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs, neighbors_key); 564 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata); 565 if n_dcs is not None:; --> 566 if n_dcs > len(self._eigen_values):; 567 raise ValueError(; 568 'Cannot instantiate using `n_dcs`={}. '. TypeError: '>' not supported between instances of 'str' and 'int'; ```. because n_dcs is incorrectly set to ""neighbors"".",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1262
https://github.com/scverse/scanpy/issues/1263:247,Deployability,continuous,continuous,247,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:479,Deployability,integrat,integration,479,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:479,Integrability,integrat,integration,479,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:378,Modifiability,variab,variable,378,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1263:494,Performance,load,loading,494,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263
https://github.com/scverse/scanpy/issues/1264:47,Performance,load,load,47,Is there any interest in writing a function to load any of the public datasets offered by 10x genomics?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1264
https://github.com/scverse/scanpy/issues/1265:512,Availability,Error,Error,512,"<!-- Please give a clear and concise description of what the bug is: -->; sc.pl.tracksplot, produce a wrong highlight bar without brackets. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain',; var_group_positions=[(0,2),(4,5)],var_group_labels=['set1','set2']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![image](https://user-images.githubusercontent.com/30639029/83604801-9dedb700-a52b-11ea-9c32-fc35ea959d61.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.7.dev136+g7f5c907 anndata==0.7.1 umap==0.4.1 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1265
https://github.com/scverse/scanpy/issues/1265:739,Testability,log,logging,739,"<!-- Please give a clear and concise description of what the bug is: -->; sc.pl.tracksplot, produce a wrong highlight bar without brackets. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain',; var_group_positions=[(0,2),(4,5)],var_group_labels=['set1','set2']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![image](https://user-images.githubusercontent.com/30639029/83604801-9dedb700-a52b-11ea-9c32-fc35ea959d61.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.7.dev136+g7f5c907 anndata==0.7.1 umap==0.4.1 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1265
https://github.com/scverse/scanpy/issues/1265:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; sc.pl.tracksplot, produce a wrong highlight bar without brackets. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain',; var_group_positions=[(0,2),(4,5)],var_group_labels=['set1','set2']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![image](https://user-images.githubusercontent.com/30639029/83604801-9dedb700-a52b-11ea-9c32-fc35ea959d61.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.7.dev136+g7f5c907 anndata==0.7.1 umap==0.4.1 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1265
https://github.com/scverse/scanpy/issues/1266:832,Performance,perform,performed,832,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, ; I am little confused about the parameter in pl.ump, use_raw=False. ; When you set raw=False, it takes normalized, log transformed but not corrected gene expression, while when you set user_raw=True, it takes scaled and corrected gene expression. What does corrected gene expression means here? . From tutorial it reads as below:; ""As we set the .raw attribute of adata, the previous plots showed the “raw” (normalized, logarithmized, but uncorrected) gene expression. You can also plot the scaled and corrected gene expression by explicitly stating that you don’t want to use .raw."". Trying to get some clarification on my results, in case, where i performed DE with t-test, and get top 5 genes, When i want to look them in clusters and plot ump, I do not see them with pl.ump with user_raw=True but can see them with user_raw=False. ; Any clarification will be great. . thanks, ; Preeti ; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:297,Testability,log,log,297,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, ; I am little confused about the parameter in pl.ump, use_raw=False. ; When you set raw=False, it takes normalized, log transformed but not corrected gene expression, while when you set user_raw=True, it takes scaled and corrected gene expression. What does corrected gene expression means here? . From tutorial it reads as below:; ""As we set the .raw attribute of adata, the previous plots showed the “raw” (normalized, logarithmized, but uncorrected) gene expression. You can also plot the scaled and corrected gene expression by explicitly stating that you don’t want to use .raw."". Trying to get some clarification on my results, in case, where i performed DE with t-test, and get top 5 genes, When i want to look them in clusters and plot ump, I do not see them with pl.ump with user_raw=True but can see them with user_raw=False. ; Any clarification will be great. . thanks, ; Preeti ; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:602,Testability,log,logarithmized,602,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, ; I am little confused about the parameter in pl.ump, use_raw=False. ; When you set raw=False, it takes normalized, log transformed but not corrected gene expression, while when you set user_raw=True, it takes scaled and corrected gene expression. What does corrected gene expression means here? . From tutorial it reads as below:; ""As we set the .raw attribute of adata, the previous plots showed the “raw” (normalized, logarithmized, but uncorrected) gene expression. You can also plot the scaled and corrected gene expression by explicitly stating that you don’t want to use .raw."". Trying to get some clarification on my results, in case, where i performed DE with t-test, and get top 5 genes, When i want to look them in clusters and plot ump, I do not see them with pl.ump with user_raw=True but can see them with user_raw=False. ; Any clarification will be great. . thanks, ; Preeti ; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/issues/1266:852,Testability,test,test,852,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, ; I am little confused about the parameter in pl.ump, use_raw=False. ; When you set raw=False, it takes normalized, log transformed but not corrected gene expression, while when you set user_raw=True, it takes scaled and corrected gene expression. What does corrected gene expression means here? . From tutorial it reads as below:; ""As we set the .raw attribute of adata, the previous plots showed the “raw” (normalized, logarithmized, but uncorrected) gene expression. You can also plot the scaled and corrected gene expression by explicitly stating that you don’t want to use .raw."". Trying to get some clarification on my results, in case, where i performed DE with t-test, and get top 5 genes, When i want to look them in clusters and plot ump, I do not see them with pl.ump with user_raw=True but can see them with user_raw=False. ; Any clarification will be great. . thanks, ; Preeti ; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1266
https://github.com/scverse/scanpy/pull/1271:252,Modifiability,variab,variables,252,"[sctransform](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) uses Pearson residuals from “regularized negative binomial regression,” to correct for the sequencing depth. After regressing out total number of UMIs (and other variables if given) it ranks the genes based on their residual variances and therefore also acts as a HVG selection method. This function replaces `sc.pp.normalize_total` and `sc.pp.highly_variable_genes` and requires raw counts in ``adata.X``.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1271
https://github.com/scverse/scanpy/issues/1273:84,Availability,down,download,84,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:721,Availability,avail,available,721,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:55,Deployability,release,release-latest,55,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:327,Deployability,install,install,327,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:340,Deployability,install,install-scripts,340,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:2269,Deployability,install,install,2269,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:2301,Deployability,install,install,2301,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:2339,Deployability,upgrade,upgrade,2339,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:2353,Deployability,install,install,2353,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:2399,Deployability,upgrade,upgrade,2399,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:268,Performance,load,load,268,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:528,Performance,load,load,528,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1310,Performance,load,load,1310,"stall \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYT",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:1406,Performance,load,load,1406,"/install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:425,Testability,log,log,425,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1273:3137,Testability,log,logging,3137,"/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData; File ""/home/common/lib/python3.6/site-packages/anndata/base.py"", line 21, in <module>; from scipy.sparse.sputils import IndexMixin; ImportError: cannot import name 'IndexMixin'; ```. ```bash; #pip3 install works any better?; pip3 install scanpy --target $PYTHONPATH --upgrade; pip3 install scanpy-scripts --target $PYTHONPATH --upgrade; scanpy; #same thing; ```. There are multiple versions of many packages in PYTHONPATH and at some point it seems to be picking the wrong ones. Examples:. ```bash; ls -1 $PYTHONPATH | grep scanpy; scanpy; scanpy-1.4.3.dist-info; scanpy-1.4.3-py3.6.egg; scanpy-1.4.6.dist-info; scanpy-1.5.1.dist-info; scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg; scanpy_scripts; scanpy_scripts-0.2.10.dist-info; scanpy_scripts-0.2.10-py3.6.egg; ls -1 $PYTHONPATH | grep scipy; scipy; scipy-1.2.3.dist-info; scipy-1.2.3-py3.6-linux-x86_64.egg; scipy-1.4.1.dist-info; ls -1 $PYTHONPATH | grep anndata; anndata; anndata-0.6.19.dist-info; anndata-0.6.19-py3.6.egg; anndata-0.7.1.dist-info; anndata-0.7.3.dist-info; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; current git (plus others).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273
https://github.com/scverse/scanpy/issues/1275:424,Availability,Error,Error,424,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:566,Availability,error,error,566,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:653,Availability,error,error,653,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:740,Availability,error,error,740,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:871,Testability,log,logging,871,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1275:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275
https://github.com/scverse/scanpy/issues/1277:856,Availability,error,error,856,"When giving a plotting function the `gene_symbols` argument to specify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:878,Availability,Error,Error,878,"When giving a plotting function the `gene_symbols` argument to specify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:964,Availability,ERROR,ERROR,964,"When giving a plotting function the `gene_symbols` argument to specify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1499,Testability,log,log,1499,"ecify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:1882,Testability,log,logging,1882,"ecify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1277:2006,Usability,learn,learn,2006,"ecify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277
https://github.com/scverse/scanpy/issues/1279:235,Availability,down,downstream,235,"In a recent paper, we found the brute force KNN computation to become very expensive as the data sizes increase. I’ve noticed the kNN graph computed during the “neighbors” computation can be cached and reused when Umap-learn is called downstream but when Cuml UMAP is used, the kNN graph is recomputed each time. . In cuml 0.13 we added an optional `knn_graph` argument to umap’s training and inference methods to allow it to accept pre-computed kNN graph. This will allow the kNN graph to be computed once and reused when `n_neighbors` has not been changed. I think this would further accelerate the exploratory data analysis and visualization process with scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1279
https://github.com/scverse/scanpy/issues/1279:191,Performance,cache,cached,191,"In a recent paper, we found the brute force KNN computation to become very expensive as the data sizes increase. I’ve noticed the kNN graph computed during the “neighbors” computation can be cached and reused when Umap-learn is called downstream but when Cuml UMAP is used, the kNN graph is recomputed each time. . In cuml 0.13 we added an optional `knn_graph` argument to umap’s training and inference methods to allow it to accept pre-computed kNN graph. This will allow the kNN graph to be computed once and reused when `n_neighbors` has not been changed. I think this would further accelerate the exploratory data analysis and visualization process with scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1279
https://github.com/scverse/scanpy/issues/1279:219,Usability,learn,learn,219,"In a recent paper, we found the brute force KNN computation to become very expensive as the data sizes increase. I’ve noticed the kNN graph computed during the “neighbors” computation can be cached and reused when Umap-learn is called downstream but when Cuml UMAP is used, the kNN graph is recomputed each time. . In cuml 0.13 we added an optional `knn_graph` argument to umap’s training and inference methods to allow it to accept pre-computed kNN graph. This will allow the kNN graph to be computed once and reused when `n_neighbors` has not been changed. I think this would further accelerate the exploratory data analysis and visualization process with scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1279
https://github.com/scverse/scanpy/issues/1280:179,Availability,error,error,179,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:198,Availability,ERROR,ERROR,198,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:356,Availability,ERROR,ERROR,356,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:69,Deployability,install,install,69,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:130,Deployability,install,install,130,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:782,Deployability,install,install,782,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:841,Deployability,install,install,841,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:1015,Deployability,install,install,1015,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1280:1217,Security,access,access,1217,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280
https://github.com/scverse/scanpy/issues/1281:775,Modifiability,variab,variables,775,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; Sorry to file two issues in a row! I've been using Scanpy + scVI for my analysis recently, and am really enjoying it!. Currently, if use_rep is set in `sc.pp.neighbors`, then n_pcs is ignored. These seems like sane default behaviour to me - if we aren't using 'X_pca', then n_pcs doesn't really make sense. . This can actually be limiting, as I recently discovered. If you calculate a latent representation with scVI with `n_latent = 50`, you can't then do... ```python; sc.pp.neighbors(adata, use_rep='X_scvi', n_pcs = 25); ```. ...as the neighborhood graph is calculated on all 50 latent variables. If I want to use only 25 - say, as a point of comparison to see which best represents my data - I have to recalculate the latent representation with scVI with `n_latent = 25`. Basically, if you aren't using PCA, you have to calculate a full reduction for every number of dimensions you are interested in. . I don't think the fix would be that major. The source seems to be in the `_choose_representation` function, with the directly relevant snippet below:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L48-L58. I think the only change needed would be to have the `n_pcs is not None` catch in all cases, not just when `use_rep = 'X_pca'`. Might also generalise the variable name to make it more clear it refers to any reduction, not just PCA. Admittedly, I only just started exploring the code base, so I'm not sure where else `_choose_representation` is called, or what other impacts this could have. . I have some blue sky time tomorrow, so I'll fork it then and see if I can whip up a pull request. Thanks for the excellent product!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1281
https://github.com/scverse/scanpy/issues/1281:1510,Modifiability,variab,variable,1510,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; Sorry to file two issues in a row! I've been using Scanpy + scVI for my analysis recently, and am really enjoying it!. Currently, if use_rep is set in `sc.pp.neighbors`, then n_pcs is ignored. These seems like sane default behaviour to me - if we aren't using 'X_pca', then n_pcs doesn't really make sense. . This can actually be limiting, as I recently discovered. If you calculate a latent representation with scVI with `n_latent = 50`, you can't then do... ```python; sc.pp.neighbors(adata, use_rep='X_scvi', n_pcs = 25); ```. ...as the neighborhood graph is calculated on all 50 latent variables. If I want to use only 25 - say, as a point of comparison to see which best represents my data - I have to recalculate the latent representation with scVI with `n_latent = 25`. Basically, if you aren't using PCA, you have to calculate a full reduction for every number of dimensions you are interested in. . I don't think the fix would be that major. The source seems to be in the `_choose_representation` function, with the directly relevant snippet below:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L48-L58. I think the only change needed would be to have the `n_pcs is not None` catch in all cases, not just when `use_rep = 'X_pca'`. Might also generalise the variable name to make it more clear it refers to any reduction, not just PCA. Admittedly, I only just started exploring the code base, so I'm not sure where else `_choose_representation` is called, or what other impacts this could have. . I have some blue sky time tomorrow, so I'll fork it then and see if I can whip up a pull request. Thanks for the excellent product!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1281
https://github.com/scverse/scanpy/issues/1281:1540,Usability,clear,clear,1540,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; Sorry to file two issues in a row! I've been using Scanpy + scVI for my analysis recently, and am really enjoying it!. Currently, if use_rep is set in `sc.pp.neighbors`, then n_pcs is ignored. These seems like sane default behaviour to me - if we aren't using 'X_pca', then n_pcs doesn't really make sense. . This can actually be limiting, as I recently discovered. If you calculate a latent representation with scVI with `n_latent = 50`, you can't then do... ```python; sc.pp.neighbors(adata, use_rep='X_scvi', n_pcs = 25); ```. ...as the neighborhood graph is calculated on all 50 latent variables. If I want to use only 25 - say, as a point of comparison to see which best represents my data - I have to recalculate the latent representation with scVI with `n_latent = 25`. Basically, if you aren't using PCA, you have to calculate a full reduction for every number of dimensions you are interested in. . I don't think the fix would be that major. The source seems to be in the `_choose_representation` function, with the directly relevant snippet below:. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L48-L58. I think the only change needed would be to have the `n_pcs is not None` catch in all cases, not just when `use_rep = 'X_pca'`. Might also generalise the variable name to make it more clear it refers to any reduction, not just PCA. Admittedly, I only just started exploring the code base, so I'm not sure where else `_choose_representation` is called, or what other impacts this could have. . I have some blue sky time tomorrow, so I'll fork it then and see if I can whip up a pull request. Thanks for the excellent product!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1281
https://github.com/scverse/scanpy/issues/1282:847,Energy Efficiency,efficient,efficient,847,"Hi all, there are three packages I would like to suggest adding to the [scanpy ecosystem](https://scanpy.readthedocs.io/en/stable/ecosystem.html):. - [CellRank](https://cellrank.readthedocs.io/en/latest/): computing root, final and intermediate metastable states as well as lineage probabilities bases on RNA velocity. Fully compatible with scanpy and scvelo, well documented and scales to large cell numbers; - [scachepy](https://github.com/theislab/scachepy): caching the output of expensive scanpy/scvelo computations. Works with different backends (pickle etc). This is handy in a typical data analysis workflow where I have a couple of commands in my jupyter notebook which take very long to compute. This is more convenient then storing each attribute manually (many scanpy commands write to different `AnnData` attributes`) and more memory efficient than saving the entire `AnnData` object; - [interactive plotting](https://github.com/theislab/interactive_plotting): offers a set of interactive plotting functions based on bokeh and holoviews. Fully compatible with scanpy and scales to large cell numbers thanks to holoviews. Basically, it's a way to interactively work with your data from within a jupyter notebook. . Involved in the development of these three projects are @VolkerBergen , @michalk8 and myself.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1282
https://github.com/scverse/scanpy/issues/1283:149,Availability,error,error,149,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:334,Availability,Error,Error,334,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:1108,Testability,log,logging,1108,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1283:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283
https://github.com/scverse/scanpy/issues/1284:161,Availability,error,error,161,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:313,Availability,Error,Error,313,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:76,Deployability,install,installed,76,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:106,Deployability,install,install,106,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:942,Testability,log,logging,942,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:953,Testability,log,logg,953,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:1388,Testability,log,logging,1388,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1284:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284
https://github.com/scverse/scanpy/issues/1285:52,Availability,error,error,52,"When exporting a SPRING project I get the following error (NameError: name 'NeighborsView' is not defined ). 16 days ago a bug issue was closed related to this ( #1260 ), however I still encounter the bug when using both Scanpy 1.5.1 or 1.5.0; . **Input**:; ```import time; t0 = time.time(); sc.external.exporting.spring_project(adata, './SPRING',; 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; custom_color_tracks=['total_counts']); print(time.time() - t0); ```. **Output**: ; ```Writing subplot to SPRING\all; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-59-9c683583ff59> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sc.external.exporting.spring_project(adata, './SPRING',; 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### AnnData: ; ```AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1285:2389,Usability,learn,learn,2389,"print(time.time() - t0); ```. **Output**: ; ```Writing subplot to SPRING\all; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-59-9c683583ff59> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sc.external.exporting.spring_project(adata, './SPRING',; 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### AnnData: ; ```AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'connectivities', 'distances'; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.3.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285
https://github.com/scverse/scanpy/issues/1286:589,Availability,Error,Error,589,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:104,Deployability,install,installed,104,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:704,Testability,log,logging,704,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1286:825,Usability,learn,learn,825,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286
https://github.com/scverse/scanpy/issues/1287:515,Deployability,continuous,continuous,515,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am using Delaunay triangulation to give a continuous and smooth aspect for plotting values at 2D discrete points. I think it would be useful to have it in scanpy/episcanpy for plotting spatial gene expressions, on top of the scatter plot that is currently used. This can also be used for 3D plotting (3D transcriptomics, such as STARMAP, or even 3D epigenomics in the future). One can have the option of slicing the 3D volume image with a user defined plane position, etc... I can provide my scripts and would be happy to contribute. Thank you very much.; Adem Saglam (DZNE-Bonn, AG Schultze)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1287:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am using Delaunay triangulation to give a continuous and smooth aspect for plotting values at 2D discrete points. I think it would be useful to have it in scanpy/episcanpy for plotting spatial gene expressions, on top of the scatter plot that is currently used. This can also be used for 3D plotting (3D transcriptomics, such as STARMAP, or even 3D epigenomics in the future). One can have the option of slicing the 3D volume image with a user defined plane position, etc... I can provide my scripts and would be happy to contribute. Thank you very much.; Adem Saglam (DZNE-Bonn, AG Schultze)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287
https://github.com/scverse/scanpy/issues/1288:858,Availability,Error,Error,858,"<!-- Please give a clear and concise description of what the bug is: -->; In the `sc.tl.dendrogram` module, I noticed that the correlation matrix was directly inputted into the `scipy.cluster.hierarchy.linkage`. That results in calculating the distance between samples by the Euclidean(X1_cor_with_others, X2_cor_with_others). Shouldn't the distance be the pure correlation value here? Please correct me if I didn't understand it correctly. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; The one I would perfer; ```python; df = 1-adata.uns['dendrogram_sample']['correlation_matrix']; data_linkage = hierarchy.linkage(ssd.squareform(; df); ...; ```; The one currently in sc.tl.dendrogram; ```python; data_linkage = hierarchy.linkage(adata.uns['dendrogram_sample']['correlation_matrix']); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288
https://github.com/scverse/scanpy/issues/1288:992,Testability,log,logging,992,"<!-- Please give a clear and concise description of what the bug is: -->; In the `sc.tl.dendrogram` module, I noticed that the correlation matrix was directly inputted into the `scipy.cluster.hierarchy.linkage`. That results in calculating the distance between samples by the Euclidean(X1_cor_with_others, X2_cor_with_others). Shouldn't the distance be the pure correlation value here? Please correct me if I didn't understand it correctly. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; The one I would perfer; ```python; df = 1-adata.uns['dendrogram_sample']['correlation_matrix']; data_linkage = hierarchy.linkage(ssd.squareform(; df); ...; ```; The one currently in sc.tl.dendrogram; ```python; data_linkage = hierarchy.linkage(adata.uns['dendrogram_sample']['correlation_matrix']); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288
https://github.com/scverse/scanpy/issues/1288:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; In the `sc.tl.dendrogram` module, I noticed that the correlation matrix was directly inputted into the `scipy.cluster.hierarchy.linkage`. That results in calculating the distance between samples by the Euclidean(X1_cor_with_others, X2_cor_with_others). Shouldn't the distance be the pure correlation value here? Please correct me if I didn't understand it correctly. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; The one I would perfer; ```python; df = 1-adata.uns['dendrogram_sample']['correlation_matrix']; data_linkage = hierarchy.linkage(ssd.squareform(; df); ...; ```; The one currently in sc.tl.dendrogram; ```python; data_linkage = hierarchy.linkage(adata.uns['dendrogram_sample']['correlation_matrix']); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288
https://github.com/scverse/scanpy/issues/1289:858,Energy Efficiency,reduce,reduce,858,"<!-- What kind of feature would you like to request? -->; - [ X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?. <!-- Please describe your wishes below: -->; It may be useful to adopt a PCA option similar to **`multiBatchPCA`** in the R batchelor package.; This is a useful approach where there are imbalances in batch size and PCA is conducted across a merged experiment.; It is pretty slow in R. From their documentation:. > ; > _""Our approach is to effectively weight the cells in each batch to mimic the situation where all batches; > have the same number of cells. This ensures that the low-dimensional space can distinguish subpopulations in smaller batches. Otherwise, batches with a large number of cells would dominate; > the PCA, i.e., the definition of the mean vector and covariance matrix. This may reduce resolution; > of unique subpopulations in smaller batches that differ in a different dimension to the subspace of; > the larger batches.""_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/issues/1289:86,Usability,simpl,simple,86,"<!-- What kind of feature would you like to request? -->; - [ X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?. <!-- Please describe your wishes below: -->; It may be useful to adopt a PCA option similar to **`multiBatchPCA`** in the R batchelor package.; This is a useful approach where there are imbalances in batch size and PCA is conducted across a merged experiment.; It is pretty slow in R. From their documentation:. > ; > _""Our approach is to effectively weight the cells in each batch to mimic the situation where all batches; > have the same number of cells. This ensures that the low-dimensional space can distinguish subpopulations in smaller batches. Otherwise, batches with a large number of cells would dominate; > the PCA, i.e., the definition of the mean vector and covariance matrix. This may reduce resolution; > of unique subpopulations in smaller batches that differ in a different dimension to the subspace of; > the larger batches.""_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289
https://github.com/scverse/scanpy/pull/1290:102,Availability,error,error,102,Simplification of _ranks in rang_genes_groups. Passing pandas index to scipy dendrogram now causes an error. This fixes the problem.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1290
https://github.com/scverse/scanpy/pull/1290:0,Usability,Simpl,Simplification,0,Simplification of _ranks in rang_genes_groups. Passing pandas index to scipy dendrogram now causes an error. This fixes the problem.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1290
https://github.com/scverse/scanpy/issues/1291:688,Availability,Error,Error,688,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291
https://github.com/scverse/scanpy/issues/1291:970,Testability,log,logging,970,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291
https://github.com/scverse/scanpy/issues/1291:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291
https://github.com/scverse/scanpy/issues/1291:1092,Usability,learn,learn,1092,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291
https://github.com/scverse/scanpy/issues/1292:399,Deployability,update,update,399,"A description of the ""key"" argument is missing from the documentation for the rank_genes_groups plotting function located at https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.rank_genes_groups.html#scanpy.pl.rank_genes_groups. Without this, it's unclear how to plot the results of an alternative differential expression analysis (which is not stored in uns.rank_genes_groups). Would be great to update the documentation to include it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292
https://github.com/scverse/scanpy/issues/1293:276,Availability,error,error,276,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:431,Deployability,install,installing,431,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:589,Deployability,update,updates,589,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:600,Deployability,install,installed,600,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:699,Deployability,install,installation,699,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:724,Deployability,install,installed,724,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:481,Integrability,depend,dependencies,481,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:7086,Integrability,wrap,wrap,7086,1 he4413a7_1000 conda-forge; freetype 2.10.2 he06d7ca_0 conda-forge; get-version 2.1 pypi_0 pypi; glib 2.63.1 h3eb4bd4_1 ; gst-plugins-base 1.14.0 hbbd80ab_1 ; gstreamer 1.14.0 hb31296c_0 ; h5py 2.10.0 pypi_0 pypi; hdf5 1.10.4 hb1b8bf9_0 ; icu 58.2 hf484d3e_1000 conda-forge; importlib-metadata 1.6.1 py36h9f0ad1d_0 conda-forge; importlib_metadata 1.6.1 0 conda-forge; intel-openmp 2020.1 217 ; ipyevents 0.7.1 py_0 conda-forge; ipykernel 5.3.0 py36h95af2a2_0 conda-forge; ipython 7.15.0 py36h9f0ad1d_0 conda-forge; ipython_genutils 0.2.0 py_1 conda-forge; ipywidgets 7.5.1 py_0 conda-forge; jedi 0.17.1 py36h9f0ad1d_0 conda-forge; jinja2 2.11.2 pyh9f0ad1d_0 conda-forge; joblib 0.15.1 py_0 ; jpeg 9d h516909a_0 conda-forge; jsonschema 3.2.0 py36h9f0ad1d_1 conda-forge; jupyter 1.0.0 py_2 conda-forge; jupyter_client 6.1.3 py_0 conda-forge; jupyter_console 6.1.0 py_1 conda-forge; jupyter_core 4.6.3 py36h9f0ad1d_1 conda-forge; kiwisolver 1.2.0 py36hfd86e86_0 ; ld_impl_linux-64 2.33.1 h53a641e_7 ; legacy-api-wrap 1.2 pypi_0 pypi; leidenalg 0.8.0 pypi_0 pypi; libedit 3.1.20191231 h7b6447c_0 ; libffi 3.3 he6710b0_1 ; libgcc-ng 9.1.0 hdf63c60_0 ; libgfortran-ng 7.3.0 hdf63c60_0 ; libpng 1.6.37 hed695b0_1 conda-forge; libsodium 1.0.17 h516909a_0 conda-forge; libstdcxx-ng 9.1.0 hdf63c60_0 ; libuuid 2.32.1 h14c3975_1000 conda-forge; libxcb 1.13 h14c3975_1002 conda-forge; libxml2 2.9.10 he19cac6_1 ; llvmlite 0.33.0 pypi_0 pypi; lz4-c 1.9.2 he6710b0_0 ; lzo 2.10 h7b6447c_2 ; markupsafe 1.1.1 py36h8c4c3a4_1 conda-forge; matplotlib 3.2.2 0 ; matplotlib-base 3.2.2 py36hef1b27d_0 ; mistune 0.8.4 py36h8c4c3a4_1001 conda-forge; mkl 2020.1 217 ; mkl-service 2.3.0 py36he904b0f_0 ; mkl_fft 1.1.0 py36h23d657b_0 ; mkl_random 1.1.1 py36h0573a6f_0 ; mock 4.0.2 py_0 ; natsort 7.0.1 pypi_0 pypi; nbconvert 5.6.1 py36h9f0ad1d_1 conda-forge; nbformat 5.0.6 py_0 conda-forge; ncurses 6.2 he6710b0_1 ; networkx 2.4 pypi_0 pypi; notebook 6.0.3 py36h9f0ad1d_0 conda-forge; numba 0.50.0 pypi_0 pypi; numexpr 2.7.1 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:6203,Modifiability,plugin,plugins-base,6203,"on3.6/site-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so in View.MemoryView.memoryview.__cinit__(). TypeError: a bytes-like object is required, not 'list'; ```. Conda list output. ```; # packages in environment at /wynton/home/state/alkhairohr/miniconda3/envs/python_env:; #; # Name Version Build Channel; _libgcc_mutex 0.1 main ; anndata 0.7.3 pypi_0 pypi; attrs 19.3.0 py_0 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; blas 1.0 mkl ; bleach 3.1.5 pyh9f0ad1d_0 conda-forge; blosc 1.19.0 hd408876_0 ; bzip2 1.0.8 h7b6447c_0 ; ca-certificates 2020.1.1 0 ; certifi 2020.6.20 py36_0 ; colorlover 0.3.0 py_0 conda-forge; cycler 0.10.0 py36_0 ; dbus 1.13.6 he372182_0 conda-forge; decorator 4.4.2 py_0 conda-forge; defusedxml 0.6.0 py_0 conda-forge; entrypoints 0.3 py36h9f0ad1d_1001 conda-forge; expat 2.2.9 he1b5a44_2 conda-forge; fontconfig 2.13.1 he4413a7_1000 conda-forge; freetype 2.10.2 he06d7ca_0 conda-forge; get-version 2.1 pypi_0 pypi; glib 2.63.1 h3eb4bd4_1 ; gst-plugins-base 1.14.0 hbbd80ab_1 ; gstreamer 1.14.0 hb31296c_0 ; h5py 2.10.0 pypi_0 pypi; hdf5 1.10.4 hb1b8bf9_0 ; icu 58.2 hf484d3e_1000 conda-forge; importlib-metadata 1.6.1 py36h9f0ad1d_0 conda-forge; importlib_metadata 1.6.1 0 conda-forge; intel-openmp 2020.1 217 ; ipyevents 0.7.1 py_0 conda-forge; ipykernel 5.3.0 py36h95af2a2_0 conda-forge; ipython 7.15.0 py36h9f0ad1d_0 conda-forge; ipython_genutils 0.2.0 py_1 conda-forge; ipywidgets 7.5.1 py_0 conda-forge; jedi 0.17.1 py36h9f0ad1d_0 conda-forge; jinja2 2.11.2 pyh9f0ad1d_0 conda-forge; joblib 0.15.1 py_0 ; jpeg 9d h516909a_0 conda-forge; jsonschema 3.2.0 py36h9f0ad1d_1 conda-forge; jupyter 1.0.0 py_2 conda-forge; jupyter_client 6.1.3 py_0 conda-forge; jupyter_console 6.1.0 py_1 conda-forge; jupyter_core 4.6.3 py36h9f0ad1d_1 conda-forge; kiwisolver 1.2.0 py36hfd86e86_0 ; ld_impl_linux-64 2.33.1 h53a641e_7 ; legacy-api-wrap 1.2 pypi_0 pypi; leidenalg 0.8.0 pypi_0 pypi; libedit 3.1.20191231 h7b6447c_0 ; libffi 3.3 he6710b0_1 ; libgcc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:5761,Security,certificate,certificates,5761,"ptr = np.empty(M + 1, dtype=idx_dtype); 461 indptr[0] = 0; --> 462 _csparsetools.lil_get_lengths(self.rows, indptr[1:]); 463 np.cumsum(indptr, out=indptr); 464 nnz = indptr[-1]. _csparsetools.pyx in scipy.sparse._csparsetools.lil_get_lengths(). ~/miniconda3/envs/python_env/lib/python3.6/site-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so in View.MemoryView.memoryview_cwrapper(). ~/miniconda3/envs/python_env/lib/python3.6/site-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so in View.MemoryView.memoryview.__cinit__(). TypeError: a bytes-like object is required, not 'list'; ```. Conda list output. ```; # packages in environment at /wynton/home/state/alkhairohr/miniconda3/envs/python_env:; #; # Name Version Build Channel; _libgcc_mutex 0.1 main ; anndata 0.7.3 pypi_0 pypi; attrs 19.3.0 py_0 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; blas 1.0 mkl ; bleach 3.1.5 pyh9f0ad1d_0 conda-forge; blosc 1.19.0 hd408876_0 ; bzip2 1.0.8 h7b6447c_0 ; ca-certificates 2020.1.1 0 ; certifi 2020.6.20 py36_0 ; colorlover 0.3.0 py_0 conda-forge; cycler 0.10.0 py36_0 ; dbus 1.13.6 he372182_0 conda-forge; decorator 4.4.2 py_0 conda-forge; defusedxml 0.6.0 py_0 conda-forge; entrypoints 0.3 py36h9f0ad1d_1001 conda-forge; expat 2.2.9 he1b5a44_2 conda-forge; fontconfig 2.13.1 he4413a7_1000 conda-forge; freetype 2.10.2 he06d7ca_0 conda-forge; get-version 2.1 pypi_0 pypi; glib 2.63.1 h3eb4bd4_1 ; gst-plugins-base 1.14.0 hbbd80ab_1 ; gstreamer 1.14.0 hb31296c_0 ; h5py 2.10.0 pypi_0 pypi; hdf5 1.10.4 hb1b8bf9_0 ; icu 58.2 hf484d3e_1000 conda-forge; importlib-metadata 1.6.1 py36h9f0ad1d_0 conda-forge; importlib_metadata 1.6.1 0 conda-forge; intel-openmp 2020.1 217 ; ipyevents 0.7.1 py_0 conda-forge; ipykernel 5.3.0 py36h95af2a2_0 conda-forge; ipython 7.15.0 py36h9f0ad1d_0 conda-forge; ipython_genutils 0.2.0 py_1 conda-forge; ipywidgets 7.5.1 py_0 conda-forge; jedi 0.17.1 py36h9f0ad1d_0 conda-forge; jinja2 2.11.2 pyh9f0ad1d_0 conda-forge; joblib 0.15.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:7821,Testability,mock,mock,7821,.0 py36h9f0ad1d_1 conda-forge; jupyter 1.0.0 py_2 conda-forge; jupyter_client 6.1.3 py_0 conda-forge; jupyter_console 6.1.0 py_1 conda-forge; jupyter_core 4.6.3 py36h9f0ad1d_1 conda-forge; kiwisolver 1.2.0 py36hfd86e86_0 ; ld_impl_linux-64 2.33.1 h53a641e_7 ; legacy-api-wrap 1.2 pypi_0 pypi; leidenalg 0.8.0 pypi_0 pypi; libedit 3.1.20191231 h7b6447c_0 ; libffi 3.3 he6710b0_1 ; libgcc-ng 9.1.0 hdf63c60_0 ; libgfortran-ng 7.3.0 hdf63c60_0 ; libpng 1.6.37 hed695b0_1 conda-forge; libsodium 1.0.17 h516909a_0 conda-forge; libstdcxx-ng 9.1.0 hdf63c60_0 ; libuuid 2.32.1 h14c3975_1000 conda-forge; libxcb 1.13 h14c3975_1002 conda-forge; libxml2 2.9.10 he19cac6_1 ; llvmlite 0.33.0 pypi_0 pypi; lz4-c 1.9.2 he6710b0_0 ; lzo 2.10 h7b6447c_2 ; markupsafe 1.1.1 py36h8c4c3a4_1 conda-forge; matplotlib 3.2.2 0 ; matplotlib-base 3.2.2 py36hef1b27d_0 ; mistune 0.8.4 py36h8c4c3a4_1001 conda-forge; mkl 2020.1 217 ; mkl-service 2.3.0 py36he904b0f_0 ; mkl_fft 1.1.0 py36h23d657b_0 ; mkl_random 1.1.1 py36h0573a6f_0 ; mock 4.0.2 py_0 ; natsort 7.0.1 pypi_0 pypi; nbconvert 5.6.1 py36h9f0ad1d_1 conda-forge; nbformat 5.0.6 py_0 conda-forge; ncurses 6.2 he6710b0_1 ; networkx 2.4 pypi_0 pypi; notebook 6.0.3 py36h9f0ad1d_0 conda-forge; numba 0.50.0 pypi_0 pypi; numexpr 2.7.1 py36h423224d_0 ; numpy 1.19.0 pypi_0 pypi; numpy-base 1.18.5 py36hde5b4d6_0 ; openssl 1.1.1g h7b6447c_0 ; packaging 20.4 pyh9f0ad1d_0 conda-forge; pandas 1.0.5 py36h0573a6f_0 ; pandoc 2.9.2.1 0 conda-forge; pandocfilters 1.4.2 py_1 conda-forge; parso 0.7.0 pyh9f0ad1d_0 conda-forge; patsy 0.5.1 py36_0 ; pcre 8.44 he1b5a44_0 conda-forge; pexpect 4.8.0 py36h9f0ad1d_1 conda-forge; pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge; pip 20.1.1 py36_1 ; plotly 4.0.0 py_0 plotly; prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge; prompt-toolkit 3.0.5 py_1 conda-forge; prompt_toolkit 3.0.5 1 conda-forge; pthread-stubs 0.4 h14c3975_1001 conda-forge; ptyprocess 0.6.0 py_1001 conda-forge; pygments 2.6.1 py_0 conda-forge; pyparsing 2.4.7 pyh9f0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:8685,Testability,stub,stubs,8685,6h8c4c3a4_1001 conda-forge; mkl 2020.1 217 ; mkl-service 2.3.0 py36he904b0f_0 ; mkl_fft 1.1.0 py36h23d657b_0 ; mkl_random 1.1.1 py36h0573a6f_0 ; mock 4.0.2 py_0 ; natsort 7.0.1 pypi_0 pypi; nbconvert 5.6.1 py36h9f0ad1d_1 conda-forge; nbformat 5.0.6 py_0 conda-forge; ncurses 6.2 he6710b0_1 ; networkx 2.4 pypi_0 pypi; notebook 6.0.3 py36h9f0ad1d_0 conda-forge; numba 0.50.0 pypi_0 pypi; numexpr 2.7.1 py36h423224d_0 ; numpy 1.19.0 pypi_0 pypi; numpy-base 1.18.5 py36hde5b4d6_0 ; openssl 1.1.1g h7b6447c_0 ; packaging 20.4 pyh9f0ad1d_0 conda-forge; pandas 1.0.5 py36h0573a6f_0 ; pandoc 2.9.2.1 0 conda-forge; pandocfilters 1.4.2 py_1 conda-forge; parso 0.7.0 pyh9f0ad1d_0 conda-forge; patsy 0.5.1 py36_0 ; pcre 8.44 he1b5a44_0 conda-forge; pexpect 4.8.0 py36h9f0ad1d_1 conda-forge; pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge; pip 20.1.1 py36_1 ; plotly 4.0.0 py_0 plotly; prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge; prompt-toolkit 3.0.5 py_1 conda-forge; prompt_toolkit 3.0.5 1 conda-forge; pthread-stubs 0.4 h14c3975_1001 conda-forge; ptyprocess 0.6.0 py_1001 conda-forge; pygments 2.6.1 py_0 conda-forge; pyparsing 2.4.7 pyh9f0ad1d_0 conda-forge; pyqt 5.9.2 py36hcca6a23_4 conda-forge; pyrsistent 0.16.0 py36h8c4c3a4_0 conda-forge; pytables 3.6.1 py36h71ec239_0 ; python 3.6.10 h7579374_2 ; python-dateutil 2.8.1 py_0 conda-forge; python-igraph 0.8.2 pypi_0 pypi; python_abi 3.6 1_cp36m conda-forge; pytz 2020.1 py_0 ; pyzmq 19.0.1 py36h9947dbf_0 conda-forge; qt 5.9.7 h5867ecd_1 ; qtconsole 4.7.5 pyh9f0ad1d_0 conda-forge; qtpy 1.9.0 py_0 conda-forge; readline 8.0 h7b6447c_0 ; retrying 1.3.3 py_2 conda-forge; sam-algorithm 0.7.3 pypi_0 pypi; scanpy 1.5.1 pypi_0 pypi; scikit-learn 0.23.1 py36h423224d_0 ; scipy 1.5.0 py36h0b6359f_0 ; seaborn 0.10.1 py_0 ; send2trash 1.5.0 py_0 conda-forge; setuptools 47.3.1 py36_0 ; setuptools-scm 4.1.2 pypi_0 pypi; sip 4.19.8 py36hf484d3e_0 ; six 1.15.0 pyh9f0ad1d_0 conda-forge; snappy 1.1.8 he6710b0_0 ; sqlite 3.32.3 h62c20be_0 ; statsmodels 0.11,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:9769,Testability,test,testpath,9769,0 conda-forge; pexpect 4.8.0 py36h9f0ad1d_1 conda-forge; pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge; pip 20.1.1 py36_1 ; plotly 4.0.0 py_0 plotly; prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge; prompt-toolkit 3.0.5 py_1 conda-forge; prompt_toolkit 3.0.5 1 conda-forge; pthread-stubs 0.4 h14c3975_1001 conda-forge; ptyprocess 0.6.0 py_1001 conda-forge; pygments 2.6.1 py_0 conda-forge; pyparsing 2.4.7 pyh9f0ad1d_0 conda-forge; pyqt 5.9.2 py36hcca6a23_4 conda-forge; pyrsistent 0.16.0 py36h8c4c3a4_0 conda-forge; pytables 3.6.1 py36h71ec239_0 ; python 3.6.10 h7579374_2 ; python-dateutil 2.8.1 py_0 conda-forge; python-igraph 0.8.2 pypi_0 pypi; python_abi 3.6 1_cp36m conda-forge; pytz 2020.1 py_0 ; pyzmq 19.0.1 py36h9947dbf_0 conda-forge; qt 5.9.7 h5867ecd_1 ; qtconsole 4.7.5 pyh9f0ad1d_0 conda-forge; qtpy 1.9.0 py_0 conda-forge; readline 8.0 h7b6447c_0 ; retrying 1.3.3 py_2 conda-forge; sam-algorithm 0.7.3 pypi_0 pypi; scanpy 1.5.1 pypi_0 pypi; scikit-learn 0.23.1 py36h423224d_0 ; scipy 1.5.0 py36h0b6359f_0 ; seaborn 0.10.1 py_0 ; send2trash 1.5.0 py_0 conda-forge; setuptools 47.3.1 py36_0 ; setuptools-scm 4.1.2 pypi_0 pypi; sip 4.19.8 py36hf484d3e_0 ; six 1.15.0 pyh9f0ad1d_0 conda-forge; snappy 1.1.8 he6710b0_0 ; sqlite 3.32.3 h62c20be_0 ; statsmodels 0.11.1 py36h7b6447c_0 ; tbb 2020.0.133 pypi_0 pypi; terminado 0.8.3 py36h9f0ad1d_1 conda-forge; testpath 0.4.4 py_0 conda-forge; texttable 1.6.2 pypi_0 pypi; threadpoolctl 2.1.0 pyh5ca1d4c_0 ; tk 8.6.10 hbc83047_0 ; tornado 6.0.4 py36h8c4c3a4_1 conda-forge; tqdm 4.46.1 pypi_0 pypi; traitlets 4.3.3 py36h9f0ad1d_1 conda-forge; umap-learn 0.4.4 pypi_0 pypi; wcwidth 0.2.5 pyh9f0ad1d_0 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.34.2 py36_0 ; widgetsnbextension 3.5.1 py36_0 conda-forge; xorg-libxau 1.0.9 h14c3975_0 conda-forge; xorg-libxdmcp 1.1.3 h516909a_0 conda-forge; xz 5.2.5 h7b6447c_0 ; zeromq 4.3.2 he1b5a44_2 conda-forge; zipp 3.1.0 py_0 conda-forge; zlib 1.2.11 h7b6447c_3 ; zstd 1.4.4 h0b5b093_3 ; ```,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:9366,Usability,learn,learn,9366, patsy 0.5.1 py36_0 ; pcre 8.44 he1b5a44_0 conda-forge; pexpect 4.8.0 py36h9f0ad1d_1 conda-forge; pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge; pip 20.1.1 py36_1 ; plotly 4.0.0 py_0 plotly; prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge; prompt-toolkit 3.0.5 py_1 conda-forge; prompt_toolkit 3.0.5 1 conda-forge; pthread-stubs 0.4 h14c3975_1001 conda-forge; ptyprocess 0.6.0 py_1001 conda-forge; pygments 2.6.1 py_0 conda-forge; pyparsing 2.4.7 pyh9f0ad1d_0 conda-forge; pyqt 5.9.2 py36hcca6a23_4 conda-forge; pyrsistent 0.16.0 py36h8c4c3a4_0 conda-forge; pytables 3.6.1 py36h71ec239_0 ; python 3.6.10 h7579374_2 ; python-dateutil 2.8.1 py_0 conda-forge; python-igraph 0.8.2 pypi_0 pypi; python_abi 3.6 1_cp36m conda-forge; pytz 2020.1 py_0 ; pyzmq 19.0.1 py36h9947dbf_0 conda-forge; qt 5.9.7 h5867ecd_1 ; qtconsole 4.7.5 pyh9f0ad1d_0 conda-forge; qtpy 1.9.0 py_0 conda-forge; readline 8.0 h7b6447c_0 ; retrying 1.3.3 py_2 conda-forge; sam-algorithm 0.7.3 pypi_0 pypi; scanpy 1.5.1 pypi_0 pypi; scikit-learn 0.23.1 py36h423224d_0 ; scipy 1.5.0 py36h0b6359f_0 ; seaborn 0.10.1 py_0 ; send2trash 1.5.0 py_0 conda-forge; setuptools 47.3.1 py36_0 ; setuptools-scm 4.1.2 pypi_0 pypi; sip 4.19.8 py36hf484d3e_0 ; six 1.15.0 pyh9f0ad1d_0 conda-forge; snappy 1.1.8 he6710b0_0 ; sqlite 3.32.3 h62c20be_0 ; statsmodels 0.11.1 py36h7b6447c_0 ; tbb 2020.0.133 pypi_0 pypi; terminado 0.8.3 py36h9f0ad1d_1 conda-forge; testpath 0.4.4 py_0 conda-forge; texttable 1.6.2 pypi_0 pypi; threadpoolctl 2.1.0 pyh5ca1d4c_0 ; tk 8.6.10 hbc83047_0 ; tornado 6.0.4 py36h8c4c3a4_1 conda-forge; tqdm 4.46.1 pypi_0 pypi; traitlets 4.3.3 py36h9f0ad1d_1 conda-forge; umap-learn 0.4.4 pypi_0 pypi; wcwidth 0.2.5 pyh9f0ad1d_0 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.34.2 py36_0 ; widgetsnbextension 3.5.1 py36_0 conda-forge; xorg-libxau 1.0.9 h14c3975_0 conda-forge; xorg-libxdmcp 1.1.3 h516909a_0 conda-forge; xz 5.2.5 h7b6447c_0 ; zeromq 4.3.2 he1b5a44_2 conda-forge; zipp 3.1.0 py_0 conda-forge; zlib 1.2.11,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1293:10005,Usability,learn,learn,10005,0 conda-forge; pexpect 4.8.0 py36h9f0ad1d_1 conda-forge; pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge; pip 20.1.1 py36_1 ; plotly 4.0.0 py_0 plotly; prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge; prompt-toolkit 3.0.5 py_1 conda-forge; prompt_toolkit 3.0.5 1 conda-forge; pthread-stubs 0.4 h14c3975_1001 conda-forge; ptyprocess 0.6.0 py_1001 conda-forge; pygments 2.6.1 py_0 conda-forge; pyparsing 2.4.7 pyh9f0ad1d_0 conda-forge; pyqt 5.9.2 py36hcca6a23_4 conda-forge; pyrsistent 0.16.0 py36h8c4c3a4_0 conda-forge; pytables 3.6.1 py36h71ec239_0 ; python 3.6.10 h7579374_2 ; python-dateutil 2.8.1 py_0 conda-forge; python-igraph 0.8.2 pypi_0 pypi; python_abi 3.6 1_cp36m conda-forge; pytz 2020.1 py_0 ; pyzmq 19.0.1 py36h9947dbf_0 conda-forge; qt 5.9.7 h5867ecd_1 ; qtconsole 4.7.5 pyh9f0ad1d_0 conda-forge; qtpy 1.9.0 py_0 conda-forge; readline 8.0 h7b6447c_0 ; retrying 1.3.3 py_2 conda-forge; sam-algorithm 0.7.3 pypi_0 pypi; scanpy 1.5.1 pypi_0 pypi; scikit-learn 0.23.1 py36h423224d_0 ; scipy 1.5.0 py36h0b6359f_0 ; seaborn 0.10.1 py_0 ; send2trash 1.5.0 py_0 conda-forge; setuptools 47.3.1 py36_0 ; setuptools-scm 4.1.2 pypi_0 pypi; sip 4.19.8 py36hf484d3e_0 ; six 1.15.0 pyh9f0ad1d_0 conda-forge; snappy 1.1.8 he6710b0_0 ; sqlite 3.32.3 h62c20be_0 ; statsmodels 0.11.1 py36h7b6447c_0 ; tbb 2020.0.133 pypi_0 pypi; terminado 0.8.3 py36h9f0ad1d_1 conda-forge; testpath 0.4.4 py_0 conda-forge; texttable 1.6.2 pypi_0 pypi; threadpoolctl 2.1.0 pyh5ca1d4c_0 ; tk 8.6.10 hbc83047_0 ; tornado 6.0.4 py36h8c4c3a4_1 conda-forge; tqdm 4.46.1 pypi_0 pypi; traitlets 4.3.3 py36h9f0ad1d_1 conda-forge; umap-learn 0.4.4 pypi_0 pypi; wcwidth 0.2.5 pyh9f0ad1d_0 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.34.2 py36_0 ; widgetsnbextension 3.5.1 py36_0 conda-forge; xorg-libxau 1.0.9 h14c3975_0 conda-forge; xorg-libxdmcp 1.1.3 h516909a_0 conda-forge; xz 5.2.5 h7b6447c_0 ; zeromq 4.3.2 he1b5a44_2 conda-forge; zipp 3.1.0 py_0 conda-forge; zlib 1.2.11 h7b6447c_3 ; zstd 1.4.4 h0b5b093_3 ; ```,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293
https://github.com/scverse/scanpy/issues/1294:273,Availability,error,errors,273,"In the documentation (https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html) the figure given as an example for pl.violin does not match the actual output of pl.violin (rather, it's showing a stacked violin). If there's a more appropriate place for me to record errors in the documentation, please let me know. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1294
https://github.com/scverse/scanpy/issues/1295:114,Availability,error,error,114,"<!-- Please give a clear and concise description of what the bug is: -->; I was plotting the paga path, I got the error of TypeError: float() argument must be a string or a number, not 'csr_matrix'. I guess this might be related with the sparse format of adata.raw.X, because my codes works if I deleted adata.raw. What would be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 excep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:1187,Availability,Error,Error,1187,"ould be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:2023,Integrability,wrap,wrap,2023,"python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:2105,Integrability,wrap,wrap,2105,"python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:2253,Testability,log,logging,2253,"python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I was plotting the paga path, I got the error of TypeError: float() argument must be a string or a number, not 'csr_matrix'. I guess this might be related with the sparse format of adata.raw.X, because my codes works if I deleted adata.raw. What would be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 excep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/issues/1295:2374,Usability,learn,learn,2374,"python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295
https://github.com/scverse/scanpy/pull/1296:20,Availability,down,downloading,20,This is helpful for downloading datasets from the 10x website and generally fixes #1264.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296
https://github.com/scverse/scanpy/issues/1298:42,Availability,error,error,42,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:799,Availability,Avail,Available,799,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:6,Deployability,install,installation,6,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:49,Deployability,Install,Installation,49,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:83,Deployability,install,install,83,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1023,Deployability,install,installs,1023,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:1066,Deployability,install,install,1066,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:258,Modifiability,flexible,flexible,258,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:504,Modifiability,flexible,flexible,504,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:646,Safety,abort,abort,646,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1298:975,Security,validat,validate,975,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298
https://github.com/scverse/scanpy/issues/1299:871,Testability,log,logging,871,"<!-- Please give a clear and concise description of what the bug is: -->; It seems the sc.tl.draw_graph() method fix the layout to 'fr' regardless of the input parameter? So I'm unable to use other method to produce the layout. . I'm using an example data from your tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata, layout='fa'); adata.obsm; ```. Although I set layout to 'fa', the output is still a 'fr' layout?. ```; AxisArrays with keys: X_pca, X_draw_graph_fr; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.3.10 numpy==1.17.4 scipy==1.4.1 pandas==1.0.0 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1299
https://github.com/scverse/scanpy/issues/1299:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; It seems the sc.tl.draw_graph() method fix the layout to 'fr' regardless of the input parameter? So I'm unable to use other method to produce the layout. . I'm using an example data from your tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata, layout='fa'); adata.obsm; ```. Although I set layout to 'fa', the output is still a 'fr' layout?. ```; AxisArrays with keys: X_pca, X_draw_graph_fr; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.3.10 numpy==1.17.4 scipy==1.4.1 pandas==1.0.0 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1299
https://github.com/scverse/scanpy/issues/1299:993,Usability,learn,learn,993,"<!-- Please give a clear and concise description of what the bug is: -->; It seems the sc.tl.draw_graph() method fix the layout to 'fr' regardless of the input parameter? So I'm unable to use other method to produce the layout. . I'm using an example data from your tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata, layout='fa'); adata.obsm; ```. Although I set layout to 'fa', the output is still a 'fr' layout?. ```; AxisArrays with keys: X_pca, X_draw_graph_fr; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.3.10 numpy==1.17.4 scipy==1.4.1 pandas==1.0.0 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1299
https://github.com/scverse/scanpy/issues/1300:38,Deployability,update,update,38,"I think with a recent numpy or Pandas update, an if clause in sc.tl.dendrogram no longer works properly. . ```python; import numpy as np; import pandas as pd; import scanpy as sc. # Use pbmc3k dataset; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.normalize_total(adata); sc.pp.highly_variable_genes(adata); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata); sc.tl.rank_genes_groups(adata, groupby='leiden'). # Save the ranks.; results_dict = dict(); for cluster_i in adata.uns['rank_genes_groups']['names'].dtype.names:; # print(cluster_i); # Get keys that we want from the dataframe.; data_keys = list(; set(['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj']) &; set(adata.uns['rank_genes_groups'].keys()); ); # Build a table using these keys.; key_i = data_keys.pop(); results_dict[cluster_i] = pd.DataFrame(; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ); results_dict[cluster_i].columns = [key_i]; for key_i in data_keys:; results_dict[cluster_i][key_i] = [; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ]; results_dict[cluster_i]['cluster'] = cluster_i; marker_df = pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:694,Testability,log,logfoldchanges,694,"I think with a recent numpy or Pandas update, an if clause in sc.tl.dendrogram no longer works properly. . ```python; import numpy as np; import pandas as pd; import scanpy as sc. # Use pbmc3k dataset; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.normalize_total(adata); sc.pp.highly_variable_genes(adata); sc.tl.pca(adata); sc.pp.neighbors(adata); sc.tl.leiden(adata); sc.tl.rank_genes_groups(adata, groupby='leiden'). # Save the ranks.; results_dict = dict(); for cluster_i in adata.uns['rank_genes_groups']['names'].dtype.names:; # print(cluster_i); # Get keys that we want from the dataframe.; data_keys = list(; set(['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj']) &; set(adata.uns['rank_genes_groups'].keys()); ); # Build a table using these keys.; key_i = data_keys.pop(); results_dict[cluster_i] = pd.DataFrame(; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ); results_dict[cluster_i].columns = [key_i]; for key_i in data_keys:; results_dict[cluster_i][key_i] = [; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ]; results_dict[cluster_i]['cluster'] = cluster_i; marker_df = pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:1608,Testability,test,test,1608,"keys that we want from the dataframe.; data_keys = list(; set(['names', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj']) &; set(adata.uns['rank_genes_groups'].keys()); ); # Build a table using these keys.; key_i = data_keys.pop(); results_dict[cluster_i] = pd.DataFrame(; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ); results_dict[cluster_i].columns = [key_i]; for key_i in data_keys:; results_dict[cluster_i][key_i] = [; row[cluster_i] for row in adata.uns['rank_genes_groups'][key_i]; ]; results_dict[cluster_i]['cluster'] = cluster_i; marker_df = pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order of groupby categories. /lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276; -> 3277 if labels and Z.shape[0] + 1 != len(labels):; 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""); 3279. /lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self); 2148 def __nonzero__(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1300:2996,Usability,learn,learn,2996,"pd.concat(results_dict, ignore_index=True). marker_df = marker_df.sort_values(by=['scores'], ascending=False); # Make dataframe of the top 3 markers per cluster; marker_df_plt = marker_df.groupby('cluster').head(3); ; # here sc.tl.dendrogram will fail; _ = sc.pl.dotplot(; adata,; var_names=marker_df_plt['names'],; groupby='leiden',; dendrogram=True,; use_raw=False,; show=False,; color_map='Blues'; save='{}.png'.format('test'); ); ```. ```pytb; /lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133; 134 # order of groupby categories. /lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276; -> 3277 if labels and Z.shape[0] + 1 != len(labels):; 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""); 3279. /lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self); 2148 def __nonzero__(self):; 2149 raise ValueError(; -> 2150 f""The truth value of a {type(self).__name__} is ambiguous. ""; 2151 ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""; 2152 ). ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.17.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1. Conda environment is attached. ; [environment.txt](https://github.com/theislab/scanpy/files/4857757/environment.txt)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300
https://github.com/scverse/scanpy/issues/1301:493,Modifiability,layers,layers,493,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I find using the `adata.layers` really useful to compare normalisation strategies. I'd like to also be able to seamlessly run `sc.tl.pca` on data stored in different layers of the same `anndata` object. . At the moment my workaround is to set `adata.X` before PCA and changing the key to the `adata.obsm` element after:; ```python; adata.X = adata.layers[""mylayer""]; sc.tl.pca(adata); adata.obsm[""mylayer_pca""] = adata.obsm[""X_pca""]; ```; Ideally I'd like to just be able to set a `layer` argument in `sc.tl.pca`, as in the plotting functions. . Any plans on linking data layers to dimensionality reductions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:635,Modifiability,layers,layers,635,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I find using the `adata.layers` really useful to compare normalisation strategies. I'd like to also be able to seamlessly run `sc.tl.pca` on data stored in different layers of the same `anndata` object. . At the moment my workaround is to set `adata.X` before PCA and changing the key to the `adata.obsm` element after:; ```python; adata.X = adata.layers[""mylayer""]; sc.tl.pca(adata); adata.obsm[""mylayer_pca""] = adata.obsm[""X_pca""]; ```; Ideally I'd like to just be able to set a `layer` argument in `sc.tl.pca`, as in the plotting functions. . Any plans on linking data layers to dimensionality reductions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:817,Modifiability,layers,layers,817,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I find using the `adata.layers` really useful to compare normalisation strategies. I'd like to also be able to seamlessly run `sc.tl.pca` on data stored in different layers of the same `anndata` object. . At the moment my workaround is to set `adata.X` before PCA and changing the key to the `adata.obsm` element after:; ```python; adata.X = adata.layers[""mylayer""]; sc.tl.pca(adata); adata.obsm[""mylayer_pca""] = adata.obsm[""X_pca""]; ```; Ideally I'd like to just be able to set a `layer` argument in `sc.tl.pca`, as in the plotting functions. . Any plans on linking data layers to dimensionality reductions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:1041,Modifiability,layers,layers,1041,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I find using the `adata.layers` really useful to compare normalisation strategies. I'd like to also be able to seamlessly run `sc.tl.pca` on data stored in different layers of the same `anndata` object. . At the moment my workaround is to set `adata.X` before PCA and changing the key to the `adata.obsm` element after:; ```python; adata.X = adata.layers[""mylayer""]; sc.tl.pca(adata); adata.obsm[""mylayer_pca""] = adata.obsm[""X_pca""]; ```; Ideally I'd like to just be able to set a `layer` argument in `sc.tl.pca`, as in the plotting functions. . Any plans on linking data layers to dimensionality reductions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1301:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I find using the `adata.layers` really useful to compare normalisation strategies. I'd like to also be able to seamlessly run `sc.tl.pca` on data stored in different layers of the same `anndata` object. . At the moment my workaround is to set `adata.X` before PCA and changing the key to the `adata.obsm` element after:; ```python; adata.X = adata.layers[""mylayer""]; sc.tl.pca(adata); adata.obsm[""mylayer_pca""] = adata.obsm[""X_pca""]; ```; Ideally I'd like to just be able to set a `layer` argument in `sc.tl.pca`, as in the plotting functions. . Any plans on linking data layers to dimensionality reductions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1301
https://github.com/scverse/scanpy/issues/1302:317,Availability,Error,Error,317,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:147,Deployability,install,installing,147,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:1662,Deployability,install,install,1662,"ut your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:33:30) ; [Clang 9.0.1 ]; >>> import platform; print(platform.python_implementation()); print(platform.platform()); CPython; Darwin-17.7.0-x86_64-i386-64bit; ```; ...; ```; $ sw_vers; ProductName:	Mac OS X; ProductVersion:	10.13.6; BuildVersion:	17G11023; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:1845,Deployability,install,installed,1845,"ut your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:33:30) ; [Clang 9.0.1 ]; >>> import platform; print(platform.python_implementation()); print(platform.platform()); CPython; Darwin-17.7.0-x86_64-i386-64bit; ```; ...; ```; $ sw_vers; ProductName:	Mac OS X; ProductVersion:	10.13.6; BuildVersion:	17G11023; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:110,Integrability,depend,dependancy,110,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:1783,Integrability,depend,dependancy,1783,"ut your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:33:30) ; [Clang 9.0.1 ]; >>> import platform; print(platform.python_implementation()); print(platform.platform()); CPython; Darwin-17.7.0-x86_64-i386-64bit; ```; ...; ```; $ sw_vers; ProductName:	Mac OS X; ProductVersion:	10.13.6; BuildVersion:	17G11023; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/issues/1302:1654,Usability,simpl,simple,1654,"ut your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:33:30) ; [Clang 9.0.1 ]; >>> import platform; print(platform.python_implementation()); print(platform.platform()); CPython; Darwin-17.7.0-x86_64-i386-64bit; ```; ...; ```; $ sw_vers; ProductName:	Mac OS X; ProductVersion:	10.13.6; BuildVersion:	17G11023; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302
https://github.com/scverse/scanpy/pull/1305:30,Testability,test,tests,30,"Hi,; currently, our notebooks tests fail (see https://travis-ci.com/github/theislab/cellrank_notebooks/jobs/357647707) because of missing `exists_ok` in `mkdir`.; `_check_datafile_present_and_download` eventually calls `_download` (where `exists_ok=True`), so I've deferred creation + logging of the directory to `_download`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1305:285,Testability,log,logging,285,"Hi,; currently, our notebooks tests fail (see https://travis-ci.com/github/theislab/cellrank_notebooks/jobs/357647707) because of missing `exists_ok` in `mkdir`.; `_check_datafile_present_and_download` eventually calls `_download` (where `exists_ok=True`), so I've deferred creation + logging of the directory to `_download`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305
https://github.com/scverse/scanpy/pull/1306:21,Deployability,integrat,integrating,21,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:142,Deployability,integrat,integration,142,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:21,Integrability,integrat,integrating,21,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:142,Integrability,integrat,integration,142,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/pull/1306:200,Integrability,wrap,wrapper,200,I've had better luck integrating data from multiple experiments using [Harmony](https://portals.broadinstitute.org/harmony/) than the current integration methods in scanpy.external.pp. This PR adds a wrapper for Harmony to the external API.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306
https://github.com/scverse/scanpy/issues/1307:271,Availability,error,errors,271,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:363,Availability,error,error,363,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:708,Availability,error,errors,708,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:761,Availability,error,errors,761,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2965,Availability,error,errors,2965,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3192,Availability,error,error,3192,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3418,Availability,error,error,3418,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:3547,Availability,error,errors,3547,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2947,Integrability,message,message,2947,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:369,Testability,log,logs,369,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2017,Testability,log,logging,2017,"ss/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2080,Testability,log,logger,2080,"rg/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2205,Testability,log,logging,2205," in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as err",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2240,Testability,log,logger,2240,"e_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2316,Testability,log,logging,2316,"4/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2440,Testability,log,logging,2440,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just runnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2564,Testability,log,logging,2564,"n build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2686,Testability,log,logging,2686,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1307:2872,Testability,log,logging,2872,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307
https://github.com/scverse/scanpy/issues/1312:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When multiple plots in one figure, if the legend of one figure is comprehensive, there is no space left for the legend to be shown. The scanpy just overlap the next plot on it. ![25AD7E00-E9A8-4CC6-A347-C4C76177F770](https://user-images.githubusercontent.com/16257776/86968887-e0ae3a80-c13a-11ea-805c-8620a9557087.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata, color=['sample_id','IMPACT_TMB']) ; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1312
https://github.com/scverse/scanpy/issues/1313:640,Testability,test,test,640,"The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); adata.var_names_make_unique(); adata.var[""mt""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""); ```. The results are as follows:; ```ranking genes; finished: added to `.uns['rank_genes_groups']`; 'names', sorted np.recarray to be indexed by group ids; 'scores', sorted np.recarray to be indexed by group ids; 'logfoldchanges', sorted np.recarray to be indexed by group ids; 'pvals', sorted np.recarray to be indexed by group ids; 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02); WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using 'X_pca' with n_pcs = 50; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-a44c51f396af> in <module>; 2 # genes across clusters.; 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds); 454 show=show,; 455 save=save,; --> 456 **kwds,; 457 ); 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:946,Testability,log,logfoldchanges,946,"The following issue occurs when running the function sc.pl.rank_gene_groups_heatmap (as in the spatial transcriptomics tutorial found at https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html#Cluster-marker-genes), under ""Cluster marker genes"". ```import scanpy as sc; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); adata.var_names_make_unique(); adata.var[""mt""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""); ```. The results are as follows:; ```ranking genes; finished: added to `.uns['rank_genes_groups']`; 'names', sorted np.recarray to be indexed by group ids; 'scores', sorted np.recarray to be indexed by group ids; 'logfoldchanges', sorted np.recarray to be indexed by group ids; 'pvals', sorted np.recarray to be indexed by group ids; 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02); WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using 'X_pca' with n_pcs = 50; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-a44c51f396af> in <module>; 2 # genes across clusters.; 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds); 454 show=show,; 455 save=save,; --> 456 **kwds,; 457 ); 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:1614,Testability,test,test,1614,"nes_groups(adata, ""clusters"", method=""t-test""); sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""); ```. The results are as follows:; ```ranking genes; finished: added to `.uns['rank_genes_groups']`; 'names', sorted np.recarray to be indexed by group ids; 'scores', sorted np.recarray to be indexed by group ids; 'logfoldchanges', sorted np.recarray to be indexed by group ids; 'pvals', sorted np.recarray to be indexed by group ids; 'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:02); WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using 'X_pca' with n_pcs = 50; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-a44c51f396af> in <module>; 2 # genes across clusters.; 3 sc.tl.rank_genes_groups(adata, ""clusters"", method=""t-test""); ----> 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds); 454 show=show,; 455 save=save,; --> 456 **kwds,; 457 ); 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 392 from .._anndata import heatmap; 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,; --> 394 var_group_positions=group_positions, show=show, save=save, **kwds); 395 ; 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:2492,Testability,log,log,2492," 4 sc.pl.rank_genes_groups_heatmap(adata, groups=""5"", n_genes=10, groupby=""clusters""). ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, key, show, save, **kwds); 454 show=show,; 455 save=save,; --> 456 **kwds,; 457 ); 458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 392 from .._anndata import heatmap; 393 heatmap(adata, gene_names, groupby, var_group_labels=group_names,; --> 394 var_group_positions=group_positions, show=show, save=save, **kwds); 395 ; 396 elif plot_type == 'stacked_violin':. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1454 var_names=var_names,; 1455 var_group_labels=var_group_labels,; -> 1456 var_group_positions=var_group_positions,; 1457 ); 1458 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions); 3109 """"""; 3110 ; -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby); 3112 ; 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; 3196 ); -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key); 3198 ; 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1313:4929,Usability,learn,learn,4929,"110 ; -> 3111 key = _get_dendrogram_key(adata, dendrogram, groupby); 3112 ; 3113 dendro_info = adata.uns[key]. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 3195 ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; 3196 ); -> 3197 dendrogram(adata, groupby, key_added=dendrogram_key); 3198 ; 3199 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 130 corr_matrix, method=linkage_method, optimal_ordering=optimal_ordering; 131 ); --> 132 dendro_info = sch.dendrogram(z_var, labels=categories, no_plot=True); 133 ; 134 # order of groupby categories. ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/scipy/cluster/hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0] + 1 != len(labels):; 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""); 3279 . ~/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pandas/core/indexes/base.py in __nonzero__(self); 2229 raise ValueError(""The truth value of a {0} is ambiguous. ""; 2230 ""Use a.empty, a.bool(), a.item(), a.any() or a.all().""; -> 2231 .format(self.__class__.__name__)); 2232 ; 2233 __bool__ = __nonzero__. ValueError: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().; ```. **VERSIONS:** scanpy==1.5.1 anndata==0.7.3 umap==0.4.6 numpy==1.16.4 scipy==1.5.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.8.2 leidenalg==0.8.1; Python version: 3.6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313
https://github.com/scverse/scanpy/issues/1315:142,Availability,error,error,142,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:503,Availability,Error,Error,503,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1311,Testability,log,logging,1311,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/issues/1315:1430,Usability,learn,learn,1430,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315
https://github.com/scverse/scanpy/pull/1316:2,Deployability,update,updated,2,* updated documentation images; * fix overwrite of style parameters after multiple calls to `style()`; * added padding parameter to dotplot and stacked_violin to address #1270; * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316
https://github.com/scverse/scanpy/issues/1318:1461,Availability,Error,Error,1461,"escription of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:847,Modifiability,layers,layers,847,"<!-- Please give a clear and concise description of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:789,Safety,detect,detectable,789,"<!-- Please give a clear and concise description of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1841,Testability,log,logging,1841,"escription of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/issues/1318:1960,Usability,learn,learn,1960,"escription of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318
https://github.com/scverse/scanpy/pull/1320:120,Deployability,install,installed,120,"Travis builds are currently breaking due to incompatible versions of numpy being present, so no compatible version gets installed. This should fix that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1320
https://github.com/scverse/scanpy/issues/1321:562,Availability,Error,Error,562,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:641,Availability,down,download,641,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:502,Testability,log,log,502,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:517,Testability,log,logging,517,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:792,Testability,log,logging,792,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1321:929,Usability,learn,learn,929,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321
https://github.com/scverse/scanpy/issues/1322:487,Availability,Error,Error,487,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:197,Performance,load,load,197,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:866,Testability,log,logging,866,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/issues/1322:990,Usability,learn,learn,990,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322
https://github.com/scverse/scanpy/pull/1323:8,Integrability,depend,depends,8,nx <2.3 depends on a since-removed matplotlib API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323
https://github.com/scverse/scanpy/issues/1324:807,Safety,detect,detected,807,"Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`.; I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells).; There are mainly two possibilities, namely:; - a gene is expressed in at least X% of cells of **both** groups;; - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks!; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1324:783,Testability,test,test,783,"Hi there,. I am doing a DE analysis using the functions `rank_genes_groups` and `filter_rank_genes_groups`.; I noticed that when two groups are compared (I did not check when multiple groups are compared) the parameter `min_in_group_fraction` of the function `filter_rank_genes_groups` is used only to filter the first group. I applied twice the functions `rank_genes_groups` and `filter_rank_genes_groups` to filter the calculated genes (I am asking that a gene is expressed in at least X% of cells).; There are mainly two possibilities, namely:; - a gene is expressed in at least X% of cells of **both** groups;; - a gene is expressed in at least X% of cells of **either** group1 or group2. In Seurat, the function `FindAllMarkers` has the parameter `min.pct `that is used to only test the genes that are detected in a minimum fraction of `min.pct` cells in either group1 or group2. It would be interesting to include these filtering steps in the `filter_rank_genes_groups` (maybe both strategies, i.e., **both** groups and **either** group1 or group2). What do you think? . Thanks!; Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1324
https://github.com/scverse/scanpy/issues/1325:175,Availability,down,downregulated,175,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:274,Availability,down,downregulated,274,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:874,Availability,down,downregulated,874,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1325:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325
https://github.com/scverse/scanpy/issues/1326:231,Testability,log,log,231,"I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```; adata.raw = adata; sc.pp.recipe_weinreb17(adata, log=False); sc.tl.pca(adata); ```. I keep getting this output:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-bfa4168a87e6> in <module>; 1 adata.raw = adata; ----> 2 sc.pp.recipe_weinreb17(adata, log=False); 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy); 48 ); 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself; ---> 50 X_pca = pp.pca(; 51 pp.zscore_deprecated(adata.X),; 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'; ```. Versions:; `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:530,Testability,log,log,530,"I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```; adata.raw = adata; sc.pp.recipe_weinreb17(adata, log=False); sc.tl.pca(adata); ```. I keep getting this output:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-bfa4168a87e6> in <module>; 1 adata.raw = adata; ----> 2 sc.pp.recipe_weinreb17(adata, log=False); 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy); 48 ); 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself; ---> 50 X_pca = pp.pca(; 51 pp.zscore_deprecated(adata.X),; 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'; ```. Versions:; `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:665,Testability,log,log,665,"I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```; adata.raw = adata; sc.pp.recipe_weinreb17(adata, log=False); sc.tl.pca(adata); ```. I keep getting this output:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-bfa4168a87e6> in <module>; 1 adata.raw = adata; ----> 2 sc.pp.recipe_weinreb17(adata, log=False); 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy); 48 ); 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself; ---> 50 X_pca = pp.pca(; 51 pp.zscore_deprecated(adata.X),; 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'; ```. Versions:; `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/issues/1326:1086,Usability,learn,learn,1086,"I'm unable to complete the [Nestrorowa et al. 2016](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/nestorowa16/nestorowa16.ipynb) paga tutorial. On ln[3] . ```; adata.raw = adata; sc.pp.recipe_weinreb17(adata, log=False); sc.tl.pca(adata); ```. I keep getting this output:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-bfa4168a87e6> in <module>; 1 adata.raw = adata; ----> 2 sc.pp.recipe_weinreb17(adata, log=False); 3 sc.tl.pca(adata). /opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py in recipe_weinreb17(adata, log, mean_threshold, cv_threshold, n_pcs, svd_solver, random_state, copy); 48 ); 49 adata._inplace_subset_var(gene_subset) # this modifies the object itself; ---> 50 X_pca = pp.pca(; 51 pp.zscore_deprecated(adata.X),; 52 n_comps=n_pcs,. AttributeError: module 'scanpy.preprocessing._simple' has no attribute 'pca'; ```. Versions:; `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.7.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1326
https://github.com/scverse/scanpy/pull/1327:118,Testability,test,test,118,"Fixes https://github.com/theislab/scanpy/issues/1326. `pca` was being imported from an old location, and there was no test. Cleaned up a bit of related code while I was at it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1327
https://github.com/scverse/scanpy/pull/1330:127,Testability,test,test,127,"Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```; # tie_correct=False by default; sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True); ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1330:258,Testability,test,test,258,"Addresses https://github.com/theislab/scanpy/issues/698. Adds some bug fixes and optional tie correction for wilcoxon rank sum test. ```; # tie_correct=False by default; sc.tl.rank_genes_groups(adata, ..., method='wilcoxon', tie_correct=True); ```. Also the test here compares `rank_genes_groups` method `'wilcoxon'` to `scipy.stats.mannwhitneyu`. @idavydov , thanks for the `matrix_tiecorrect` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1330
https://github.com/scverse/scanpy/pull/1332:109,Deployability,integrat,integration,109,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:283,Deployability,integrat,integration,283,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:109,Integrability,integrat,integration,109,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:283,Integrability,integrat,integration,283,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/pull/1332:295,Testability,test,testing,295,Hello! I thought it might be useful to add [Scanorama ](https://github.com/brianhie/scanorama) to the set of integration methods in scanpy.external.pp. I've followed the example laid out in https://github.com/theislab/scanpy/pull/1306 pretty closely. I've also done some small scale integration testing on a local machine just to verify that batch effect correction indeed works when called with this API. Let me know what I can do to help get this merged!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1332
https://github.com/scverse/scanpy/issues/1333:611,Availability,Error,Error,611,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:510,Modifiability,layers,layers,510,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:194,Testability,log,logged,194,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:218,Testability,log,logging,218,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:279,Testability,log,logging,279,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:330,Testability,log,logged,330,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:734,Testability,log,log-transformed,734,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:795,Testability,log,logging,795,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/issues/1333:932,Usability,learn,learn,932,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333
https://github.com/scverse/scanpy/pull/1334:39,Availability,Error,Error,39,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:61,Availability,error,error,61,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:150,Availability,error,error,150,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/pull/1334:214,Availability,down,downloading,214,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334
https://github.com/scverse/scanpy/issues/1335:526,Testability,test,test,526,"<!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. sc.set_figure_params(dpi=72); adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'); sc.pl.rank_genes_groups(adata, sharey=False); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:623,Testability,log,logging,623,"<!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. sc.set_figure_params(dpi=72); adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'); sc.pl.rank_genes_groups(adata, sharey=False); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. sc.set_figure_params(dpi=72); adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'); sc.pl.rank_genes_groups(adata, sharey=False); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/issues/1335:758,Usability,learn,learn,758,"<!-- Please give a clear and concise description of what the bug is: -->. y-axis range of sc.pl.rank_genes_groups seems unnecessarily long:. ![image](https://user-images.githubusercontent.com/1140359/88754278-41bea200-d12c-11ea-9d8c-aeb013ea6a02.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. sc.set_figure_params(dpi=72); adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', method='t-test'); sc.pl.rank_genes_groups(adata, sharey=False); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.5.2.dev52+g10937f5f anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335
https://github.com/scverse/scanpy/pull/1337:120,Usability,simpl,simplification,120,"* Previously min and max were set by full range of scores, not just the ones being plotted.; * Also did some minor code simplification. Fixes #1335. Still need to change reference plots",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1337
https://github.com/scverse/scanpy/issues/1338:2297,Availability,Error,Error,2297,"3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1; S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B; PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; >>> adata.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2847,Security,hash,hashtable,2847,"7672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1; S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B; PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; >>> adata.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:2960,Security,hash,hashtable,2960,"19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1; S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B; PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; >>> adata.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3751,Security,hash,hashtable,3751,"Engine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:3864,Security,hash,hashtable,3864,"Table.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4388,Security,hash,hashtable,4388,"s/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:4501,Security,hash,hashtable,4501,"; File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; ```. #### Versions:; ```; scanpy==1.5.1 annda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5292,Security,hash,hashtable,5292,"ndex.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5405,Security,hash,hashtable,5405,"ndex.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:729,Testability,test,tests,729,"I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of?. ```; >>> import anndata; >>> adata = anndata.read('./src/tests/test.h5ad'); >>> adata; AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'; >>> adata.var; gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names; TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4; CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:735,Testability,test,test,735,"I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of?. ```; >>> import anndata; >>> adata = anndata.read('./src/tests/test.h5ad'); >>> adata; AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'; >>> adata.var; gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names; TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4; CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:229,Usability,simpl,simply,229,"I was following Scanpy's tutorial for preprocessing and clustering the 3k PBMC data set, as seen [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). Unfortunately, many of the most informative marker genes are simply missing/discarded from the data set. Some of the genes a contributor has pointed out are missing from this set are: CD14, CD68, FTH1, SERPINA1, LYZ. Similar R tools, such as [rook/pagoda1](http://pklab.med.harvard.edu/cgi-bin/R/rook/10x.pbmc/index.html), have these genes displayed, some of them with quite high variance values (e.g. LYZ). Is this an issue with the tutorial itself, or is there a bug in scanpy that we are unaware of?. ```; >>> import anndata; >>> adata = anndata.read('./src/tests/test.h5ad'); >>> adata; AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'cell_ids'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_names'; >>> adata.var; gene_ids n_cells mt n_cells_by_counts mean_counts ... dispersions dispersions_norm mean std gene_names; TNFRSF4 ENSG00000186827 155 False 155 0.077407 ... 2.086050 0.665406 -3.672069e-10 0.424481 TNFRSF4; CPSF3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1338:5576,Usability,learn,learn,5576,"ndex.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; >>> adata.raw.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338
https://github.com/scverse/scanpy/issues/1340:510,Modifiability,variab,variables,510,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1340:168,Usability,simpl,simple,168,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When determining colours of categorical variables in uns they are based on alphabetical order (if I am not mistaken) - being represented just as an ordered list. Thus it is a bit inconvenient to change colours, especially if categories change during the analysis - the whole order changes and the mapping breaks. Would it be possible to use a dictionary of colours as values and categories as keys (with a default for any categories missing colours)?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1340
https://github.com/scverse/scanpy/issues/1341:339,Availability,error,error,339,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:477,Availability,error,errors,477,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4672,Availability,error,error,4672,"False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4810,Availability,error,error,4810,"ull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4835,Availability,error,error,4835,"ull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6706,Availability,error,errors,6706,"rcent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent_top); 115 for i, n in enumerate(percent_top):; 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 377 mtx = csr_matrix(mtx); 378 return top_segment_proportions_sparse_csr(; --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 380 ); 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7288,Availability,error,errors,7288,", **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:7812,Availability,error,errors,7812,"t of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8135,Availability,error,error,8135,"dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9304,Availability,avail,available,9304,"\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 370 res = None; 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:; 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13109,Availability,error,errors,13109,"ent values; 232 self.extract_function_arguments(); --> 233 entry_block_tail = self.lower_function_body(); 234 ; 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self); 257 bb = self.blkmap[offset]; 258 self.builder.position_at_end(bb); --> 259 self.lower_block(block); 260 self.post_lower(); 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13727,Availability,error,error,13727,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13752,Availability,error,error,13752,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:1721,Deployability,pipeline,pipeline,1721,"ore\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._compile_ir(); 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self); 407 assert self.state.func_ir is not None; --> 408 return self._compile_core(); 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 380 if is_final_pipeline:; --> 381 raise e; 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 340 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3802,Deployability,pipeline,pipeline,3802,"\numba\core\compiler_machinery.py in run(self, state); 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:4754,Deployability,pipeline,pipeline,4754,"ull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8420,Deployability,pipeline,pipeline,8420," in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8532,Deployability,pipeline,pipeline,8532," in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:9314,Deployability,pipeline,pipelines,9314,"\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 370 res = None; 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:; 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:11229,Deployability,pipeline,pipeline,11229,"compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 289 mutated |= check(pss.run_initialization, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:; 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 440 ; 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']; 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 368 lower = lowering.Lower(targetctx, library, fndesc, interp,; 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:; 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 177 if self.generator_info is None:; 178 self.genlower = None; --> 179 self.lower_normal_function(self.fndesc); 180 else:; 181 self.genlower = self.GeneratorLower(self). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc); 231 # Init argument values; 232 self.extract_function_arguments(); --> 233 entry_block_tail = self.lower_function_body(); 234 ; 235 # Close tail of e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13607,Deployability,pipeline,pipeline,13607,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13671,Deployability,pipeline,pipeline,13671,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:345,Integrability,message,message,345,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:6376,Modifiability,config,config,6376," 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent_top); 115 for i, n in enumerate(percent_top):; 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 377 mtx = csr_matrix(mtx); 378 return top_segment_proportions_sparse_csr(; --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 380 ); 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:13274,Modifiability,config,config,13274,"\numba\core\lowering.py in lower_function_body(self); 257 bb = self.blkmap[offset]; 258 self.builder.position_at_end(bb); --> 259 self.lower_block(block); 260 self.post_lower(); 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:2124,Testability,assert,assert,2124,"arfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._compile_ir(); 350 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_ir(self); 407 assert self.state.func_ir is not None; --> 408 return self._compile_core(); 409 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 380 if is_final_pipeline:; --> 381 raise e; 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:8974,Testability,assert,assert,8974,"le_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 370 res = None; 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:; 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:19,Usability,clear,clear,19,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3298,Usability,Simpl,SimpleTimer,3298,"re(self); 380 if is_final_pipeline:; --> 381 raise e; 382 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:3392,Usability,Simpl,SimpleTimer,3392,"aconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10586,Usability,Simpl,SimpleTimer,10586,"numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 289 mutated |= check(pss.run_initialization, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:; 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 440 ; 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']; 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 368 lower = lowering.Lower(targetctx, library, fndesc, interp,; 369 metadata=metadata); --> 370 lower.lower(); ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:10680,Usability,Simpl,SimpleTimer,10680,"hed_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in _runPass(self, index, pss, internal_state); 289 mutated |= check(pss.run_initialization, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:; 293 mutated |= check(pss.run_finalizer, internal_state). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 440 ; 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']; 444 signature = typing.signature(state.return_type, *state.args). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 368 lower = lowering.Lower(targetctx, library, fndesc, interp,; 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:; 372 lower.create_cpython_wrapper(flags.release_gil). ~\AppDat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/issues/1341:15138,Usability,learn,learn,15138,"s, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (416)>, 318: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (417)>}Var(parfor_index.264, _qc.py:412)"" at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412); ```. **The package version is as follows:**. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1+5.3b99dbf6 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341
https://github.com/scverse/scanpy/pull/1342:186,Testability,log,log,186,"PR to solve #1321 . ```PYTHON; marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(adata,marker_genes,groupby='louvain', return_fig=True,log=False).style(yticklabels=True,row_palette='muted').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/88898994-cbb25c00-d24d-11ea-8de2-5768752c9939.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1342
https://github.com/scverse/scanpy/pull/1344:26,Availability,down,downloads,26,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:69,Availability,down,downloads,69,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:450,Availability,down,download,450,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:549,Availability,down,downloaded,549,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:594,Deployability,update,updated,594,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:515,Testability,test,test,515,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/pull/1344:585,Testability,test,test,585,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344
https://github.com/scverse/scanpy/issues/1347:46,Testability,log,logo,46,"Hi,. I was always a bit perplexed by Scanpy's logo (some sort of shrimp? ant?), since the name doesn't make me think of an animal. Would you mind explaining, @falexwolf? Is it, maybe, a pun on ""scampi""? Because that would explain it. thanks,; Niko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1347
https://github.com/scverse/scanpy/issues/1351:94,Availability,error,error,94,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:201,Availability,error,error,201,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:474,Availability,Error,Error,474,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1989,Availability,error,error,1989,"3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2019,Availability,error,error,2019,"3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3218,Availability,error,error,3218,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3334,Availability,error,error,3334,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1312,Integrability,wrap,wrapper,1312," dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <mo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1368,Integrability,wrap,wrapper,1368,"M / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1625,Integrability,wrap,wrapper,1625,"py2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1681,Integrability,wrap,wrapper,1681,"n func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:1995,Integrability,message,message,1995,"3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:2826,Integrability,wrap,wrapper,2826,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:15,Performance,load,load,15,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1351:3533,Usability,learn,learn,3533,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351
https://github.com/scverse/scanpy/issues/1352:1045,Availability,down,down,1045,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1349,Deployability,integrat,integrated,1349,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:1349,Integrability,integrat,integrated,1349,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1352:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352
https://github.com/scverse/scanpy/issues/1354:1656,Usability,learn,learn,1656,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.filter_genes(adata, min_cells=10); # with <3298x24714 sparse matrix of type '<class 'numpy.float32'>'; # with 11965294 stored elements in Compressed Sparse Row format>; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-37-431c88656c87> in <module>; ----> 1 sc.pp.filter_genes(adata, min_cells=3, max_cells=None). /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy); 216 filter_genes(adata.X, min_cells=min_cells,; 217 min_counts=min_counts, max_cells=max_cells,; --> 218 max_counts=max_counts)); 219 if not inplace:; 220 return gene_subset, number. /usr/local/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in filter_genes(data, min_counts, min_cells, max_counts, max_cells, inplace, copy); 230 max_number = max_counts if max_cells is None else max_cells; 231 number_per_gene = np.sum(X if min_cells is None and max_cells is None; --> 232 else X > 0, axis=0); 233 if issparse(X):; 234 number_per_gene = number_per_gene.A1. TypeError: '>' not supported between instances of 'SparseDataset' and 'int'; ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.2 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354
https://github.com/scverse/scanpy/pull/1356:1001,Availability,down,down,1001,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:774,Deployability,Update,Update,774,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1094,Deployability,continuous,continuous,1094,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:1112,Deployability,update,update,1112,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:837,Integrability,wrap,wrap,837,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:44,Testability,test,tests,44,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:906,Testability,test,tests,906,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/pull/1356:953,Testability,Test,Tests,953,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356
https://github.com/scverse/scanpy/issues/1357:96,Deployability,release,release,96,"Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1357:543,Usability,simpl,simple,543,"Right now, figures for tutorials and documentation have to be manually generated when we make a release. This often leads to out of date figures, and a fair amount of pain for otherwise small style changes. It would be good if this could be part of an automatic build process. For the sphinx docs, we could probably do this on the readthedocs servers since we have extra capacity. For notebooks, this could take some consideration. Some notebooks deal with large data that we don't want to reprocess frequently. A good step could just be some simple scripting around automatically running the notebooks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1357
https://github.com/scverse/scanpy/issues/1358:599,Deployability,integrat,integration,599,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:599,Integrability,integrat,integration,599,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:652,Integrability,depend,depending,652,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:29,Performance,queue,queue,29,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:196,Performance,concurren,concurrent,196,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:364,Performance,concurren,concurrent,364,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:415,Performance,concurren,concurrent,415,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:491,Testability,test,testing,491,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:635,Testability,test,test,635,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:752,Testability,test,testing,752,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1358:805,Usability,learn,learn,805,"We've been dealing with long queue times for CI builds. This is at least partially because for each PR four jobs start, each of which takes at least 12 minutes. Since travis gives us at most five concurrent jobs, only one PR can be built at a time. This becomes worse if a PR is based on a branch on the main repo, since CI runs on those too. Azure offers 10 free concurrent jobs. Seems like an easy win. * 10 free concurrent jobs; * Easier to do multiple checks per build (i.e. linting and testing can happen in the same build, but be independent checks); * Output looks easy to navigate, has good integration with github; * We could test on windows (depending on how hard this is to set up); * (possible) Some projects seem to use multiple cores for testing. Cons:. * New system, will take some time to learn; * Maybe microsoft will start being evil again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1358
https://github.com/scverse/scanpy/issues/1361:673,Modifiability,variab,variable,673,"The function `sc.pl.dotplot()` can be used with processed data or raw data by setting `use_raw=True`. The % cells that express a gene is obtained by counting cells with expression above `expression_cutoff` (which by default is 0.0). . However this is likely to produce a wrong result when using scaled and centered data (i.e. after `pp.scale()` ). Unless I'm missing something, the percentage of cells expressing a gene should only be computed from raw data. . Although this is the default usage of the dotplot function in scanpy notebooks, the default use in Seurat is the opposite, and it seems easy to use `sc.pl.dotplot()` in scaled data without noticing this. Maybe a variable similar to `use_raw` to uncouple the use of raw data for the colormap and dotsize could solve this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1361
https://github.com/scverse/scanpy/pull/1362:438,Availability,error,error,438,"`scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362
https://github.com/scverse/scanpy/issues/1364:957,Integrability,depend,depend,957,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:406,Modifiability,variab,variable,406,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:971,Safety,detect,detection,971,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:446,Testability,log,log,446,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:881,Testability,log,log,881,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1120,Testability,log,log-counts,1120," version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell; >>> X_norm_again.sum(axis=1); array([1., 1., 1.], dtype=float32) # Counts the same again; ```. #### Versions. I'm n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1164,Testability,log,log-mean,1164," version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. This is probably a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell; >>> X_norm_again.sum(axis=1); array([1., 1., 1.], dtype=float32) # Counts the same again; ```. #### Versions. I'm n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:1236,Testability,log,log-transformation,1236,"y a bug in my thinking, but naively I thought that `sc.pp.normalize_total()` normalizes counts per cell, thus allowing comparison of different cells by correcting for variable sequencing depth. However, the log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell; >>> X_norm_again.sum(axis=1); array([1., 1., 1.], dtype=float32) # Counts the same again; ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2251,Testability,log,logging,2251,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell; >>> X_norm_again.sum(axis=1); array([1., 1., 1.], dtype=float32) # Counts the same again; ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(); scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1364:2380,Usability,learn,learn,2380,"log transformation applied after normalisation seems to upset this relationship, example below. Why is this not problematic?. Incidentally, I first noticed this on my real biological dataset, not the toy example below. Edit: [relevant paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6215955/). > We can show, mathematically, that if we normalize expression profiles to have the same mean across cells, the mean after the equation [log] transformation used for RNA-Seq data will not be the same, and it will depend on the detection rate... And this [one](https://www.biorxiv.org/content/10.1101/404962v1.full):. > One issue of particular interest is that the mean of the log-counts is not generally the same as the log-mean count [1]. This is problematic in scRNA-seq contexts where the log-transformation is applied to normalized expression data. ---. ### Minimal code sample. ```python; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import numpy as np; >>> adata = AnnData(np.array([[3, 3, 3, 6, 6],[1, 1, 1, 2, 2],[1, 22, 1, 2, 2], ])); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; >>> X_norm_log = np.log1p(X_norm); >>> X_norm_again = np.expm1(X_norm_log); >>> adata.X.sum(axis=1); array([21., 7., 28.], dtype=float32) # Different counts for each cell; >>> X_norm.sum(axis=1); array([1., 1., 1.], dtype=float32) # Normalisation means same counts for each cell; >>> X_norm_log.sum(axis=1); array([0.90322304, 0.90322304, 0.7879869 ], dtype=float32) # <<< Interested in this! Different counts for each cell; >>> X_norm_again.sum(axis=1); array([1., 1., 1.], dtype=float32) # Counts the same again; ```. #### Versions. I'm not using the latest scanpy and anndata verions, but i don't think this will be different on the master branch. <details>. >>> sc.logging.print_versions(); scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364
https://github.com/scverse/scanpy/issues/1365:136,Deployability,release,release,136,"Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:153,Energy Efficiency,schedul,scheduled,153,"Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1365:37,Modifiability,enhance,enhancement,37,"Hi Scanpy devs. Sorry, this isn't an enhancement request, just wan't sure where this fitted. . Just a quick one- when's the next Scanpy release (1.6.0?) scheduled for?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1365
https://github.com/scverse/scanpy/issues/1367:514,Availability,error,error,514,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:637,Availability,error,error,637,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:874,Performance,Perform,Performing,874,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1367:3056,Usability,learn,learn,3056,"45f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,; 125 compute_angle=compute_angle, mnn_order=mnn_order,; --> 126 svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs); 127 print('Packing AnnData object...'); 128 if do_concatenate:. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 180 print(' Computing correction vectors...'); 181 correction_in = compute_correction(ref_batch_in, new_batch_in, mnn_ref, mnn_new,; --> 182 new_batch_in, sigma); 183 if not same_set:; 184 correction_out = compute_correction(ref_batch_out, new_batch_out, mnn_ref, mnn_new,. IndexError: arrays used as indices must be of integer (or boolean) type; ```. #### Versions. <details>. scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.19.1 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. numba==0.50.1; llvmlite==0.33.0+1.g022ab0f. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367
https://github.com/scverse/scanpy/issues/1368:467,Availability,down,downsample,467,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:877,Availability,error,error,877,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:973,Availability,error,error,973,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1527,Testability,log,logging,1527,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1368:1689,Usability,learn,learn,1689,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368
https://github.com/scverse/scanpy/issues/1369:22,Availability,error,error,22,"Getting the following error with the latest version of scanpy:. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-24-7f6e74b434f4> in <module>; ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10); 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369
https://github.com/scverse/scanpy/issues/1370:85,Deployability,integrat,integrated,85,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:146,Deployability,integrat,integrated,146,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:335,Deployability,integrat,integrated,335,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:484,Deployability,integrat,integrated,484,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:866,Deployability,integrat,integrated,866,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1105,Deployability,integrat,integrated,1105,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:85,Integrability,integrat,integrated,85,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:146,Integrability,integrat,integrated,146,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:335,Integrability,integrat,integrated,335,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:484,Integrability,integrat,integrated,484,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:866,Integrability,integrat,integrated,866,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1370:1105,Integrability,integrat,integrated,1105,"Hi @all,; Thanks to develop the great tools,; I encounter a pecular problem on bbknn integrated data.; i follow the workflow code to run the data integrated,the code showing below,; #; sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; sc.tl.pca(adata, svd_solver='arpack'); sc.tl.tsne(adata); ///data integrated; sc.external.pp.bbknn(adata, batch_key='orig.ident'). sc.tl.umap(adata); adata; sc.pl.umap(adata, color=['orig.ident']); showing the well integrated, picture below,; ![image](https://user-images.githubusercontent.com/41668708/90249921-df74d980-de6d-11ea-8283-3830dd3c6ad2.png); But,when i want to see the tsne picture, the batch from different sample showing up on the tsne but umap like above picture; ,i runing ,; sc.tl.tsne(adata); sc.pl.tsne(adata, color=['orig.ident']); the picture show below, indicating that the integrated can not be worked on tsne.; ![image](https://user-images.githubusercontent.com/41668708/90250154-3c708f80-de6e-11ea-8d43-7a597c5693a2.png); So, why this tsne showing significantly different with the object just running over the integrated process.; any advice would be appreciated; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1370
https://github.com/scverse/scanpy/issues/1371:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ x] Other?; s; <!-- Please describe your wishes below: -->; ...; In sc.pl.dotplot(), dot_ax.grid(False) is the default. Can an argument please be added to the function that allows the option of True: dot_ax.grid(True, linewidth = x) with linewidth as part of the argument?. Thank you!; Salwan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1371
https://github.com/scverse/scanpy/pull/1373:274,Deployability,update,updated,274,"log a short version of the sinfo header:. ```; -----; anndata 0.7.4; scanpy 1.5.2.dev106+gd355654f; sinfo 0.3.1; -----; Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]; Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5; 16 logical CPU cores; -----; Session information updated at 2020-08-16 21:09; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:0,Testability,log,log,0,"log a short version of the sinfo header:. ```; -----; anndata 0.7.4; scanpy 1.5.2.dev106+gd355654f; sinfo 0.3.1; -----; Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]; Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5; 16 logical CPU cores; -----; Session information updated at 2020-08-16 21:09; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1373:228,Testability,log,logical,228,"log a short version of the sinfo header:. ```; -----; anndata 0.7.4; scanpy 1.5.2.dev106+gd355654f; sinfo 0.3.1; -----; Python 3.8.5 (default, Jul 27 2020, 08:42:51) [GCC 10.1.0]; Linux-5.7.12-arch1-1-x86_64-with-glibc2.2.5; 16 logical CPU cores; -----; Session information updated at 2020-08-16 21:09; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1373
https://github.com/scverse/scanpy/pull/1377:96,Deployability,install,install,96,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:123,Deployability,Install,Installation,123,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:165,Deployability,install,install,165,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:193,Deployability,install,install,193,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:232,Deployability,install,install,232,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:527,Deployability,update,update,527,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1377:280,Usability,simpl,simply,280,I hope that solves all workflow woes! @ivirshup?. - Users still only need `pip` and can do `pip install scanpy[extras]`; - Installation from source happens via `pip install .[extras]` or `flit install --deps`/`--extras`; - Dev mode install is nonstandard and therefore happens by simply `ln -s scanpy path/to/env/site-packages/` or flit:. ![grafik](https://user-images.githubusercontent.com/291575/90508913-c8c5cf80-e158-11ea-802a-2e0e47578bd6.png). PS: we could also mention `--pth-file` for the 3 windows users who refuse to update to win10 and therefore can’t create symlinks.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377
https://github.com/scverse/scanpy/pull/1378:179,Deployability,install,install,179,@Koncopd said in https://github.com/theislab/scanpy/pull/1377#issuecomment-675422847 that he has problems with the package metadata being found. Which is extremely weird as `flit install --symlink` creates both a symlink and package metadata:. ```console; $ ls -l ~/.conda/envs/anndata/lib/python3.8/site-packages/ | grep anndata; lrwxrwxrwx 49 phil 2020-08-18 14:30 anndata -> ~/Dev/Python/Single Cell/anndata/anndata; drwxr-sr-x - phil 2020-08-18 14:30 anndata-0.7.5.dev9_gd32f11b.dist-info; ```. @Koncopd does that help? please post your stack trace before and after this PR so I see what’s going on. And also please post if the `.dist-info` directory has been created. Maybe we need to recommend `--pth-file` for windows users.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378
https://github.com/scverse/scanpy/issues/1379:523,Deployability,upgrade,upgrade,523,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; import warnings; warnings.simplefilter('always'); import scanpy; ```. ```pytb; /home/scottgigante/.local/lib/python3.6/site-packages/scanpy/tools/_louvain.py:17: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.; from louvain.VertexPartition import MutableVertexPartition; ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.3; apport_python_hook NA; cffi 1.14.1; colorama 0.3.7; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.0.5; pkg_resources NA; psutil 5.7.2; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.5; yaml 3.12; zipp NA; zope NA; -----; Python 3.6.9 (default, Nov 7 2019, 10:44:02) [GCC 8.3.0]; Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-08-18 15:10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1379
https://github.com/scverse/scanpy/issues/1379:1543,Deployability,update,updated,1543,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; import warnings; warnings.simplefilter('always'); import scanpy; ```. ```pytb; /home/scottgigante/.local/lib/python3.6/site-packages/scanpy/tools/_louvain.py:17: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.; from louvain.VertexPartition import MutableVertexPartition; ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.3; apport_python_hook NA; cffi 1.14.1; colorama 0.3.7; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.0.5; pkg_resources NA; psutil 5.7.2; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.5; yaml 3.12; zipp NA; zope NA; -----; Python 3.6.9 (default, Nov 7 2019, 10:44:02) [GCC 8.3.0]; Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-08-18 15:10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1379
https://github.com/scverse/scanpy/issues/1379:1489,Testability,log,logical,1489,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; import warnings; warnings.simplefilter('always'); import scanpy; ```. ```pytb; /home/scottgigante/.local/lib/python3.6/site-packages/scanpy/tools/_louvain.py:17: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.; from louvain.VertexPartition import MutableVertexPartition; ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.3; apport_python_hook NA; cffi 1.14.1; colorama 0.3.7; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.0.5; pkg_resources NA; psutil 5.7.2; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.5; yaml 3.12; zipp NA; zope NA; -----; Python 3.6.9 (default, Nov 7 2019, 10:44:02) [GCC 8.3.0]; Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-08-18 15:10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1379
https://github.com/scverse/scanpy/issues/1379:266,Usability,simpl,simplefilter,266,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; import warnings; warnings.simplefilter('always'); import scanpy; ```. ```pytb; /home/scottgigante/.local/lib/python3.6/site-packages/scanpy/tools/_louvain.py:17: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.; from louvain.VertexPartition import MutableVertexPartition; ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.3; apport_python_hook NA; cffi 1.14.1; colorama 0.3.7; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.0.5; pkg_resources NA; psutil 5.7.2; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.5; yaml 3.12; zipp NA; zope NA; -----; Python 3.6.9 (default, Nov 7 2019, 10:44:02) [GCC 8.3.0]; Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-08-18 15:10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1379
https://github.com/scverse/scanpy/pull/1381:387,Deployability,install,installed,387,"This prepares the complete centralization of all setup information in pyproject.toml once we switch to flit. To this end, it moves all setup metadata that also needs to be accessed at runtime (`__version__`, `__author__` and `__email__`) to a new `scanpy._metadata` module which retrieves them. - during development from a checked-out project's git metadata and `pyproject.toml`; - when installed from the `scanpy-$version.dist-info` metadata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1381
https://github.com/scverse/scanpy/pull/1381:172,Security,access,accessed,172,"This prepares the complete centralization of all setup information in pyproject.toml once we switch to flit. To this end, it moves all setup metadata that also needs to be accessed at runtime (`__version__`, `__author__` and `__email__`) to a new `scanpy._metadata` module which retrieves them. - during development from a checked-out project's git metadata and `pyproject.toml`; - when installed from the `scanpy-$version.dist-info` metadata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1381
https://github.com/scverse/scanpy/pull/1383:151,Usability,clear,clear,151,Here's that `spatial_graph` function I had mentioned @giovp and @Mirkazemi. I figure it should probably be named something different to make sure it's clear it would only work for hex wells.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383
https://github.com/scverse/scanpy/issues/1385:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1385
https://github.com/scverse/scanpy/issues/1386:87,Deployability,integrat,integrative,87,"Hi!; Thank you for tutorials, they're very helpful. ; Do you have a spatial/sc-rna seq integrative analysis tutorial? . Thanks in advance!. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1386
https://github.com/scverse/scanpy/issues/1386:87,Integrability,integrat,integrative,87,"Hi!; Thank you for tutorials, they're very helpful. ; Do you have a spatial/sc-rna seq integrative analysis tutorial? . Thanks in advance!. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1386
https://github.com/scverse/scanpy/issues/1387:181,Deployability,pipeline,pipeline,181,"As we are refactoring scvi, I'm wondering what the utility would be to spin off the i/o part of scanpy into it's own lightweight package that's more general for reading single cell pipeline outputs into anndata. For example, we'd like to use the scanpy read from 10x/visium functions, but don't necessarily want to have scanpy be a full requirement. It's also a bit confusing why something like `read_umi_tools` is in anndata but not `read_10x_h5`. The same goes for loom to some extent. I could imagine either moving such functionality to anndata or a standalone package that could be expanded to include support for other technologies like scATAC-seq. . This overall could be a big benefit to methods developers who would like to build on anndata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387
https://github.com/scverse/scanpy/issues/1387:10,Modifiability,refactor,refactoring,10,"As we are refactoring scvi, I'm wondering what the utility would be to spin off the i/o part of scanpy into it's own lightweight package that's more general for reading single cell pipeline outputs into anndata. For example, we'd like to use the scanpy read from 10x/visium functions, but don't necessarily want to have scanpy be a full requirement. It's also a bit confusing why something like `read_umi_tools` is in anndata but not `read_10x_h5`. The same goes for loom to some extent. I could imagine either moving such functionality to anndata or a standalone package that could be expanded to include support for other technologies like scATAC-seq. . This overall could be a big benefit to methods developers who would like to build on anndata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387
https://github.com/scverse/scanpy/pull/1390:199,Integrability,interface,interface,199,This pr moves the (in)famous `_prepare_dataframe` function from scanpy.plotting._anndata to sc.get as `_indexed_expression_df` (bcs why would it be in plotting anyway) and implements a simple public interface called `sc.get.summarized_expresion_df` which simply provides nonzero mean/var and fraction using `_indexed_expression_df` function. . As discussed here (https://github.com/theislab/scanpy/pull/1388#issuecomment-678739734) we can use this in rank_genes_groups_df.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1390
https://github.com/scverse/scanpy/pull/1390:185,Usability,simpl,simple,185,This pr moves the (in)famous `_prepare_dataframe` function from scanpy.plotting._anndata to sc.get as `_indexed_expression_df` (bcs why would it be in plotting anyway) and implements a simple public interface called `sc.get.summarized_expresion_df` which simply provides nonzero mean/var and fraction using `_indexed_expression_df` function. . As discussed here (https://github.com/theislab/scanpy/pull/1388#issuecomment-678739734) we can use this in rank_genes_groups_df.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1390
https://github.com/scverse/scanpy/pull/1390:255,Usability,simpl,simply,255,This pr moves the (in)famous `_prepare_dataframe` function from scanpy.plotting._anndata to sc.get as `_indexed_expression_df` (bcs why would it be in plotting anyway) and implements a simple public interface called `sc.get.summarized_expresion_df` which simply provides nonzero mean/var and fraction using `_indexed_expression_df` function. . As discussed here (https://github.com/theislab/scanpy/pull/1388#issuecomment-678739734) we can use this in rank_genes_groups_df.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1390
https://github.com/scverse/scanpy/pull/1391:4,Testability,log,logfoldchanges,4,"Use logfoldchanges, fractions for filtering if they are in `adata.uns['rank_genes_groups']` already, otherwise calculate using the same formula as in `rank_genes_groups`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1391
https://github.com/scverse/scanpy/pull/1393:171,Deployability,install,installation,171,"This is the place where we can discuss the necessary workflow changes, as documented in the changed documentation:. https://icb-scanpy--1393.com.readthedocs.build/en/1393/installation.html. anndata sibling PR: theislab/anndata#427. @ivirshup here is the setup.py: https://gist.github.com/flying-sheep/9e7776f4cbe967397702e1c581e3a40a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1393
https://github.com/scverse/scanpy/pull/1394:314,Testability,test,tests,314,"@ivirshup @falexwolf the new black 20 lets users manually control which parameter lists, lists, tuples, dicts, … to explode onto multiple lines. Another advantage is that the removal of e.g. a parameter doesn’t lead to long diffs because they won’t automatically get collapsed again. Finally, it’s useful for e.g. tests or so, where we can format consecutive similar lines of data consistently. I tried to figure out the cleanest version of every spot where black 20 made changes. If you want to change some, or add new spots that can now be formatted more clearly, just create a new PR. This one is supposed to quickly fix Travis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1394
https://github.com/scverse/scanpy/pull/1394:557,Usability,clear,clearly,557,"@ivirshup @falexwolf the new black 20 lets users manually control which parameter lists, lists, tuples, dicts, … to explode onto multiple lines. Another advantage is that the removal of e.g. a parameter doesn’t lead to long diffs because they won’t automatically get collapsed again. Finally, it’s useful for e.g. tests or so, where we can format consecutive similar lines of data consistently. I tried to figure out the cleanest version of every spot where black 20 made changes. If you want to change some, or add new spots that can now be formatted more clearly, just create a new PR. This one is supposed to quickly fix Travis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1394
https://github.com/scverse/scanpy/issues/1395:2754,Deployability,update,updated,2754,".score_genes(adata, ['0']). ~/miniconda3/envs/spols200618/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 174 elif len(gene_list) == 1:; 175 if _adata[:, gene_list].X.ndim == 2:; --> 176 vector = _adata[:, gene_list].X.toarray()[:, 0] # new anndata; 177 else:; 178 vector = _adata[:, gene_list].X # old anndata. AttributeError: 'numpy.ndarray' object has no attribute 'toarray'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.1.2; anndata 0.7.4; backcall 0.2.0; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.18.1; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; ipykernel 5.3.0; ipyparallel 6.3.0; ipython_genutils 0.2.0; jedi 0.17.0; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.49.1; numexpr 2.7.1; numpy 1.17.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.4; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:57:50) [GCC 7.5.0]; Linux-4.12.14-lp151.28.44-default-x86_64-with-glibc2.10; 16 logical CPU cores, x86_64; -----; Session information updated at 2020-08-28 14:42. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1395
https://github.com/scverse/scanpy/issues/1395:1480,Performance,bottleneck,bottleneck,1480,"bs(); adata.raw = adata; sc.tl.score_genes(adata, ['0']); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-c835b3ad221d> in <module>; 2 adata = sc.datasets.blobs(); 3 adata.raw = adata; ----> 4 sc.tl.score_genes(adata, ['0']). ~/miniconda3/envs/spols200618/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 174 elif len(gene_list) == 1:; 175 if _adata[:, gene_list].X.ndim == 2:; --> 176 vector = _adata[:, gene_list].X.toarray()[:, 0] # new anndata; 177 else:; 178 vector = _adata[:, gene_list].X # old anndata. AttributeError: 'numpy.ndarray' object has no attribute 'toarray'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.1.2; anndata 0.7.4; backcall 0.2.0; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.18.1; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; ipykernel 5.3.0; ipyparallel 6.3.0; ipython_genutils 0.2.0; jedi 0.17.0; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.49.1; numexpr 2.7.1; numpy 1.17.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.4; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1395
https://github.com/scverse/scanpy/issues/1395:2700,Testability,log,logical,2700,".score_genes(adata, ['0']). ~/miniconda3/envs/spols200618/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 174 elif len(gene_list) == 1:; 175 if _adata[:, gene_list].X.ndim == 2:; --> 176 vector = _adata[:, gene_list].X.toarray()[:, 0] # new anndata; 177 else:; 178 vector = _adata[:, gene_list].X # old anndata. AttributeError: 'numpy.ndarray' object has no attribute 'toarray'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.1.2; anndata 0.7.4; backcall 0.2.0; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2.18.1; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; ipykernel 5.3.0; ipyparallel 6.3.0; ipython_genutils 0.2.0; jedi 0.17.0; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.49.1; numexpr 2.7.1; numpy 1.17.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tlz 0.10.0; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.4; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:57:50) [GCC 7.5.0]; Linux-4.12.14-lp151.28.44-default-x86_64-with-glibc2.10; 16 logical CPU cores, x86_64; -----; Session information updated at 2020-08-28 14:42. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1395
https://github.com/scverse/scanpy/issues/1396:571,Deployability,install,installation,571,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ... Hi,. I notice that even if I set n_jobs=1 in sc.pp.regress_out, all cpus are utilized. This also happens if I set n_jobs to other numbers. Basically there isn't a noticeable difference in cpu usage no matter what number of n_jobs I set. I'm using CentOS6.8 on a machine with 28 physical cores and hyper threading on (appears as 56 cores in the os). Is this an intended behavior, or just my installation? I understand that some numpy functions are naturally multi-threaded because of the setup of BLAS libraries. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396
https://github.com/scverse/scanpy/issues/1396:638,Performance,multi-thread,multi-threaded,638,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ... Hi,. I notice that even if I set n_jobs=1 in sc.pp.regress_out, all cpus are utilized. This also happens if I set n_jobs to other numbers. Basically there isn't a noticeable difference in cpu usage no matter what number of n_jobs I set. I'm using CentOS6.8 on a machine with 28 physical cores and hyper threading on (appears as 56 cores in the os). Is this an intended behavior, or just my installation? I understand that some numpy functions are naturally multi-threaded because of the setup of BLAS libraries. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396
https://github.com/scverse/scanpy/issues/1397:1234,Deployability,update,update,1234,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy.api as sc; ```. ```pytb; File ""./scanpy_normalization.py"", line 4, in <module>; import scanpy.api as sc; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py); ```. This is with the latest version of scanpy. I looked at the code and scanpy/apt/pl.py still has **from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot**, even as the plotting library has been refactored and the dotplot, matrixplot and stacked_violin are now in separate files. I tested this a few days ago and it was working fine then, the update to anndata probably happened in the last couple of days",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397
https://github.com/scverse/scanpy/issues/1397:1086,Modifiability,refactor,refactored,1086,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy.api as sc; ```. ```pytb; File ""./scanpy_normalization.py"", line 4, in <module>; import scanpy.api as sc; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py); ```. This is with the latest version of scanpy. I looked at the code and scanpy/apt/pl.py still has **from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot**, even as the plotting library has been refactored and the dotplot, matrixplot and stacked_violin are now in separate files. I tested this a few days ago and it was working fine then, the update to anndata probably happened in the last couple of days",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397
https://github.com/scverse/scanpy/issues/1397:1173,Testability,test,tested,1173,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy.api as sc; ```. ```pytb; File ""./scanpy_normalization.py"", line 4, in <module>; import scanpy.api as sc; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py); ```. This is with the latest version of scanpy. I looked at the code and scanpy/apt/pl.py still has **from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot**, even as the plotting library has been refactored and the dotplot, matrixplot and stacked_violin are now in separate files. I tested this a few days ago and it was working fine then, the update to anndata probably happened in the last couple of days",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397
https://github.com/scverse/scanpy/pull/1398:152,Availability,error,error,152,Fixes #1395. It looks like this code was originally added for dealing with the automatic flattening of `X` when indices had length 1. I also made it an error if there were no genes to score. Arguably it should be an error if any of the passed genes are missing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398
https://github.com/scverse/scanpy/pull/1398:216,Availability,error,error,216,Fixes #1395. It looks like this code was originally added for dealing with the automatic flattening of `X` when indices had length 1. I also made it an error if there were no genes to score. Arguably it should be an error if any of the passed genes are missing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398
https://github.com/scverse/scanpy/issues/1399:109,Deployability,release,release,109,"As discussed on the last call, we'd like to be better about semantic versioning. The plan for this is to cut release branches which we can back port bug fixes onto, and keep new features for minor releases. We need to develop some processes for marking which PRs should get back ported, and for doing the back porting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1399
https://github.com/scverse/scanpy/issues/1399:197,Deployability,release,releases,197,"As discussed on the last call, we'd like to be better about semantic versioning. The plan for this is to cut release branches which we can back port bug fixes onto, and keep new features for minor releases. We need to develop some processes for marking which PRs should get back ported, and for doing the back porting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1399
https://github.com/scverse/scanpy/pull/1400:444,Integrability,wrap,wrapper,444,"Fixes #435. Breaking case:. ```python; import scanpy as sc, numpy as np; sc.pp.log1p(; sc.AnnData(np.ones((100, 100)), dtype=int); ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-f3ae2b50ac50> in <module>; ----> 1 sc.pp.log1p(a). /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_anndata(adata, base, copy, chunked, chunk_size, layer, obsm); 348 else:; 349 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 350 X = log1p(X, copy=False, base=base); 351 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 352 . /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_array(X, base, copy); 316 else:; 317 X = X.copy(); --> 318 np.log1p(X, out=X); 319 if base is not None:; 320 np.divide(X, np.log(base), out=X). TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1400
https://github.com/scverse/scanpy/pull/1400:1026,Integrability,wrap,wrapper,1026,"Fixes #435. Breaking case:. ```python; import scanpy as sc, numpy as np; sc.pp.log1p(; sc.AnnData(np.ones((100, 100)), dtype=int); ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-f3ae2b50ac50> in <module>; ----> 1 sc.pp.log1p(a). /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_anndata(adata, base, copy, chunked, chunk_size, layer, obsm); 348 else:; 349 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 350 X = log1p(X, copy=False, base=base); 351 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 352 . /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_array(X, base, copy); 316 else:; 317 X = X.copy(); --> 318 np.log1p(X, out=X); 319 if base is not None:; 320 np.divide(X, np.log(base), out=X). TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1400
https://github.com/scverse/scanpy/pull/1400:1398,Testability,log,log,1398,"Fixes #435. Breaking case:. ```python; import scanpy as sc, numpy as np; sc.pp.log1p(; sc.AnnData(np.ones((100, 100)), dtype=int); ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-f3ae2b50ac50> in <module>; ----> 1 sc.pp.log1p(a). /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_anndata(adata, base, copy, chunked, chunk_size, layer, obsm); 348 else:; 349 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 350 X = log1p(X, copy=False, base=base); 351 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 352 . /usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/scanpy/scanpy/preprocessing/_simple.py in log1p_array(X, base, copy); 316 else:; 317 X = X.copy(); --> 318 np.log1p(X, out=X); 319 if base is not None:; 320 np.divide(X, np.log(base), out=X). TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1400
https://github.com/scverse/scanpy/issues/1401:324,Usability,simpl,simply,324,"As the title suggests, it can be suboptimal w.r.t computation time to use. ```python; list(map(lambda x: ..., SOME_LIST)); ```. In `readwrite.py` [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/readwrite.py#L190) for example, instead of chaining of the three functions, we can simply compare to a `pandas.Series`:. ```python; adata = adata[:, adata.var['genome'] == f""{genome}""]; ```. This improves readability and is slightly faster. In a quick check I ran in Jupyter Lab, this approach is three times faster. The following code should run in Jupyter Lab as is:. ```python; import random; import string. import numpy as np; import pandas as pd. from anndata import AnnData. letters = string.ascii_lowercase. adata = AnnData(pd.DataFrame(np.random.randn(1000, 30000))); adata.var[""genome""] = np.array([random.choice(letters) for _ in range(30000)]).reshape(-1, 1). genome = 'g'; %timeit adata[:, list(map(lambda x: x == f""{genome}"", adata.var['genome']))]. %timeit adata[:, adata.var['genome'] == f""{genome}""]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1401
https://github.com/scverse/scanpy/issues/1406:288,Availability,error,error,288,"I tried import .loom file generate from Seurat into scanpy for drawing heatmap.; There is a gene ""CD34"", when I draw in R, it reported as ""Warning: Could not find CD34 in the default search locations, found in RNA assay instead"". but still work.; While in scanpy, it showed the following error: KeyError: ""Values ['CD34'], from ..., are not valid obs/ var names or indices.""; How can I fix it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406
https://github.com/scverse/scanpy/issues/1407:51,Availability,error,error,51,"While trying to cluster using phenograph I get the error below. Could you help me understand why this happens?; ```; >>adata1; AnnData object with n_obs × n_vars = 77969 × 18417; obs: 'Id', 'Donor', 'Sample', 'Method', 'Position', 'UMI.Count', 'Expressed.Genes', 'Percent.Mitochond.', 'Percent.Ribo', 'CellType', 'Sex', 'Age'; var: 'name'; uns: 'pca'; obsm: 'X_pca'; varm: 'PCs'. >>import scanpy.external as sce; >>result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). PhenoGraph clustering; Finding 100 nearest neighbors using minkowski metric and 'auto' algorithm; Neighbors computed in 67.26673102378845 seconds; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-22-2cf1719c59ce> in <module>; 1 import scanpy.external as sce; ----> 2 result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). /usr/local/lib/python3.8/site-packages/scanpy/external/tl/_phenograph.py in phenograph(data, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method); 143 ); 144 ; --> 145 communities, graph, Q = phenograph.cluster(; 146 data=data,; 147 k=k,. /usr/local/lib/python3.8/site-packages/phenograph/cluster.py in cluster(data, clustering_algo, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method, partition_type, resolution_parameter, n_iterations, use_weights, seed, **kargs); 243 ""Leiden completed in {} seconds"".format(time.time() - tic_), flush=True,; 244 ); --> 245 communities = np.asarray(communities.membership); 246 ; 247 print(""Sorting communities by size, please wait ..."", flush=True). /usr/local/lib/python3.8/site-packages/phenograph/core.py in neighbor_graph(kernel, kernelargs); 82 :return graph: n-by-n COO sparse matrix; 83 """"""; ---> 84 i, j, s = kernel(**kernelargs); 85 n, k = kernelargs[""idx""].shape; 86 graph = sp.coo_matrix((s, (i, j)), shape=(n, n)). /usr/local/lib/python3.8/site-packages/phenogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407
https://github.com/scverse/scanpy/issues/1408:33,Availability,down,downloaded,33,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:296,Availability,error,error,296,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:673,Availability,toler,tolerance,673,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3162,Availability,toler,tolerance,3162,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3365,Availability,toler,tolerance,3365,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3375,Availability,toler,tolerance,3375,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:2509,Energy Efficiency,reduce,reduce,2509,"_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:302,Integrability,message,message,302,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:375,Performance,cache,cache,375,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:429,Performance,cache,cache,429,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:1475,Performance,cache,cache,1475,"most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applica",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:1546,Performance,cache,cache,1546,"most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applica",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:1552,Performance,cache,cache,1552,"most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applica",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:1761,Performance,cache,cache,1761,".index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:2650,Performance,cache,cache,2650,"xists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:2781,Performance,cache,cache,2781,"he_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:953,Security,hash,hashtable,953,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:1046,Security,hash,hashtable,1046,"O using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3579,Security,hash,hashtable,3579,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3672,Security,hash,hashtable,3672,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1408:3859,Usability,learn,learn,3859,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408
https://github.com/scverse/scanpy/issues/1409:2591,Deployability,update,updated,2591,"ed, there were issues on how to concatenate objects, but they did not seem to answer my question here. . ### Minimal code sample (that we can copy&paste without having any data). ```python; # Concatenate to main adata object; adata = adata.concatenate(adata_tmp, batch_key='sample_id'); ```. ```pytb; InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; anndata2ri 1.0.4; attr 20.2.0; backcall 0.2.0; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; gprofiler 1.0.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.6.1; markupsafe 1.1.1; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.7; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; seaborn 0.10.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.0; storemagic NA; tables 3.6.1; terminado 0.8.3; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-4.13.0-36-generic-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2020-09-08 15:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409
https://github.com/scverse/scanpy/issues/1409:2537,Testability,log,logical,2537,"ed, there were issues on how to concatenate objects, but they did not seem to answer my question here. . ### Minimal code sample (that we can copy&paste without having any data). ```python; # Concatenate to main adata object; adata = adata.concatenate(adata_tmp, batch_key='sample_id'); ```. ```pytb; InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; anndata2ri 1.0.4; attr 20.2.0; backcall 0.2.0; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; gprofiler 1.0.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.6.1; markupsafe 1.1.1; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.7; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; seaborn 0.10.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.0; storemagic NA; tables 3.6.1; terminado 0.8.3; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-4.13.0-36-generic-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2020-09-08 15:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409
https://github.com/scverse/scanpy/issues/1409:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; ### Comment; I was just going over the GSE92332 case study. On Section 2, the AnnData objects were created fine, but the concatenation method for AnnData object did not work out for me. I browsed through issues raised, there were issues on how to concatenate objects, but they did not seem to answer my question here. . ### Minimal code sample (that we can copy&paste without having any data). ```python; # Concatenate to main adata object; adata = adata.concatenate(adata_tmp, batch_key='sample_id'); ```. ```pytb; InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; anndata2ri 1.0.4; attr 20.2.0; backcall 0.2.0; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; gprofiler 1.0.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.6.1; markupsafe 1.1.1; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.7; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; requests 2.24.0; r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409
https://github.com/scverse/scanpy/issues/1410:1063,Availability,down,downgrade,1063,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to cluster a manifold of around 100K cells computed from scVI using the `leiden` ; algorithm as follows: . ``` ; sc.tl.leiden(adata_latent, resolution = 1, random_state = 1786); ```; This works fine:. ```; running Leiden clustering; Trying to set attribute `.obs` of view, copying.; finished: found 17 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:07:14); ```. However, when I inspect the object where I just ran `leiden`, I can't see the `leiden` labels in `adata.obs`. ; Instead, it seems to be located in `adata.uns`. . ```; AnnData object with n_obs × n_vars = 106774 × 50; obs: 'percent_mito', 'n_genes', 'n_counts'; uns: 'neighbors', 'umap', 'sampleID_colors', 'batch_colors', 'status_colors', 'leiden'; obsm: 'X_umap'; obsp: 'distances', 'connectivities'; ```. I have tried to downgrade `leidenalg` but there is no change. Do you have an idea what may be happening? . #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.1.1 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410
https://github.com/scverse/scanpy/issues/1410:1269,Usability,learn,learn,1269,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to cluster a manifold of around 100K cells computed from scVI using the `leiden` ; algorithm as follows: . ``` ; sc.tl.leiden(adata_latent, resolution = 1, random_state = 1786); ```; This works fine:. ```; running Leiden clustering; Trying to set attribute `.obs` of view, copying.; finished: found 17 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:07:14); ```. However, when I inspect the object where I just ran `leiden`, I can't see the `leiden` labels in `adata.obs`. ; Instead, it seems to be located in `adata.uns`. . ```; AnnData object with n_obs × n_vars = 106774 × 50; obs: 'percent_mito', 'n_genes', 'n_counts'; uns: 'neighbors', 'umap', 'sampleID_colors', 'batch_colors', 'status_colors', 'leiden'; obsm: 'X_umap'; obsp: 'distances', 'connectivities'; ```. I have tried to downgrade `leidenalg` but there is no change. Do you have an idea what may be happening? . #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.1.1 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410
https://github.com/scverse/scanpy/issues/1411:27,Deployability,install,installed,27,"Dear There,. I recently re-installed the single cell environment. Then, the example code of sc.tl.marker_gene_overlap() on scanpy tutorial does not work. It give the same values to each cluster. Thanks for your help!. Lianyun. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pp.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata); sc.tl.louvain(adata); sc.tl.rank_genes_groups(adata, groupby='louvain'); marker_genes = {'CD4 T cells': {'IL7R'},; 'CD14+ Monocytes': {'CD14', 'LYZ'},; 'B cells': {'MS4A1'},; 'CD8 T cells': {'CD8A'},; 'NK cells': {'GNLY', 'NKG7'},; 'FCGR3A+ Monocytes': {'FCGR3A', 'MS4A7'},; 'Dendritic Cells': {'FCER1A', 'CST3'},; 'Megakaryocytes': {'PPBP'}}; marker_matches = sc.tl.marker_gene_overlap(adata, marker_genes); ```. ```pytb; 	0	1	2	3	4	5	6; CD4 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD14+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; B cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD8 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; NK cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; FCGR3A+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; Dendritic Cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; Megakaryocytes	0.0	0.0	0.0	0.0	0.0	0.0	0.0; ![image](https://user-images.githubusercontent.com/57720451/92608724-029c7880-f2b6-11ea-9860-59c705183fb2.png). ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cffi 1.14.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1411
https://github.com/scverse/scanpy/issues/1411:2446,Deployability,update,updated,2446,"nocytes': {'CD14', 'LYZ'},; 'B cells': {'MS4A1'},; 'CD8 T cells': {'CD8A'},; 'NK cells': {'GNLY', 'NKG7'},; 'FCGR3A+ Monocytes': {'FCGR3A', 'MS4A7'},; 'Dendritic Cells': {'FCER1A', 'CST3'},; 'Megakaryocytes': {'PPBP'}}; marker_matches = sc.tl.marker_gene_overlap(adata, marker_genes); ```. ```pytb; 	0	1	2	3	4	5	6; CD4 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD14+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; B cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD8 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; NK cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; FCGR3A+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; Dendritic Cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; Megakaryocytes	0.0	0.0	0.0	0.0	0.0	0.0	0.0; ![image](https://user-images.githubusercontent.com/57720451/92608724-029c7880-f2b6-11ea-9860-59c705183fb2.png). ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cffi 1.14.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.0; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; umap 0.4.6; wcwidth 0.2.5; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10; 128 logical CPU cores, x86_64; -----; Session information updated at 2020-09-09 15:47. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1411
https://github.com/scverse/scanpy/issues/1411:2392,Testability,log,logical,2392,"nocytes': {'CD14', 'LYZ'},; 'B cells': {'MS4A1'},; 'CD8 T cells': {'CD8A'},; 'NK cells': {'GNLY', 'NKG7'},; 'FCGR3A+ Monocytes': {'FCGR3A', 'MS4A7'},; 'Dendritic Cells': {'FCER1A', 'CST3'},; 'Megakaryocytes': {'PPBP'}}; marker_matches = sc.tl.marker_gene_overlap(adata, marker_genes); ```. ```pytb; 	0	1	2	3	4	5	6; CD4 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD14+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; B cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; CD8 T cells	1.0	1.0	1.0	1.0	1.0	1.0	1.0; NK cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; FCGR3A+ Monocytes	1.0	1.0	1.0	1.0	1.0	1.0	1.0; Dendritic Cells	2.0	2.0	2.0	2.0	2.0	2.0	2.0; Megakaryocytes	0.0	0.0	0.0	0.0	0.0	0.0	0.0; ![image](https://user-images.githubusercontent.com/57720451/92608724-029c7880-f2b6-11ea-9860-59c705183fb2.png). ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cffi 1.14.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.0; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; umap 0.4.6; wcwidth 0.2.5; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10; 128 logical CPU cores, x86_64; -----; Session information updated at 2020-09-09 15:47. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1411
https://github.com/scverse/scanpy/issues/1412:1081,Availability,error,error,1081,"[ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412
https://github.com/scverse/scanpy/issues/1412:1089,Availability,Error,Error,1089,"canpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412
https://github.com/scverse/scanpy/issues/1412:1867,Testability,log,log,1867,"symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories,; -> 1385 layer=layer, gene_symbols=gene_symbols); 1386 ; 1387 # for if category defined by groupby (if any) compute for each var_name. TypeError: cannot unpack non-iterable NoneType object. My understanding is that it should search for 'ENSG00000104814' in the index column and return the corresponding value in 'symbols', but it seems that is directly searching 'ENSG00000104814' in the 'symbols' column. . Thanks for helping, find below the version I am using: . #### Versions. scanpy==1.4.1 anndata==0.6.22.post1 numpy==1.15.4 scipy==1.1.0 pandas==0.25.2 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412
https://github.com/scverse/scanpy/issues/1412:2222,Testability,log,log,2222,"symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories,; -> 1385 layer=layer, gene_symbols=gene_symbols); 1386 ; 1387 # for if category defined by groupby (if any) compute for each var_name. TypeError: cannot unpack non-iterable NoneType object. My understanding is that it should search for 'ENSG00000104814' in the index column and return the corresponding value in 'symbols', but it seems that is directly searching 'ENSG00000104814' in the 'symbols' column. . Thanks for helping, find below the version I am using: . #### Versions. scanpy==1.4.1 anndata==0.6.22.post1 numpy==1.15.4 scipy==1.1.0 pandas==0.25.2 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412
https://github.com/scverse/scanpy/issues/1412:2808,Usability,learn,learn,2808,"symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories,; -> 1385 layer=layer, gene_symbols=gene_symbols); 1386 ; 1387 # for if category defined by groupby (if any) compute for each var_name. TypeError: cannot unpack non-iterable NoneType object. My understanding is that it should search for 'ENSG00000104814' in the index column and return the corresponding value in 'symbols', but it seems that is directly searching 'ENSG00000104814' in the 'symbols' column. . Thanks for helping, find below the version I am using: . #### Versions. scanpy==1.4.1 anndata==0.6.22.post1 numpy==1.15.4 scipy==1.1.0 pandas==0.25.2 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412
https://github.com/scverse/scanpy/pull/1413:165,Testability,test,tests,165,This is an attempt to fix #1011. I have taken my cue from https://github.com/lmcinnes/umap/pull/259/files as suggested in the issue's thread. I have also added some tests (which focus on ensuring that results are successfully created rather than ensuring correctness). I hope this helps.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413
https://github.com/scverse/scanpy/issues/1414:1004,Testability,log,log,1004,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters"") ; adata.obs[""seurat_clusters""].dtype.name != 'category'; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-33-097156e92bcf> in <module>; ----> 1 ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters""). D:\python\empty for python\lib\site-packages\scanpy\plotting\_anndata.py in tracksplot(adata, var_names, groupby, use_raw, log, dendrogram, gene_symbols, var_group_positions, var_group_labels, layer, show, save, figsize, **kwds); 1304 if groupby not in adata.obs_keys() or adata.obs[groupby].dtype.name != 'category':; 1305 raise ValueError(; -> 1306 'groupby has to be a valid categorical observation. '; 1307 f'Given value: {groupby}, valid categorical observations: '; 1308 f'{[x for x in adata.obs_keys() if adata.obs[x].dtype.name == ""category""]}'. ValueError: groupby has to be a valid categorical observation. Given value: seurat_clusters, valid categorical observations: []. Ture; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414
https://github.com/scverse/scanpy/issues/1414:1629,Testability,log,logging,1629,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters"") ; adata.obs[""seurat_clusters""].dtype.name != 'category'; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-33-097156e92bcf> in <module>; ----> 1 ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters""). D:\python\empty for python\lib\site-packages\scanpy\plotting\_anndata.py in tracksplot(adata, var_names, groupby, use_raw, log, dendrogram, gene_symbols, var_group_positions, var_group_labels, layer, show, save, figsize, **kwds); 1304 if groupby not in adata.obs_keys() or adata.obs[groupby].dtype.name != 'category':; 1305 raise ValueError(; -> 1306 'groupby has to be a valid categorical observation. '; 1307 f'Given value: {groupby}, valid categorical observations: '; 1308 f'{[x for x in adata.obs_keys() if adata.obs[x].dtype.name == ""category""]}'. ValueError: groupby has to be a valid categorical observation. Given value: seurat_clusters, valid categorical observations: []. Ture; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414
https://github.com/scverse/scanpy/issues/1414:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters"") ; adata.obs[""seurat_clusters""].dtype.name != 'category'; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-33-097156e92bcf> in <module>; ----> 1 ax = sc.pl.tracksplot(adata, markers, groupby = ""seurat_clusters""). D:\python\empty for python\lib\site-packages\scanpy\plotting\_anndata.py in tracksplot(adata, var_names, groupby, use_raw, log, dendrogram, gene_symbols, var_group_positions, var_group_labels, layer, show, save, figsize, **kwds); 1304 if groupby not in adata.obs_keys() or adata.obs[groupby].dtype.name != 'category':; 1305 raise ValueError(; -> 1306 'groupby has to be a valid categorical observation. '; 1307 f'Given value: {groupby}, valid categorical observations: '; 1308 f'{[x for x in adata.obs_keys() if adata.obs[x].dtype.name == ""category""]}'. ValueError: groupby has to be a valid categorical observation. Given value: seurat_clusters, valid categorical observations: []. Ture; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414
https://github.com/scverse/scanpy/issues/1418:206,Availability,Error,Error,206,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:360,Availability,Failure,Failure,360,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:638,Availability,FAILURE,FAILURES,638,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:2924,Availability,toler,tolerance,2924,"GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:2971,Availability,toler,tolerance,2971,"ga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3134,Availability,toler,tolerance,3134," save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ---------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3154,Availability,toler,tolerance,3154," save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ---------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3249,Availability,toler,tolerance,3249,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3308,Availability,Error,Error,3308,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3679,Availability,Toler,Tolerance,3679," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3708,Availability,Error,Error,3708," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3917,Availability,Toler,Tolerance,3917,"erance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leavi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:5894,Deployability,update,updated,5894,": \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ```pytb; -----; anndata 0.7.4; scanpy 1.6.1.dev25+g74ac4d37; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; asciitree NA; cycler 0.10.0; cython_runtime NA; dask 2.26.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.7.0; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; monotonic NA; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.1.dev25+g74ac4d37; scipy 1.5.2; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; tlz 0.10.0; toolz 0.10.0; yaml 5.3.1; zappy NA; zarr 2.4.0; zipp NA; -----; Python 3.7.9 (default, Aug 31 2020, 07:22:35) [Clang 10.0.0 ]; Darwin-19.6.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-09-16 13:37. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:368,Integrability,message,message,368,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:35,Testability,test,tests,35,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:116,Testability,test,test,116,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:129,Testability,test,tests,129,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:190,Testability,Assert,AssertionError,190,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:404,Testability,test,tests,404,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:435,Testability,test,tests,435,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:1478,Testability,test,test,1478,".................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:2637,Testability,test,tests,2637,"olor='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3265,Testability,assert,assert,3265,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3292,Testability,Assert,AssertionError,3292,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3437,Testability,test,tests,3437,"nge(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA posit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3532,Testability,test,tests,3532,"for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3630,Testability,test,tests,3630,"_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> add",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3700,Testability,assert,assert,3700," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3869,Testability,test,tests,3869," _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3951,Testability,test,tests,3951,"ompare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:3973,Testability,Assert,AssertionError,3973,"tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ```pytb; -----; anndata 0.7.4; scanpy 1.6.1.dev25+g74ac4d37; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; asciitree NA; cycler 0.10.0; cython_runtime NA; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:4897,Testability,log,logging,4897,"iled-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ```pytb; -----; anndata 0.7.4; scanpy 1.6.1.dev25+g74ac4d37; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; asciitree NA; cycler 0.10.0; cython_runtime NA; dask 2.26.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.7.0; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; monotonic NA; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.1.dev25+g74ac4d37; scipy 1.5.2; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; tlz 0.10.0; toolz 0.10.0; yaml 5.3.1; zappy NA; zarr 2.4.0; zipp NA; -----; Python 3.7.9 (default, Aug 31 2020, 07:22:35) [Clang 10.0.0 ]; Darwin-19.6.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1418:5842,Testability,log,logical,5842,": \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ```pytb; -----; anndata 0.7.4; scanpy 1.6.1.dev25+g74ac4d37; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; asciitree NA; cycler 0.10.0; cython_runtime NA; dask 2.26.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.7.0; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; monotonic NA; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.1.dev25+g74ac4d37; scipy 1.5.2; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; tlz 0.10.0; toolz 0.10.0; yaml 5.3.1; zappy NA; zarr 2.4.0; zipp NA; -----; Python 3.7.9 (default, Aug 31 2020, 07:22:35) [Clang 10.0.0 ]; Darwin-19.6.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-09-16 13:37. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418
https://github.com/scverse/scanpy/issues/1419:306,Deployability,install,installed,306,"## Description. For an easier start of potential contributors, it might be helpful to add a file such as `requirements-dev.txt` including all packages required to e.g. run unit tests locally. Otherwise, several packages (e.g. `leidenalg`, `louvain`, `scikit-misc`, `harmonypy`, `python-igraph`) have to be installed manually which is rather tedious:. ```txt; -r requirements.txt. harmonypy; leidenalg; louvain; scitkit-misc; python-igraph; ```. The wheels to install `python-igraph` under Windows can, for example, be found [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419
https://github.com/scverse/scanpy/issues/1419:459,Deployability,install,install,459,"## Description. For an easier start of potential contributors, it might be helpful to add a file such as `requirements-dev.txt` including all packages required to e.g. run unit tests locally. Otherwise, several packages (e.g. `leidenalg`, `louvain`, `scikit-misc`, `harmonypy`, `python-igraph`) have to be installed manually which is rather tedious:. ```txt; -r requirements.txt. harmonypy; leidenalg; louvain; scitkit-misc; python-igraph; ```. The wheels to install `python-igraph` under Windows can, for example, be found [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419
https://github.com/scverse/scanpy/issues/1419:177,Testability,test,tests,177,"## Description. For an easier start of potential contributors, it might be helpful to add a file such as `requirements-dev.txt` including all packages required to e.g. run unit tests locally. Otherwise, several packages (e.g. `leidenalg`, `louvain`, `scikit-misc`, `harmonypy`, `python-igraph`) have to be installed manually which is rather tedious:. ```txt; -r requirements.txt. harmonypy; leidenalg; louvain; scitkit-misc; python-igraph; ```. The wheels to install `python-igraph` under Windows can, for example, be found [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419
https://github.com/scverse/scanpy/issues/1420:56,Testability,test,tests,56,"## Description. Using the `seaborn==0.11` makes `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail. The warning. ```bash; UserWarning: Vertical orientation ignored with only `x` specified.; ```. is thrown by `seaborn` in the stack trace for the failed tests. The problem seems to originate from [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L745) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L747), where `x` and `y` are not both specified. See #1417 and especially [this](https://github.com/theislab/scanpy/pull/1417#issuecomment-693488428) comment by @fidelram for more details.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420
https://github.com/scverse/scanpy/issues/1420:104,Testability,test,tests,104,"## Description. Using the `seaborn==0.11` makes `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail. The warning. ```bash; UserWarning: Vertical orientation ignored with only `x` specified.; ```. is thrown by `seaborn` in the stack trace for the failed tests. The problem seems to originate from [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L745) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L747), where `x` and `y` are not both specified. See #1417 and especially [this](https://github.com/theislab/scanpy/pull/1417#issuecomment-693488428) comment by @fidelram for more details.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420
https://github.com/scverse/scanpy/issues/1420:294,Testability,test,tests,294,"## Description. Using the `seaborn==0.11` makes `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail. The warning. ```bash; UserWarning: Vertical orientation ignored with only `x` specified.; ```. is thrown by `seaborn` in the stack trace for the failed tests. The problem seems to originate from [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L745) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L747), where `x` and `y` are not both specified. See #1417 and especially [this](https://github.com/theislab/scanpy/pull/1417#issuecomment-693488428) comment by @fidelram for more details.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420
https://github.com/scverse/scanpy/pull/1421:57,Deployability,update,update,57,We recently transitioned from scvi to scvi-tools. Here I update the ecosystem docs to reflect this change. I decided to make a new section for it as we have a diversity of models in our package that don't fit any of the other categories well.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1421
https://github.com/scverse/scanpy/pull/1422:84,Testability,test,tests,84,"## Description. As briefly outlined in #1420, using `seaborn==0.11` causes the unit tests `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail as the violin plots are no longer vertically oriented. ## Changes. * Rely on `seaborn.catplot` and `seaborn.stripplot` instead of `seaborn.FacetGrid` in `scanpy/plotting/_anndata.py`. ## Related issues. Closes #1420.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:98,Testability,test,tests,98,"## Description. As briefly outlined in #1420, using `seaborn==0.11` causes the unit tests `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail as the violin plots are no longer vertically oriented. ## Changes. * Rely on `seaborn.catplot` and `seaborn.stripplot` instead of `seaborn.FacetGrid` in `scanpy/plotting/_anndata.py`. ## Related issues. Closes #1420.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:146,Testability,test,tests,146,"## Description. As briefly outlined in #1420, using `seaborn==0.11` causes the unit tests `scanpy/tests/test_plotting.py:test_violin` and `scanpy/tests/notebooks/test_pbmc3k.py` fail as the violin plots are no longer vertically oriented. ## Changes. * Rely on `seaborn.catplot` and `seaborn.stripplot` instead of `seaborn.FacetGrid` in `scanpy/plotting/_anndata.py`. ## Related issues. Closes #1420.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/issues/1426:368,Deployability,install,installed,368,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. After running sc.tl.rank_genes_groups and sc.get.rank_genes_groups_df using the same data and python/scanpy code, Spider and Jupyter (both installed in the same environment of Anaconda) generate two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:769,Testability,log,logfoldchanges,769,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. After running sc.tl.rank_genes_groups and sc.get.rank_genes_groups_df using the same data and python/scanpy code, Spider and Jupyter (both installed in the same environment of Anaconda) generate two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:1156,Testability,log,logfoldchanges,1156," (optional) I have confirmed this bug exists on the master branch of scanpy. ---. After running sc.tl.rank_genes_groups and sc.get.rank_genes_groups_df using the same data and python/scanpy code, Spider and Jupyter (both installed in the same environment of Anaconda) generate two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; In Spider:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 panda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:1993,Testability,log,logging,1993,"e two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; In Spider:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0. In Jupyter:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:2164,Usability,learn,learn,2164,"e two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; In Spider:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0. In Jupyter:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:2339,Usability,learn,learn,2339,"e two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; In Spider:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0. In Jupyter:; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 leidenalg==0.7.0; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/pull/1428:65,Deployability,install,installed,65,This skips the test `test_harmony_integrate` if harmonypy is not installed.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1428
https://github.com/scverse/scanpy/pull/1428:15,Testability,test,test,15,This skips the test `test_harmony_integrate` if harmonypy is not installed.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1428
https://github.com/scverse/scanpy/issues/1429:50,Availability,avail,available,50,We should make the `random_state` of `make_blobs` available through our `blobs` function. This would make it easier to generate random data for testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:144,Testability,test,testing,144,We should make the `random_state` of `make_blobs` available through our `blobs` function. This would make it easier to generate random data for testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/pull/1430:781,Integrability,depend,depends,781,"Companion PR to https://github.com/theislab/anndata/pull/434. Basically, I would like to deprecate the `dtype` argument of `AnnData._init_as_actual`, since it mostly just makes unexpected copies of `X`. Since other elements of an AnnData object are passed by reference, it makes sense for this to happen with `X` as well. Right now, this PR will fail CI. What I've done so far is remove all uses of that argument from the scanpy code base, while keeping the tests passing. I'm trying to figure out how to best preserve compatibility with older versions of `anndata`, without throwing too many warnings. I think the thing to do will be make code work with both (`AnnData(X.astype(dtype), dtype=dtype))` should only make one copy) and catch warnings. This can be removed once scanpy depends on `anndata 0.8`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1430
https://github.com/scverse/scanpy/pull/1430:458,Testability,test,tests,458,"Companion PR to https://github.com/theislab/anndata/pull/434. Basically, I would like to deprecate the `dtype` argument of `AnnData._init_as_actual`, since it mostly just makes unexpected copies of `X`. Since other elements of an AnnData object are passed by reference, it makes sense for this to happen with `X` as well. Right now, this PR will fail CI. What I've done so far is remove all uses of that argument from the scanpy code base, while keeping the tests passing. I'm trying to figure out how to best preserve compatibility with older versions of `anndata`, without throwing too many warnings. I think the thing to do will be make code work with both (`AnnData(X.astype(dtype), dtype=dtype))` should only make one copy) and catch warnings. This can be removed once scanpy depends on `anndata 0.8`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1430
https://github.com/scverse/scanpy/issues/1431:235,Modifiability,variab,variability,235,"I've been working on scRNA from different patients (diseased and healthy) control and was wondering what is the best approach to concatenate these data? It seems like inner join is usually recommended, but given significant individual variability (especially disease versus healthy states) there would be a large proportion of genes lost. Clustering also does not have good result. So I was wondering in this situation, shall I use outer join and fill value to zero? . Another issue is memory use, I'm running this on google colab, and even using TPU, either using combat for batch correction after concatenation or concatetating two subsets of data after batch correction, would take much RAM that it just crashes (there're about 38K cells). Are there any way to limit memory use in this kind of situation? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/pull/1432:33,Security,hash,hashsolo,33,"Hi there,. I implemented my tool hashsolo for demultiplexing cell hashing data for scanpy to address https://github.com/theislab/scanpy/issues/351. Would be great to to get this in. Let me know if this is close or way off how you would like it implemented for scanpy. associated paper if that matters: ; https://www.cell.com/cell-systems/fulltext/S2405-4712(20)30195-2. Best; Nick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:66,Security,hash,hashing,66,"Hi there,. I implemented my tool hashsolo for demultiplexing cell hashing data for scanpy to address https://github.com/theislab/scanpy/issues/351. Would be great to to get this in. Let me know if this is close or way off how you would like it implemented for scanpy. associated paper if that matters: ; https://www.cell.com/cell-systems/fulltext/S2405-4712(20)30195-2. Best; Nick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/issues/1433:24,Deployability,install,installed,24,"Hi. I have successfully installed scanpy but ; ImportError Traceback (most recent call last); <ipython-input-5-99fcf407c387> in <module>; ----> 1 import scvelo as scv; 2 import scanpy as sc; 3 import numpy as np. ~/anaconda3/lib/python3.7/site-packages/scvelo/__init__.py in <module>; 14 del version; 15 ; ---> 16 from .read_load import AnnData, read, read_loom, load, read_csv, get_df, DataFrame; 17 from .preprocessing.neighbors import Neighbors; 18 from .tools.run import run_all, test. ~/anaconda3/lib/python3.7/site-packages/scvelo/read_load.py in <module>; 10 from scipy.sparse import issparse; 11 from anndata import AnnData; ---> 12 from scanpy import read, read_loom; 13 ; 14 . ImportError: cannot import name 'read' from 'scanpy' (unknown location). Would you please help me to fix this problem. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:363,Performance,load,load,363,"Hi. I have successfully installed scanpy but ; ImportError Traceback (most recent call last); <ipython-input-5-99fcf407c387> in <module>; ----> 1 import scvelo as scv; 2 import scanpy as sc; 3 import numpy as np. ~/anaconda3/lib/python3.7/site-packages/scvelo/__init__.py in <module>; 14 del version; 15 ; ---> 16 from .read_load import AnnData, read, read_loom, load, read_csv, get_df, DataFrame; 17 from .preprocessing.neighbors import Neighbors; 18 from .tools.run import run_all, test. ~/anaconda3/lib/python3.7/site-packages/scvelo/read_load.py in <module>; 10 from scipy.sparse import issparse; 11 from anndata import AnnData; ---> 12 from scanpy import read, read_loom; 13 ; 14 . ImportError: cannot import name 'read' from 'scanpy' (unknown location). Would you please help me to fix this problem. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:484,Testability,test,test,484,"Hi. I have successfully installed scanpy but ; ImportError Traceback (most recent call last); <ipython-input-5-99fcf407c387> in <module>; ----> 1 import scvelo as scv; 2 import scanpy as sc; 3 import numpy as np. ~/anaconda3/lib/python3.7/site-packages/scvelo/__init__.py in <module>; 14 del version; 15 ; ---> 16 from .read_load import AnnData, read, read_loom, load, read_csv, get_df, DataFrame; 17 from .preprocessing.neighbors import Neighbors; 18 from .tools.run import run_all, test. ~/anaconda3/lib/python3.7/site-packages/scvelo/read_load.py in <module>; 10 from scipy.sparse import issparse; 11 from anndata import AnnData; ---> 12 from scanpy import read, read_loom; 13 ; 14 . ImportError: cannot import name 'read' from 'scanpy' (unknown location). Would you please help me to fix this problem. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1434:276,Modifiability,variab,variable,276,"Hi, . Thanks for developing a good tool for analyzing scRNAseq data. In the process of learning scRNAseq analysis with scanpy I have come across a few places in the documentation that left me a bit confused. . The most confusing is that I could not find a description for the variable `n_genes_by_counts` calculated by the function scanpy.pp.calculate_qc_metrics and mentioned in the tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. . I asked a question about this in [the discourse](https://scanpy.discourse.group/t/clarification-of-qc-metrics/295) and was asked to open a github issue. . I guess an explanation for the docs could be something like `n_genes_by_counts: The number of genes with at least 1 count in a cell. Calculated for all cells.` . Since I am writing this I might add that I did not understand exactly how the normalization function [scanpy.pp.normalize_total](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html) works before I stumbled upon the description of the deprecated function with the same purpose: [scanpy.pp.normalize_per_cell](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_per_cell.html) . The deprecated function has a helpful line saying: `Normalize each cell by total counts over all genes, so that every cell has the same total count after normalization.` which at least helped me clear things up. Maybe this line should be added to the new version of the function?. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1434
https://github.com/scverse/scanpy/issues/1434:87,Usability,learn,learning,87,"Hi, . Thanks for developing a good tool for analyzing scRNAseq data. In the process of learning scRNAseq analysis with scanpy I have come across a few places in the documentation that left me a bit confused. . The most confusing is that I could not find a description for the variable `n_genes_by_counts` calculated by the function scanpy.pp.calculate_qc_metrics and mentioned in the tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. . I asked a question about this in [the discourse](https://scanpy.discourse.group/t/clarification-of-qc-metrics/295) and was asked to open a github issue. . I guess an explanation for the docs could be something like `n_genes_by_counts: The number of genes with at least 1 count in a cell. Calculated for all cells.` . Since I am writing this I might add that I did not understand exactly how the normalization function [scanpy.pp.normalize_total](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html) works before I stumbled upon the description of the deprecated function with the same purpose: [scanpy.pp.normalize_per_cell](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_per_cell.html) . The deprecated function has a helpful line saying: `Normalize each cell by total counts over all genes, so that every cell has the same total count after normalization.` which at least helped me clear things up. Maybe this line should be added to the new version of the function?. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1434
https://github.com/scverse/scanpy/issues/1434:1382,Usability,clear,clear,1382,"Hi, . Thanks for developing a good tool for analyzing scRNAseq data. In the process of learning scRNAseq analysis with scanpy I have come across a few places in the documentation that left me a bit confused. . The most confusing is that I could not find a description for the variable `n_genes_by_counts` calculated by the function scanpy.pp.calculate_qc_metrics and mentioned in the tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. . I asked a question about this in [the discourse](https://scanpy.discourse.group/t/clarification-of-qc-metrics/295) and was asked to open a github issue. . I guess an explanation for the docs could be something like `n_genes_by_counts: The number of genes with at least 1 count in a cell. Calculated for all cells.` . Since I am writing this I might add that I did not understand exactly how the normalization function [scanpy.pp.normalize_total](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html) works before I stumbled upon the description of the deprecated function with the same purpose: [scanpy.pp.normalize_per_cell](https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_per_cell.html) . The deprecated function has a helpful line saying: `Normalize each cell by total counts over all genes, so that every cell has the same total count after normalization.` which at least helped me clear things up. Maybe this line should be added to the new version of the function?. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1434
https://github.com/scverse/scanpy/issues/1437:380,Availability,error,error,380,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1437:246,Deployability,install,installed,246,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1437:1000,Integrability,depend,dependencies,1000,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1437:329,Testability,log,logging,329,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1437:952,Testability,log,logging,952,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1438:150,Availability,error,error,150,"The docs for `sc.pl.scatter` say . > The palette can be a valid ListedColormap name ('Set2', 'tab20', …). but setting `palette` to a string throws an error. ```python; adata = sc.datasets.paul15(); sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""); ```. ```pytb; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-698-58a5366a0f70> in <module>; 1 adata = sc.datasets.paul15(); ----> 2 sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:1775,Availability,error,error,1775,"rs, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:1829,Availability,error,error,1829,"ion, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:4044,Deployability,update,updated,4044," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:3710,Integrability,wrap,wrapt,3710," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:779,Modifiability,layers,layers,779,"The docs for `sc.pl.scatter` say . > The palette can be a valid ListedColormap name ('Set2', 'tab20', …). but setting `palette` to a string throws an error. ```python; adata = sc.datasets.paul15(); sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""); ```. ```pytb; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-698-58a5366a0f70> in <module>; 1 adata = sc.datasets.paul15(); ----> 2 sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:1299,Modifiability,layers,layers,1299,"---------------; TypeError Traceback (most recent call last); <ipython-input-698-58a5366a0f70> in <module>; 1 adata = sc.datasets.paul15(); ----> 2 sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:3990,Testability,log,logical,3990," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:3406,Usability,simpl,simplejson,3406," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1439:84,Availability,error,error,84,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:1415,Deployability,update,updated,1415,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:1363,Testability,log,logical,1363,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/pull/1440:50,Safety,avoid,avoids,50,"Anndata's __init__.py is a shortcut, a full path; avoids the issue. This PR uses the full path as fallback if the; shortcut fails. Issue: #1439",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/issues/1441:112,Deployability,install,installed,112,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:131,Deployability,install,install,131,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:182,Deployability,install,install,182,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:244,Deployability,install,install,244,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:71,Integrability,depend,dependencies,71,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:97,Testability,test,testing,97,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:146,Testability,test,test,146,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:198,Testability,test,test,198,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:259,Testability,test,test,259,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:296,Testability,test,test,296,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/pull/1442:40,Deployability,install,install,40,"## Changes / Fixes. * Change / fix `pip install scanpy[test]` to `pip install ""scanpy[test]""`. ## Related issues. Closes #1442.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:70,Deployability,install,install,70,"## Changes / Fixes. * Change / fix `pip install scanpy[test]` to `pip install ""scanpy[test]""`. ## Related issues. Closes #1442.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:55,Testability,test,test,55,"## Changes / Fixes. * Change / fix `pip install scanpy[test]` to `pip install ""scanpy[test]""`. ## Related issues. Closes #1442.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:86,Testability,test,test,86,"## Changes / Fixes. * Change / fix `pip install scanpy[test]` to `pip install ""scanpy[test]""`. ## Related issues. Closes #1442.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/issues/1443:106,Deployability,update,update,106,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:235,Deployability,integrat,integrated,235,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:56,Integrability,wrap,wrapper,56,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:117,Integrability,wrap,wrapper,117,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:235,Integrability,integrat,integrated,235,"I was wondering if we could deprecate the scvi external wrapper as we now have `scvi-tools`. I could also update the wrapper to have minimal functionality, but I think it would be better for people to use our API now that it's tightly integrated with scanpy anyway.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1445:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Would it be possible to add a parameter 'annotate_var_explained' = True/False to the function scanpy.pp.pca to annotate the x- and y-axis of the PCA plot with the variance explained by the component? E.g. x-axis label = PC1 (29%) and y-axis label = PC2 (3%),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1446:989,Testability,log,logfoldchanges,989,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata,'leiden', n_genes=10000,use_raw=False); sc.tl.filter_rank_genes_groups(adata, min_fold_change=2,min_in_group_fraction=0.3,use_raw=False,key='rank_genes_groups'); sc.pl.rank_genes_groups_heatmap(adata, swap_axes=True, use_raw=False, cmap='bwr', dendrogram=True,n_genes=1000,; standard_scale='var',key='rank_genes_groups_filtered'). df1=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); df2=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups_filtered'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); ```. <img width=""721"" alt=""image"" src=""https://user-images.githubusercontent.com/34993687/95295823-56e14b00-08aa-11eb-9b8d-6bbbd4221d10.png"">. Hi,. I have run sc.tl.filter_rank_genes_groups() succssfully, but I find some gene names in adata.uns['rank_genes_groups_filtered']['names'] is nan, but all gene names in adata.uns['rank_genes_groups']['names'] are correct. So, how could this happern?. Thanks,; Jphe. #### Versions. <details>. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:1147,Testability,log,logfoldchanges,1147,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata,'leiden', n_genes=10000,use_raw=False); sc.tl.filter_rank_genes_groups(adata, min_fold_change=2,min_in_group_fraction=0.3,use_raw=False,key='rank_genes_groups'); sc.pl.rank_genes_groups_heatmap(adata, swap_axes=True, use_raw=False, cmap='bwr', dendrogram=True,n_genes=1000,; standard_scale='var',key='rank_genes_groups_filtered'). df1=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); df2=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups_filtered'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); ```. <img width=""721"" alt=""image"" src=""https://user-images.githubusercontent.com/34993687/95295823-56e14b00-08aa-11eb-9b8d-6bbbd4221d10.png"">. Hi,. I have run sc.tl.filter_rank_genes_groups() succssfully, but I find some gene names in adata.uns['rank_genes_groups_filtered']['names'] is nan, but all gene names in adata.uns['rank_genes_groups']['names'] are correct. So, how could this happern?. Thanks,; Jphe. #### Versions. <details>. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata,'leiden', n_genes=10000,use_raw=False); sc.tl.filter_rank_genes_groups(adata, min_fold_change=2,min_in_group_fraction=0.3,use_raw=False,key='rank_genes_groups'); sc.pl.rank_genes_groups_heatmap(adata, swap_axes=True, use_raw=False, cmap='bwr', dendrogram=True,n_genes=1000,; standard_scale='var',key='rank_genes_groups_filtered'). df1=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); df2=pd.DataFrame( {group + '_' + key[:1]: adata.uns['rank_genes_groups_filtered'][key][group] for group in ['0','1'] for key in ['names','logfoldchanges']}); ```. <img width=""721"" alt=""image"" src=""https://user-images.githubusercontent.com/34993687/95295823-56e14b00-08aa-11eb-9b8d-6bbbd4221d10.png"">. Hi,. I have run sc.tl.filter_rank_genes_groups() succssfully, but I find some gene names in adata.uns['rank_genes_groups_filtered']['names'] is nan, but all gene names in adata.uns['rank_genes_groups']['names'] are correct. So, how could this happern?. Thanks,; Jphe. #### Versions. <details>. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1447:408,Performance,bottleneck,bottleneck,408,"Scanpy 1.5.0; Out of curiousity I set min_fold_change to different values but it didn't work. Even when I set min_fold_change=100 it doesn't shorten the gene list. So is it because the filters are working in an OR logic? If that's the case, I don't think the default values for each filter should be the ones you set - they should be a very harsh condition to make sure customer-specified parameters are the bottleneck.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1447
https://github.com/scverse/scanpy/issues/1447:214,Testability,log,logic,214,"Scanpy 1.5.0; Out of curiousity I set min_fold_change to different values but it didn't work. Even when I set min_fold_change=100 it doesn't shorten the gene list. So is it because the filters are working in an OR logic? If that's the case, I don't think the default values for each filter should be the ones you set - they should be a very harsh condition to make sure customer-specified parameters are the bottleneck.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1447
https://github.com/scverse/scanpy/issues/1449:3341,Deployability,update,updated,3341,"ing up 98% of my CPU while running `filter_rank_genes_groups`. #### Versions. <details>. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1`. and. ```; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; Bio 1.77; PIL 7.2.0; adjustText NA; anndata 0.7.4; annoy NA; backcall 0.2.0; bbknn NA; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; changeo 1.0.0; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dandelion 0.0.15; dateutil 2.8.0; decorator 4.4.2; descartes NA; distance NA; get_version 2.1; h5py 2.10.0; hdmedians NA; idna 2.10; igraph 0.8.2; importlib_metadata 1.7.0; ipykernel 5.3.3; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; markupsafe 1.1.1; matplotlib 3.3.0; mizani 0.7.1; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; networkx 2.4; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; palettable 3.3.0; pandas 1.0.5; parso 0.7.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.6.0; polyleven NA; presto 0.6.1; prompt_toolkit 3.0.6; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scrublet NA; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.12.0; skbio 0.5.6; sklearn 0.23.1; socks 1.7.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tools NA; tornado 6.0.4; tqdm 4.48.0; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; yaml 5.1.2; zipp NA; zmq 19.0.1; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:57:50) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-10-08 16:18; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1449
https://github.com/scverse/scanpy/issues/1449:1802,Performance,cache,cachecontrol,1802,"_groups(adata, min_fold_change=1); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 1.5828611850738525 seconds ---; ```. with version 1.6.0:; ```python; import time; start_time = time.time(); sc.tl.rank_genes_groups(adata, groupby = 'leiden', method = 'wilcoxon'); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 49.53031611442566 seconds ---. start_time = time.time(); sc.tl.filter_rank_genes_groups(adata, min_fold_change=1); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 600.4000315666199 seconds ---; ```; I also noticed that it was using up 98% of my CPU while running `filter_rank_genes_groups`. #### Versions. <details>. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1`. and. ```; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; Bio 1.77; PIL 7.2.0; adjustText NA; anndata 0.7.4; annoy NA; backcall 0.2.0; bbknn NA; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; changeo 1.0.0; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dandelion 0.0.15; dateutil 2.8.0; decorator 4.4.2; descartes NA; distance NA; get_version 2.1; h5py 2.10.0; hdmedians NA; idna 2.10; igraph 0.8.2; importlib_metadata 1.7.0; ipykernel 5.3.3; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; markupsafe 1.1.1; matplotlib 3.3.0; mizani 0.7.1; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; networkx 2.4; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; palettable 3.3.0; pandas 1.0.5; parso 0.7.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.6.0; polyleven NA; presto 0.6.1; prompt_toolkit 3.0.6; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scrublet NA; seaborn 0.10.1; setuptools_scm NA; sinf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1449
https://github.com/scverse/scanpy/issues/1449:3287,Testability,log,logical,3287,"ing up 98% of my CPU while running `filter_rank_genes_groups`. #### Versions. <details>. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1`. and. ```; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; Bio 1.77; PIL 7.2.0; adjustText NA; anndata 0.7.4; annoy NA; backcall 0.2.0; bbknn NA; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; changeo 1.0.0; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dandelion 0.0.15; dateutil 2.8.0; decorator 4.4.2; descartes NA; distance NA; get_version 2.1; h5py 2.10.0; hdmedians NA; idna 2.10; igraph 0.8.2; importlib_metadata 1.7.0; ipykernel 5.3.3; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; markupsafe 1.1.1; matplotlib 3.3.0; mizani 0.7.1; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; networkx 2.4; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; palettable 3.3.0; pandas 1.0.5; parso 0.7.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.6.0; polyleven NA; presto 0.6.1; prompt_toolkit 3.0.6; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pyparsing 2.4.7; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scrublet NA; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.12.0; skbio 0.5.6; sklearn 0.23.1; socks 1.7.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; texttable 1.6.2; tools NA; tornado 6.0.4; tqdm 4.48.0; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; yaml 5.1.2; zipp NA; zmq 19.0.1; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jun 1 2020, 18:57:50) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-10-08 16:18; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1449
https://github.com/scverse/scanpy/issues/1449:1564,Usability,learn,learn,1564," = time.time(); sc.tl.rank_genes_groups(adata, groupby = 'leiden', method = 'wilcoxon'); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 50.23415994644165 seconds ---. start_time = time.time(); sc.tl.filter_rank_genes_groups(adata, min_fold_change=1); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 1.5828611850738525 seconds ---; ```. with version 1.6.0:; ```python; import time; start_time = time.time(); sc.tl.rank_genes_groups(adata, groupby = 'leiden', method = 'wilcoxon'); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 49.53031611442566 seconds ---. start_time = time.time(); sc.tl.filter_rank_genes_groups(adata, min_fold_change=1); print(""--- %s seconds ---"" % (time.time() - start_time)); # --- 600.4000315666199 seconds ---; ```; I also noticed that it was using up 98% of my CPU while running `filter_rank_genes_groups`. #### Versions. <details>. `scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1`. and. ```; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; Bio 1.77; PIL 7.2.0; adjustText NA; anndata 0.7.4; annoy NA; backcall 0.2.0; bbknn NA; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.1; changeo 1.0.0; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dandelion 0.0.15; dateutil 2.8.0; decorator 4.4.2; descartes NA; distance NA; get_version 2.1; h5py 2.10.0; hdmedians NA; idna 2.10; igraph 0.8.2; importlib_metadata 1.7.0; ipykernel 5.3.3; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.33.0; markupsafe 1.1.1; matplotlib 3.3.0; mizani 0.7.1; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; networkx 2.4; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; palettable 3.3.0; pandas 1.0.5; parso 0.7.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.6.0; poly",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1449
https://github.com/scverse/scanpy/issues/1451:76,Performance,perform,performing,76,"I am wondering about the motivation that went into subtracting the min when performing standardisation of the scale between genes. I find that it leads a misleading visualisation when the genes expressed by all clusters so I am now copying and modifying your function for my work. Do you think it would be justified to remove min subtraction step or make it optional?; Thanks, and please let me know what you think!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1452:52,Performance,perform,performed,52,"My issue is...; 1. I read the data into anndata and performed all preprocessed steps and then used data matrix to perform non-linear dimensionality reduction (DR).; 2. I performed DR and k-means clustering.; 3. I added back the data into one of the components (X_tsne); 4. Added KM labels also. Now, I am not able to select the clusters based on the cluster.; I want to select one of the clusters and perform clustering on that. Please find the code snippets below. mlle_3d_data=pd.read_csv(""C:/Users/saite/source/df.csv""); mlle_3dc_data=pd.read_csv(""C:/Users/saite/source/dfc.csv""). adata.obsm['X_tsne']=np.asanyarray(mlle_3d_data); adata.obs['km']=list(mlle_3dc_data['clusters']); adata.obs['km']=adata.obs['km'].astype('category'); sc.pl.tsne(adata,color=['km']). ------------------; I am trying to select based on the cluster number how we do with leiden or louvain clustering, but I am not seeing any data.; Please help me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:114,Performance,perform,perform,114,"My issue is...; 1. I read the data into anndata and performed all preprocessed steps and then used data matrix to perform non-linear dimensionality reduction (DR).; 2. I performed DR and k-means clustering.; 3. I added back the data into one of the components (X_tsne); 4. Added KM labels also. Now, I am not able to select the clusters based on the cluster.; I want to select one of the clusters and perform clustering on that. Please find the code snippets below. mlle_3d_data=pd.read_csv(""C:/Users/saite/source/df.csv""); mlle_3dc_data=pd.read_csv(""C:/Users/saite/source/dfc.csv""). adata.obsm['X_tsne']=np.asanyarray(mlle_3d_data); adata.obs['km']=list(mlle_3dc_data['clusters']); adata.obs['km']=adata.obs['km'].astype('category'); sc.pl.tsne(adata,color=['km']). ------------------; I am trying to select based on the cluster number how we do with leiden or louvain clustering, but I am not seeing any data.; Please help me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:170,Performance,perform,performed,170,"My issue is...; 1. I read the data into anndata and performed all preprocessed steps and then used data matrix to perform non-linear dimensionality reduction (DR).; 2. I performed DR and k-means clustering.; 3. I added back the data into one of the components (X_tsne); 4. Added KM labels also. Now, I am not able to select the clusters based on the cluster.; I want to select one of the clusters and perform clustering on that. Please find the code snippets below. mlle_3d_data=pd.read_csv(""C:/Users/saite/source/df.csv""); mlle_3dc_data=pd.read_csv(""C:/Users/saite/source/dfc.csv""). adata.obsm['X_tsne']=np.asanyarray(mlle_3d_data); adata.obs['km']=list(mlle_3dc_data['clusters']); adata.obs['km']=adata.obs['km'].astype('category'); sc.pl.tsne(adata,color=['km']). ------------------; I am trying to select based on the cluster number how we do with leiden or louvain clustering, but I am not seeing any data.; Please help me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:401,Performance,perform,perform,401,"My issue is...; 1. I read the data into anndata and performed all preprocessed steps and then used data matrix to perform non-linear dimensionality reduction (DR).; 2. I performed DR and k-means clustering.; 3. I added back the data into one of the components (X_tsne); 4. Added KM labels also. Now, I am not able to select the clusters based on the cluster.; I want to select one of the clusters and perform clustering on that. Please find the code snippets below. mlle_3d_data=pd.read_csv(""C:/Users/saite/source/df.csv""); mlle_3dc_data=pd.read_csv(""C:/Users/saite/source/dfc.csv""). adata.obsm['X_tsne']=np.asanyarray(mlle_3d_data); adata.obs['km']=list(mlle_3dc_data['clusters']); adata.obs['km']=adata.obs['km'].astype('category'); sc.pl.tsne(adata,color=['km']). ------------------; I am trying to select based on the cluster number how we do with leiden or louvain clustering, but I am not seeing any data.; Please help me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1454:288,Integrability,depend,depending,288,<!-- What kind of feature would you like to request? -->; - [X ] Additional function parameters / changed functionality / changed defaults?; <!-- Please describe your wishes below: -->; Could the function add a boolean parameter to make it work for non-log transformed data?. if [boolean depending on whether data is log transformed or not]:; foldchanges = (self.expm1_func(mean_group) + 1e-9) / (self.expm1_func(mean_rest) + 1e-9); else:; foldchanges = (mean_group+ 1e-9) / (mean_rest + 1e-9),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:253,Testability,log,log,253,<!-- What kind of feature would you like to request? -->; - [X ] Additional function parameters / changed functionality / changed defaults?; <!-- Please describe your wishes below: -->; Could the function add a boolean parameter to make it work for non-log transformed data?. if [boolean depending on whether data is log transformed or not]:; foldchanges = (self.expm1_func(mean_group) + 1e-9) / (self.expm1_func(mean_rest) + 1e-9); else:; foldchanges = (mean_group+ 1e-9) / (mean_rest + 1e-9),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:317,Testability,log,log,317,<!-- What kind of feature would you like to request? -->; - [X ] Additional function parameters / changed functionality / changed defaults?; <!-- Please describe your wishes below: -->; Could the function add a boolean parameter to make it work for non-log transformed data?. if [boolean depending on whether data is log transformed or not]:; foldchanges = (self.expm1_func(mean_group) + 1e-9) / (self.expm1_func(mean_rest) + 1e-9); else:; foldchanges = (mean_group+ 1e-9) / (mean_rest + 1e-9),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1457:1600,Modifiability,variab,variable,1600,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ```; the simple simulation dataset(filter_gene_dis.h5,which is the adata in the simulation code) is; AnnData object with n_obs × n_vars = 3 × 50; [[ 8. 10. 7. 11. 14. 12. 11. 9. 14. 11. 8. 2. 8. 10. 7. 12. 11. 12.; 12. 10. 3. 11. 13. 7. 8. 11. 14. 9. 11. 9. 5. 13. 8. 13. 9. 15.; 11. 8. 7. 7. 5. 12. 9. 12. 11. 8. 11. 6. 10. 11.]; [19. 22. 19. 23. 20. 16. 13. 26. 20. 29. 22. 16. 19. 22. 24. 20. 19. 15.; 17. 25. 23. 19. 18. 18. 24. 18. 25. 22. 25. 16. 25. 23. 27. 22. 14. 21.; 24. 23. 16. 15. 14. 27. 23. 24. 21. 27. 17. 20. 20. 12.]; [27. 31. 32. 30. 29. 31. 24. 29. 29. 33. 29. 29. 26. 38. 27. 32. 21. 24.; 28. 27. 25. 19. 28. 24. 23. 23. 30. 39. 29. 42. 34. 28. 25. 26. 27. 32.; 28. 35. 34. 26. 27. 22. 24. 42. 30. 32. 29. 28. 29. 34.]]```; ```. ```python; import scanpy as sc; import logging; sc.settings.verbosity = 3 ; adata=sc.read(""filter_gene_dis.h5"")#a simulation dataset; #when n_top_genes=10,it returns 3*10; #when n_top_genes=20,it returns 3*19; sc.pp.filter_genes_dispersion(adata,n_top_genes=20); print(adata); ```. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; finished (0:00:00); AnnData object with n_obs × n_vars = 3 × 19; var: 'means', 'dispersions', 'dispersions_norm'; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:1277,Testability,log,logging,1277,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ```; the simple simulation dataset(filter_gene_dis.h5,which is the adata in the simulation code) is; AnnData object with n_obs × n_vars = 3 × 50; [[ 8. 10. 7. 11. 14. 12. 11. 9. 14. 11. 8. 2. 8. 10. 7. 12. 11. 12.; 12. 10. 3. 11. 13. 7. 8. 11. 14. 9. 11. 9. 5. 13. 8. 13. 9. 15.; 11. 8. 7. 7. 5. 12. 9. 12. 11. 8. 11. 6. 10. 11.]; [19. 22. 19. 23. 20. 16. 13. 26. 20. 29. 22. 16. 19. 22. 24. 20. 19. 15.; 17. 25. 23. 19. 18. 18. 24. 18. 25. 22. 25. 16. 25. 23. 27. 22. 14. 21.; 24. 23. 16. 15. 14. 27. 23. 24. 21. 27. 17. 20. 20. 12.]; [27. 31. 32. 30. 29. 31. 24. 29. 29. 33. 29. 29. 26. 38. 27. 32. 21. 24.; 28. 27. 25. 19. 28. 24. 23. 23. 30. 39. 29. 42. 34. 28. 25. 26. 27. 32.; 28. 35. 34. 26. 27. 22. 24. 42. 30. 32. 29. 28. 29. 34.]]```; ```. ```python; import scanpy as sc; import logging; sc.settings.verbosity = 3 ; adata=sc.read(""filter_gene_dis.h5"")#a simulation dataset; #when n_top_genes=10,it returns 3*10; #when n_top_genes=20,it returns 3*19; sc.pp.filter_genes_dispersion(adata,n_top_genes=20); print(adata); ```. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; finished (0:00:00); AnnData object with n_obs × n_vars = 3 × 19; var: 'means', 'dispersions', 'dispersions_norm'; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ```; the simple simulation dataset(filter_gene_dis.h5,which is the adata in the simulation code) is; AnnData object with n_obs × n_vars = 3 × 50; [[ 8. 10. 7. 11. 14. 12. 11. 9. 14. 11. 8. 2. 8. 10. 7. 12. 11. 12.; 12. 10. 3. 11. 13. 7. 8. 11. 14. 9. 11. 9. 5. 13. 8. 13. 9. 15.; 11. 8. 7. 7. 5. 12. 9. 12. 11. 8. 11. 6. 10. 11.]; [19. 22. 19. 23. 20. 16. 13. 26. 20. 29. 22. 16. 19. 22. 24. 20. 19. 15.; 17. 25. 23. 19. 18. 18. 24. 18. 25. 22. 25. 16. 25. 23. 27. 22. 14. 21.; 24. 23. 16. 15. 14. 27. 23. 24. 21. 27. 17. 20. 20. 12.]; [27. 31. 32. 30. 29. 31. 24. 29. 29. 33. 29. 29. 26. 38. 27. 32. 21. 24.; 28. 27. 25. 19. 28. 24. 23. 23. 30. 39. 29. 42. 34. 28. 25. 26. 27. 32.; 28. 35. 34. 26. 27. 22. 24. 42. 30. 32. 29. 28. 29. 34.]]```; ```. ```python; import scanpy as sc; import logging; sc.settings.verbosity = 3 ; adata=sc.read(""filter_gene_dis.h5"")#a simulation dataset; #when n_top_genes=10,it returns 3*10; #when n_top_genes=20,it returns 3*19; sc.pp.filter_genes_dispersion(adata,n_top_genes=20); print(adata); ```. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; finished (0:00:00); AnnData object with n_obs × n_vars = 3 × 19; var: 'means', 'dispersions', 'dispersions_norm'; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:497,Usability,simpl,simple,497,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ```; the simple simulation dataset(filter_gene_dis.h5,which is the adata in the simulation code) is; AnnData object with n_obs × n_vars = 3 × 50; [[ 8. 10. 7. 11. 14. 12. 11. 9. 14. 11. 8. 2. 8. 10. 7. 12. 11. 12.; 12. 10. 3. 11. 13. 7. 8. 11. 14. 9. 11. 9. 5. 13. 8. 13. 9. 15.; 11. 8. 7. 7. 5. 12. 9. 12. 11. 8. 11. 6. 10. 11.]; [19. 22. 19. 23. 20. 16. 13. 26. 20. 29. 22. 16. 19. 22. 24. 20. 19. 15.; 17. 25. 23. 19. 18. 18. 24. 18. 25. 22. 25. 16. 25. 23. 27. 22. 14. 21.; 24. 23. 16. 15. 14. 27. 23. 24. 21. 27. 17. 20. 20. 12.]; [27. 31. 32. 30. 29. 31. 24. 29. 29. 33. 29. 29. 26. 38. 27. 32. 21. 24.; 28. 27. 25. 19. 28. 24. 23. 23. 30. 39. 29. 42. 34. 28. 25. 26. 27. 32.; 28. 35. 34. 26. 27. 22. 24. 42. 30. 32. 29. 28. 29. 34.]]```; ```. ```python; import scanpy as sc; import logging; sc.settings.verbosity = 3 ; adata=sc.read(""filter_gene_dis.h5"")#a simulation dataset; #when n_top_genes=10,it returns 3*10; #when n_top_genes=20,it returns 3*19; sc.pp.filter_genes_dispersion(adata,n_top_genes=20); print(adata); ```. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; finished (0:00:00); AnnData object with n_obs × n_vars = 3 × 19; var: 'means', 'dispersions', 'dispersions_norm'; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:1850,Usability,learn,learn,1850,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ```; the simple simulation dataset(filter_gene_dis.h5,which is the adata in the simulation code) is; AnnData object with n_obs × n_vars = 3 × 50; [[ 8. 10. 7. 11. 14. 12. 11. 9. 14. 11. 8. 2. 8. 10. 7. 12. 11. 12.; 12. 10. 3. 11. 13. 7. 8. 11. 14. 9. 11. 9. 5. 13. 8. 13. 9. 15.; 11. 8. 7. 7. 5. 12. 9. 12. 11. 8. 11. 6. 10. 11.]; [19. 22. 19. 23. 20. 16. 13. 26. 20. 29. 22. 16. 19. 22. 24. 20. 19. 15.; 17. 25. 23. 19. 18. 18. 24. 18. 25. 22. 25. 16. 25. 23. 27. 22. 14. 21.; 24. 23. 16. 15. 14. 27. 23. 24. 21. 27. 17. 20. 20. 12.]; [27. 31. 32. 30. 29. 31. 24. 29. 29. 33. 29. 29. 26. 38. 27. 32. 21. 24.; 28. 27. 25. 19. 28. 24. 23. 23. 30. 39. 29. 42. 34. 28. 25. 26. 27. 32.; 28. 35. 34. 26. 27. 22. 24. 42. 30. 32. 29. 28. 29. 34.]]```; ```. ```python; import scanpy as sc; import logging; sc.settings.verbosity = 3 ; adata=sc.read(""filter_gene_dis.h5"")#a simulation dataset; #when n_top_genes=10,it returns 3*10; #when n_top_genes=20,it returns 3*19; sc.pp.filter_genes_dispersion(adata,n_top_genes=20); print(adata); ```. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; finished (0:00:00); AnnData object with n_obs × n_vars = 3 × 19; var: 'means', 'dispersions', 'dispersions_norm'; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1459:3837,Deployability,update,updated,3837,"kwds); 577 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 578 ; --> 579 if not cb.iterable(width):; 580 lw = (width,); 581 else:. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ![Screenshot 2020-10-16 at 16 10 20](https://user-images.githubusercontent.com/32264060/96275744-ff3d9080-0fc9-11eb-8706-d398e3b08c79.png). #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.3; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.14.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; matplotlib 3.3.2; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; py 1.8.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.2; pytest 5.2.1; pytz 2019.2; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; sphinxcontrib NA; storemagic NA; tables 3.5.2; texttable 1.6.3; tornado 6.0.4; tqdm 4.36.1; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-190-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-10-16 15:10. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:3783,Testability,log,logical,3783,"kwds); 577 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 578 ; --> 579 if not cb.iterable(width):; 580 lw = (width,); 581 else:. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ![Screenshot 2020-10-16 at 16 10 20](https://user-images.githubusercontent.com/32264060/96275744-ff3d9080-0fc9-11eb-8706-d398e3b08c79.png). #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.3; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.14.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; matplotlib 3.3.2; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; py 1.8.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.2; pytest 5.2.1; pytz 2019.2; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; sphinxcontrib NA; storemagic NA; tables 3.5.2; texttable 1.6.3; tornado 6.0.4; tqdm 4.36.1; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-190-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-10-16 15:10. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:3286,Usability,simpl,simplejson,3286,"kwds); 577 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 578 ; --> 579 if not cb.iterable(width):; 580 lw = (width,); 581 else:. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ![Screenshot 2020-10-16 at 16 10 20](https://user-images.githubusercontent.com/32264060/96275744-ff3d9080-0fc9-11eb-8706-d398e3b08c79.png). #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.3; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.14.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; matplotlib 3.3.2; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; py 1.8.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.2; pytest 5.2.1; pytz 2019.2; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; sphinxcontrib NA; storemagic NA; tables 3.5.2; texttable 1.6.3; tornado 6.0.4; tqdm 4.36.1; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-190-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-10-16 15:10. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1460:764,Availability,error,error,764,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi scanpy develovepers,. A rotation student asked me what is `sc.pl.umap` showing if `sc.tl.umap` was not computed beforehand. To which I don't have the answer since I have never done it. If you know the answer I'd like to know it, but most importantly, I think it would be nice to have an error message in the UMAP plotting function if UMAP has not been computed. Unless there were meaning and a reason to use `sc.pl.umap` without running `sc.tl.umap` previously, and it was designed that way purposely. I assume this would apply to other plotting functions too. Thanks!; Alejandro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:770,Integrability,message,message,770,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi scanpy develovepers,. A rotation student asked me what is `sc.pl.umap` showing if `sc.tl.umap` was not computed beforehand. To which I don't have the answer since I have never done it. If you know the answer I'd like to know it, but most importantly, I think it would be nice to have an error message in the UMAP plotting function if UMAP has not been computed. Unless there were meaning and a reason to use `sc.pl.umap` without running `sc.tl.umap` previously, and it was designed that way purposely. I assume this would apply to other plotting functions too. Thanks!; Alejandro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi scanpy develovepers,. A rotation student asked me what is `sc.pl.umap` showing if `sc.tl.umap` was not computed beforehand. To which I don't have the answer since I have never done it. If you know the answer I'd like to know it, but most importantly, I think it would be nice to have an error message in the UMAP plotting function if UMAP has not been computed. Unless there were meaning and a reason to use `sc.pl.umap` without running `sc.tl.umap` previously, and it was designed that way purposely. I assume this would apply to other plotting functions too. Thanks!; Alejandro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1461:870,Testability,log,logfoldchanges,870,"Hi，here is a bug in the funtion named ""scanpy.tl.rank_genes_groups"". I tried to filter the genes starting with ""HLA"", then I used ""scanpy.tl.rank_genes_groups"" to check the marker genes in each group. However, the genes starting with ""HLA"" still existed. ### Minimal code sample (that we can copy&paste without having any data). ```python; no_HLA_genes =~adata.var_names.str.startswith(('HLA')); adata = adata[:, no_HLA_genes].copy(); print(adata.var_names[adata.var_names.str.startswith(('HLA'))]); ```; output: Index([], dtype='object'). ```python; sc.tl.rank_genes_groups(adata , 'leiden_r2', method='wilcoxon',n_genes=-1); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(20); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges']}).head(20); ```; ![image](https://user-images.githubusercontent.com/53402047/96684056-8feee480-13ad-11eb-9aef-00858ce3394e.png). #### Versions. <details>; scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.17.3 scipy==1.5.2 pandas==0.23.4 scikit-learn==0.23.2 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1461
https://github.com/scverse/scanpy/issues/1461:1132,Usability,learn,learn,1132,"Hi，here is a bug in the funtion named ""scanpy.tl.rank_genes_groups"". I tried to filter the genes starting with ""HLA"", then I used ""scanpy.tl.rank_genes_groups"" to check the marker genes in each group. However, the genes starting with ""HLA"" still existed. ### Minimal code sample (that we can copy&paste without having any data). ```python; no_HLA_genes =~adata.var_names.str.startswith(('HLA')); adata = adata[:, no_HLA_genes].copy(); print(adata.var_names[adata.var_names.str.startswith(('HLA'))]); ```; output: Index([], dtype='object'). ```python; sc.tl.rank_genes_groups(adata , 'leiden_r2', method='wilcoxon',n_genes=-1); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(20); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names','logfoldchanges']}).head(20); ```; ![image](https://user-images.githubusercontent.com/53402047/96684056-8feee480-13ad-11eb-9aef-00858ce3394e.png). #### Versions. <details>; scanpy==1.5.1 anndata==0.7.1 umap==0.4.6 numpy==1.17.3 scipy==1.5.2 pandas==0.23.4 scikit-learn==0.23.2 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1461
https://github.com/scverse/scanpy/issues/1462:512,Usability,learn,learn,512,"- [x] I have checked that this issue has not already been reported. ---. Hi,. with scanpy version 1.6.0, the `standard_scale = 'var'` option looks like scaling wasn't done and looks exactly the same as `standard_scale = None`. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.stacked_violin(adata, genes, standard_scale = 'var', groupby = 'leiden'); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.5.3 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.7.1 leidenalg==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1462
https://github.com/scverse/scanpy/issues/1463:2490,Testability,log,logical,2490,"rplot is wrong. . ### Minimal code sample. ```python; import anndata; import numpy as np; import scanpy as sc. X = np.array([[1], [2], [3]]); pos = np.array([[1, 0], [0, 2], [0, 0]]); conn = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]). adata = anndata.AnnData(X=X); adata.obsm[""X_spatial""] = pos; adata.obsp[""spatial_connectivity""] = conn. key_added = ""spatial""; conns_key = ""spatial_connectivity""; adata.uns[key_added] = {}; neighbors_dict = adata.uns[key_added]; neighbors_dict[""connectivities_key""] = conns_key; neighbors_dict[""distances_key""] = ""dummy"". sc.pl.embedding(adata, basis=""spatial"", edges=True, neighbors_key=""spatial"", edges_width=4); ```. ![image](https://user-images.githubusercontent.com/25104767/96718181-ee18c900-13a7-11eb-92ef-147e1d4345a6.png). #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 6.2.1; anndata 0.7.4; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.7.0; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.2.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; networkx 2.3; numba 0.51.0; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.1; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; -----; Python 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) [GCC 7.3.0]; Linux-4.15.0-118-generic-x86_64-with-debian-buster-sid; 4 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1463
https://github.com/scverse/scanpy/pull/1465:272,Modifiability,variab,variable,272,"Right now, if you specify `groupby` to `sc.tl.dendrogram`, but not `dendrogram_key`, storage (and subsequent retrieval) from `adata.uns` is messed up because `groupby` is converted from `str` --> `list` during computation. To give a more concrete example, if my `groupby` variable was ""cell_subtype"", I would expect it to be stored in `adata.uns` as ""dendrogram_cell_subtype"". However, because of the list conversion it's stored as ""dendrogram_['cell_subtype']"" (shown below). ![image](https://user-images.githubusercontent.com/4998310/96769236-d5f77880-13ac-11eb-947f-3dbcf7069d82.png). This PR attempts to address that. I'm not sure if this is the way you want to go about fixing it, but it's one option. Thanks for the great package!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1465
https://github.com/scverse/scanpy/issues/1467:460,Availability,error,error,460,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:724,Availability,error,error,724,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:382,Deployability,pipeline,pipeline,382,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:2032,Testability,log,logging,2032,"s on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.2; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:808,Usability,guid,guide,808,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:1910,Usability,learn,learn,1910,"s on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.2; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1468:40,Availability,error,error,40,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:145,Availability,error,error,145,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:251,Modifiability,config,config,251,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:51,Performance,load,load,51,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:296,Performance,load,load,296,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:311,Performance,Load,Loader,311,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:352,Performance,Load,Loader,352,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:405,Performance,load,load,405,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:441,Performance,load,load,441,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1264,Performance,load,load,1264,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:362,Safety,unsafe,unsafe,362,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:961,Testability,log,logging,961,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:972,Testability,log,logg,972,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1469:357,Testability,log,log-ratio,357,"Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1471:4,Availability,down,download,4,"The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:128,Availability,down,downloaded,128,"The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/pull/1472:97,Availability,error,error,97,The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:118,Availability,down,download,118,The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1473:0,Deployability,Update,Update,0,Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1474:15,Usability,simpl,simple,15,This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/issues/1475:285,Availability,error,errors,285,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:23,Deployability,release,released,23,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:114,Usability,simpl,simple,114,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/pull/1476:1236,Availability,mainten,maintenance,1236,"This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required.; - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. ; - I've moved what was sensible to use Scanpy functions. ; - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:284,Integrability,wrap,wrapped,284,"This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required.; - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. ; - I've moved what was sensible to use Scanpy functions. ; - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/issues/1477:1814,Deployability,install,installed,1814,"set_figure_params(figsize=(4, 4), ipython_format=None); ```; then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:; ```; def set_figure_params(; ......etc.....; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; from matplotlib import rcParams; .....etc......; ```; where the:; ```; IPython.display.set_matplotlib_formats(*ipython_format); ```; produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": ; ```; def set_figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:; ```; def _is_run_from_ipython():; """"""Determines whether run from Ipython.; Only affects progress bars.; """"""; try:; __IPYTHON__; return True; except NameError:; return False; ```. #### Versions. <details>. scanpy.logging.print_versions(); -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.0; anndata 0.7.4; cairo 1.20.0; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3444,Deployability,update,updated,3444,"figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:; ```; def _is_run_from_ipython():; """"""Determines whether run from Ipython.; Only affects progress bars.; """"""; try:; __IPYTHON__; return True; except NameError:; return False; ```. #### Versions. <details>. scanpy.logging.print_versions(); -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.0; anndata 0.7.4; cairo 1.20.0; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.34.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; -----; Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]; Linux-3.13.0-143-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2020-11-01 11:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1344,Integrability,message,message,1344," the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data); ```; import scanpy as sc; sc.set_figure_params(figsize=(4, 4)); ```; The output in console is:; ```; In :. In :; ```; and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":; ```; sc.set_figure_params(figsize=(4, 4), ipython_format=None); ```; then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:; ```; def set_figure_params(; ......etc.....; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; from matplotlib import rcParams; .....etc......; ```; where the:; ```; IPython.display.set_matplotlib_formats(*ipython_format); ```; produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": ; ```; def set_figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2603,Testability,log,logging,2603,"figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:; ```; def _is_run_from_ipython():; """"""Determines whether run from Ipython.; Only affects progress bars.; """"""; try:; __IPYTHON__; return True; except NameError:; return False; ```. #### Versions. <details>. scanpy.logging.print_versions(); -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.0; anndata 0.7.4; cairo 1.20.0; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.34.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; -----; Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]; Linux-3.13.0-143-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2020-11-01 11:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3390,Testability,log,logical,3390,"figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:; ```; def _is_run_from_ipython():; """"""Determines whether run from Ipython.; Only affects progress bars.; """"""; try:; __IPYTHON__; return True; except NameError:; return False; ```. #### Versions. <details>. scanpy.logging.print_versions(); -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.0; anndata 0.7.4; cairo 1.20.0; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.34.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; -----; Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]; Linux-3.13.0-143-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2020-11-01 11:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2479,Usability,progress bar,progress bars,2479," set_figure_params(; ......etc.....; if self._is_run_from_ipython():; try:; import IPython; if isinstance(ipython_format, str):; ipython_format = [ipython_format]; IPython.display.set_matplotlib_formats(*ipython_format); except Exception:; pass; ```; The ""try:"" ; ```; >>> import IPython; ```; doesn't throw an exception, as IPython is installed:; ```; $ pip show IPython; Name: ipython; Version: 7.18.1; Summary: IPython: Productive Interactive Computing; Home-page: https://ipython.org; Author: The IPython Development Team; Author-email: ipython-dev@python.org; License: BSD; Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages; Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare; Required-by: ipywidgets, ipykernel; ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:; ```; def _is_run_from_ipython():; """"""Determines whether run from Ipython.; Only affects progress bars.; """"""; try:; __IPYTHON__; return True; except NameError:; return False; ```. #### Versions. <details>. scanpy.logging.print_versions(); -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.0; anndata 0.7.4; cairo 1.20.0; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.34.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; -----; Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]; Linux-3.13.0-143-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2020-11-01 11:37. </deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1478:121,Availability,error,error,121,"Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---; ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-92-a8f4e965724c> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 607 for col in test_obj.stats.columns.levels[0]:; 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(; --> 609 index=False, column_dtypes=dtypes[col]; 610 ); 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'; ```; I was wondering that its associate with my pandas version? or other issues?; my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:54,Performance,perform,perform,54,"Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---; ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-92-a8f4e965724c> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 607 for col in test_obj.stats.columns.levels[0]:; 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(; --> 609 index=False, column_dtypes=dtypes[col]; 610 ); 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'; ```; I was wondering that its associate with my pandas version? or other issues?; my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1479:686,Energy Efficiency,green,green,686,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description; The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23.; Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7.; However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample; Below are a few lines to reproduce this behaviour:; ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],; 'T-cell': ['CD3D'],; 'B-cell': ['CD79A', 'MS4A1'],; 'Monocytes': ['FCGR3A'],; 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1480:501,Deployability,update,update,501,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # update to h5py e.g. as: pip install h5py==3.0.0; import scanpy as sc. adata = sc.datasets.blobs(); sc.read(""foo.h5ad"").obs_names # names are bytes, not str; # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640); ```; When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:529,Deployability,install,install,529,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # update to h5py e.g. as: pip install h5py==3.0.0; import scanpy as sc. adata = sc.datasets.blobs(); sc.read(""foo.h5ad"").obs_names # names are bytes, not str; # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640); ```; When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3875,Deployability,update,updated,3875,", delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; opt_einsum v3.3.0; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pyparsing 2.4.7; python_utils NA; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; scvelo 0.2.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; threadpoolctl 2.1.0; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-3-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2020-11-03 13:36. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3612,Integrability,wrap,wrapt,3612,", delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; opt_einsum v3.3.0; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pyparsing 2.4.7; python_utils NA; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; scvelo 0.2.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; threadpoolctl 2.1.0; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-3-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2020-11-03 13:36. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1613,Performance,cache,cache,1613,"x([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640); ```; When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1959,Performance,cache,cache,1959,"m/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2140,Testability,log,logg,2140,"m/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3829,Testability,log,logical,3829,", delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; opt_einsum v3.3.0; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pyparsing 2.4.7; python_utils NA; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; scvelo 0.2.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; threadpoolctl 2.1.0; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-3-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2020-11-03 13:36. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # update to h5py e.g. as: pip install h5py==3.0.0; import scanpy as sc. adata = sc.datasets.blobs(); sc.read(""foo.h5ad"").obs_names # names are bytes, not str; # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640); ```; When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1481:542,Availability,error,error,542,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
