id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:19419,Testability,test,test-environment,19419,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_mkl.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:19680,Testability,test,tests,19680,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_mkl.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:19750,Testability,test,test-environment,19750,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_mkl.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20035,Testability,test,test-environment,20035,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20164,Testability,test,test-environment,20164,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20424,Testability,test,tests,20424,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20495,Testability,test,test-environment,20495,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_noise.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20780,Testability,test,test-environment,20780,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:20909,Testability,test,test-environment,20909,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21168,Testability,test,tests,21168,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21240,Testability,test,test-environment,21240,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_openmp.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21525,Testability,test,test-environment,21525,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21654,Testability,test,test-environment,21654,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21909,Testability,test,tests,21909,"rt__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON_",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:21985,Testability,test,test-environment,21985,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_operators.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:22270,Testability,test,test-environment,22270,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:22399,Testability,test,test-environment,22399,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:22658,Testability,test,tests,22658,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:22730,Testability,test,test-environment,22730,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_optpulseprocessor.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23015,Testability,test,test-environment,23015,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23144,Testability,test,test-environment,23144,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23399,Testability,test,tests,23399,"rt__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON_",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23475,Testability,test,test-environment,23475,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_parallel.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23760,Testability,test,test-environment,23760,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:23889,Testability,test,test-environment,23889,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24150,Testability,test,tests,24150,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYT",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24220,Testability,test,test-environment,24220,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _______________ ERROR collecting tests/test_partial_transpose.py _______________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24505,Testability,test,test-environment,24505,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24634,Testability,test,test-environment,24634,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting test",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24893,Testability,test,tests,24893,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:24965,Testability,test,test-environment,24965,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_piqs.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:25250,Testability,test,test-environment,25250,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:25379,Testability,test,test-environment,25379,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:25637,Testability,test,tests,25637,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:25710,Testability,test,test-environment,25710,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_processor.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:25995,Testability,test,test-environment,25995,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:26124,Testability,test,test-environment,26124,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:26384,Testability,test,tests,26384,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:26455,Testability,test,test-environment,26455,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_propagator.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:26740,Testability,test,test-environment,26740,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:26869,Testability,test,test-environment,26869,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27130,Testability,test,tests,27130,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27200,Testability,test,test-environment,27200,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_ptrace.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27485,Testability,test,test-environment,27485,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27614,Testability,test,test-environment,27614,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27876,Testability,test,tests,27876,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYT",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:27945,Testability,test,test-environment,27945,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_pulse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:28230,Testability,test,test-environment,28230,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:28359,Testability,test,test-environment,28359,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:28620,Testability,test,tests,28620,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYT",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:28690,Testability,test,test-environment,28690,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qft.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:28975,Testability,test,test-environment,28975,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:29104,Testability,test,test-environment,29104,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:29364,Testability,test,tests,29364,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:29435,Testability,test,test-environment,29435,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_qobj.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:29720,Testability,test,test-environment,29720,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:29849,Testability,test,test-environment,29849,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30111,Testability,test,tests,30111,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYT",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30180,Testability,test,test-environment,30180,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qobjevo.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30465,Testability,test,test-environment,30465,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30594,Testability,test,test-environment,30594,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30850,Testability,test,tests,30850,"rt__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:30925,Testability,test,test-environment,30925,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ______________________ ERROR collecting tests/test_qpt.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:31210,Testability,test,test-environment,31210,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:31339,Testability,test,test-environment,31339,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:31596,Testability,test,tests,31596,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:31670,Testability,test,test-environment,31670,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ________________ ERROR collecting tests/test_qubit_evolution.py ________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:31955,Testability,test,test-environment,31955,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:32084,Testability,test,test-environment,32084,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:32344,Testability,test,tests,32344,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:32415,Testability,test,test-environment,32415,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_qubitcircuit.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:32700,Testability,test,test-environment,32700,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:32829,Testability,test,test-environment,32829,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33090,Testability,test,tests,33090,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYT",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33160,Testability,test,test-environment,33160,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_qubits.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33445,Testability,test,test-environment,33445,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33574,Testability,test,test-environment,33574,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33834,Testability,test,tests,33834,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:33905,Testability,test,test-environment,33905,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _____________________ ERROR collecting tests/test_rand.py ______________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:34190,Testability,test,test-environment,34190,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:34319,Testability,test,test-environment,34319,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting test",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:34578,Testability,test,tests,34578,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:34650,Testability,test,test-environment,34650,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_random.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:34935,Testability,test,test-environment,34935,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:35064,Testability,test,test-environment,35064,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:35322,Testability,test,tests,35322,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:35395,Testability,test,test-environment,35395,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_rhs_reuse.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:35680,Testability,test,test-environment,35680,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:35809,Testability,test,test-environment,35809,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36069,Testability,test,tests,36069,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36140,Testability,test,test-environment,36140,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_scattering.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36425,Testability,test,test-environment,36425,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36554,Testability,test,test-environment,36554,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36814,Testability,test,tests,36814,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:36885,Testability,test,test-environment,36885,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sesolve.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:37170,Testability,test,test-environment,37170,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:37299,Testability,test,test-environment,37299,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:37559,Testability,test,tests,37559,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:37630,Testability,test,test-environment,37630,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sp_eigs.py ____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:37915,Testability,test,test-environment,37915,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:38044,Testability,test,test-environment,38044,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:38303,Testability,test,tests,38303,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:38375,Testability,test,test-environment,38375,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_sparse.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:38660,Testability,test,test-environment,38660,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:38789,Testability,test,test-environment,38789,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39049,Testability,test,tests,39049,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39120,Testability,test,test-environment,39120,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_spinchain.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39405,Testability,test,test-environment,39405,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39534,Testability,test,test-environment,39534,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting test",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39794,Testability,test,tests,39794,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:39865,Testability,test,test-environment,39865,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_spmath.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:40150,Testability,test,test-environment,40150,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:40279,Testability,test,test-environment,40279,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:40537,Testability,test,tests,40537,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:40610,Testability,test,test-environment,40610,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_states.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:40895,Testability,test,test-environment,40895,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:41024,Testability,test,test-environment,41024,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:41281,Testability,test,tests,41281,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:41355,Testability,test,test-environment,41355,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_steadystate.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:41640,Testability,test,test-environment,41640,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:41769,Testability,test,test-environment,41769,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42026,Testability,test,tests,42026,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42100,Testability,test,test-environment,42100,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_me.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42385,Testability,test,test-environment,42385,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42514,Testability,test,test-environment,42514,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42771,Testability,test,tests,42771,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:42845,Testability,test,test-environment,42845,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_stochastic_se.py _________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:43130,Testability,test,test-environment,43130,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:43259,Testability,test,test-environment,43259,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:43516,Testability,test,tests,43516,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:43590,Testability,test,test-environment,43590,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_subsys_apply.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:43875,Testability,test,test-environment,43875,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:44004,Testability,test,test-environment,44004,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting test",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:44263,Testability,test,tests,44263,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:44335,Testability,test,test-environment,44335,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; _________________ ERROR collecting tests/test_superop_reps.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:44620,Testability,test,test-environment,44620,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:44749,Testability,test,test-environment,44749,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45007,Testability,test,tests,45007,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45080,Testability,test,test-environment,45080,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_superoper.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45365,Testability,test,test-environment,45365,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45494,Testability,test,test-environment,45494,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting test",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45754,Testability,test,tests,45754,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTH",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:45825,Testability,test,test-environment,45825,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_td_formats.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46110,Testability,test,test-environment,46110,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46239,Testability,test,test-environment,46239,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tes",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46497,Testability,test,tests,46497,"ort__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46570,Testability,test,test-environment,46570,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_tensor.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46855,Testability,test,test-environment,46855,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:46984,Testability,test,test-environment,46984,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting te",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:47243,Testability,test,tests,47243,"port__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHO",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:47315,Testability,test,test-environment,47315,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; __________________ ERROR collecting tests/test_three_level.py __________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:47600,Testability,test,test-environment,47600,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:47729,Testability,test,test-environment,47729,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, pyt",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:47989,Testability,test,tests,47989,"mport__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; -----------------------------------------------------------------------------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:48060,Testability,test,test-environment,48060,"x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ___________________ ERROR collecting tests/test_utilities.py ___________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:48345,Testability,test,test-environment,48345,"packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:48474,Testability,test,test-environment,48474,"THON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:48991,Testability,test,test-environment,48991,"False; E AttributeError: module 'qutip' has no attribute 'settings'; ____________________ ERROR collecting tests/test_wigner.py _____________________; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49142,Testability,test,test-environment,49142,"-linux-x86_64.egg/qutip/__init__.py:46: in <module>; __IPYTHON__; E NameError: name '__IPYTHON__' is not defined; During handling of the above exception, another exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49296,Testability,test,test-environment,49296,"nother exception occurred:; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/py/_path/local.py:701: in pyimport; __import__(modname); ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec3",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49452,Testability,test,test-environment,49452,"; ../../../../miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py:49: in <module>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49604,Testability,test,test-environment,49604,"e>; qutip.settings.ipython = False; E AttributeError: module 'qutip' has no attribute 'settings'; ---------- coverage: platform linux, python 3.6.10-final-0 -----------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49763,Testability,test,test-environment,49763,---------; Name Stmts Miss Cover; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ====================,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:49918,Testability,test,test-environment,49918,--------------------------------------------------; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/tes,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50073,Testability,test,test-environment,50073,-linux-x86_64.egg/qutip/__init__.py 150 97 35%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50222,Testability,test,test-environment,50222,6-linux-x86_64.egg/qutip/_mkl/__init__.py 3 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' h,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50374,Testability,test,test-environment,50374,y3.6-linux-x86_64.egg/qutip/_mkl/utilities.py 39 16 59%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/__init__.py 1 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'quti,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50719,Testability,test,test,50719,thon3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/openmp/__init__.py 0 0 100%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50776,Testability,test,tests,50776,.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50821,Testability,test,tests,50821,7-py3.6-linux-x86_64.egg/qutip/cy/pyxbuilder.py 18 11 39%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50903,Testability,test,tests,50903,nvs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:50985,Testability,test,tests,50985,linux-x86_64.egg/qutip/hardware_info.py 72 32 56%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51067,Testability,test,tests,51067,-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51149,Testability,test,tests,51149,gg/qutip/settings.py 24 2 92%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - Attribute,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51231,Testability,test,tests,51231,/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/utilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - Attri,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51313,Testability,test,tests,51313,ilities.py 117 83 29%; /home/travis/miniconda/envs/test-environment/lib/python3.6/site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51395,Testability,test,tests,51395,site-packages/qutip-4.5.1.dev1+0ffec37-py3.6-linux-x86_64.egg/qutip/version.py 3 0 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51477,Testability,test,tests,51477, 100%; --------------------------------------------------------------------------------------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51559,Testability,test,tests,51559,----------------------------------------------------------------------------------------------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51641,Testability,test,tests,51641,---------; TOTAL 427 241 44%; =========================== short test summary info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - Attribu,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51723,Testability,test,tests,51723,info ============================; ERROR ../tests/test_basis_transformation.py; ERROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51805,Testability,test,tests,51805,RROR ../tests/test_brmesolve.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - Attri,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51887,Testability,test,tests,51887,OR ../tests/test_brmesolve_td.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - Attri,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:51969,Testability,test,tests,51969,RROR ../tests/test_brtools.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52051,Testability,test,tests,52051,ROR ../tests/test_cavityqed.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52133,Testability,test,tests,52133,RROR ../tests/test_control_pulseoptim.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseproce,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52215,Testability,test,tests,52215,RROR ../tests/test_correlation.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52297,Testability,test,tests,52297,R ../tests/test_countstat.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpos,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52379,Testability,test,tests,52379,R ../tests/test_cy_structs.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - Attrib,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52461,Testability,test,tests,52461,ROR ../tests/test_dimensions.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52543,Testability,test,tests,52543,ROR ../tests/test_eigenstates.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52625,Testability,test,tests,52625,ROR ../tests/test_enr_state_operator.py - AttributeError: module 'qutip' ha...; ERROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52707,Testability,test,tests,52707,ROR ../tests/test_entropy.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52789,Testability,test,tests,52789,ERROR ../tests/test_expect.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52871,Testability,test,tests,52871,RROR ../tests/test_fastsparse.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:52953,Testability,test,tests,52953,RROR ../tests/test_fileio.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53035,Testability,test,tests,53035,OR ../tests/test_floquet.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - Attrib,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53117,Testability,test,tests,53117,./tests/test_gates.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53199,Testability,test,tests,53199,ROR ../tests/test_graph.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53281,Testability,test,tests,53281,./tests/test_heom_solver.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - Attribu,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53363,Testability,test,tests,53363,ERROR ../tests/test_interpolate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53445,Testability,test,tests,53445,OR ../tests/test_lattice.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - Att,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53527,Testability,test,tests,53527,OR ../tests/test_mcsolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53609,Testability,test,tests,53609,RROR ../tests/test_mesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53691,Testability,test,tests,53691,RROR ../tests/test_metrics.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53773,Testability,test,tests,53773,ERROR ../tests/test_mkl.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53855,Testability,test,tests,53855,ERROR ../tests/test_noise.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:53937,Testability,test,tests,53937,ROR ../tests/test_openmp.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py -,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54019,Testability,test,tests,54019,ERROR ../tests/test_operators.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54101,Testability,test,tests,54101,../tests/test_optpulseprocessor.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - Attrib,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54183,Testability,test,tests,54183,R ../tests/test_parallel.py - AttributeError: module 'qutip' has no attri...; ERROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54265,Testability,test,tests,54265,RROR ../tests/test_partial_transpose.py - AttributeError: module 'qutip' has...; ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54347,Testability,test,tests,54347,ERROR ../tests/test_piqs.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54429,Testability,test,tests,54429,RROR ../tests/test_processor.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.p,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54511,Testability,test,tests,54511,OR ../tests/test_propagator.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54593,Testability,test,tests,54593,OR ../tests/test_ptrace.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - A,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54675,Testability,test,tests,54675,ROR ../tests/test_pulse.py - AttributeError: module 'qutip' has no attribut...; ERROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54757,Testability,test,tests,54757,ROR ../tests/test_qft.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54839,Testability,test,tests,54839,RROR ../tests/test_qobj.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:54921,Testability,test,tests,54921,OR ../tests/test_qobjevo.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - ,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55003,Testability,test,tests,55003,RROR ../tests/test_qpt.py - AttributeError: module 'qutip' has no attribute ...; ERROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - At,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55085,Testability,test,tests,55085,RROR ../tests/test_qubit_evolution.py - AttributeError: module 'qutip' has n...; ERROR ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 6,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55167,Testability,test,tests,55167,"R ../tests/test_qubitcircuit.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings,",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55249,Testability,test,tests,55249," ../tests/test_qubits.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --d",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55331,Testability,test,tests,55331," ../tests/test_rand.py - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your buil",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55413,Testability,test,tests,55413,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55495,Testability,test,tests,55495,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55577,Testability,test,tests,55577,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55659,Testability,test,tests,55659,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55741,Testability,test,tests,55741,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55823,Testability,test,tests,55823,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55905,Testability,test,tests,55905,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-619398997:55987,Testability,test,tests,55987,"y - AttributeError: module 'qutip' has no attribute...; ERROR ../tests/test_random.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_rhs_reuse.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_scattering.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_sesolve.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sp_eigs.py - AttributeError: module 'qutip' has no attrib...; ERROR ../tests/test_sparse.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_spinchain.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_spmath.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_states.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_steadystate.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_stochastic_me.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_stochastic_se.py - AttributeError: module 'qutip' has no ...; ERROR ../tests/test_subsys_apply.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superop_reps.py - AttributeError: module 'qutip' has no a...; ERROR ../tests/test_superoper.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_td_formats.py - AttributeError: module 'qutip' has no att...; ERROR ../tests/test_tensor.py - AttributeError: module 'qutip' has no attribu...; ERROR ../tests/test_three_level.py - AttributeError: module 'qutip' has no at...; ERROR ../tests/test_utilities.py - AttributeError: module 'qutip' has no attr...; ERROR ../tests/test_wigner.py - AttributeError: module 'qutip' has no attribu...; !!!!!!!!!!!!!!!!!!! Interrupted: 65 errors during collection !!!!!!!!!!!!!!!!!!!; ======================== 2 warnings, 65 errors in 2.53s ========================; The command ""pytest --verbosity=1 --disable-pytest-warnings --cov=qutip --pyargs qutip"" exited with 2.; Done. Your build exited with 1.; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-619398997
https://github.com/qutip/qutip/pull/1232#issuecomment-633933697:7,Availability,ping,ping,7,Just a ping to @araza6 for any update. Cc @quantshah.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-633933697
https://github.com/qutip/qutip/pull/1232#issuecomment-633933697:31,Deployability,update,update,31,Just a ping to @araza6 for any update. Cc @quantshah.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1232#issuecomment-633933697
https://github.com/qutip/qutip/issues/1238#issuecomment-621485756:203,Energy Efficiency,energy,energy,203,"The documentation is wrong here. When `e_ops` is a function, `result.expect` is not empty, but a list of all outputs for that function. So the results is the transposed of what you propose here. For the energy, you would need to do `result.expect[t][3]`. ; The alternative could be a good options.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1238#issuecomment-621485756
https://github.com/qutip/qutip/issues/1238#issuecomment-643878326:187,Deployability,update,update,187,"Thanks for your comments @Ericgig , I will see if there is a way to implement the alternative solution while maintaining the backwards compatibility. Also I'll be happy to contribute and update the docs, let's keep this issue open, I have my full time work but after hours gradually I'll come up with a pull request.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1238#issuecomment-643878326
https://github.com/qutip/qutip/issues/1239#issuecomment-620130318:155,Availability,error,error,155,"`qutip.ptrace()` takes the partial trace. It is defined only on composite Hilbert spaces. You are applying it on a single Hilbert space, hence it gives an error. If you want to take the trace, you could call it with `qp.sigmax().tr()`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1239#issuecomment-620130318
https://github.com/qutip/qutip/issues/1240#issuecomment-620486072:325,Availability,avail,available,325,"Hopefully `sin(t) if t > 4 else cos(t)` should work for you?. Internally the relevant data structures either compile standard Python to code objects or go native via Cython, so the rule of thumb is ""would `eval(my_string)` give me what I want?"". QuTiP provides some basic wrapping of the scoping rules so things like `t` are available, and the standard numpy functions `sin`, `cos`, etc., are available without needing the namespace, but it's not got a full DSL for specifying time-dependence - it just uses regular Python.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1240#issuecomment-620486072
https://github.com/qutip/qutip/issues/1240#issuecomment-620486072:393,Availability,avail,available,393,"Hopefully `sin(t) if t > 4 else cos(t)` should work for you?. Internally the relevant data structures either compile standard Python to code objects or go native via Cython, so the rule of thumb is ""would `eval(my_string)` give me what I want?"". QuTiP provides some basic wrapping of the scoping rules so things like `t` are available, and the standard numpy functions `sin`, `cos`, etc., are available without needing the namespace, but it's not got a full DSL for specifying time-dependence - it just uses regular Python.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1240#issuecomment-620486072
https://github.com/qutip/qutip/issues/1240#issuecomment-620486072:272,Integrability,wrap,wrapping,272,"Hopefully `sin(t) if t > 4 else cos(t)` should work for you?. Internally the relevant data structures either compile standard Python to code objects or go native via Cython, so the rule of thumb is ""would `eval(my_string)` give me what I want?"". QuTiP provides some basic wrapping of the scoping rules so things like `t` are available, and the standard numpy functions `sin`, `cos`, etc., are available without needing the namespace, but it's not got a full DSL for specifying time-dependence - it just uses regular Python.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1240#issuecomment-620486072
https://github.com/qutip/qutip/issues/1240#issuecomment-620486072:482,Integrability,depend,dependence,482,"Hopefully `sin(t) if t > 4 else cos(t)` should work for you?. Internally the relevant data structures either compile standard Python to code objects or go native via Cython, so the rule of thumb is ""would `eval(my_string)` give me what I want?"". QuTiP provides some basic wrapping of the scoping rules so things like `t` are available, and the standard numpy functions `sin`, `cos`, etc., are available without needing the namespace, but it's not got a full DSL for specifying time-dependence - it just uses regular Python.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1240#issuecomment-620486072
https://github.com/qutip/qutip/pull/1242#issuecomment-622091888:39,Availability,error,error,39,"Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long. There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; For example, if you have a list ``gates = [a, b, c]`` and use ``gates.pop(0)``. ; The list will become; ```; >>> gates; [b, c]; ```; if you now iterate to ``i=1``, you skip element `b`; This can be solved by iterating in the inverse order.; ```; elif name is not None and remove == ""all"":; for i in reverse(range(len(self.gates))):; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622091888
https://github.com/qutip/qutip/pull/1242#issuecomment-622091888:84,Availability,error,error,84,"Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long. There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; For example, if you have a list ``gates = [a, b, c]`` and use ``gates.pop(0)``. ; The list will become; ```; >>> gates; [b, c]; ```; if you now iterate to ``i=1``, you skip element `b`; This can be solved by iterating in the inverse order.; ```; elif name is not None and remove == ""all"":; for i in reverse(range(len(self.gates))):; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622091888
https://github.com/qutip/qutip/pull/1242#issuecomment-622091888:301,Availability,error,error,301,"Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long. There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; For example, if you have a list ``gates = [a, b, c]`` and use ``gates.pop(0)``. ; The list will become; ```; >>> gates; [b, c]; ```; if you now iterate to ``i=1``, you skip element `b`; This can be solved by iterating in the inverse order.; ```; elif name is not None and remove == ""all"":; for i in reverse(range(len(self.gates))):; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622091888
https://github.com/qutip/qutip/pull/1242#issuecomment-622099083:41,Availability,error,error,41,"> Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long.; > ; > There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; > For example, if you have a list `gates = [a, b, c]` and use `gates.pop(0)`.; > The list will become; > ; > ```; > >>> gates; > [b, c]; > ```; > ; > if you now iterate to `i=1`, you skip element `b`; > This can be solved by iterating in the inverse order.; > ; > ```; > elif name is not None and remove == ""all"":; > for i in reverse(range(len(self.gates))):; > ```. Ah, sure. Thanks to point it out. It's fixed now. I actually used the reversed order but then deleted it as I forgot why I did that. LOL",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622099083
https://github.com/qutip/qutip/pull/1242#issuecomment-622099083:86,Availability,error,error,86,"> Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long.; > ; > There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; > For example, if you have a list `gates = [a, b, c]` and use `gates.pop(0)`.; > The list will become; > ; > ```; > >>> gates; > [b, c]; > ```; > ; > if you now iterate to `i=1`, you skip element `b`; > This can be solved by iterating in the inverse order.; > ; > ```; > elif name is not None and remove == ""all"":; > for i in reverse(range(len(self.gates))):; > ```. Ah, sure. Thanks to point it out. It's fixed now. I actually used the reversed order but then deleted it as I forgot why I did that. LOL",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622099083
https://github.com/qutip/qutip/pull/1242#issuecomment-622099083:310,Availability,error,error,310,"> Hi @Canoming, thanks for spotting this error and fixing it. I'm surprised that this error is hidden here for so long.; > ; > There is still a flaw in the option for `remove=""all""`. When you remove the first element in a list, the rest elements will move forward and eventually leads to an index out of range error.; > For example, if you have a list `gates = [a, b, c]` and use `gates.pop(0)`.; > The list will become; > ; > ```; > >>> gates; > [b, c]; > ```; > ; > if you now iterate to `i=1`, you skip element `b`; > This can be solved by iterating in the inverse order.; > ; > ```; > elif name is not None and remove == ""all"":; > for i in reverse(range(len(self.gates))):; > ```. Ah, sure. Thanks to point it out. It's fixed now. I actually used the reversed order but then deleted it as I forgot why I did that. LOL",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1242#issuecomment-622099083
https://github.com/qutip/qutip/issues/1244#issuecomment-623071030:121,Availability,down,downloading,121,"Hi @TakumiAizawa, yes in a future QuTiP release this will be fixed. If you need to use this right now, I would recommend downloading the code from GitHub and install from source code. http://qutip.org/docs/latest/installation.html#installing-from-source",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1244#issuecomment-623071030
https://github.com/qutip/qutip/issues/1244#issuecomment-623071030:40,Deployability,release,release,40,"Hi @TakumiAizawa, yes in a future QuTiP release this will be fixed. If you need to use this right now, I would recommend downloading the code from GitHub and install from source code. http://qutip.org/docs/latest/installation.html#installing-from-source",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1244#issuecomment-623071030
https://github.com/qutip/qutip/issues/1244#issuecomment-623071030:158,Deployability,install,install,158,"Hi @TakumiAizawa, yes in a future QuTiP release this will be fixed. If you need to use this right now, I would recommend downloading the code from GitHub and install from source code. http://qutip.org/docs/latest/installation.html#installing-from-source",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1244#issuecomment-623071030
https://github.com/qutip/qutip/issues/1244#issuecomment-623071030:213,Deployability,install,installation,213,"Hi @TakumiAizawa, yes in a future QuTiP release this will be fixed. If you need to use this right now, I would recommend downloading the code from GitHub and install from source code. http://qutip.org/docs/latest/installation.html#installing-from-source",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1244#issuecomment-623071030
https://github.com/qutip/qutip/issues/1244#issuecomment-623071030:231,Deployability,install,installing-from-source,231,"Hi @TakumiAizawa, yes in a future QuTiP release this will be fixed. If you need to use this right now, I would recommend downloading the code from GitHub and install from source code. http://qutip.org/docs/latest/installation.html#installing-from-source",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1244#issuecomment-623071030
https://github.com/qutip/qutip/issues/1247#issuecomment-623299478:219,Usability,guid,guide,219,This is because of the automatic tidy up of any matrix entries smaller than 1.e-12. You can turn it off by ``qutip.settings.auto_tidyup=False``. Or set this threshold to a different number (http://qutip.org/docs/latest/guide/guide-settings.html). This behaviour does seem a bit confusing though...,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1247#issuecomment-623299478
https://github.com/qutip/qutip/issues/1247#issuecomment-623299478:225,Usability,guid,guide-settings,225,This is because of the automatic tidy up of any matrix entries smaller than 1.e-12. You can turn it off by ``qutip.settings.auto_tidyup=False``. Or set this threshold to a different number (http://qutip.org/docs/latest/guide/guide-settings.html). This behaviour does seem a bit confusing though...,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1247#issuecomment-623299478
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:120,Availability,error,errors,120,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:965,Deployability,integrat,integration,965,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:938,Integrability,message,message,938,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:965,Integrability,integrat,integration,965,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:650,Modifiability,variab,variable,650,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:760,Modifiability,variab,variable,760,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:1475,Performance,optimiz,optimize,1475,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-740126949:1163,Testability,test,test,1163,"**Summary of what was done:**. - Changes in floquet_master_equation_rates to make it faster.; - Corrected transposition errors in _floquet_master_equation_tensor_ and changes to make it faster. I also removed a line so that the ME is solved in the interaction picture, this implies a different basis change in the _floquet_markov_mesolve_ function.; - Correction in _floquet_markov_mesolve_. As explained in the point above, the Floquet-Markov ME was not being solved in the interaction picture, therefore I modified _floquet_master_equation_tensor_ and modified the basis change in _floquet_markov_mesolve_. This modification requires an additional variable in the entry of _floquet_markov_mesolve_ which can not be chosen by default. For the moment, if this variable is not given and _floquet_basis=False_, then the density matrix or expectation values are returned in the interaction picture, in the computational basis, and a warning message is sent. ; - Added integration options in: _floquet_modes, floquet_modes_t, floquet_modes_table, floquet_states_t, floquet_modes_t, floquet_wavefunction_t, fsesolve, floquet_master_equation_rates, fmmesolve_; - Added test functions to verify the dissipative dynamics:; a) Compare _fmmesolve_ and _mesolve_ for the cases: (NO drive but dissipation) and (Drive but NO dissipation); b) Compare numerical and analytical matrix elements for a driven-dissipative TLS with RWA. There are some places where the code could be modified to optimize the running time, especially in the basis change in _floquet_markov_mesolve_.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-740126949
https://github.com/qutip/qutip/pull/1248#issuecomment-779265736:72,Usability,learn,learned,72,"Sure, I'll try soon. I can add stuff to the merge I've already done - I learned some `git` magic to combine merge commits into the same object without losing my previous work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-779265736
https://github.com/qutip/qutip/pull/1248#issuecomment-779453398:36,Deployability,patch,patch,36,"I couldn't work out how to attach a patch to a GitHub comment, so I've made PR (CamilleLCal/qutip#1) against your fork to show the sort of changes I think `floquet_markov_mesolve` could benefit from.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1248#issuecomment-779453398
https://github.com/qutip/qutip/pull/1249#issuecomment-623953963:25,Availability,failure,failure,25,@Ericgig: another random failure in the CI here (errored test is unchanged in this PR).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-623953963
https://github.com/qutip/qutip/pull/1249#issuecomment-623953963:49,Availability,error,errored,49,@Ericgig: another random failure in the CI here (errored test is unchanged in this PR).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-623953963
https://github.com/qutip/qutip/pull/1249#issuecomment-623953963:57,Testability,test,test,57,@Ericgig: another random failure in the CI here (errored test is unchanged in this PR).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-623953963
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:9,Availability,error,error,9,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:317,Availability,toler,tolerance,317,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:366,Availability,error,error,366,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:142,Testability,test,test,142,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:170,Testability,test,test,170,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:212,Testability,test,tests,212,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625283606:412,Testability,test,test,412,"Computed error 1.08705544e-07, tol 1e-7... The initial ket in `rand_ket(2)`. I believe that with `nosetest`, the random seed was kept between test file. One of our early test would fix the seed and all following tests would be deterministic. With `pytest` the seed is probably reset at each file. We could loosen the tolerance. Ideally we would get the stats on the error first. Maybe `pytest` has a support for test that pass 99% of the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625283606
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:549,Availability,failure,failure,549,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:897,Availability,error,errors,897,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:57,Testability,test,test,57,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:111,Testability,test,test,111,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:237,Testability,test,test,237,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:312,Testability,test,tests,312,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:451,Testability,test,test,451,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:632,Testability,test,test,632,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:645,Testability,test,test,645,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:835,Testability,log,log,835,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625290303:811,Usability,clear,clearly,811,"I'd be vastly surprised if there's a way of permitting a test which passes 99% of the time - on any particular test run how would it know?. I don't remember having seen anything about setting the initial seeds, but relying on a previous test to set a seed isn't a good idea - you'd always have to ensure that no tests were ever added or changed in-between that ever used random state or everything would get lost. We could fix the random seed for any test which uses random methods with a fixture to get around that. I actually think this is a true failure; the default solver `rtol = 1e-6`, but here we're using `rtol=1e-7` as the test, so the test is bugged (it's probably not the only one, and I may have missed some of these in `mcsolve` too). I should change this when I convert `test_mesolve.py`. Also, I clearly didn't read the log properly on that one - I thought it was one of the random errors from before!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625290303
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:266,Availability,toler,tolerance,266,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:322,Availability,toler,tolerance,322,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:453,Availability,error,error,453,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:502,Availability,error,error,502,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:69,Energy Efficiency,adapt,adapting,69,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:69,Modifiability,adapt,adapting,69,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:11,Testability,test,test,11,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:82,Testability,test,tests,82,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:152,Testability,test,tests,152,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:215,Testability,test,tests,215,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:261,Testability,test,test,261,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:297,Testability,test,test,297,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625307705:422,Testability,test,test,422,"Repeat the test 20 times and accept if at least 19 pass?. I remember adapting the tests when numpy's rng changed. 1~2 where failing. I believe that the tests pass over 99% with a random seed, but with the number of tests, it's not enough. I did not realize the test tolerance was smaller than the test one. But the solver tolerance is for the state itself, not expectation values and other scalars obtained from them. The test is not to check numerical error. When there is an mistake in the code, the error is orders of magnitude greater. Not sure if using the sovler's tol is right, but probably better than using a number that just seems to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625307705
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:42,Availability,failure,failure,42,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:279,Availability,toler,tolerance,279,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:351,Availability,error,error,351,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:366,Availability,error,error,366,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:409,Availability,error,errors,409,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:488,Availability,toler,tolerances,488,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:556,Availability,toler,tolerance,556,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:72,Safety,detect,detecting,72,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:124,Testability,test,tests,124,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625344751:193,Usability,simpl,simple,193,"Repeating just changes the probability of failure, rather than actually detecting whether it was a rare fail, and `mesolve` tests aren't always the fastest, so repetition here isn't great. For simple unitary qubit operations, I think it should be easy enough to work out how the tolerance translates. It's difficult to say that if there's a numerical error then the error will be much greater - I caught some errors in the `test_gates.py` (I think) that were sneaking through because the tolerances were set too high. It's probably best to keep as tight a tolerance as is reasonable - here I think `2 * qutip.Options.rtol` would always be correct if the numerics are.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625344751
https://github.com/qutip/qutip/pull/1249#issuecomment-625407196:133,Availability,error,error,133,`2 * Options.rtol` could be good enough for most the tests.; ; But expecting `Options.rtol` to be a good estimation of the numerical error in all case is risky. There is no promise by the solver that the result is within rtol of the analytical solution and it ignore error propagation in the post-treatment steps.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625407196
https://github.com/qutip/qutip/pull/1249#issuecomment-625407196:267,Availability,error,error,267,`2 * Options.rtol` could be good enough for most the tests.; ; But expecting `Options.rtol` to be a good estimation of the numerical error in all case is risky. There is no promise by the solver that the result is within rtol of the analytical solution and it ignore error propagation in the post-treatment steps.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625407196
https://github.com/qutip/qutip/pull/1249#issuecomment-625407196:154,Safety,risk,risky,154,`2 * Options.rtol` could be good enough for most the tests.; ; But expecting `Options.rtol` to be a good estimation of the numerical error in all case is risky. There is no promise by the solver that the result is within rtol of the analytical solution and it ignore error propagation in the post-treatment steps.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625407196
https://github.com/qutip/qutip/pull/1249#issuecomment-625407196:53,Testability,test,tests,53,`2 * Options.rtol` could be good enough for most the tests.; ; But expecting `Options.rtol` to be a good estimation of the numerical error in all case is risky. There is no promise by the solver that the result is within rtol of the analytical solution and it ignore error propagation in the post-treatment steps.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-625407196
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:82,Availability,error,error,82,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:241,Availability,error,error,241,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:510,Availability,failure,failure,510,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:714,Deployability,rolling,rolling,714,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:749,Modifiability,refactor,refactoring,749,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:365,Safety,risk,risking,365,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:171,Testability,test,tests,171,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:203,Testability,test,test,203,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:310,Testability,test,tests,310,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:442,Testability,test,testing,442,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:505,Testability,test,test,505,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-628265133:744,Testability,test,test,744,"I realised I never replied to this. I suggested `2*rtol` in this case because the error propagation in this case would guarantee that this is always sufficient. For other tests, we can always design the test so that it's calculable what the error term should be. I'd say it's generally a good idea to have the tests be as tight as we can possibly make them without risking false-negatives on the results, because otherwise we're not properly testing that the parameters do what they say. Regardless, that test failure isn't due to any of my PRs - it's a pre-existing problem that we happened to get unlucky on this time round. It'll get fixed when I modify `test_mesolve.py`. Can we review this PR to get the ball rolling on getting all of the test refactoring considered?. Possible reviewers: @Ericgig, @BoxiLi, @nathanshammah",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-628265133
https://github.com/qutip/qutip/pull/1249#issuecomment-633698798:138,Integrability,message,messages,138,"@Ericgig: I see you've been on a merging spree!. If you're about to merge, please don't squash this - I've taken care to have good commit messages and modular commits, and I'll have to rebase all the other PRs if this one gets squashed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1249#issuecomment-633698798
https://github.com/qutip/qutip/pull/1250#issuecomment-633709875:248,Deployability,update,update,248,"@Ericgig: the commits are the same ones you just merged in (as in the same SHA-1 - they're completely identical git objects), so they shouldn't appear if you do a regular merge - the fact they still appear here _should_ just be that GitHub doesn't update its UI when other PRs are merged. I suggest regular merges because I've tidied up the commit history in these PRs, so it's easier to search back through the commit history.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1250#issuecomment-633709875
https://github.com/qutip/qutip/pull/1251#issuecomment-624802081:105,Availability,fault,fault,105,"On mac, testing #1241, I get:; `qutip/tests/test_cavityqed.py::Testcqed::test_numerical_evo Segmentation fault: 11`; Does this address it somewhay?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624802081
https://github.com/qutip/qutip/pull/1251#issuecomment-624802081:8,Testability,test,testing,8,"On mac, testing #1241, I get:; `qutip/tests/test_cavityqed.py::Testcqed::test_numerical_evo Segmentation fault: 11`; Does this address it somewhay?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624802081
https://github.com/qutip/qutip/pull/1251#issuecomment-624802081:38,Testability,test,tests,38,"On mac, testing #1241, I get:; `qutip/tests/test_cavityqed.py::Testcqed::test_numerical_evo Segmentation fault: 11`; Does this address it somewhay?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624802081
https://github.com/qutip/qutip/pull/1251#issuecomment-624802081:63,Testability,Test,Testcqed,63,"On mac, testing #1241, I get:; `qutip/tests/test_cavityqed.py::Testcqed::test_numerical_evo Segmentation fault: 11`; Does this address it somewhay?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624802081
https://github.com/qutip/qutip/pull/1251#issuecomment-624835925:454,Availability,error,error,454,"Unfortunately not, or at least, certainly not the underlying cause - I was only able to reproduce the segfaults maybe once, but then it disappeared once I attached a debugger. It's very unlikely to be that particular test function, since I used to get them in fairly random locations. Just rearranging the test functions may have caused it to temporarily disappear, but it'll be back eventually until we find out whatever use-after-free or out-of-bounds error's actually causing it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624835925
https://github.com/qutip/qutip/pull/1251#issuecomment-624835925:217,Testability,test,test,217,"Unfortunately not, or at least, certainly not the underlying cause - I was only able to reproduce the segfaults maybe once, but then it disappeared once I attached a debugger. It's very unlikely to be that particular test function, since I used to get them in fairly random locations. Just rearranging the test functions may have caused it to temporarily disappear, but it'll be back eventually until we find out whatever use-after-free or out-of-bounds error's actually causing it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624835925
https://github.com/qutip/qutip/pull/1251#issuecomment-624835925:306,Testability,test,test,306,"Unfortunately not, or at least, certainly not the underlying cause - I was only able to reproduce the segfaults maybe once, but then it disappeared once I attached a debugger. It's very unlikely to be that particular test function, since I used to get them in fairly random locations. Just rearranging the test functions may have caused it to temporarily disappear, but it'll be back eventually until we find out whatever use-after-free or out-of-bounds error's actually causing it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-624835925
https://github.com/qutip/qutip/pull/1251#issuecomment-626315063:236,Modifiability,refactor,refactor,236,"#1249 should be reviewed and merged before this (because if it needs changed, then this PR has to be rebased on top of it), but also I'm going to change the Clifford group tests a little, and rebase the typo fix commit into the general refactor before this one should be merged.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626315063
https://github.com/qutip/qutip/pull/1251#issuecomment-626315063:172,Testability,test,tests,172,"#1249 should be reviewed and merged before this (because if it needs changed, then this PR has to be rebased on top of it), but also I'm going to change the Clifford group tests a little, and rebase the typo fix commit into the general refactor before this one should be merged.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626315063
https://github.com/qutip/qutip/pull/1251#issuecomment-626315402:105,Modifiability,refactor,refactor,105,"> I'm going to change the Clifford group tests a little, and rebase the typo fix commit into the general refactor before this one should be merged. Sure",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626315402
https://github.com/qutip/qutip/pull/1251#issuecomment-626315402:41,Testability,test,tests,41,"> I'm going to change the Clifford group tests a little, and rebase the typo fix commit into the general refactor before this one should be merged. Sure",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626315402
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:177,Security,hash,hashed,177,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:46,Testability,test,tests,46,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:143,Testability,test,tests,143,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:199,Testability,test,test,199,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:294,Testability,test,tests,294,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/pull/1251#issuecomment-626317467:334,Testability,test,testing,334,"The `_hashable_without_global_phase` made the tests nice and easy to read, but honestly it was just a timebomb waiting to go off and break the tests. Floats can't reasonably be hashed as an equality test, because they should always include a delta in the comparison. This technically makes the tests slower, but as long as we're just testing the single-qubit Clifford group, it's only a fraction of a second (because there's 24 of them ignoring global phase and 24^2 is only 576).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1251#issuecomment-626317467
https://github.com/qutip/qutip/issues/1253#issuecomment-624739240:655,Safety,avoid,avoid,655,"You may find it easier to create tensor-producted identity operators by using the shorthand `qeye([2, 2, 2])`, which will automatically sort out the tensor product for you. You may also want to look at `qutip.qip.operations.expand_operator`, which will handle applying your operator to qubits. You _can_ bypass the dimension checking by retrieving the underlying matrix at `C.data` or `C.full()` (these may change in QuTiP 5, but for now you're fine), doing your calculations, then reconstructing the `Qobj` at the end. If all you're really using from QuTiP is the tensor product structure though, then you may achieve what you want with `numpy.kron` and avoid all of the overhead. The only part of your example that I'd consider is convoluted is the duplication in the `rand_unitary_haar` and `rand_ket` requiring you to specify both `N` and `dims` - we probably could merge those, like how we do with `qeye`, `basis` and others.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1253#issuecomment-624739240
https://github.com/qutip/qutip/issues/1254#issuecomment-2029218180:13,Deployability,release,released,13,The recently released v5 support callback for `c_ops`.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1254#issuecomment-2029218180
https://github.com/qutip/qutip/pull/1255#issuecomment-625257862:84,Usability,undo,undo,84,"Nathan, you are pushing to the master branch, not qutip-4.5.1.; This would probably undo some commit to master that are not included in 4.5.1.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1255#issuecomment-625257862
https://github.com/qutip/qutip/issues/1259#issuecomment-628263381:119,Deployability,release,released,119,"The options is in development ( #1231 ) , the options will be set in the qutiprc file. However it will probably not be released before end of fall if not winter.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1259#issuecomment-628263381
https://github.com/qutip/qutip/issues/1259#issuecomment-809319324:65,Deployability,release,release,65,"This is implemented in the development branch for the next major release of QuTiP, but likely won't appear in the 4.x branch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1259#issuecomment-809319324
https://github.com/qutip/qutip/issues/1260#issuecomment-627565548:192,Deployability,release,released,192,"There is no support at all right now, but it is in progress.; It should work with the QobjEvoFunc PR, but it will take a quite some time before it is finished, an more before it is merged and released, it probably won't come before v5. For now, H can be a callback to a liouvillian. So he can make it work like this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mesolve(L, ..., c_ops=[]); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-627565548
https://github.com/qutip/qutip/issues/1260#issuecomment-629164724:945,Energy Efficiency,efficient,efficient,945,"Hi guys, thanks for looking at this! I actually made a fork to implement this: https://github.com/lfry512/qutip. In my fork I added some extra type checks and some extra functions in _LiouvillianFromFunc that support a c_ops callback. The way this was done just requires the user to use qt.lindblad_dissipator where appropriate. The use case that isn't implemented is H in list format and c_ops as a callback. @Ericgig thanks for the neat suggestion! This is very pertinent as I then moved on to try the same functionality with mcsolve, which doesn't support a callback for H and c_ops in the master branch. Yesterday I got callback functionality working for H in mcsolve but haven't committed it yet. However it's about 20 times slower than using the equivalent list format in my tests. @jakelishman it sounds like you worked on mcsolve. If you are interested I would love to discuss with you how to make the H callback method for mcsolve more efficient. I'm also trying to figure out if it is possible to make a cython callback builder class that can be used for building the Lindblad operators from instantaneous eigenstates of the Hamiltonian more efficiently. I am not sure how my changes fit in to the overhaul of the solver system, but in mcsolve I did somewhat make use of the SolverSystem instance that is built in place.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629164724
https://github.com/qutip/qutip/issues/1260#issuecomment-629164724:1152,Energy Efficiency,efficient,efficiently,1152,"Hi guys, thanks for looking at this! I actually made a fork to implement this: https://github.com/lfry512/qutip. In my fork I added some extra type checks and some extra functions in _LiouvillianFromFunc that support a c_ops callback. The way this was done just requires the user to use qt.lindblad_dissipator where appropriate. The use case that isn't implemented is H in list format and c_ops as a callback. @Ericgig thanks for the neat suggestion! This is very pertinent as I then moved on to try the same functionality with mcsolve, which doesn't support a callback for H and c_ops in the master branch. Yesterday I got callback functionality working for H in mcsolve but haven't committed it yet. However it's about 20 times slower than using the equivalent list format in my tests. @jakelishman it sounds like you worked on mcsolve. If you are interested I would love to discuss with you how to make the H callback method for mcsolve more efficient. I'm also trying to figure out if it is possible to make a cython callback builder class that can be used for building the Lindblad operators from instantaneous eigenstates of the Hamiltonian more efficiently. I am not sure how my changes fit in to the overhaul of the solver system, but in mcsolve I did somewhat make use of the SolverSystem instance that is built in place.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629164724
https://github.com/qutip/qutip/issues/1260#issuecomment-629164724:781,Testability,test,tests,781,"Hi guys, thanks for looking at this! I actually made a fork to implement this: https://github.com/lfry512/qutip. In my fork I added some extra type checks and some extra functions in _LiouvillianFromFunc that support a c_ops callback. The way this was done just requires the user to use qt.lindblad_dissipator where appropriate. The use case that isn't implemented is H in list format and c_ops as a callback. @Ericgig thanks for the neat suggestion! This is very pertinent as I then moved on to try the same functionality with mcsolve, which doesn't support a callback for H and c_ops in the master branch. Yesterday I got callback functionality working for H in mcsolve but haven't committed it yet. However it's about 20 times slower than using the equivalent list format in my tests. @jakelishman it sounds like you worked on mcsolve. If you are interested I would love to discuss with you how to make the H callback method for mcsolve more efficient. I'm also trying to figure out if it is possible to make a cython callback builder class that can be used for building the Lindblad operators from instantaneous eigenstates of the Hamiltonian more efficiently. I am not sure how my changes fit in to the overhaul of the solver system, but in mcsolve I did somewhat make use of the SolverSystem instance that is built in place.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629164724
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:1241,Availability,redundant,redundant,1241,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:1611,Availability,avail,available,1611,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:435,Performance,optimiz,optimizations,435,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:986,Performance,optimiz,optimization,986,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:1241,Safety,redund,redundant,1241,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-629231634:1111,Usability,simpl,simple,1111,"Hi Louis,. There is work in development that will allow `QobjEvo` to be build from callback also, not just list. This will make callback work anywhere easily. . I was in the impression that H callback worked already for mcsolve. I rewrote part of mcsolve and broke it. Looking at your commit, I inverted `_funcrhs_with_state` and `_funcrhs`...; Sorry to have you take time to correct it. The 20x is big, but the list format allows for optimizations that are hard to do with a callback. A big one is that you don't need to create a new matrix/Qobj when calling `mul_vec`, just use it. With this code, I see a 20x between `mul_vec` and creating a Qobj a python function. . ```; import numpy as np; import qutip as qt. qoe = qt.QobjEvo([qt.qeye(3),[qt.destroy(3), lambda t,_:np.sin(t)]]); qoe.compile(). o1 = qt.qeye(3); o2 = qt.destroy(3) ; def H(t):; return o1 + o2 * np.sin(t). v = np.ones(3)+0j; %timeit qoe(0); %timeit qoe.mul_vec(0, v); %timeit H(0); %timeit H(0).data * v; ```. One optimization you could do is having the callback return a `np.array` instead of a Qobj. In `mcsolve`, this would probably be simple to implement and I expect some speed gain. But it can't really be officially supported in Qutip, for now. . ps. All those 'redundant' argument setting are for reusing the system (`ss`) in multiple call of `mcsolve` with different args, used in `correlation`. Using string coefficient, the compilation step can take a few second, so it is set to be able to reuse a compiled system, changing the `psi0`, `args`, `e_ops`, etc. This will become a less obscure feature in v5 when solver object are available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-629231634
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1771,Deployability,integrat,integrate,1771,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1838,Deployability,integrat,integrate,1838,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1064,Energy Efficiency,energy,energy,1064,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1771,Integrability,integrat,integrate,1771,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1838,Integrability,integrat,integrate,1838,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1260#issuecomment-630067552:1539,Modifiability,coupling,coupling,1539,"Hi @Ericgig, @jakelishman,. Thanks very much for the very helpful replies! I will try these suggestions in my application Eric!. Jake, when you say the following:; > Oh of course, I had `mcsolve` in mind as to why that couldn't be done (and in that case, my interpolation wouldn't work either because of the separation of the decay channels)... Is it that, this:; ```; def L(t, args):; H = H(t, ...); c_op = C(H, t, ...); return qutip.liouvillian(H, [c_op]). mcsolve(L, ..., c_ops=[]); ```. won't work due to `_funcrhs` treating `h_func` as a Hamiltonian always? If this is the only factor (as far as I can see), then I think I can further hack this to make callbacks work for me locally. I'm not yet sure if the numpy arrays method will work here but this is what I will strive for. Some details of my plans: I am doing dynamics simulations of quantum annealing processes. We use a certain number of qubits (between 4 and 8) biased and coupled in certain ways to produce examples of 'difficult' problems for adiabatic quantum computation, where the instantaneous energy gaps can have very small minima during evolution. The resulting ODEs appear to be 'stiff' and long evolution times are required to observe high probabilities of being in the ground state. The combination of these things appears to make solving for long evolution times very time consuming. I observed a massive speedup using `mcsolve` however. What I wish to do is include various decay channels, which in the physical systems we use, we understand to be in the 'weak coupling limit' defined by T. Albash here:; https://arxiv.org/pdf/1503.08767.pdf. Another note: A number of colleagues have found most useful the RK45 method implemented in what I understand to be 'new' ode solver scipy code `scipy.integrate.solve_ivp`. I notice that the 'dopri5' option for `scipy.integrate.ode` is likely the same thing. This is something I will play with also.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1260#issuecomment-630067552
https://github.com/qutip/qutip/issues/1262#issuecomment-628260933:733,Availability,down,down,733,"Yeah, looking at it, this functionality still does not exist. The `essolve` function is pretty out-of-date (its last real activity was back in 2013), and may well be completely deprecated in an upcoming version of QuTiP. Hopefully `qutip.mesolve` should be a near drop-in replacement for you (`c_ops_list` is now called `c_ops`, but other than that you're fine), and it may well be a lot faster as well. @Ericgig, @ajgpitch: shall we commit to maintaining `essolve` and/or the `eseries` class, or issue a deprecation warning as soon as possible? They're pretty unloved, and `QobjEvo` really is a far far more general way of specifying time-dependence. My vote (should I have one) is for deprecation. I'm always in favour of slimming down codebases if it doesn't remove useful functionality!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1262#issuecomment-628260933
https://github.com/qutip/qutip/issues/1262#issuecomment-628260933:640,Integrability,depend,dependence,640,"Yeah, looking at it, this functionality still does not exist. The `essolve` function is pretty out-of-date (its last real activity was back in 2013), and may well be completely deprecated in an upcoming version of QuTiP. Hopefully `qutip.mesolve` should be a near drop-in replacement for you (`c_ops_list` is now called `c_ops`, but other than that you're fine), and it may well be a lot faster as well. @Ericgig, @ajgpitch: shall we commit to maintaining `essolve` and/or the `eseries` class, or issue a deprecation warning as soon as possible? They're pretty unloved, and `QobjEvo` really is a far far more general way of specifying time-dependence. My vote (should I have one) is for deprecation. I'm always in favour of slimming down codebases if it doesn't remove useful functionality!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1262#issuecomment-628260933
https://github.com/qutip/qutip/issues/1262#issuecomment-628261967:70,Testability,test,tests,70,"Come to think of it, neither `eseries` nor `essolve` have significant tests, and a quick `grep` through shows that `eseries` is completely untested, and `essolve` has only one very basic test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1262#issuecomment-628261967
https://github.com/qutip/qutip/issues/1262#issuecomment-628261967:187,Testability,test,test,187,"Come to think of it, neither `eseries` nor `essolve` have significant tests, and a quick `grep` through shows that `eseries` is completely untested, and `essolve` has only one very basic test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1262#issuecomment-628261967
https://github.com/qutip/qutip/issues/1263#issuecomment-809340570:382,Deployability,install,install,382,"This issue is mostly obseleted by the merging of #1465, since the complete build structure is now different. In that we didn't necessarily implement the complete change requested here (we don't have `pytest` as a requirement), but we do have the PEP-517-approved way of fully specifying build requirements, so getting a correct build environment is automated. I will note that `pip install -e .` doesn't play very nicely with packages with Cython components to build; at the time of writing, `pip` would tend to install dependencies and perform the build in a venv regardless of what was installed in the activated Python environment (especially if conda), which meant that the complete set of Cython files needed to be re-compiled every time this command was run. That's fine if you just want to edit the Python files, but `setup.py develop` would correctly remember which Cython files actually _needed_ to be re-compiled, so remains much more useful for low-level QuTiP development for practical purposes right now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1263#issuecomment-809340570
https://github.com/qutip/qutip/issues/1263#issuecomment-809340570:512,Deployability,install,install,512,"This issue is mostly obseleted by the merging of #1465, since the complete build structure is now different. In that we didn't necessarily implement the complete change requested here (we don't have `pytest` as a requirement), but we do have the PEP-517-approved way of fully specifying build requirements, so getting a correct build environment is automated. I will note that `pip install -e .` doesn't play very nicely with packages with Cython components to build; at the time of writing, `pip` would tend to install dependencies and perform the build in a venv regardless of what was installed in the activated Python environment (especially if conda), which meant that the complete set of Cython files needed to be re-compiled every time this command was run. That's fine if you just want to edit the Python files, but `setup.py develop` would correctly remember which Cython files actually _needed_ to be re-compiled, so remains much more useful for low-level QuTiP development for practical purposes right now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1263#issuecomment-809340570
https://github.com/qutip/qutip/issues/1263#issuecomment-809340570:588,Deployability,install,installed,588,"This issue is mostly obseleted by the merging of #1465, since the complete build structure is now different. In that we didn't necessarily implement the complete change requested here (we don't have `pytest` as a requirement), but we do have the PEP-517-approved way of fully specifying build requirements, so getting a correct build environment is automated. I will note that `pip install -e .` doesn't play very nicely with packages with Cython components to build; at the time of writing, `pip` would tend to install dependencies and perform the build in a venv regardless of what was installed in the activated Python environment (especially if conda), which meant that the complete set of Cython files needed to be re-compiled every time this command was run. That's fine if you just want to edit the Python files, but `setup.py develop` would correctly remember which Cython files actually _needed_ to be re-compiled, so remains much more useful for low-level QuTiP development for practical purposes right now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1263#issuecomment-809340570
https://github.com/qutip/qutip/issues/1263#issuecomment-809340570:520,Integrability,depend,dependencies,520,"This issue is mostly obseleted by the merging of #1465, since the complete build structure is now different. In that we didn't necessarily implement the complete change requested here (we don't have `pytest` as a requirement), but we do have the PEP-517-approved way of fully specifying build requirements, so getting a correct build environment is automated. I will note that `pip install -e .` doesn't play very nicely with packages with Cython components to build; at the time of writing, `pip` would tend to install dependencies and perform the build in a venv regardless of what was installed in the activated Python environment (especially if conda), which meant that the complete set of Cython files needed to be re-compiled every time this command was run. That's fine if you just want to edit the Python files, but `setup.py develop` would correctly remember which Cython files actually _needed_ to be re-compiled, so remains much more useful for low-level QuTiP development for practical purposes right now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1263#issuecomment-809340570
https://github.com/qutip/qutip/issues/1263#issuecomment-809340570:537,Performance,perform,perform,537,"This issue is mostly obseleted by the merging of #1465, since the complete build structure is now different. In that we didn't necessarily implement the complete change requested here (we don't have `pytest` as a requirement), but we do have the PEP-517-approved way of fully specifying build requirements, so getting a correct build environment is automated. I will note that `pip install -e .` doesn't play very nicely with packages with Cython components to build; at the time of writing, `pip` would tend to install dependencies and perform the build in a venv regardless of what was installed in the activated Python environment (especially if conda), which meant that the complete set of Cython files needed to be re-compiled every time this command was run. That's fine if you just want to edit the Python files, but `setup.py develop` would correctly remember which Cython files actually _needed_ to be re-compiled, so remains much more useful for low-level QuTiP development for practical purposes right now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1263#issuecomment-809340570
https://github.com/qutip/qutip/pull/1264#issuecomment-628910011:11,Availability,failure,failure,11,"False test failure again - we really have too many tests which fail probabilistically! This particular one should have been smoothed out by #1250, since the current test is rather convoluted and there's several imprecise floating-point literals in use.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1264#issuecomment-628910011
https://github.com/qutip/qutip/pull/1264#issuecomment-628910011:6,Testability,test,test,6,"False test failure again - we really have too many tests which fail probabilistically! This particular one should have been smoothed out by #1250, since the current test is rather convoluted and there's several imprecise floating-point literals in use.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1264#issuecomment-628910011
https://github.com/qutip/qutip/pull/1264#issuecomment-628910011:51,Testability,test,tests,51,"False test failure again - we really have too many tests which fail probabilistically! This particular one should have been smoothed out by #1250, since the current test is rather convoluted and there's several imprecise floating-point literals in use.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1264#issuecomment-628910011
https://github.com/qutip/qutip/pull/1264#issuecomment-628910011:165,Testability,test,test,165,"False test failure again - we really have too many tests which fail probabilistically! This particular one should have been smoothed out by #1250, since the current test is rather convoluted and there's several imprecise floating-point literals in use.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1264#issuecomment-628910011
https://github.com/qutip/qutip/issues/1265#issuecomment-629680971:12,Availability,error,error,12,"I find this error appears when the two pulses are separated by a distance d > 23.0017... Have no idea why...; ```; c_x_bug = lambda t, arg: cosine_pulse(t, t0=piLen/2.0, amp=0.5*piAmp)+\; cosine_pulse(t, t0=23.0018 + 1.0*piLen+piLen/2.0, amp=0.5*piAmp); ```; The generated `QuobjEvo` seems to be correct. . If I change the `[Qobj, func]` representation to `[Qobj, np.array]`, the same thing appears but with a different threshold. . The bug disappears if I give an epsilon small value to the pulse, like 0.000001, instead of 0. ```; def cosine_pulse(t, t0=piLen/2.0, amp=piAmp, w=piLen, phase=0, df=0):; ...; return ... + 0.000001; ```. Does this somehow ring a bell @Ericgig? Is this possible that the algorithm terminates if the coefficients are all zero for a while?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-629680971
https://github.com/qutip/qutip/issues/1265#issuecomment-629712706:51,Modifiability,variab,variable,51,"We had an issue like this in the past. The ODE use variable steps sizes, when nothing happens, these steps can become very long and skip over the pulse. The option max_step can limit this step size, so it should be set to be shorter than the shortest pulse.; Here I beleive that using `options=qu.Options(max_step=5)` in the solver calls would fix it.; If it does not work, I can look in more details next week.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-629712706
https://github.com/qutip/qutip/issues/1265#issuecomment-629729386:723,Availability,fault,fault,723,"Thanks for your replies @BoxiLi @Ericgig , very helpful!. The output seems right after adding the `max_step` option to mesolve().; We changed the width of the cosine shaped pulse, here are some simple observations.; ```; if width = 20, then setting max_step < 27 can produce the correct answer.; if width = 50, then setting max_step < 70 can produce the correct answer.; if width = 100, then setting max_step < 130 can produce the correct answer.; ```. But as we are most caring about how to use the solvers correctly, we still have some doubts:; 1. We only observed two results, one is 'perfectly correct', and another is 'totally wrong' (Like @Ericgig said, the second pulse has been completely skipped over). Would some fault result in the middle happen? Some wrong result very similar to the correct would be even worse. 2. The Ode version of mesolve function is very fast, which is one of the reasons we love it. But we did not find document about other solvers (raw propagator, flatten to Liouville space?) for the master equation. Could you explain why the ODE method is the best over others, in aspect of accuracy and speed?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-629729386
https://github.com/qutip/qutip/issues/1265#issuecomment-629729386:194,Usability,simpl,simple,194,"Thanks for your replies @BoxiLi @Ericgig , very helpful!. The output seems right after adding the `max_step` option to mesolve().; We changed the width of the cosine shaped pulse, here are some simple observations.; ```; if width = 20, then setting max_step < 27 can produce the correct answer.; if width = 50, then setting max_step < 70 can produce the correct answer.; if width = 100, then setting max_step < 130 can produce the correct answer.; ```. But as we are most caring about how to use the solvers correctly, we still have some doubts:; 1. We only observed two results, one is 'perfectly correct', and another is 'totally wrong' (Like @Ericgig said, the second pulse has been completely skipped over). Would some fault result in the middle happen? Some wrong result very similar to the correct would be even worse. 2. The Ode version of mesolve function is very fast, which is one of the reasons we love it. But we did not find document about other solvers (raw propagator, flatten to Liouville space?) for the master equation. Could you explain why the ODE method is the best over others, in aspect of accuracy and speed?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-629729386
https://github.com/qutip/qutip/issues/1265#issuecomment-629730292:241,Modifiability,evolve,evolve,241,"When doing pulse type simulations, it is best to set the max_step size to be half the width of the smallest pulse in the simulation. This makes sure that pulses do not get over stepped. Propagators are unitaries. To compute them you need to evolve all basis vectors. In addition, it is normal to get a dense matrix for the resulting unitary. In contrast, canonical Hamiltonians are usually quite sparse, and the computing the evolution is quick sparse matrix - dense vector multiplication.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-629730292
https://github.com/qutip/qutip/issues/1265#issuecomment-809335608:54,Safety,detect,detect,54,"Closing for now as the fix is not something QuTiP can detect - we need to have `max_step` to a suitable value to know how stiff the input is. If there's further discussion we need to have, let's talk about it more in other issues / the Google groups discussion boards.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1265#issuecomment-809335608
https://github.com/qutip/qutip/issues/1266#issuecomment-629656289:219,Usability,clear,clear,219,"Indeed, all subtitles are meant to be kept. But I agree that rewording the titles could help. I also like the idea to make the comment only visible when writing. What about; ```; **Feature Request Description**; <!-- A clear and concise description of what you want to happen.-->; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1266#issuecomment-629656289
https://github.com/qutip/qutip/issues/1267#issuecomment-629274156:65,Testability,test,testing,65,"I think `xdist` is about self-managing a distributed cluster for testing? The little line at the bottom about ""it effectively `rsync`s the code to the remote locations"" certainly sounds like it, and those descriptions seem to match too. I think the current `pytest.mark.skipif(...)` is fine - skipping based on the platform in use is actually one of the main examples in the documentation for that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1267#issuecomment-629274156
https://github.com/qutip/qutip/issues/1267#issuecomment-809395266:127,Testability,test,testing,127,"I'll close this for now, unless anyone wants to discuss it further. I believe `xdist` is more if we were managing distributing testing runs manually on our own test runners. The `skipif` would still be important even with `xdist` to decide which tests should run on which system.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1267#issuecomment-809395266
https://github.com/qutip/qutip/issues/1267#issuecomment-809395266:160,Testability,test,test,160,"I'll close this for now, unless anyone wants to discuss it further. I believe `xdist` is more if we were managing distributing testing runs manually on our own test runners. The `skipif` would still be important even with `xdist` to decide which tests should run on which system.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1267#issuecomment-809395266
https://github.com/qutip/qutip/issues/1267#issuecomment-809395266:246,Testability,test,tests,246,"I'll close this for now, unless anyone wants to discuss it further. I believe `xdist` is more if we were managing distributing testing runs manually on our own test runners. The `skipif` would still be important even with `xdist` to decide which tests should run on which system.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1267#issuecomment-809395266
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:584,Availability,toler,tolerance,584,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:603,Availability,error,error,603,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:957,Modifiability,refactor,refactor,957,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:990,Modifiability,rewrite,rewrite,990,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:251,Testability,test,test,251,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:860,Testability,test,tests,860,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-629272663:809,Usability,usab,usability,809,"I think `hypothesis` is the best method here in the long term, but it will most likely have to be a long-term goal. I think the main pro in favour of it is that it actually is making an attempt to remove randomness; it's attempting to comprehensively test a spanning set of input parameters, rather than just Monte-Carlo'ing our way through and hoping. There's a couple of points which make it difficult to implement:. 1. QuTiP can be quite fragile with respect to unexpected input formats, particularly in older parts of the code.; 2. Various components are only accurate up to some tolerance, and the error propagation to work out how that corresponds to useful measurable quantities can be rather tricky. Those are certainly both solvable problems, and point 1 in particular is just general improvement of usability. The second point is about designing the tests well, which again is certainly doable, but will take a while (it takes long enough just to refactor them, let alone a total rewrite of large chunks of them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-629272663
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:827,Availability,failure,failures,827,"Hi @nathanshammah,. Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1703,Availability,mainten,maintenance,1703,"started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another con",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3269,Availability,failure,failures,3269,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1664,Deployability,update,updates,1664,"started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another con",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2590,Deployability,pipeline,pipeline,2590,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2123,Energy Efficiency,power,powerful,2123,"w the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed exper",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3310,Energy Efficiency,efficient,efficient,3310,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1176,Integrability,depend,depend,1176," Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on tho",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2007,Integrability,depend,depend,2007,"the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inp",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2780,Integrability,depend,depending,2780,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1582,Modifiability,coupling,coupling,1582,"started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another con",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2080,Modifiability,coupling,coupling,2080,"w the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed exper",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2110,Modifiability,flexible,flexible,2110,"w the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed exper",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3063,Performance,perform,performing,3063,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:786,Testability,test,tests,786,"Hi @nathanshammah,. Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:822,Testability,test,test,822,"Hi @nathanshammah,. Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:967,Testability,test,tests,967," Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on tho",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1026,Testability,test,testing,1026," Could this issue perhaps be broken into sub-tasks in some way, perhaps, in order to enable work starting on it a bit more feasible?. Also, I can see it's been labelled as a ""good first issue"" but it seems to me the definition of done (i.e., what would a PR - or a set of PRs - that would successfully address the problem entail?), with respect to the entire issue, could be clarified a bit further, and the breakdown into sub-tasks (which itself might result organically from some further discussion) might help a bit in that direction. Regarding possible approaches for handling randomness - I have to admit I've started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on tho",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1618,Testability,log,logic,1618,"started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another con",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1653,Testability,test,tests,1653,"started looking into QuTiP only very recently, and I'm yet to start familiarising myself with its more intricate details and get to run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another con",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1781,Testability,mock,mock,1781," run the full set of tests, and investigate what kind of test failures occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landsc",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:1831,Testability,mock,mock,1831,"es occur. In the meantime, I'll generally share some (what I _think_ is) relevant experience in the context of handling randomness in tests:; - My understanding is that we're talking about not testing the behaviour of random-number generations per se, but how the numbers they generate affect the non-deterministic functions/algorithms, which depend on the former. In such cases, I've either used a fixed seed (as you've mentioned in your [original post](https://github.com/qutip/qutip/issues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - th",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2428,Testability,test,test,2428,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2508,Testability,test,tests,2508,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2542,Testability,test,tests,2542,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2617,Testability,test,tests,2617,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2751,Testability,test,testing,2751,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2813,Testability,test,tests,2813,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3119,Testability,test,tests,3119,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3166,Testability,test,testing,3166,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:3210,Testability,test,test-run-completion,3210,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707:2647,Usability,intuit,intuitively,2647,"ssues/1268#issue-619006856)), which can get a bit messy, as there's Python's `random`, NumPy's `random` (which also comes in a legacy and a modern flavour, namely `numpy.random.RandomState` and `numpy.random.Generator`). Also, as you've mentioned, there's tight coupling between the implementation logic and the corresponding set of tests, and updates in the former require constant maintenance of the latter.; - As an alternative, I've sometimes resorted to [`mock`](https://docs.python.org/3/library/unittest.mock.html)ing the random-number generation process itself, and - in a way equivalent to using a fixed seed - providing a pre-defined sequence of numbers to the functions which depend on those. It comes with the same disadvantage of relatively tight coupling, but is somehow more flexible and powerful than just setting the seeds.; - I have used Hypothesis in the past (on a relatively small-scale project), and it's indeed a great framework with a lot of interesting and nice functionalities. I like it very much, but one disadvantage I ran into was the increased overall time for completion of a test run. In my case, a viable approach, for instance, was to run my Hypothesis tests (which were a subset of all tests) with a bit larger periodicity (in the CI pipeline) than the regular tests. Another concern that I intuitively have (I may be _wildly_ wrong on this one, though, not having yet properly explored QuTiP's testing landscape) is that - depending on how some Hypothesis tests are set up - there might be a cost incurred in that, eventually, one might have to implement guards against inputs, that would be virtually impossible (or very close to that) to occur in practical scenarios. In any case, I'd strongly recommend performing a time-boxed experiment on a small subset of tests, which are more suited to property-based testing, and examining how that affects the test-run-completion time(s) and whether it introduces more failures than what would be desired/cost-efficient.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1268#issuecomment-1123679707
https://github.com/qutip/qutip/pull/1269#issuecomment-629656336:51,Testability,test,tests,51,Thanks for the fix. Could you also please add some tests for the addition of SWAP gates and removal?,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629656336
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:158,Modifiability,refactor,refactoring,158,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:251,Modifiability,rewrite,rewrite,251,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:119,Testability,test,test,119,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:201,Testability,test,tests,201,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:263,Testability,test,test,263,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629662675:310,Testability,test,test,310,"Thank for spotting another bug @Canoming, I'll check it and merge if everything is good. @quantshah I'd say we let the test wait for a while. @jakelishman 's refactoring is still not merged and adding tests now will lead to conflicts. He will need to rewrite the test again. Maybe we can build a more thorough test for the circuit module during the GSoC project @sarsid ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629662675
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:2842,Availability,error,error,2842,"s ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not necessary). First run; ```; git remote add qutip https://github.com/qutip/qutip.git; git fetch qutip; ```; to add the upstream `qutip` remote. Then run; ```; git checkout master; git rebase -i $(git merge-base qutip/master master); ```; and modify the file so that the instruction list looks like (only the first word of each line changes); ```; pick ea1c129a fix function QubitCircuit.remove_gate; fixup 3bd94603 fix function QubitCircui.remove_gate; fixup b4f75cfe fix; pick 4aa90f56 fix bug in QubitCircuit.add_circuit; pick 3a2676de fix function QubitCircuit.add_circuit; pick 58aebc7f fix indent; ```; Should you save and close the file, it would modify your commit history. We'd only do this to avoid a merge conflict which would otherwise occur in the next step. Then, run; ```; git rebase qutip/master; ```; which should complete without error. Finally, your local `master` would now have diverged from Github's copy (and this PR's), so you'd have to force-push the changes by doing; ```; git push --force; ```; which would update this PR accordingly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:3028,Deployability,update,update,3028,"s ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not necessary). First run; ```; git remote add qutip https://github.com/qutip/qutip.git; git fetch qutip; ```; to add the upstream `qutip` remote. Then run; ```; git checkout master; git rebase -i $(git merge-base qutip/master master); ```; and modify the file so that the instruction list looks like (only the first word of each line changes); ```; pick ea1c129a fix function QubitCircuit.remove_gate; fixup 3bd94603 fix function QubitCircui.remove_gate; fixup b4f75cfe fix; pick 4aa90f56 fix bug in QubitCircuit.add_circuit; pick 3a2676de fix function QubitCircuit.add_circuit; pick 58aebc7f fix indent; ```; Should you save and close the file, it would modify your commit history. We'd only do this to avoid a merge conflict which would otherwise occur in the next step. Then, run; ```; git rebase qutip/master; ```; which should complete without error. Finally, your local `master` would now have diverged from Github's copy (and this PR's), so you'd have to force-push the changes by doing; ```; git push --force; ```; which would update this PR accordingly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:54,Modifiability,refactor,refactor,54,"Don't worry about the tests - progress on merging the refactor is slow (though if you want to review #1249 it'll help!). Besides, these tests would probably go in `test_qubitcircuit.py` which I haven't touched yet. Add the tests here, and I'll rebase #1251 onto `master` after this is merged if it's necessary to add them to the new style. Hopefully this will be the last time!. About the merge oddness: it comes about because this PR is built on a false version of the upstream (our) `master`. As long as you apply this merge as a squash, it will actually be ok and the history will be clean. Don't apply the merge as a history-preserving merge (i.e. a regular one), because it will make the commit history confusing (and defeats the purpose of having merged #1242 as a squash). ## Unnecessary detail. The exact reason is that this commit is build on top of #1242, but this is inconsistent with the upstream `master`; because #1242 was merged as a squash, `qutip/master` and `Canoming/master` diverged at fd13ae0 (i.e. before #1242), so `git` sees commits ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not neces",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:2697,Safety,avoid,avoid,2697,"s ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not necessary). First run; ```; git remote add qutip https://github.com/qutip/qutip.git; git fetch qutip; ```; to add the upstream `qutip` remote. Then run; ```; git checkout master; git rebase -i $(git merge-base qutip/master master); ```; and modify the file so that the instruction list looks like (only the first word of each line changes); ```; pick ea1c129a fix function QubitCircuit.remove_gate; fixup 3bd94603 fix function QubitCircui.remove_gate; fixup b4f75cfe fix; pick 4aa90f56 fix bug in QubitCircuit.add_circuit; pick 3a2676de fix function QubitCircuit.add_circuit; pick 58aebc7f fix indent; ```; Should you save and close the file, it would modify your commit history. We'd only do this to avoid a merge conflict which would otherwise occur in the next step. Then, run; ```; git rebase qutip/master; ```; which should complete without error. Finally, your local `master` would now have diverged from Github's copy (and this PR's), so you'd have to force-push the changes by doing; ```; git push --force; ```; which would update this PR accordingly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:22,Testability,test,tests,22,"Don't worry about the tests - progress on merging the refactor is slow (though if you want to review #1249 it'll help!). Besides, these tests would probably go in `test_qubitcircuit.py` which I haven't touched yet. Add the tests here, and I'll rebase #1251 onto `master` after this is merged if it's necessary to add them to the new style. Hopefully this will be the last time!. About the merge oddness: it comes about because this PR is built on a false version of the upstream (our) `master`. As long as you apply this merge as a squash, it will actually be ok and the history will be clean. Don't apply the merge as a history-preserving merge (i.e. a regular one), because it will make the commit history confusing (and defeats the purpose of having merged #1242 as a squash). ## Unnecessary detail. The exact reason is that this commit is build on top of #1242, but this is inconsistent with the upstream `master`; because #1242 was merged as a squash, `qutip/master` and `Canoming/master` diverged at fd13ae0 (i.e. before #1242), so `git` sees commits ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not neces",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:136,Testability,test,tests,136,"Don't worry about the tests - progress on merging the refactor is slow (though if you want to review #1249 it'll help!). Besides, these tests would probably go in `test_qubitcircuit.py` which I haven't touched yet. Add the tests here, and I'll rebase #1251 onto `master` after this is merged if it's necessary to add them to the new style. Hopefully this will be the last time!. About the merge oddness: it comes about because this PR is built on a false version of the upstream (our) `master`. As long as you apply this merge as a squash, it will actually be ok and the history will be clean. Don't apply the merge as a history-preserving merge (i.e. a regular one), because it will make the commit history confusing (and defeats the purpose of having merged #1242 as a squash). ## Unnecessary detail. The exact reason is that this commit is build on top of #1242, but this is inconsistent with the upstream `master`; because #1242 was merged as a squash, `qutip/master` and `Canoming/master` diverged at fd13ae0 (i.e. before #1242), so `git` sees commits ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not neces",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629701269:223,Testability,test,tests,223,"Don't worry about the tests - progress on merging the refactor is slow (though if you want to review #1249 it'll help!). Besides, these tests would probably go in `test_qubitcircuit.py` which I haven't touched yet. Add the tests here, and I'll rebase #1251 onto `master` after this is merged if it's necessary to add them to the new style. Hopefully this will be the last time!. About the merge oddness: it comes about because this PR is built on a false version of the upstream (our) `master`. As long as you apply this merge as a squash, it will actually be ok and the history will be clean. Don't apply the merge as a history-preserving merge (i.e. a regular one), because it will make the commit history confusing (and defeats the purpose of having merged #1242 as a squash). ## Unnecessary detail. The exact reason is that this commit is build on top of #1242, but this is inconsistent with the upstream `master`; because #1242 was merged as a squash, `qutip/master` and `Canoming/master` diverged at fd13ae0 (i.e. before #1242), so `git` sees commits ea1c129 to b4f75cf as ""new"" (the first three commits of this PR). However, when those commits are taken together, they make the same changes as commit 4102b99 (the one which merged #1242) in `qutip/master`. The Github ""Files changed"" dialog is a pretty-printed version of the `git` command `git diff qutip/master...Canoming/master`, which means ""show all changes on either branch since `qutip/master` and `Canoming/master` diverged"". Because they diverged before #1242 was merged, it includes those changes. The merge completes without conflict, however, because `git` is clever and recognises that the changes introduced in the two branches `qutip/master` and `Canoming/master` are identical, even though the commits are different. As a consequence, however, merging this PR without squashing it would cause commits ea1c129 to b4f75cf to suddenly appear in our commit history, which we don't want. ### If Canoming wanted to fix this (not neces",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629701269
https://github.com/qutip/qutip/pull/1269#issuecomment-629800241:259,Deployability,update,update,259,"@jakelishman, thanks for the explanation! I forget the tests here belong to the circuit module. @Canoming Would you still like to add some tests to `tests\test_qubitcircuit.py` for `remove_gate` and `add_circuit`? Otherwise, I can also merge this and we will update the tests later.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629800241
https://github.com/qutip/qutip/pull/1269#issuecomment-629800241:55,Testability,test,tests,55,"@jakelishman, thanks for the explanation! I forget the tests here belong to the circuit module. @Canoming Would you still like to add some tests to `tests\test_qubitcircuit.py` for `remove_gate` and `add_circuit`? Otherwise, I can also merge this and we will update the tests later.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629800241
https://github.com/qutip/qutip/pull/1269#issuecomment-629800241:139,Testability,test,tests,139,"@jakelishman, thanks for the explanation! I forget the tests here belong to the circuit module. @Canoming Would you still like to add some tests to `tests\test_qubitcircuit.py` for `remove_gate` and `add_circuit`? Otherwise, I can also merge this and we will update the tests later.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629800241
https://github.com/qutip/qutip/pull/1269#issuecomment-629800241:149,Testability,test,tests,149,"@jakelishman, thanks for the explanation! I forget the tests here belong to the circuit module. @Canoming Would you still like to add some tests to `tests\test_qubitcircuit.py` for `remove_gate` and `add_circuit`? Otherwise, I can also merge this and we will update the tests later.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629800241
https://github.com/qutip/qutip/pull/1269#issuecomment-629800241:270,Testability,test,tests,270,"@jakelishman, thanks for the explanation! I forget the tests here belong to the circuit module. @Canoming Would you still like to add some tests to `tests\test_qubitcircuit.py` for `remove_gate` and `add_circuit`? Otherwise, I can also merge this and we will update the tests later.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629800241
https://github.com/qutip/qutip/pull/1269#issuecomment-629826086:161,Usability,simpl,simple,161,"@Canoming: if this gets merged, it's much easier to bring your `master` up-to-date because we'd want to overwrite everything on it. In that case, it would be as simple as; ```; git remote add qutip https://github.com/qutip/qutip.git; git fetch qutip; git reset --hard qutip/master; ```; and you'd have forced your `master` to mirror ours (destructively - if you had additional work you wanted saving, this would overwrite it). In the future, it will be a bit easier for you if you develop pull requests on a separate branch, and always keep `master` as mirroring ours.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629826086
https://github.com/qutip/qutip/pull/1269#issuecomment-629843104:100,Availability,error,error,100,"@BoxiLi Sure, the tests looks not too complex. I'm working on it. I'm grouping the gates for better error handling. @jakelishman Thanks. Sorry, I was just too lazy to set up the tests on my machine, LOL. I simply create the pull request and see if the code pass. That's why there are always one or two minor fixes here.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629843104
https://github.com/qutip/qutip/pull/1269#issuecomment-629843104:18,Testability,test,tests,18,"@BoxiLi Sure, the tests looks not too complex. I'm working on it. I'm grouping the gates for better error handling. @jakelishman Thanks. Sorry, I was just too lazy to set up the tests on my machine, LOL. I simply create the pull request and see if the code pass. That's why there are always one or two minor fixes here.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629843104
https://github.com/qutip/qutip/pull/1269#issuecomment-629843104:178,Testability,test,tests,178,"@BoxiLi Sure, the tests looks not too complex. I'm working on it. I'm grouping the gates for better error handling. @jakelishman Thanks. Sorry, I was just too lazy to set up the tests on my machine, LOL. I simply create the pull request and see if the code pass. That's why there are always one or two minor fixes here.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629843104
https://github.com/qutip/qutip/pull/1269#issuecomment-629843104:206,Usability,simpl,simply,206,"@BoxiLi Sure, the tests looks not too complex. I'm working on it. I'm grouping the gates for better error handling. @jakelishman Thanks. Sorry, I was just too lazy to set up the tests on my machine, LOL. I simply create the pull request and see if the code pass. That's why there are always one or two minor fixes here.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-629843104
https://github.com/qutip/qutip/pull/1269#issuecomment-630932121:833,Deployability,update,update,833,"After you created a fork to work on #1242, a different PR (#1226) was merged into `master`. It so happens that #1242 and #1226 don't conflict so that merge succeeded, but the new changes you're now trying to make do. This is fundamentally a true merge conflict and so unfortunately there's no fancy way around it, though it could have been avoided if you'd matched the state of our `master` before beginning work here, and it would be a bit easier for you for future PRs to branch off before starting work (GitHub has [some nice material about this workflow](https://guides.github.com/introduction/flow/)). I've rebased your PR onto our `master` and fixed the resulting merge conflict for you. You should _immediately, without doing anything else_ reset your branch state to match mine, and then force-push your changes to GitHub to update the PR. To do this, do; ```bash; git remote add jakelishman https://www.github.com/jakelishman/qutip.git; git fetch jakelishman; git checkout master; git reset --hard jakelishman/Canoming-circuit-patch; git push --force; git remote remove jakelishman; ```; This will destroy anything on `master` that you may have but haven't yet pushed. You should do it anyway, because a lot of the underlying structure has changed from underneath you, and your changes aren't consistent with the current state of `circuit.py`. Please also note that the tests are failing after your modifications in (the current) 10e457e.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-630932121
https://github.com/qutip/qutip/pull/1269#issuecomment-630932121:1036,Deployability,patch,patch,1036,"After you created a fork to work on #1242, a different PR (#1226) was merged into `master`. It so happens that #1242 and #1226 don't conflict so that merge succeeded, but the new changes you're now trying to make do. This is fundamentally a true merge conflict and so unfortunately there's no fancy way around it, though it could have been avoided if you'd matched the state of our `master` before beginning work here, and it would be a bit easier for you for future PRs to branch off before starting work (GitHub has [some nice material about this workflow](https://guides.github.com/introduction/flow/)). I've rebased your PR onto our `master` and fixed the resulting merge conflict for you. You should _immediately, without doing anything else_ reset your branch state to match mine, and then force-push your changes to GitHub to update the PR. To do this, do; ```bash; git remote add jakelishman https://www.github.com/jakelishman/qutip.git; git fetch jakelishman; git checkout master; git reset --hard jakelishman/Canoming-circuit-patch; git push --force; git remote remove jakelishman; ```; This will destroy anything on `master` that you may have but haven't yet pushed. You should do it anyway, because a lot of the underlying structure has changed from underneath you, and your changes aren't consistent with the current state of `circuit.py`. Please also note that the tests are failing after your modifications in (the current) 10e457e.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-630932121
https://github.com/qutip/qutip/pull/1269#issuecomment-630932121:340,Safety,avoid,avoided,340,"After you created a fork to work on #1242, a different PR (#1226) was merged into `master`. It so happens that #1242 and #1226 don't conflict so that merge succeeded, but the new changes you're now trying to make do. This is fundamentally a true merge conflict and so unfortunately there's no fancy way around it, though it could have been avoided if you'd matched the state of our `master` before beginning work here, and it would be a bit easier for you for future PRs to branch off before starting work (GitHub has [some nice material about this workflow](https://guides.github.com/introduction/flow/)). I've rebased your PR onto our `master` and fixed the resulting merge conflict for you. You should _immediately, without doing anything else_ reset your branch state to match mine, and then force-push your changes to GitHub to update the PR. To do this, do; ```bash; git remote add jakelishman https://www.github.com/jakelishman/qutip.git; git fetch jakelishman; git checkout master; git reset --hard jakelishman/Canoming-circuit-patch; git push --force; git remote remove jakelishman; ```; This will destroy anything on `master` that you may have but haven't yet pushed. You should do it anyway, because a lot of the underlying structure has changed from underneath you, and your changes aren't consistent with the current state of `circuit.py`. Please also note that the tests are failing after your modifications in (the current) 10e457e.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-630932121
https://github.com/qutip/qutip/pull/1269#issuecomment-630932121:1379,Testability,test,tests,1379,"After you created a fork to work on #1242, a different PR (#1226) was merged into `master`. It so happens that #1242 and #1226 don't conflict so that merge succeeded, but the new changes you're now trying to make do. This is fundamentally a true merge conflict and so unfortunately there's no fancy way around it, though it could have been avoided if you'd matched the state of our `master` before beginning work here, and it would be a bit easier for you for future PRs to branch off before starting work (GitHub has [some nice material about this workflow](https://guides.github.com/introduction/flow/)). I've rebased your PR onto our `master` and fixed the resulting merge conflict for you. You should _immediately, without doing anything else_ reset your branch state to match mine, and then force-push your changes to GitHub to update the PR. To do this, do; ```bash; git remote add jakelishman https://www.github.com/jakelishman/qutip.git; git fetch jakelishman; git checkout master; git reset --hard jakelishman/Canoming-circuit-patch; git push --force; git remote remove jakelishman; ```; This will destroy anything on `master` that you may have but haven't yet pushed. You should do it anyway, because a lot of the underlying structure has changed from underneath you, and your changes aren't consistent with the current state of `circuit.py`. Please also note that the tests are failing after your modifications in (the current) 10e457e.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-630932121
https://github.com/qutip/qutip/pull/1269#issuecomment-630932121:567,Usability,guid,guides,567,"After you created a fork to work on #1242, a different PR (#1226) was merged into `master`. It so happens that #1242 and #1226 don't conflict so that merge succeeded, but the new changes you're now trying to make do. This is fundamentally a true merge conflict and so unfortunately there's no fancy way around it, though it could have been avoided if you'd matched the state of our `master` before beginning work here, and it would be a bit easier for you for future PRs to branch off before starting work (GitHub has [some nice material about this workflow](https://guides.github.com/introduction/flow/)). I've rebased your PR onto our `master` and fixed the resulting merge conflict for you. You should _immediately, without doing anything else_ reset your branch state to match mine, and then force-push your changes to GitHub to update the PR. To do this, do; ```bash; git remote add jakelishman https://www.github.com/jakelishman/qutip.git; git fetch jakelishman; git checkout master; git reset --hard jakelishman/Canoming-circuit-patch; git push --force; git remote remove jakelishman; ```; This will destroy anything on `master` that you may have but haven't yet pushed. You should do it anyway, because a lot of the underlying structure has changed from underneath you, and your changes aren't consistent with the current state of `circuit.py`. Please also note that the tests are failing after your modifications in (the current) 10e457e.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-630932121
https://github.com/qutip/qutip/pull/1269#issuecomment-636370643:56,Deployability,update,update,56,"@Canoming, I'll merge this one now. If you have any new update, you are welcome to open another PR. . I also recommend to open a new branch for further changes and keep your master up to date with the qutip master.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1269#issuecomment-636370643
https://github.com/qutip/qutip/pull/1273#issuecomment-650731854:209,Energy Efficiency,schedul,scheduler,209,[![Coverage Status](https://coveralls.io/builds/36512426/badge)](https://coveralls.io/builds/36512426). Coverage increased (+0.05%) to 63.454% when pulling **9e080a769cf147c31de25cb7e219168cdb631689 on BoxiLi:scheduler** into **c719cbe13c69b18741c67578e720b654984afd7c on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1273#issuecomment-650731854
https://github.com/qutip/qutip/pull/1273#issuecomment-661857844:141,Integrability,interface,interface,141,"Hi @sarsid, if you are going to play with it. It would be very helpful if you could give some feedback ;) Like if the doc is clear or if the interface is reasonable, or if there are any bugs. Thanks!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1273#issuecomment-661857844
https://github.com/qutip/qutip/pull/1273#issuecomment-661857844:94,Usability,feedback,feedback,94,"Hi @sarsid, if you are going to play with it. It would be very helpful if you could give some feedback ;) Like if the doc is clear or if the interface is reasonable, or if there are any bugs. Thanks!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1273#issuecomment-661857844
https://github.com/qutip/qutip/pull/1273#issuecomment-661857844:125,Usability,clear,clear,125,"Hi @sarsid, if you are going to play with it. It would be very helpful if you could give some feedback ;) Like if the doc is clear or if the interface is reasonable, or if there are any bugs. Thanks!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1273#issuecomment-661857844
https://github.com/qutip/qutip/pull/1274#issuecomment-633747691:102,Modifiability,coupling,coupling,102,"Hi @sarsid! I'd like to recommend that we land #1090 separately. It's a stand alone piece of work and coupling PRs together into big PRs where it can be avoided generally makes things harder to review and land. I can show you how to merge that branch into this one if you need to it make progress before #1090 lands. I would also recommend making the formatting changes you have made (I assume using black or your editor?) in a separate PR to this one. Lumping them into one PR also makes reviewing harder since one doesn't know which changes are intentional or meaningful. I'm also happy to help with this if you need!. I've started work on the docs for #1090, so hopefully it can land this week.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-633747691
https://github.com/qutip/qutip/pull/1274#issuecomment-633747691:153,Safety,avoid,avoided,153,"Hi @sarsid! I'd like to recommend that we land #1090 separately. It's a stand alone piece of work and coupling PRs together into big PRs where it can be avoided generally makes things harder to review and land. I can show you how to merge that branch into this one if you need to it make progress before #1090 lands. I would also recommend making the formatting changes you have made (I assume using black or your editor?) in a separate PR to this one. Lumping them into one PR also makes reviewing harder since one doesn't know which changes are intentional or meaningful. I'm also happy to help with this if you need!. I've started work on the docs for #1090, so hopefully it can land this week.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-633747691
https://github.com/qutip/qutip/pull/1274#issuecomment-633964657:393,Safety,redund,redundancy,393,"I think I agree that the two PRs should be kept separate. Initially, I wanted to make them the same since I was trying to use the code in #1090 but right now the two don't interact much. . Wrt the formatting changes, they were put inadvertently and I'll make sure to revert them but thanks for pointing them out. Let me know what you think of the code in this PR and if you think there's some redundancy between the two (I think there should be but I can't quite put a finger on it).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-633964657
https://github.com/qutip/qutip/pull/1274#issuecomment-637291687:56,Modifiability,variab,variable,56,I think I am pretty happy now with all my functions and variable names (for now). I would say we should leave the variable name changing and moving gates and measurement to separate files for a different PR (it can just be a restructuring one !). I was wondering how to check if it passes current tests (I am not sure what changes were there on Travis).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637291687
https://github.com/qutip/qutip/pull/1274#issuecomment-637291687:114,Modifiability,variab,variable,114,I think I am pretty happy now with all my functions and variable names (for now). I would say we should leave the variable name changing and moving gates and measurement to separate files for a different PR (it can just be a restructuring one !). I was wondering how to check if it passes current tests (I am not sure what changes were there on Travis).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637291687
https://github.com/qutip/qutip/pull/1274#issuecomment-637291687:297,Testability,test,tests,297,I think I am pretty happy now with all my functions and variable names (for now). I would say we should leave the variable name changing and moving gates and measurement to separate files for a different PR (it can just be a restructuring one !). I was wondering how to check if it passes current tests (I am not sure what changes were there on Travis).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637291687
https://github.com/qutip/qutip/pull/1274#issuecomment-637357742:156,Testability,test,tests,156,"You can either run it on your local machine by the command `pytest` or turn it from a draft PR into a ready-for-reveiw PR, which will trigger the Travis CI tests.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637357742
https://github.com/qutip/qutip/pull/1274#issuecomment-637475315:54,Testability,test,tests,54,"I will reiterate @BoxiLi suggestion. If you find that tests pass locally, then switch from draft to review ready. You can also set the 'ready for review' label with your group membership permissions. I will take a look over the code now, but will not fully review it until you mark it as ready for such. Would be best if tests were in place before this. Take a look at the codeclimate issues. They don't have to fixed, they are just suggestions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637475315
https://github.com/qutip/qutip/pull/1274#issuecomment-637475315:321,Testability,test,tests,321,"I will reiterate @BoxiLi suggestion. If you find that tests pass locally, then switch from draft to review ready. You can also set the 'ready for review' label with your group membership permissions. I will take a look over the code now, but will not fully review it until you mark it as ready for such. Would be best if tests were in place before this. Take a look at the codeclimate issues. They don't have to fixed, they are just suggestions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-637475315
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:5,Deployability,Update,Updates,5,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:37,Testability,test,tests,37,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:78,Testability,test,tests,78,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:148,Testability,test,tests,148,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:261,Testability,test,tests,261,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:381,Testability,test,tests,381,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:396,Testability,test,tests,396,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-639989935:439,Testability,test,tests,439,"Some Updates: . 1. I have added some tests for both the Measurement (in qutip/tests/test_circuit_measurement.py) portion and the circuit run (qutip/tests/test_qubitcircuit.py) portions of the code. There is a slight hiccup with the Python 3.8 run of one of the tests (test_run_statistics). I am not sure why it is only failing in the Python 3.8 case. ; 2. I have converted all the tests in qutip/tests/test_qubitcircuit.py to pytest style tests. Maybe, @jakelishman can comment if further changes are required. ; 3. Finally, since `measurement_density` and `measurement_ket` allow for POVM style measurements, it might be better to move those functions to qutip/measurement.py but I am not sure. Maybe @hodgestar can comment on that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-639989935
https://github.com/qutip/qutip/pull/1274#issuecomment-640005926:192,Safety,avoid,avoided,192,"> I am not sure why it is only failing in the Python 3.8 case. Well, it's a statistical average, so it can deviate. I don't think it has anything to do with Python 3.8. But probably it can be avoided? I guess its the same question as #1268 . I'm thinking, what about adding a `targets` parameters to `QubitCircuit.run_statistics`. Usually, people don't interested in the full output state of the circuit because many of them are ancillary qubits. They can use `targets` to specify what is the qubits they want to look at. In the function, we can use `ptrace(state, targets)` to trace out the ancilla.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640005926
https://github.com/qutip/qutip/pull/1274#issuecomment-640006594:887,Availability,toler,tolerance,887,"> > I am not sure why it is only failing in the Python 3.8 case.; > ; > Well, it's a statistical average, so it can deviate. I don't think it has anything to do with Python 3.8. But probably it can be avoided? I guess its the same question as #1268; > ; > I'm thinking, what about adding a `targets` parameters to `QubitCircuit.run_statistics`. Usually, people don't interested in the full output state of the circuit because many of them are ancillary qubits. They can use `targets` to specify what is the qubits they want to look at. In the function, we can use `ptrace(state, targets)` to trace out the ancilla. Seems like a good idea, maybe we can add it as optional parameter to both `QubitCircuit.run_statistics` and `QubitCircuit.run`. Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640006594
https://github.com/qutip/qutip/pull/1274#issuecomment-640006594:201,Safety,avoid,avoided,201,"> > I am not sure why it is only failing in the Python 3.8 case.; > ; > Well, it's a statistical average, so it can deviate. I don't think it has anything to do with Python 3.8. But probably it can be avoided? I guess its the same question as #1268; > ; > I'm thinking, what about adding a `targets` parameters to `QubitCircuit.run_statistics`. Usually, people don't interested in the full output state of the circuit because many of them are ancillary qubits. They can use `targets` to specify what is the qubits they want to look at. In the function, we can use `ptrace(state, targets)` to trace out the ancilla. Seems like a good idea, maybe we can add it as optional parameter to both `QubitCircuit.run_statistics` and `QubitCircuit.run`. Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640006594
https://github.com/qutip/qutip/pull/1274#issuecomment-640006594:826,Testability,test,test,826,"> > I am not sure why it is only failing in the Python 3.8 case.; > ; > Well, it's a statistical average, so it can deviate. I don't think it has anything to do with Python 3.8. But probably it can be avoided? I guess its the same question as #1268; > ; > I'm thinking, what about adding a `targets` parameters to `QubitCircuit.run_statistics`. Usually, people don't interested in the full output state of the circuit because many of them are ancillary qubits. They can use `targets` to specify what is the qubits they want to look at. In the function, we can use `ptrace(state, targets)` to trace out the ancilla. Seems like a good idea, maybe we can add it as optional parameter to both `QubitCircuit.run_statistics` and `QubitCircuit.run`. Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640006594
https://github.com/qutip/qutip/pull/1274#issuecomment-640007551:146,Availability,toler,tolerance,146,"> Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?. Ok.... Let me try restart the CI test once",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640007551
https://github.com/qutip/qutip/pull/1274#issuecomment-640007551:85,Testability,test,test,85,"> Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?. Ok.... Let me try restart the CI test once",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640007551
https://github.com/qutip/qutip/pull/1274#issuecomment-640007551:199,Testability,test,test,199,"> Also, regarding Python 3.8, I was saying because both times it only failed in that test run, also never failed in any of my runs. Should I make tolerance higher ?. Ok.... Let me try restart the CI test once",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640007551
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:559,Availability,failure,failure,559,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:959,Availability,toler,tolerance,959,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:1119,Availability,toler,tolerance,1119,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:1161,Availability,failure,failure,1161,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:1248,Availability,toler,tolerance,1248,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:142,Testability,test,test,142,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:157,Testability,test,test,157,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:284,Testability,test,test,284,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:864,Testability,test,test,864,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:898,Testability,test,test,898,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640043626:1156,Testability,test,test,1156,"Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; ```python; import scipy.stats; def success(n, p, tol):; dist = scipy.stats.binom(n, p); return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); ```; where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times. You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken. If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640043626
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:583,Availability,failure,failure,583,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:990,Availability,toler,tolerance,990,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1157,Availability,toler,tolerance,1157,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1199,Availability,failure,failure,1199,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1286,Availability,toler,tolerance,1286,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:144,Testability,test,test,144,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:159,Testability,test,test,159,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:286,Testability,test,test,286,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:895,Testability,test,test,895,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:929,Testability,test,test,929,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1194,Testability,test,test,1194,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1557,Testability,test,test,1557,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1749,Testability,test,test,1749,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640087689:1524,Usability,guid,guideline,1524,"> Consider what you're doing from a statistical sense here. If everything works correctly, then you're effectively trying a two-tail hypothesis test that your test binomial distribution has a probability of 0.25, given you made `n` observations of it. The analytic success rate of your test is then; > ; > ```python; > import scipy.stats; > def success(n, p, tol):; > dist = scipy.stats.binom(n, p); > return dist.cdf(n * (p+tol)) - dist.cdf(n * (p-tol)); > ```; > ; > where `success(4096, 0.25, 0.02)` is 99.67%. Since there are 5 independent runs on Travis, that's equivalent to a failure rate of 1.6% on every single CI run, which is several orders of magnitude too high. It's probably just luck that it was Python 3.8 on both occasions - it's a one-in-five chance that in two failing CI runs, it was the same setup both times.; > ; > You have to consider what is most appropriate to fix the test, and what you can reasonably test in ~1 second of runtime. You don't want to increase the tolerance too much, because then you can get a lot of false positives even if something is broken.; > ; > If you can bump the number of runs up to 100,000 and set the tolerance at 0.01, you'll have a per-test failure rate of ~3e-13, which is more like what we'd want. If you keep it at 4096, the tolerance should be more like 0.05 (which is pretty big tbh). Thanks for the excellent analysis. I don't think it's feasible to do 100,000 given the current. efficiency. It did give me incentive to make it somewhat faster. What is a good guideline for the maximum time a test can take. It seems like I can maybe do 150 runs in ~ 1s. In any case, it doesnt seem feasible to do even 4096 claims without taking quite a bit of time. Any ideas on how to structure the test differently ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640087689
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:106,Testability,test,test,106,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:155,Testability,Test,Tests,155,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:192,Testability,Test,Test,192,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:240,Testability,Test,Test,240,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:324,Testability,test,test,324,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640102122:427,Testability,test,test,427,"Hmmm... 4000/150\~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min\~20min on Travis. . Just ideas. Tests here seem to be two-folded:. - Test classical controlled gates in a circuit; - Test the measurement functions. So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?. On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640102122
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:107,Testability,test,test,107,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:160,Testability,Test,Tests,160,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:203,Testability,Test,Test,203,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:253,Testability,Test,Test,253,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:343,Testability,test,test,343,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:446,Testability,test,test,446,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:1260,Testability,test,test,1260,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:1411,Testability,test,test,1411,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:1235,Usability,simpl,simple,1235,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640107253:1475,Usability,simpl,simpler,1475,"> Hmmm... 4000/150~25 second. That's not very short actually. The total time for a whole round of qutip CI test costs 15min~20min on Travis.; > ; > Just ideas. Tests here seem to be two-folded:; > ; > * Test classical controlled gates in a circuit; > * Test the measurement functions; > ; > So maybe we can split it. The teleportation circuit test can be done without measurement. Just check the final state tracing out the ancillary qubits. The test for measurement can probably be done for single or two `Qobj` along without circuit. But `run_circuit_statistics`... Probably we then only need to check if the number of elements in the result is correct after some 50 runs?; > ; > On a different matter, I'm wondering if running the statistics takes so long, for such a small teleportation circuit, is it still advantageous in any case? Since we are doing simulation and have the full quantum state, one can actually calculate all 4 possible final states, classically mix them into a density matrix with the corresponding measurement probability and calculate the exact statistics distribution. I doubt that will be slower than 25s, although coding will be harder I suppose. I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ? . Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ? Seems like a decent idea !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640107253
https://github.com/qutip/qutip/pull/1274#issuecomment-640113087:85,Testability,test,test,85,">I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?. Maybe, but I find teleportation already a very short circuit, isn't it?. >Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?. Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640113087
https://github.com/qutip/qutip/pull/1274#issuecomment-640113087:236,Testability,test,test,236,">I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?. Maybe, but I find teleportation already a very short circuit, isn't it?. >Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?. Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640113087
https://github.com/qutip/qutip/pull/1274#issuecomment-640113087:60,Usability,simpl,simple,60,">I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?. Maybe, but I find teleportation already a very short circuit, isn't it?. >Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?. Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640113087
https://github.com/qutip/qutip/pull/1274#issuecomment-640113087:300,Usability,simpl,simpler,300,">I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?. Maybe, but I find teleportation already a very short circuit, isn't it?. >Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?. Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640113087
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:1688,Energy Efficiency,efficient,efficient,1688,"er than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:1156,Performance,load,loads,1156,"er than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:1166,Performance,load,loads,1166,"er than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:108,Testability,test,testing,108,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:203,Testability,test,tests,203,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:327,Testability,test,test,327,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:361,Testability,test,test,361,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:380,Testability,test,test,380,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:426,Testability,test,testing,426,"1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640127213:1669,Testability,test,test,1669,"er than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function. The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up. With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead. I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them. Minor things that _may_ speed up - check the profiling!; 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640127213
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:1726,Energy Efficiency,efficient,efficient,1726," many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`. Excellent Suggestions ! I already added some of the speed-ups you suggested, just haven't pushed them yet ! However, I think it might just be a better idea to go with Boxi's idea of removing the need for way too many runs in the first place !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:1179,Performance,load,loads,1179,"r current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`. Excellent Suggestions ! I already added some of the speed-ups you suggested, just haven't pushed",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:1189,Performance,load,loads,1189,"r current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`. Excellent Suggestions ! I already added some of the speed-ups you suggested, just haven't pushed",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:110,Testability,test,testing,110,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:205,Testability,test,tests,205,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:329,Testability,test,test,329,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:363,Testability,test,test,363,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:389,Testability,test,test,389,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:435,Testability,test,testing,435,"> 1 second was meant to be the order of magnitude rather than a hard limit, but it's a good rule of thumb for testing one piece of functionality. [Here's a (slightly out-dated) list of our current longest tests](https://github.com/qutip/qutip/issues/1217#issuecomment-604116373), bearing in mind that some of those ones actually test many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements inter",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640128273:1705,Testability,test,test,1705," many many things in the same test function.; > ; > The test seems structured ok to me. Certainly the testing algorithm isn't the major cause of speed loss. You could try timing some ""real-world"" examples of using your measurements, and try running them in a profiler to see if there are any obvious ways to speed things up.; > ; > With any luck the new data-layer tools and the possibility of using dense `Qobj` storage will give you a fair amount of speed-up once they're complete, since I imagine in your small circuit you're paying quite a lot of sparse matrix overhead.; > ; > I'll prefix this last part with: _you should always profile your code before optimising it_. That said, let me wildly break that rule and guess at where I think you'll find big speed-ups: caching and pre-computation. If you know you're going to run the same thing loads and loads of times, then you shouldn't have to call `self.propagators` each time, or build `measurement_ops` inside `measure_comp_basis`. Do those once at the start of `run_statistics`, and save them.; > ; > Minor things that _may_ speed up - check the profiling!; > ; > 1. ""compress"" the output of `self.propagators`: consecutive propagators with no measurements or classical controls inbetween can be pre-multiplied together at the start to make one matrix. This will save you ~3 matrix multiplications per run in the test.; > 2. use more efficient ways to construct large tensor spaces: `qutip.basis`, `qutip.projection` and `qutip.qeye` can all directly constructor product spaces (e.g. `qutip.basis([2, 2, 2], [0, 1, 0])`). `tensor` is a comparatively expensive operation, and tensoring a list of elements internally is effectively `tensor(...(tensor(tensor(els[0], els[1]), els[2]), ...), els[-1])`. Excellent Suggestions ! I already added some of the speed-ups you suggested, just haven't pushed them yet ! However, I think it might just be a better idea to go with Boxi's idea of removing the need for way too many runs in the first place !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640128273
https://github.com/qutip/qutip/pull/1274#issuecomment-640714799:806,Integrability,message,message,806,"Hi, sorry for coming late to the party. This is a very nice PR and I have a couple of comments on the naming of the functions. Instead of having three different measurement functions - `measurement_ket`, `measurement_density` and `measurement_comp_basis` why not have a single `measure` function that has the same signature as `qutip.measurement.measure`, i.e., measure(op, state) where internally you check if the state is a ket or dm and just apply the operation internally? You could also have a `basis='computational`` keyword if you need to specify the basis. But I do not see why you make that distinction? . Also, in a real experiment you will not be able to make multiple measurements on the same state which seems to be possible now in your PR. We need to either not allow this or leave a warning message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-640714799
https://github.com/qutip/qutip/pull/1274#issuecomment-641961716:371,Energy Efficiency,efficient,efficient,371,"Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works. . Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-641961716
https://github.com/qutip/qutip/pull/1274#issuecomment-641961716:103,Usability,simpl,simplifying,103,"Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works. . Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-641961716
https://github.com/qutip/qutip/pull/1274#issuecomment-641961716:115,Usability,user experience,user experience,115,"Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works. . Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-641961716
https://github.com/qutip/qutip/pull/1274#issuecomment-641961716:149,Usability,simpl,simple,149,"Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works. . Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-641961716
https://github.com/qutip/qutip/pull/1274#issuecomment-641961716:478,Usability,simpl,simpler,478,"Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works. . Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-641961716
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:378,Energy Efficiency,efficient,efficient,378,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:751,Security,expose,exposed,751,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:105,Usability,simpl,simplifying,105,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:117,Usability,user experience,user experience,117,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:151,Usability,simpl,simple,151,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730389:485,Usability,simpl,simpler,485,"> Thanks @ajgpitch for the comments. I agree that there should be the specific functions but I think for simplifying user experience there should be a simple overarching function. E.g, when you plot Wigner functions in QuTiP you can send it kets or dms or operators and it just works.; > ; > Internally, it still calls specific functions to compute the Wigner function based on efficient methods specific to the inputs. But it is just a small convenience to the average user to have a simpler clean overarching function to do the same. I have now made it so that the measure and measurement_statistics function precisely do this. Should we keep either mode (one mode is of the ""observable"" type and the other with the ""projective"" type) also as a api-exposed function? If that is not the case, what would be the correct way to write doc_strings ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730389
https://github.com/qutip/qutip/pull/1274#issuecomment-643730550:1212,Security,expose,exposed,1212,"> > Instead of having three different measurement functions - `measurement_ket`, `measurement_density` and `measurement_comp_basis` why not have a single `measure` function that has the same signature as `qutip.measurement.measure`, i.e., measure(op, state) where internally you check if the state is a ket or dm and just apply the operation internally? You could also have a `basis='computational`` keyword if you need to specify the basis. But I do not see why you make that distinction?; > ; > In the GSoC meeting we discussed. There may be some efficiency benefits of specific functions for certain tasks. There could be some advantage of an overarching func too. So maybe both is the best approach.; > ; > As far as it makes sense the measurement stuff should go it the main package. Anything that is specific to circuits could go in qip. We have suggested @sarsid and @hodgestar discuss and come up with a design. I have ""proposed"" a preliminary design that basically works by adding a dispatch function that appropriately calls either of the two types of measurements. The new concern is writing good documentation for the same. I am wondering if both kinds of measurements should both have their own api-exposed function (or only one function which dispatches to both types, as is right now)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730550
https://github.com/qutip/qutip/pull/1274#issuecomment-643730645:88,Testability,test,test,88,"> > I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?; > ; > Maybe, but I find teleportation already a very short circuit, isn't it?; > ; > > Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?; > ; > Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics. I have changed the run_statistics function to now do this method in place of running it a number of times. This solves the problem of slow testing of the function as well !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730645
https://github.com/qutip/qutip/pull/1274#issuecomment-643730645:239,Testability,test,test,239,"> > I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?; > ; > Maybe, but I find teleportation already a very short circuit, isn't it?; > ; > > Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?; > ; > Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics. I have changed the run_statistics function to now do this method in place of running it a number of times. This solves the problem of slow testing of the function as well !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730645
https://github.com/qutip/qutip/pull/1274#issuecomment-643730645:867,Testability,test,testing,867,"> > I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?; > ; > Maybe, but I find teleportation already a very short circuit, isn't it?; > ; > > Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?; > ; > Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics. I have changed the run_statistics function to now do this method in place of running it a number of times. This solves the problem of slow testing of the function as well !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730645
https://github.com/qutip/qutip/pull/1274#issuecomment-643730645:63,Usability,simpl,simple,63,"> > I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?; > ; > Maybe, but I find teleportation already a very short circuit, isn't it?; > ; > > Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?; > ; > Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics. I have changed the run_statistics function to now do this method in place of running it a number of times. This solves the problem of slow testing of the function as well !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730645
https://github.com/qutip/qutip/pull/1274#issuecomment-643730645:303,Usability,simpl,simpler,303,"> > I added the teleportation circuit because it seemed like a simple enough example to test both classically controlled gates and measurements. I have some separate (non-circuit based) examples in the other file. Maybe the run_statistics test can be not on the teleportation circuit and something even simpler ?; > ; > Maybe, but I find teleportation already a very short circuit, isn't it?; > ; > > Re: the idea for run_statistics, do you mean tracking the various probability elements during each measurement (along with the state) ?; > ; > Yes, if we have n qubit measurements, we will have 2^n possible final state. One can calculate the state for each of them along with its probability and then get the exact statistics. I have changed the run_statistics function to now do this method in place of running it a number of times. This solves the problem of slow testing of the function as well !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643730645
https://github.com/qutip/qutip/pull/1274#issuecomment-643731499:5,Deployability,update,updates,5,Some updates:. 1. All measurements (except the one in the computational basis) have now been moved to qutip/measurement.py. The interface for the previous measurement style (using observables and eigenstates) remains the same. The only difference is that the `measure` and `measurement_statistics` functions now act as dispatch functions that can carry out projective measurements instead when the `op : list of projection operators` ; 2. I have moved all measurement tests to qutip/tests/test_measurement.py as well as moved all measurement tests to pytest style,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643731499
https://github.com/qutip/qutip/pull/1274#issuecomment-643731499:128,Integrability,interface,interface,128,Some updates:. 1. All measurements (except the one in the computational basis) have now been moved to qutip/measurement.py. The interface for the previous measurement style (using observables and eigenstates) remains the same. The only difference is that the `measure` and `measurement_statistics` functions now act as dispatch functions that can carry out projective measurements instead when the `op : list of projection operators` ; 2. I have moved all measurement tests to qutip/tests/test_measurement.py as well as moved all measurement tests to pytest style,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643731499
https://github.com/qutip/qutip/pull/1274#issuecomment-643731499:468,Testability,test,tests,468,Some updates:. 1. All measurements (except the one in the computational basis) have now been moved to qutip/measurement.py. The interface for the previous measurement style (using observables and eigenstates) remains the same. The only difference is that the `measure` and `measurement_statistics` functions now act as dispatch functions that can carry out projective measurements instead when the `op : list of projection operators` ; 2. I have moved all measurement tests to qutip/tests/test_measurement.py as well as moved all measurement tests to pytest style,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643731499
https://github.com/qutip/qutip/pull/1274#issuecomment-643731499:483,Testability,test,tests,483,Some updates:. 1. All measurements (except the one in the computational basis) have now been moved to qutip/measurement.py. The interface for the previous measurement style (using observables and eigenstates) remains the same. The only difference is that the `measure` and `measurement_statistics` functions now act as dispatch functions that can carry out projective measurements instead when the `op : list of projection operators` ; 2. I have moved all measurement tests to qutip/tests/test_measurement.py as well as moved all measurement tests to pytest style,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643731499
https://github.com/qutip/qutip/pull/1274#issuecomment-643731499:542,Testability,test,tests,542,Some updates:. 1. All measurements (except the one in the computational basis) have now been moved to qutip/measurement.py. The interface for the previous measurement style (using observables and eigenstates) remains the same. The only difference is that the `measure` and `measurement_statistics` functions now act as dispatch functions that can carry out projective measurements instead when the `op : list of projection operators` ; 2. I have moved all measurement tests to qutip/tests/test_measurement.py as well as moved all measurement tests to pytest style,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643731499
https://github.com/qutip/qutip/pull/1274#issuecomment-643844273:215,Usability,feedback,feedback,215,I have addressed some of the potential confusion on measurements in my GSOC blogpost [here](https://sarsid.wordpress.com/2020/06/14/an-introduction-to-quantum-measurements-in-qutip/).; Hope that helps and welcoming feedback.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-643844273
https://github.com/qutip/qutip/pull/1274#issuecomment-646002967:377,Safety,detect,detect,377,"Hi @sarsid, there are still some tests failing. When you think the PR is really, just make it a ready-for-review PR and request a review. Besides, it would be great to address some of the style issues in code climate like ""Continuation line under-indented for visual indent"". Not all of them must be fixed though, it's more like a guide. The `pycodestyle` package can help you detect them locally if you would like to use it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-646002967
https://github.com/qutip/qutip/pull/1274#issuecomment-646002967:33,Testability,test,tests,33,"Hi @sarsid, there are still some tests failing. When you think the PR is really, just make it a ready-for-review PR and request a review. Besides, it would be great to address some of the style issues in code climate like ""Continuation line under-indented for visual indent"". Not all of them must be fixed though, it's more like a guide. The `pycodestyle` package can help you detect them locally if you would like to use it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-646002967
https://github.com/qutip/qutip/pull/1274#issuecomment-646002967:331,Usability,guid,guide,331,"Hi @sarsid, there are still some tests failing. When you think the PR is really, just make it a ready-for-review PR and request a review. Besides, it would be great to address some of the style issues in code climate like ""Continuation line under-indented for visual indent"". Not all of them must be fixed though, it's more like a guide. The `pycodestyle` package can help you detect them locally if you would like to use it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-646002967
https://github.com/qutip/qutip/pull/1274#issuecomment-647035492:17,Testability,test,tests,17,"Not sure why `../tests/test_interpolate.py::test_usage_in_solvers[mcsolve-complex-spline,string] `; is failing in this case, seems completely unrelated ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647035492
https://github.com/qutip/qutip/pull/1274#issuecomment-647047749:58,Availability,error,error,58,"Yeah, don't worry about that. That's a pretty unfortunate error (I've never actually seen it before) but it's certainly not related to your changes. It means that the numerical intergrator we use for solvers couldn't proceed properly (failed to converge in, or that kind of thing). It will be related to the random seed that `mcsolve` used that time round, but certainly not your fault.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647047749
https://github.com/qutip/qutip/pull/1274#issuecomment-647047749:380,Availability,fault,fault,380,"Yeah, don't worry about that. That's a pretty unfortunate error (I've never actually seen it before) but it's certainly not related to your changes. It means that the numerical intergrator we use for solvers couldn't proceed properly (failed to converge in, or that kind of thing). It will be related to the random seed that `mcsolve` used that time round, but certainly not your fault.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647047749
https://github.com/qutip/qutip/pull/1274#issuecomment-647187809:5,Deployability,update,updates,5,"Some updates: . 1. I have added specifying kets as `ops` in `measure` and `measurement_statistics`. I have also added a check for whether the sum of all the measurement operators sums to identity which should be the case with any POVMs. New tests for the same have been added as well ! ; 2. I have removed `self.gates` as well as `self.gates_and_measurements`. The replacement is the more ""general"" (and less of a mouthful) `self.circuit_ops` which contains both. I still allow `propagators` function to be allowed in this case (because it is useful internally in `run`). However, now if a circuit with measurement needs to call `resolve_gates` or `adjacent_gates`, it needs to add measurements after the fact. . @BoxiLi, any opinions ? I have also addressed all the other minor issues as well ! . P.S. All of the new codeclimate issues are just previous issues re-appearing carried on because I modified those lines.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647187809
https://github.com/qutip/qutip/pull/1274#issuecomment-647187809:241,Testability,test,tests,241,"Some updates: . 1. I have added specifying kets as `ops` in `measure` and `measurement_statistics`. I have also added a check for whether the sum of all the measurement operators sums to identity which should be the case with any POVMs. New tests for the same have been added as well ! ; 2. I have removed `self.gates` as well as `self.gates_and_measurements`. The replacement is the more ""general"" (and less of a mouthful) `self.circuit_ops` which contains both. I still allow `propagators` function to be allowed in this case (because it is useful internally in `run`). However, now if a circuit with measurement needs to call `resolve_gates` or `adjacent_gates`, it needs to add measurements after the fact. . @BoxiLi, any opinions ? I have also addressed all the other minor issues as well ! . P.S. All of the new codeclimate issues are just previous issues re-appearing carried on because I modified those lines.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647187809
https://github.com/qutip/qutip/pull/1274#issuecomment-647396416:366,Testability,test,tests,366,"Nice work!. > I have removed self.gates as well as self.gates_and_measurements. The replacement is the more ""general"" (and less of a mouthful) self.circuit_ops which contains both. I like this merge of to attributes. However, we shouldn't change the attribute name `gates`, at least not in this PR here. It's an open attribute API and as you see we used it a lot in tests. It's very likely that others are using it too. . Personally, I would keep the attribute `gates` since even for measurement operations, people still usually say ""measurement gates"". `circuit_ops` is certainly more accurate, but might be hard to remember and thus makes the learning curve steeper.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647396416
https://github.com/qutip/qutip/pull/1274#issuecomment-647396416:645,Usability,learn,learning,645,"Nice work!. > I have removed self.gates as well as self.gates_and_measurements. The replacement is the more ""general"" (and less of a mouthful) self.circuit_ops which contains both. I like this merge of to attributes. However, we shouldn't change the attribute name `gates`, at least not in this PR here. It's an open attribute API and as you see we used it a lot in tests. It's very likely that others are using it too. . Personally, I would keep the attribute `gates` since even for measurement operations, people still usually say ""measurement gates"". `circuit_ops` is certainly more accurate, but might be hard to remember and thus makes the learning curve steeper.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647396416
https://github.com/qutip/qutip/pull/1274#issuecomment-647834648:381,Testability,test,tests,381,"> Nice work!; > ; > > I have removed self.gates as well as self.gates_and_measurements. The replacement is the more ""general"" (and less of a mouthful) self.circuit_ops which contains both.; > ; > I like this merge of to attributes. However, we shouldn't change the attribute name `gates`, at least not in this PR here. It's an open attribute API and as you see we used it a lot in tests. It's very likely that others are using it too.; > ; > Personally, I would keep the attribute `gates` since even for measurement operations, people still usually say ""measurement gates"". `circuit_ops` is certainly more accurate, but might be hard to remember and thus makes the learning curve steeper. Rolled back to self.gates",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647834648
https://github.com/qutip/qutip/pull/1274#issuecomment-647834648:665,Usability,learn,learning,665,"> Nice work!; > ; > > I have removed self.gates as well as self.gates_and_measurements. The replacement is the more ""general"" (and less of a mouthful) self.circuit_ops which contains both.; > ; > I like this merge of to attributes. However, we shouldn't change the attribute name `gates`, at least not in this PR here. It's an open attribute API and as you see we used it a lot in tests. It's very likely that others are using it too.; > ; > Personally, I would keep the attribute `gates` since even for measurement operations, people still usually say ""measurement gates"". `circuit_ops` is certainly more accurate, but might be hard to remember and thus makes the learning curve steeper. Rolled back to self.gates",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-647834648
https://github.com/qutip/qutip/pull/1274#issuecomment-648113340:195,Integrability,interface,interface,195,"The PR is in good shape for merging I believe. I'd like to discuss the parameters API a bit. The parameters used now for measurement function is `ops` and `state`. I guess @hodgestar coined this interface in his PR. It fully made sense for observable and state. However, if we now generalize it to the measurement from the perspective of experimentalists. The parameter `state` becomes a more prominent one whereas `ops` becomes secondary because it only offers a basis for the measurement. This become clearer if one list all the possible use scenarios where:. - `state=Qobj, ops=None`: measure the `state` in default computational basis; - `state=Qobj, ops=ket`: Probability of measure `state` and get `ket`, (together with the post-measurement state); - `state=Qobj, ops=Qobj`: Measure the `state` with one POVM operator specified by `ops`; - `state=Qobj, ops=list of ket`; - `state=Qobj, ops=list of Qobj`. More generally, we can even provide the user with the optional parameter `targets`, where the given `ops` is only for those targets qubits. We can add identity to the measurement operator for the rest of the qubits automatically for the user.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-648113340
https://github.com/qutip/qutip/pull/1274#issuecomment-648113340:503,Usability,clear,clearer,503,"The PR is in good shape for merging I believe. I'd like to discuss the parameters API a bit. The parameters used now for measurement function is `ops` and `state`. I guess @hodgestar coined this interface in his PR. It fully made sense for observable and state. However, if we now generalize it to the measurement from the perspective of experimentalists. The parameter `state` becomes a more prominent one whereas `ops` becomes secondary because it only offers a basis for the measurement. This become clearer if one list all the possible use scenarios where:. - `state=Qobj, ops=None`: measure the `state` in default computational basis; - `state=Qobj, ops=ket`: Probability of measure `state` and get `ket`, (together with the post-measurement state); - `state=Qobj, ops=Qobj`: Measure the `state` with one POVM operator specified by `ops`; - `state=Qobj, ops=list of ket`; - `state=Qobj, ops=list of Qobj`. More generally, we can even provide the user with the optional parameter `targets`, where the given `ops` is only for those targets qubits. We can add identity to the measurement operator for the rest of the qubits automatically for the user.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-648113340
https://github.com/qutip/qutip/pull/1274#issuecomment-648548980:0,Deployability,Update,Updates,0,"Updates:; - I have switched the order of `state` and `op`/`ops`. ; - There is now an optional `targets` arguments on each of the measurement functions to enable applying `ops` on particular; `qubits` although this is inherently delicate, especially when dealing with non-qubit type dimensions. Right now, it's restricted to `qubit` style expansions (in terms of dimensions). This indicated in the docstring. I will add some more information on how to use this in the user guide but I think it works best for more simpler use cases !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-648548980
https://github.com/qutip/qutip/pull/1274#issuecomment-648548980:472,Usability,guid,guide,472,"Updates:; - I have switched the order of `state` and `op`/`ops`. ; - There is now an optional `targets` arguments on each of the measurement functions to enable applying `ops` on particular; `qubits` although this is inherently delicate, especially when dealing with non-qubit type dimensions. Right now, it's restricted to `qubit` style expansions (in terms of dimensions). This indicated in the docstring. I will add some more information on how to use this in the user guide but I think it works best for more simpler use cases !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-648548980
https://github.com/qutip/qutip/pull/1274#issuecomment-648548980:513,Usability,simpl,simpler,513,"Updates:; - I have switched the order of `state` and `op`/`ops`. ; - There is now an optional `targets` arguments on each of the measurement functions to enable applying `ops` on particular; `qubits` although this is inherently delicate, especially when dealing with non-qubit type dimensions. Right now, it's restricted to `qubit` style expansions (in terms of dimensions). This indicated in the docstring. I will add some more information on how to use this in the user guide but I think it works best for more simpler use cases !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-648548980
https://github.com/qutip/qutip/pull/1274#issuecomment-649089741:40,Testability,test,tests,40,"Again, I am not sure why some unrelated tests are failing !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649089741
https://github.com/qutip/qutip/pull/1274#issuecomment-649280292:274,Availability,error,error,274,"These failing tests are different from those random failing we've been seeing before. I also have this in my scheduler PR, but it is completely unrelated to the PR. It starts to appear yesterday, but nothing was merged in the last three weeks. Does anyone have a clue?. The error seems to come from the core data part @jakelishman @Ericgig. Scipy made a release 4 days ago and we are using one of the private attributes.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649280292
https://github.com/qutip/qutip/pull/1274#issuecomment-649280292:354,Deployability,release,release,354,"These failing tests are different from those random failing we've been seeing before. I also have this in my scheduler PR, but it is completely unrelated to the PR. It starts to appear yesterday, but nothing was merged in the last three weeks. Does anyone have a clue?. The error seems to come from the core data part @jakelishman @Ericgig. Scipy made a release 4 days ago and we are using one of the private attributes.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649280292
https://github.com/qutip/qutip/pull/1274#issuecomment-649280292:109,Energy Efficiency,schedul,scheduler,109,"These failing tests are different from those random failing we've been seeing before. I also have this in my scheduler PR, but it is completely unrelated to the PR. It starts to appear yesterday, but nothing was merged in the last three weeks. Does anyone have a clue?. The error seems to come from the core data part @jakelishman @Ericgig. Scipy made a release 4 days ago and we are using one of the private attributes.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649280292
https://github.com/qutip/qutip/pull/1274#issuecomment-649280292:14,Testability,test,tests,14,"These failing tests are different from those random failing we've been seeing before. I also have this in my scheduler PR, but it is completely unrelated to the PR. It starts to appear yesterday, but nothing was merged in the last three weeks. Does anyone have a clue?. The error seems to come from the core data part @jakelishman @Ericgig. Scipy made a release 4 days ago and we are using one of the private attributes.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649280292
https://github.com/qutip/qutip/pull/1274#issuecomment-649446743:812,Deployability,patch,patch,812,"`scipy` 1.5 has changed some of its private attributes for matrix multiplication (to a _much_ better name!), and so matrix-matrix multiplication is completely broken for us at the moment: see scipy/scipy@53fac7a. There's also been some changes to how Hermitian eigenvalues and vectors are calculated (which actually is good news for us in general), which may has a bit of a knock-on for some of the `zheevr` tests, which is going to be a bit of a nuisance to fix. To avoid polluting this PR with (any more) off-topic discussion, I've opened #1299. The new data layer types will fix the matrix multiplication issue permanently, because we'll not be duplicating/reusing large tracts of `scipy` private code - we have our own Cython versions that operate faster on more optimised types. In the meantime, #1298 is a patch to catch the renames.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649446743
https://github.com/qutip/qutip/pull/1274#issuecomment-649446743:467,Safety,avoid,avoid,467,"`scipy` 1.5 has changed some of its private attributes for matrix multiplication (to a _much_ better name!), and so matrix-matrix multiplication is completely broken for us at the moment: see scipy/scipy@53fac7a. There's also been some changes to how Hermitian eigenvalues and vectors are calculated (which actually is good news for us in general), which may has a bit of a knock-on for some of the `zheevr` tests, which is going to be a bit of a nuisance to fix. To avoid polluting this PR with (any more) off-topic discussion, I've opened #1299. The new data layer types will fix the matrix multiplication issue permanently, because we'll not be duplicating/reusing large tracts of `scipy` private code - we have our own Cython versions that operate faster on more optimised types. In the meantime, #1298 is a patch to catch the renames.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649446743
https://github.com/qutip/qutip/pull/1274#issuecomment-649446743:408,Testability,test,tests,408,"`scipy` 1.5 has changed some of its private attributes for matrix multiplication (to a _much_ better name!), and so matrix-matrix multiplication is completely broken for us at the moment: see scipy/scipy@53fac7a. There's also been some changes to how Hermitian eigenvalues and vectors are calculated (which actually is good news for us in general), which may has a bit of a knock-on for some of the `zheevr` tests, which is going to be a bit of a nuisance to fix. To avoid polluting this PR with (any more) off-topic discussion, I've opened #1299. The new data layer types will fix the matrix multiplication issue permanently, because we'll not be duplicating/reusing large tracts of `scipy` private code - we have our own Cython versions that operate faster on more optimised types. In the meantime, #1298 is a patch to catch the renames.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-649446743
https://github.com/qutip/qutip/pull/1274#issuecomment-650337844:37,Integrability,wrap,wrapped,37,"@quantshah @BoxiLi @hodgestar I have wrapped up the two measurement functions in the `measure` and `measurement_statistics` function which calls the required functions based on whether `ops` is a `list of Qobjs` or a `Qobj`. Do we want the individual functions (especially POVM) to be more granular? Moreover, the docstring for the wrapper function is really clunky (given the case-wise output types). Any ideas on how to make that simpler ?(one idea is to not specify return types and only have parameters given it's bound to be clunky!). ps. I'll fix the tests all at once after we decide on the api",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-650337844
https://github.com/qutip/qutip/pull/1274#issuecomment-650337844:332,Integrability,wrap,wrapper,332,"@quantshah @BoxiLi @hodgestar I have wrapped up the two measurement functions in the `measure` and `measurement_statistics` function which calls the required functions based on whether `ops` is a `list of Qobjs` or a `Qobj`. Do we want the individual functions (especially POVM) to be more granular? Moreover, the docstring for the wrapper function is really clunky (given the case-wise output types). Any ideas on how to make that simpler ?(one idea is to not specify return types and only have parameters given it's bound to be clunky!). ps. I'll fix the tests all at once after we decide on the api",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-650337844
https://github.com/qutip/qutip/pull/1274#issuecomment-650337844:557,Testability,test,tests,557,"@quantshah @BoxiLi @hodgestar I have wrapped up the two measurement functions in the `measure` and `measurement_statistics` function which calls the required functions based on whether `ops` is a `list of Qobjs` or a `Qobj`. Do we want the individual functions (especially POVM) to be more granular? Moreover, the docstring for the wrapper function is really clunky (given the case-wise output types). Any ideas on how to make that simpler ?(one idea is to not specify return types and only have parameters given it's bound to be clunky!). ps. I'll fix the tests all at once after we decide on the api",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-650337844
https://github.com/qutip/qutip/pull/1274#issuecomment-650337844:432,Usability,simpl,simpler,432,"@quantshah @BoxiLi @hodgestar I have wrapped up the two measurement functions in the `measure` and `measurement_statistics` function which calls the required functions based on whether `ops` is a `list of Qobjs` or a `Qobj`. Do we want the individual functions (especially POVM) to be more granular? Moreover, the docstring for the wrapper function is really clunky (given the case-wise output types). Any ideas on how to make that simpler ?(one idea is to not specify return types and only have parameters given it's bound to be clunky!). ps. I'll fix the tests all at once after we decide on the api",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-650337844
https://github.com/qutip/qutip/pull/1274#issuecomment-651781870:103,Deployability,update,update,103,I suggest we merge it after the tests and the codeclimate issues are (partially) fixed. We can make an update PR for doc if necessary.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-651781870
https://github.com/qutip/qutip/pull/1274#issuecomment-651781870:32,Testability,test,tests,32,I suggest we merge it after the tests and the codeclimate issues are (partially) fixed. We can make an update PR for doc if necessary.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1274#issuecomment-651781870
https://github.com/qutip/qutip/pull/1275#issuecomment-661868732:193,Availability,redundant,redundant,193,"Thank for the remark. ; @NS2LPS Replacing the first row of the Liouvillian is a standard way to ensure the algorithm produces a steady state with trace one. Since this condition is, in theory, redundant, adding the weighted first-row or substituting the first line should be equivalent. Often the algorithm is unstable, so one weights the trace 1 condition. Maybe how much of the first row is kept can make the algorithm even more stable?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-661868732
https://github.com/qutip/qutip/pull/1275#issuecomment-661868732:193,Safety,redund,redundant,193,"Thank for the remark. ; @NS2LPS Replacing the first row of the Liouvillian is a standard way to ensure the algorithm produces a steady state with trace one. Since this condition is, in theory, redundant, adding the weighted first-row or substituting the first line should be equivalent. Often the algorithm is unstable, so one weights the trace 1 condition. Maybe how much of the first row is kept can make the algorithm even more stable?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-661868732
https://github.com/qutip/qutip/pull/1275#issuecomment-893440155:145,Testability,test,tests,145,"@NS2LPS Apologies for the slow reviews. Would you be up for updating this PR and then we can review it properly? It would be good to somehow add tests to these cases, but I'm not sure how easy that is to do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893440155
https://github.com/qutip/qutip/pull/1275#issuecomment-893447309:7,Deployability,update,update,7,"I will update my contribution as soon as I come back from holidays. Best, Jrme. -------- Message original --------; Objet: Re: [qutip/qutip] Update steadystate.py (#1275); De: Simon Cross ; : qutip/qutip ; Cc: NS2 group at LPS ,Mention . @NS2LPS Apologies for the slow reviews. Would you be up for updating this PR and then we can review it properly? It would be good to somehow add tests to these cases, but I'm not sure how easy that is to do. -- ; You are receiving this because you were mentioned.; Reply to this email directly or view it on GitHub:; https://github.com/qutip/qutip/pull/1275#issuecomment-893440155",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893447309
https://github.com/qutip/qutip/pull/1275#issuecomment-893447309:144,Deployability,Update,Update,144,"I will update my contribution as soon as I come back from holidays. Best, Jrme. -------- Message original --------; Objet: Re: [qutip/qutip] Update steadystate.py (#1275); De: Simon Cross ; : qutip/qutip ; Cc: NS2 group at LPS ,Mention . @NS2LPS Apologies for the slow reviews. Would you be up for updating this PR and then we can review it properly? It would be good to somehow add tests to these cases, but I'm not sure how easy that is to do. -- ; You are receiving this because you were mentioned.; Reply to this email directly or view it on GitHub:; https://github.com/qutip/qutip/pull/1275#issuecomment-893440155",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893447309
https://github.com/qutip/qutip/pull/1275#issuecomment-893447309:91,Integrability,Message,Message,91,"I will update my contribution as soon as I come back from holidays. Best, Jrme. -------- Message original --------; Objet: Re: [qutip/qutip] Update steadystate.py (#1275); De: Simon Cross ; : qutip/qutip ; Cc: NS2 group at LPS ,Mention . @NS2LPS Apologies for the slow reviews. Would you be up for updating this PR and then we can review it properly? It would be good to somehow add tests to these cases, but I'm not sure how easy that is to do. -- ; You are receiving this because you were mentioned.; Reply to this email directly or view it on GitHub:; https://github.com/qutip/qutip/pull/1275#issuecomment-893440155",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893447309
https://github.com/qutip/qutip/pull/1275#issuecomment-893447309:390,Testability,test,tests,390,"I will update my contribution as soon as I come back from holidays. Best, Jrme. -------- Message original --------; Objet: Re: [qutip/qutip] Update steadystate.py (#1275); De: Simon Cross ; : qutip/qutip ; Cc: NS2 group at LPS ,Mention . @NS2LPS Apologies for the slow reviews. Would you be up for updating this PR and then we can review it properly? It would be good to somehow add tests to these cases, but I'm not sure how easy that is to do. -- ; You are receiving this because you were mentioned.; Reply to this email directly or view it on GitHub:; https://github.com/qutip/qutip/pull/1275#issuecomment-893440155",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893447309
https://github.com/qutip/qutip/pull/1275#issuecomment-893453284:9,Deployability,update,update,9,"> I will update my contribution as soon as I come back from holidays. Best, Jrme. Thanks! Enjoy your holidays.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-893453284
https://github.com/qutip/qutip/pull/1275#issuecomment-986833630:59,Testability,test,test,59,@NS2LPS Just checking whether you're still keen to write a test for this and finish off the PR?,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-986833630
https://github.com/qutip/qutip/pull/1275#issuecomment-987894724:2104,Performance,perform,performs,2104,"ata.todense(); Ldense[0, :] = +np.diag(weight*np.ones(n)).reshape((1, n ** 2)); rho1 = np.linalg.solve(Ldense, b). Weight 1.0000000000000001e-16. # Proposed modified version; weight = np.mean(np.abs(L.data).max(0)).real # added .real to get a float ; print('Weight',weight); b[0] = weight; Ldense = L.data.todense(); Ldense[0, :] = +np.diag(weight*np.ones(n)).reshape((1, n ** 2)); rho2 = np.linalg.solve(Ldense, b). Weight 1.0; ```. The current version leads to a very small weight because the imaginary part is discarded. Also, the mean is not doing anything. The proposed modification computes the modulus before evaluating the maximum for each line and then takes the mean. This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different.; ```; np.linalg.norm(rho1-rho2); >> 1.1102230246251565e-16; ```. 2 ) Construction of the matrix to obtain the steady state; As mentioned by @fminga, this should not change anything in most situations. But the proposed modification will make the matrix identical to the one computed by the algorithm when the sparse option is chosen. Here is an example, where the proposed modification performs slightly better than the current version. ; ```; H = identity(2); c_op_list = [sigmam(), 1e-8*sigmap()]; L = liouvillian(H, c_op_list); weight = 1.0; n = 2; b = np.zeros(n ** 2); b[0] = weight; ```. The current version gives:; ```; Ldense = L.data.todense(); Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); np.linalg.solve(Ldense, b); >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); ```. The proposed modification gives:; ```; Ldense = L.data.todense(); Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); np.linalg.solve(Ldense, b); >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); ```; This is a better result than the one obtained with the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-987894724
https://github.com/qutip/qutip/pull/1275#issuecomment-987894724:55,Testability,test,tests,55,"Sorry, my holidays were not that long... Here are some tests of the proposed modifications. 1 ) Computation of the weight; The proposed modification may lead to a large change of the weight in some circumstances.; For example :; ```; H = sigmaz(); c_op_list = [1e-8*sigmap()]; L = liouvillian(H, c_op_list); n = H.shape[0]; b = np.zeros(n ** 2); print(L.data.todense()). [[ 0.e+00+0.j 0.e+00+0.j 0.e+00+0.j 1.e-16+0.j]; [ 0.e+00+0.j -5.e-17+2.j 0.e+00+0.j 0.e+00+0.j]; [ 0.e+00+0.j 0.e+00+0.j -5.e-17-2.j 0.e+00+0.j]; [ 0.e+00+0.j 0.e+00+0.j 0.e+00+0.j -1.e-16+0.j]]; ```. The elements of the Liouvillian have modulus close to unity, which should be reflected in the value of the weight. ```; # Current version; weight = np.mean(np.abs(L.data.data.max())); print('Weight',weight); b[0] = weight; Ldense = L.data.todense(); Ldense[0, :] = +np.diag(weight*np.ones(n)).reshape((1, n ** 2)); rho1 = np.linalg.solve(Ldense, b). Weight 1.0000000000000001e-16. # Proposed modified version; weight = np.mean(np.abs(L.data).max(0)).real # added .real to get a float ; print('Weight',weight); b[0] = weight; Ldense = L.data.todense(); Ldense[0, :] = +np.diag(weight*np.ones(n)).reshape((1, n ** 2)); rho2 = np.linalg.solve(Ldense, b). Weight 1.0; ```. The current version leads to a very small weight because the imaginary part is discarded. Also, the mean is not doing anything. The proposed modification computes the modulus before evaluating the maximum for each line and then takes the mean. This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different.; ```; np.linalg.norm(rho1-rho2); >> 1.1102230246251565e-16; ```. 2 ) Construction of the matrix to obtain the steady state; As mentioned by @fminga, this should not change anything in most situations. But the proposed modification will make the matrix identical to the one computed ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-987894724
https://github.com/qutip/qutip/pull/1275#issuecomment-988058511:16,Testability,test,tests,16,"> Here are some tests of the proposed modifications. Thank you! I actually meant ""unit tests"" -- as in, adding the tests to `qutip/tests/test_steadystate.py`. It's also not clear to me from your examples how we should see the difference. > This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different. I agree it would be good for the sparse and dense algorithms to align where its sensible to, but it's a bit tricky to evaluate the code if we don't have a concrete idea of the kind of situation in which the new code should be better (and in which situations it might be worse). > The current version gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); > ```; > ; > The proposed modification gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); > ```; >; > This is a better result than the one obtained with the current version. I can't see any difference between the old and new results other than that the floating point numbers are formatted a bit differently? Perhaps I am missing something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-988058511
https://github.com/qutip/qutip/pull/1275#issuecomment-988058511:87,Testability,test,tests,87,"> Here are some tests of the proposed modifications. Thank you! I actually meant ""unit tests"" -- as in, adding the tests to `qutip/tests/test_steadystate.py`. It's also not clear to me from your examples how we should see the difference. > This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different. I agree it would be good for the sparse and dense algorithms to align where its sensible to, but it's a bit tricky to evaluate the code if we don't have a concrete idea of the kind of situation in which the new code should be better (and in which situations it might be worse). > The current version gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); > ```; > ; > The proposed modification gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); > ```; >; > This is a better result than the one obtained with the current version. I can't see any difference between the old and new results other than that the floating point numbers are formatted a bit differently? Perhaps I am missing something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-988058511
https://github.com/qutip/qutip/pull/1275#issuecomment-988058511:115,Testability,test,tests,115,"> Here are some tests of the proposed modifications. Thank you! I actually meant ""unit tests"" -- as in, adding the tests to `qutip/tests/test_steadystate.py`. It's also not clear to me from your examples how we should see the difference. > This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different. I agree it would be good for the sparse and dense algorithms to align where its sensible to, but it's a bit tricky to evaluate the code if we don't have a concrete idea of the kind of situation in which the new code should be better (and in which situations it might be worse). > The current version gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); > ```; > ; > The proposed modification gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); > ```; >; > This is a better result than the one obtained with the current version. I can't see any difference between the old and new results other than that the floating point numbers are formatted a bit differently? Perhaps I am missing something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-988058511
https://github.com/qutip/qutip/pull/1275#issuecomment-988058511:131,Testability,test,tests,131,"> Here are some tests of the proposed modifications. Thank you! I actually meant ""unit tests"" -- as in, adding the tests to `qutip/tests/test_steadystate.py`. It's also not clear to me from your examples how we should see the difference. > This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different. I agree it would be good for the sparse and dense algorithms to align where its sensible to, but it's a bit tricky to evaluate the code if we don't have a concrete idea of the kind of situation in which the new code should be better (and in which situations it might be worse). > The current version gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); > ```; > ; > The proposed modification gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); > ```; >; > This is a better result than the one obtained with the current version. I can't see any difference between the old and new results other than that the floating point numbers are formatted a bit differently? Perhaps I am missing something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-988058511
https://github.com/qutip/qutip/pull/1275#issuecomment-988058511:173,Usability,clear,clear,173,"> Here are some tests of the proposed modifications. Thank you! I actually meant ""unit tests"" -- as in, adding the tests to `qutip/tests/test_steadystate.py`. It's also not clear to me from your examples how we should see the difference. > This may change the final steady state in some circumstances, but I could not rapidly find a situation where this is actually important. In this example, the two steady states are the same even though the weights are very different. I agree it would be good for the sparse and dense algorithms to align where its sensible to, but it's a bit tricky to evaluate the code if we don't have a concrete idea of the kind of situation in which the new code should be better (and in which situations it might be worse). > The current version gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] = np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([0.+0.j, 0.-0.j, 0.-0.j, 1.+0.j]); > ```; > ; > The proposed modification gives:; > ; > ```; > Ldense = L.data.todense(); > Ldense[0, :] += np.diag(weight*np.ones(n)).reshape((1, n ** 2)); > np.linalg.solve(Ldense, b); > >> array([1.e-16+0.j, 0.e+00-0.j, 0.e+00-0.j, 1.e+00+0.j]); > ```; >; > This is a better result than the one obtained with the current version. I can't see any difference between the old and new results other than that the floating point numbers are formatted a bit differently? Perhaps I am missing something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-988058511
https://github.com/qutip/qutip/pull/1275#issuecomment-1034827718:98,Testability,test,tests,98,I've reimplemented this in #1802 rather than attempting to resolve conflicts in this PR and added tests there.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1275#issuecomment-1034827718
https://github.com/qutip/qutip/issues/1278#issuecomment-650581583:75,Usability,guid,guide,75,"New on 2020-06-27. You can follow the development of the QuTiP developers' guide in my repo: https://github.com/jakelishman/qutip-devguide, or more usefully see the rendered version on that repo's GH page: https://jakelishman.github.io/qutip-devguide.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1278#issuecomment-650581583
https://github.com/qutip/qutip/issues/1281#issuecomment-638108837:81,Usability,clear,clear,81,"I agree that on top level, these may seldom be used. It is not straightforwardly clear what is the added value of removing them, if no one is complaining or they are not hard to maintain. It may make things cleaner, but I am not aware of the implications. `eseries` seems used in the correlation module, possibly (marginally) also in `expect`. . If QobjEvo is a more modern way of applying`essolve`, that is fine with me, it would be nice to restructure it that way. My advice before switching to QobjEvo, is that its use be first well documented in the documentation's Users guide, which could be done by copy-pasting chunks from the notebook.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1281#issuecomment-638108837
https://github.com/qutip/qutip/issues/1281#issuecomment-638108837:576,Usability,guid,guide,576,"I agree that on top level, these may seldom be used. It is not straightforwardly clear what is the added value of removing them, if no one is complaining or they are not hard to maintain. It may make things cleaner, but I am not aware of the implications. `eseries` seems used in the correlation module, possibly (marginally) also in `expect`. . If QobjEvo is a more modern way of applying`essolve`, that is fine with me, it would be nice to restructure it that way. My advice before switching to QobjEvo, is that its use be first well documented in the documentation's Users guide, which could be done by copy-pasting chunks from the notebook.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1281#issuecomment-638108837
https://github.com/qutip/qutip/issues/1281#issuecomment-638112689:755,Usability,simpl,simple,755,"`eseries` isn't really used by `correlation`, it's just a possible solver, and `expect` doesn't use it, it just currently has to support it. Removing `eseries` would involve just removing that part of the solver. `essolve` only functions with time-independent Hamiltonians anyway, and `QobjEvo` can represent a full superset of `eseries` operations, and is an awful lot faster at it too. I agree that the documentation can definitely be improved - I'll be working on that later on in the project. No-one's complaining about the difficult of maintaining them, because nobody _is_ maintaining them. `eseries` hasn't been meaningfully touched since 2014, and there's been an issue recently (#1262) where somebody pointed out that `essolve` doesn't do really simple parts of its spec.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1281#issuecomment-638112689
https://github.com/qutip/qutip/pull/1282#issuecomment-638485105:339,Usability,simpl,simple,339,"Good work. ; Removing pxi is great. This was really old cython. I would have put solvers in core since the core usage of qutip is evolution of quantum systems. But I am thinking more in what would stay in the main package and what would become spin-off (qip, control). . The OpenMP check seems too complicated for something that should be simple. I would like to remove the need of this flag. But for now, if you set it in the `__init__` of `core` instead of `qutip`, could you then not use the `try` as before?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638485105
https://github.com/qutip/qutip/pull/1282#issuecomment-638730654:825,Integrability,depend,dependencies,825,"Solvers: absolutely the solvers should always be packaged with the main `qutip`. I had sort of envisaged that we'd put them in a `solve` package, which would be exported into the main namespace just like `core` is. This way is more just for greater separation, so that the full core isn't entangled with the solvers themselves - I think separating them like this will help us ensure that we specify the data layer API much more cleanly if the solvers aren't referenced within it. (i.e. there's no reference to any solver within `core`, but the API is built sufficiently cleanly that they can still access all the internals). OpenMP check: I think there's two neater ways:; 1. perhaps `settings` should just be in `core` too? I avoided putting the check in `core/__init__.py` because I'm really trying to avoid bi-directional dependencies between the packages, but moving `settings.py` into `core` would solve that.; 2. alternatively, we could just write `settings.py` as part of `setup.py` - determine whether we built against OpenMP/MKL at compile-time, and then just write it in? We can still choose whether or not to use it in various runtime situations. As for the current test - yeah, the comparative complexity is kind of indicative that this isn't the right way to do it. It's a relatively straightforward use of `importlib`, but still it's more difficult. (By the way: are you and @ajgpitch getting notified when I post in [the discussion board](https://github.com/orgs/qutip/teams/data-layer-devs)?)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638730654
https://github.com/qutip/qutip/pull/1282#issuecomment-638730654:727,Safety,avoid,avoided,727,"Solvers: absolutely the solvers should always be packaged with the main `qutip`. I had sort of envisaged that we'd put them in a `solve` package, which would be exported into the main namespace just like `core` is. This way is more just for greater separation, so that the full core isn't entangled with the solvers themselves - I think separating them like this will help us ensure that we specify the data layer API much more cleanly if the solvers aren't referenced within it. (i.e. there's no reference to any solver within `core`, but the API is built sufficiently cleanly that they can still access all the internals). OpenMP check: I think there's two neater ways:; 1. perhaps `settings` should just be in `core` too? I avoided putting the check in `core/__init__.py` because I'm really trying to avoid bi-directional dependencies between the packages, but moving `settings.py` into `core` would solve that.; 2. alternatively, we could just write `settings.py` as part of `setup.py` - determine whether we built against OpenMP/MKL at compile-time, and then just write it in? We can still choose whether or not to use it in various runtime situations. As for the current test - yeah, the comparative complexity is kind of indicative that this isn't the right way to do it. It's a relatively straightforward use of `importlib`, but still it's more difficult. (By the way: are you and @ajgpitch getting notified when I post in [the discussion board](https://github.com/orgs/qutip/teams/data-layer-devs)?)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638730654
https://github.com/qutip/qutip/pull/1282#issuecomment-638730654:804,Safety,avoid,avoid,804,"Solvers: absolutely the solvers should always be packaged with the main `qutip`. I had sort of envisaged that we'd put them in a `solve` package, which would be exported into the main namespace just like `core` is. This way is more just for greater separation, so that the full core isn't entangled with the solvers themselves - I think separating them like this will help us ensure that we specify the data layer API much more cleanly if the solvers aren't referenced within it. (i.e. there's no reference to any solver within `core`, but the API is built sufficiently cleanly that they can still access all the internals). OpenMP check: I think there's two neater ways:; 1. perhaps `settings` should just be in `core` too? I avoided putting the check in `core/__init__.py` because I'm really trying to avoid bi-directional dependencies between the packages, but moving `settings.py` into `core` would solve that.; 2. alternatively, we could just write `settings.py` as part of `setup.py` - determine whether we built against OpenMP/MKL at compile-time, and then just write it in? We can still choose whether or not to use it in various runtime situations. As for the current test - yeah, the comparative complexity is kind of indicative that this isn't the right way to do it. It's a relatively straightforward use of `importlib`, but still it's more difficult. (By the way: are you and @ajgpitch getting notified when I post in [the discussion board](https://github.com/orgs/qutip/teams/data-layer-devs)?)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638730654
https://github.com/qutip/qutip/pull/1282#issuecomment-638730654:598,Security,access,access,598,"Solvers: absolutely the solvers should always be packaged with the main `qutip`. I had sort of envisaged that we'd put them in a `solve` package, which would be exported into the main namespace just like `core` is. This way is more just for greater separation, so that the full core isn't entangled with the solvers themselves - I think separating them like this will help us ensure that we specify the data layer API much more cleanly if the solvers aren't referenced within it. (i.e. there's no reference to any solver within `core`, but the API is built sufficiently cleanly that they can still access all the internals). OpenMP check: I think there's two neater ways:; 1. perhaps `settings` should just be in `core` too? I avoided putting the check in `core/__init__.py` because I'm really trying to avoid bi-directional dependencies between the packages, but moving `settings.py` into `core` would solve that.; 2. alternatively, we could just write `settings.py` as part of `setup.py` - determine whether we built against OpenMP/MKL at compile-time, and then just write it in? We can still choose whether or not to use it in various runtime situations. As for the current test - yeah, the comparative complexity is kind of indicative that this isn't the right way to do it. It's a relatively straightforward use of `importlib`, but still it's more difficult. (By the way: are you and @ajgpitch getting notified when I post in [the discussion board](https://github.com/orgs/qutip/teams/data-layer-devs)?)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638730654
https://github.com/qutip/qutip/pull/1282#issuecomment-638730654:1177,Testability,test,test,1177,"Solvers: absolutely the solvers should always be packaged with the main `qutip`. I had sort of envisaged that we'd put them in a `solve` package, which would be exported into the main namespace just like `core` is. This way is more just for greater separation, so that the full core isn't entangled with the solvers themselves - I think separating them like this will help us ensure that we specify the data layer API much more cleanly if the solvers aren't referenced within it. (i.e. there's no reference to any solver within `core`, but the API is built sufficiently cleanly that they can still access all the internals). OpenMP check: I think there's two neater ways:; 1. perhaps `settings` should just be in `core` too? I avoided putting the check in `core/__init__.py` because I'm really trying to avoid bi-directional dependencies between the packages, but moving `settings.py` into `core` would solve that.; 2. alternatively, we could just write `settings.py` as part of `setup.py` - determine whether we built against OpenMP/MKL at compile-time, and then just write it in? We can still choose whether or not to use it in various runtime situations. As for the current test - yeah, the comparative complexity is kind of indicative that this isn't the right way to do it. It's a relatively straightforward use of `importlib`, but still it's more difficult. (By the way: are you and @ajgpitch getting notified when I post in [the discussion board](https://github.com/orgs/qutip/teams/data-layer-devs)?)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638730654
https://github.com/qutip/qutip/pull/1282#issuecomment-638966604:41,Deployability,install,install,41,"I prefer 2 in for openmp, it is fixed at install. It could be in `setup.py` or in a cython file with conditional compilation. The mkl flag depends on numpy's blas python interface. Cython use of blas/lapack is independent of it. . (Yes, since this week, I did not know this existed before)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638966604
https://github.com/qutip/qutip/pull/1282#issuecomment-638966604:139,Integrability,depend,depends,139,"I prefer 2 in for openmp, it is fixed at install. It could be in `setup.py` or in a cython file with conditional compilation. The mkl flag depends on numpy's blas python interface. Cython use of blas/lapack is independent of it. . (Yes, since this week, I did not know this existed before)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638966604
https://github.com/qutip/qutip/pull/1282#issuecomment-638966604:170,Integrability,interface,interface,170,"I prefer 2 in for openmp, it is fixed at install. It could be in `setup.py` or in a cython file with conditional compilation. The mkl flag depends on numpy's blas python interface. Cython use of blas/lapack is independent of it. . (Yes, since this week, I did not know this existed before)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1282#issuecomment-638966604
https://github.com/qutip/qutip/issues/1285#issuecomment-643272712:106,Availability,Ping,Pinging,106,"I think the current behaviour is fine, it just depends on the way the kronecker product is done in QuTiP. Pinging @nwlambert.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643272712
https://github.com/qutip/qutip/issues/1285#issuecomment-643272712:47,Integrability,depend,depends,47,"I think the current behaviour is fine, it just depends on the way the kronecker product is done in QuTiP. Pinging @nwlambert.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643272712
https://github.com/qutip/qutip/issues/1285#issuecomment-643295362:254,Usability,guid,guide,254,"i think this difference comes because, if you look at equation A1 in Fabrizio's paper you linked, they do a row-ordering convention in turning states into vectors. Qutip does a column ordering convention, as described here ; http://qutip.org/docs/latest/guide/guide-states.html#superoperators-and-vectorized-operators. this is an arbitrary choice, as long as you do it consistently with the definition of states and superoperators. This means in our case -i[H, rho] gives -i[spre(H) -spost(H)] == -i zcsr_kron(spI, H.data) + 1j * zcsr_kron(Ht, spI). . i think row ordering is more intuitive, but column ordering is what we do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643295362
https://github.com/qutip/qutip/issues/1285#issuecomment-643295362:260,Usability,guid,guide-states,260,"i think this difference comes because, if you look at equation A1 in Fabrizio's paper you linked, they do a row-ordering convention in turning states into vectors. Qutip does a column ordering convention, as described here ; http://qutip.org/docs/latest/guide/guide-states.html#superoperators-and-vectorized-operators. this is an arbitrary choice, as long as you do it consistently with the definition of states and superoperators. This means in our case -i[H, rho] gives -i[spre(H) -spost(H)] == -i zcsr_kron(spI, H.data) + 1j * zcsr_kron(Ht, spI). . i think row ordering is more intuitive, but column ordering is what we do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643295362
https://github.com/qutip/qutip/issues/1285#issuecomment-643295362:581,Usability,intuit,intuitive,581,"i think this difference comes because, if you look at equation A1 in Fabrizio's paper you linked, they do a row-ordering convention in turning states into vectors. Qutip does a column ordering convention, as described here ; http://qutip.org/docs/latest/guide/guide-states.html#superoperators-and-vectorized-operators. this is an arbitrary choice, as long as you do it consistently with the definition of states and superoperators. This means in our case -i[H, rho] gives -i[spre(H) -spost(H)] == -i zcsr_kron(spI, H.data) + 1j * zcsr_kron(Ht, spI). . i think row ordering is more intuitive, but column ordering is what we do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643295362
https://github.com/qutip/qutip/issues/1285#issuecomment-643321875:197,Energy Efficiency,power,powerful,197,"Indeed you are right, it turns out to be a matter of convention and everything is correct (`spre`, `spost`, `lindblad_dissipator`). For multiple superoperators, I prefer using numpy because of its powerful broadcasting support. Hopefully, this discussion will help anyone else facing a similar situation. Keep doing great!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1285#issuecomment-643321875
https://github.com/qutip/qutip/issues/1287#issuecomment-1066956078:216,Usability,simpl,simple,216,"Hi! I'm working on this issue and was wondering if the alpha value should be an array-like that would apply to each point or vector individually, similarly to the color option I've seen in dev.major, or make it more simple. Where a single value would apply to all the rendered vectors or points in their add method.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1287#issuecomment-1066956078
https://github.com/qutip/qutip/issues/1287#issuecomment-1066987120:90,Usability,simpl,simple,90,I personally would be actually a bit confused if the alpha values were array-like and the simple solution would certainly be enough for me. But then again I do not have the very big picture of `qutip`.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1287#issuecomment-1066987120
https://github.com/qutip/qutip/pull/1288#issuecomment-649533541:45,Testability,test,test,45,May not be needed anymore with scipy 1.5? To test more before merging (#1299 ),MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1288#issuecomment-649533541
https://github.com/qutip/qutip/pull/1288#issuecomment-649793403:79,Availability,avail,available,79,"While this isn't an alternative for this PR, scipy 1.5 made new LAPACK drivers available for `scipy.linalg.eigh`, one or more of which might not have the same problems in OpenBLAS on Mac. Still, we can't require scipy 1.5 when that only released like 5 days ago, but it's interesting going forwards.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1288#issuecomment-649793403
https://github.com/qutip/qutip/pull/1288#issuecomment-649793403:237,Deployability,release,released,237,"While this isn't an alternative for this PR, scipy 1.5 made new LAPACK drivers available for `scipy.linalg.eigh`, one or more of which might not have the same problems in OpenBLAS on Mac. Still, we can't require scipy 1.5 when that only released like 5 days ago, but it's interesting going forwards.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1288#issuecomment-649793403
https://github.com/qutip/qutip/pull/1289#issuecomment-779252394:111,Modifiability,variab,variable,111,"@jakelishman, Equivalent change but with different implementation have been made in `dev.,major`. Here setting variable are directly in the module, but in v5 they are in a `Settings` object. Adding the object was a big change for major.; Maybe cherry-picky commits from master to `dev-major` would be easier.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1289#issuecomment-779252394
https://github.com/qutip/qutip/pull/1289#issuecomment-779255284:370,Testability,Log,Logically,370,"Perfect, that's what I thought thanks. `git cherry-pick` isn't a good choice for merging, because it creates new commit objects. Doing that means we never explicitly told git how the two implementations should be picked going forwards, and so any additional changes on `dev.major` _also_ could never be merged in, because they'd have different commits as their parents. Logically it's a merge operation and this is a ""true"" merge conflict, so the right thing to do is to tell git how to solve the conflict. I've already got a fixed merge all ready to go - once we've got #1440 merged I'll make the PR up, so `dev.major` is once again completely ahead of `master`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1289#issuecomment-779255284
https://github.com/qutip/qutip/pull/1289#issuecomment-779258918:127,Deployability,release,release,127,"tbh, the only real use-case for `git cherry-pick` is to backport single bug-fix commits from `master` onto an already existing release branch without merging in additional feature commits. Since `dev.major` is intended to _include_ all of `master` (and `master` will eventually point to the `dev.major` tip), we shouldn't cherry pick from one to the other, but merge all changes. Having both #1289 and #1337 is effectively the same as having cherry-picked the feature onto both branches already, which is why the merge is now a bit tricky. That's not a problem at all (with how we developed it, it's the correct thing to do), it just means that when I joined them back together, I just merged this bit with the (logical - I did it all in one go) strategy `--ours` to tell `git` to keep the `dev.major` version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1289#issuecomment-779258918
https://github.com/qutip/qutip/pull/1289#issuecomment-779258918:712,Testability,log,logical,712,"tbh, the only real use-case for `git cherry-pick` is to backport single bug-fix commits from `master` onto an already existing release branch without merging in additional feature commits. Since `dev.major` is intended to _include_ all of `master` (and `master` will eventually point to the `dev.major` tip), we shouldn't cherry pick from one to the other, but merge all changes. Having both #1289 and #1337 is effectively the same as having cherry-picked the feature onto both branches already, which is why the merge is now a bit tricky. That's not a problem at all (with how we developed it, it's the correct thing to do), it just means that when I joined them back together, I just merged this bit with the (logical - I did it all in one go) strategy `--ours` to tell `git` to keep the `dev.major` version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1289#issuecomment-779258918
https://github.com/qutip/qutip/pull/1291#issuecomment-645411323:63,Testability,test,tests,63,"@sarsid thank you for the detailed description of the PR. Some tests are failing at [` TestQubitCircuit.test_user_gate`](https://travis-ci.org/github/qutip/qutip/jobs/699177830#L3017), ""NameError: name 'isfunction' is not defined"". . This is still in draft mode, however I wonder whether you think it makes sense to provide the user the option to choose from OpenQasm 2.0 and Qasm, with the same function, e.g., `read_qasm`, but with an attribute. . This is a draft, but please remember to add Numpy docstrings to functions. . It would be great to have read/write capabilities with QASM, looking forward to this PR.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-645411323
https://github.com/qutip/qutip/pull/1291#issuecomment-645411323:87,Testability,Test,TestQubitCircuit,87,"@sarsid thank you for the detailed description of the PR. Some tests are failing at [` TestQubitCircuit.test_user_gate`](https://travis-ci.org/github/qutip/qutip/jobs/699177830#L3017), ""NameError: name 'isfunction' is not defined"". . This is still in draft mode, however I wonder whether you think it makes sense to provide the user the option to choose from OpenQasm 2.0 and Qasm, with the same function, e.g., `read_qasm`, but with an attribute. . This is a draft, but please remember to add Numpy docstrings to functions. . It would be great to have read/write capabilities with QASM, looking forward to this PR.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-645411323
https://github.com/qutip/qutip/pull/1291#issuecomment-650486135:0,Deployability,Update,Update,0,"Update : Most of the functionality is now there, except `measure` and conditional statements, I hope to add those after we are done merging the measurement PR. @nathanshammah I was wondering if writing to QASM should be a separate PR or the same one ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-650486135
https://github.com/qutip/qutip/pull/1291#issuecomment-650556880:120,Deployability,Update,Update,120,"Thank you Sidhant. Id split it up. On Sat, 27 Jun 2020 at 06:07, Sidhant Saraogi <notifications@github.com>; wrote:. > Update : Most of the functionality is now there, except measure and; > conditional statements, I hope to add those after we are done merging the; > measurement PR. @nathanshammah <https://github.com/nathanshammah> I was; > wondering if writing to QASM should be a separate PR or the same one ?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/pull/1291#issuecomment-650486135>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADPF67AEYTRJEAW23HB3JLDRYVV7LANCNFSM4OAG5ZOA>; > .; >; -- ; Dr. Nathan Shammah; www.nathanshammah.com",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-650556880
https://github.com/qutip/qutip/pull/1291#issuecomment-653818309:65,Testability,test,tests,65,"> @sarsid thank you for the detailed description of the PR. Some tests are failing at [` TestQubitCircuit.test_user_gate`](https://travis-ci.org/github/qutip/qutip/jobs/699177830#L3017), ""NameError: name 'isfunction' is not defined"".; > ; > This is still in draft mode, however I wonder whether you think it makes sense to provide the user the option to choose from OpenQasm 2.0 and Qasm, with the same function, e.g., `read_qasm`, but with an attribute.; > ; > This is a draft, but please remember to add Numpy docstrings to functions.; > ; > It would be great to have read/write capabilities with QASM, looking forward to this PR. @nathanshammah I was wondering if functions only meant for internal class use should have returns and parameters specified?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-653818309
https://github.com/qutip/qutip/pull/1291#issuecomment-653818309:89,Testability,Test,TestQubitCircuit,89,"> @sarsid thank you for the detailed description of the PR. Some tests are failing at [` TestQubitCircuit.test_user_gate`](https://travis-ci.org/github/qutip/qutip/jobs/699177830#L3017), ""NameError: name 'isfunction' is not defined"".; > ; > This is still in draft mode, however I wonder whether you think it makes sense to provide the user the option to choose from OpenQasm 2.0 and Qasm, with the same function, e.g., `read_qasm`, but with an attribute.; > ; > This is a draft, but please remember to add Numpy docstrings to functions.; > ; > It would be great to have read/write capabilities with QASM, looking forward to this PR. @nathanshammah I was wondering if functions only meant for internal class use should have returns and parameters specified?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-653818309
https://github.com/qutip/qutip/pull/1291#issuecomment-655893373:272,Availability,avail,available,272,"I am trying to add some `.qasm` files to the folder `qutip/qutip/tests/qasm_files/` to use during test time. I thought it would be enough to add them to the `PACKAGE_DATA` variable in `setup.py` but that does not seem to work. Any ideas on how to make sure this folder is available during testing time? Beside this part, the PR is ready for review. @nathanshammah @BoxiLi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655893373
https://github.com/qutip/qutip/pull/1291#issuecomment-655893373:172,Modifiability,variab,variable,172,"I am trying to add some `.qasm` files to the folder `qutip/qutip/tests/qasm_files/` to use during test time. I thought it would be enough to add them to the `PACKAGE_DATA` variable in `setup.py` but that does not seem to work. Any ideas on how to make sure this folder is available during testing time? Beside this part, the PR is ready for review. @nathanshammah @BoxiLi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655893373
https://github.com/qutip/qutip/pull/1291#issuecomment-655893373:65,Testability,test,tests,65,"I am trying to add some `.qasm` files to the folder `qutip/qutip/tests/qasm_files/` to use during test time. I thought it would be enough to add them to the `PACKAGE_DATA` variable in `setup.py` but that does not seem to work. Any ideas on how to make sure this folder is available during testing time? Beside this part, the PR is ready for review. @nathanshammah @BoxiLi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655893373
https://github.com/qutip/qutip/pull/1291#issuecomment-655893373:98,Testability,test,test,98,"I am trying to add some `.qasm` files to the folder `qutip/qutip/tests/qasm_files/` to use during test time. I thought it would be enough to add them to the `PACKAGE_DATA` variable in `setup.py` but that does not seem to work. Any ideas on how to make sure this folder is available during testing time? Beside this part, the PR is ready for review. @nathanshammah @BoxiLi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655893373
https://github.com/qutip/qutip/pull/1291#issuecomment-655893373:289,Testability,test,testing,289,"I am trying to add some `.qasm` files to the folder `qutip/qutip/tests/qasm_files/` to use during test time. I thought it would be enough to add them to the `PACKAGE_DATA` variable in `setup.py` but that does not seem to work. Any ideas on how to make sure this folder is available during testing time? Beside this part, the PR is ready for review. @nathanshammah @BoxiLi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655893373
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:346,Deployability,integrat,integrate-unit-tests-for-file-parsing-with-pytest,346,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:346,Integrability,integrat,integrate-unit-tests-for-file-parsing-with-pytest,346,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:236,Performance,load,loading,236,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:259,Security,access,accessibility,259,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:198,Testability,test,test-data,198,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-655970508:361,Testability,test,tests-for-file-parsing-with-pytest,361,"I think it should be possible to do this within the pytest framework without touching the package `setup.py` or `MANIFEST`. [`pytest.fixture`](https://docs.pytest.org/en/stable/fixture.html#sharing-test-data) seems a natural choice for loading data. For file accessibility, [this](https://stackoverflow.com/questions/46019170/how-do-you-properly-integrate-unit-tests-for-file-parsing-with-pytest) might help. Porbably @jakelishman knows more about the natural way of doing this with pytest?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-655970508
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:900,Availability,down,down,900,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:592,Deployability,install,installs,592,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:719,Deployability,install,install,719,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:36,Safety,avoid,avoid,36,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:115,Testability,test,test,115,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:343,Testability,test,tests,343,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:410,Testability,test,tests,410,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:692,Testability,test,tests,692,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:1027,Testability,test,test,1027,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:1050,Testability,test,testing,1050,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:1202,Testability,test,tests,1202,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656255156:1270,Testability,test,test,1270,"As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one. I don't think there's a problem distributing files as part of the tests. You can add a line which says; ```; recursive-include qutip/tests/qasm_files *.qasm; ```; to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest. Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see. Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656255156
https://github.com/qutip/qutip/pull/1291#issuecomment-656382945:78,Deployability,update,update,78,The conflict is just because that trailing white space PR got merged. You can update from qutip master and resolve it locally. No worries.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656382945
https://github.com/qutip/qutip/pull/1291#issuecomment-656389392:80,Deployability,update,update,80,"> The conflict is just because that trailing white space PR got merged. You can update from qutip master and resolve it locally. No worries. I don't think it is that @BoxiLi, I need to change the manifest as per @jakelishman's comments to include the qasm_files folder. Is there a different way to do this? . edit: oops, I did the rebase, I think you were right!!!! Apologies",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656389392
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:932,Availability,down,down,932,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:617,Deployability,install,installs,617,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:744,Deployability,install,install,744,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:38,Safety,avoid,avoid,38,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:117,Testability,test,test,117,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:352,Testability,test,tests,352,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:427,Testability,test,tests,427,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:717,Testability,test,tests,717,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:1059,Testability,test,test,1059,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:1082,Testability,test,testing,1082,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:1234,Testability,test,tests,1234,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:1309,Testability,test,test,1309,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/pull/1291#issuecomment-656450639:1841,Testability,test,tests,1841,"> As I understand it, the only way to avoid needing to touch `MANIFEST.in` is to not have files distributed with the test suite (or to have the temporary files by `*.py`, since `setup.py` automatically recognises them). That's not really a pytest thing, it's a `setuptools` one.; > ; > I don't think there's a problem distributing files as part of the tests. You can add a line which says; > ; > ```; > recursive-include qutip/tests/qasm_files *.qasm; > ```; > ; > to `MANIFEST.in`, and that should hopefully fix the problem. You won't have the problem locally, because you'll be running `./setup.py develop`, which ""installs"" in-place, so you don't notice the fact that you've missed files from the manifest. In the tests, it runs `./setup.py install`, which does the copy, missing files which aren't in the manifest.; > ; > Boxi: I'm not certain what more you'd like to do with fixtures here. Fixtures are good for setup and tear down, parametrisation and sharing resources (like network connections), but I'm not certain what further benefit you get for a test function which is testing whether it can open a known file, read it, and construct the expected output. I think Sidhant is already doing some nice parametrisation of his tests, from what I see.; > ; > Sidhant: I added a comment on the exception test, since pytest gives us an easier-to-read context manager you can use. It's also typically better practice to handle file paths like I did in that (using the overloaded `/` operator with `pathlib.Path`, or `os.path.join`) rather than manually putting in slashes. Windows _usually_ will do the right thing now with slashes, but it's better to let Python handle it for us. Thanks for this information, it seems to work ! I was wondering if the following statement is still needed (at all) in `PACKAGE_DATA` in setup.py? ; `'qutip/tests/qasm_files': ['*.qasm'],`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1291#issuecomment-656450639
https://github.com/qutip/qutip/issues/1292#issuecomment-654410345:419,Testability,test,tested,419,"Hey, I tired solving this issue. I changed the add_vectors method such that it takes in an optional argument called 'color'. I created a dictionary called vector_color_specified which stores the vector-index and color as key-value pair. Then when plot_vectors is called, the color is taken from the dictionary if mentioned, otherwise the default value is used based on the cyclic color list which is already present. I tested my code and it works as you have mentioned above. So, is my approach right? Any advice would be helpful. This is the first open-source issue that I have taken up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1292#issuecomment-654410345
https://github.com/qutip/qutip/issues/1292#issuecomment-655742038:227,Usability,guid,guiding,227,"Hi @rajathshetty20, Thanks for the interest. What you described sounds good. Would you like to make a Pull Request? You can go to the Pull Requests page and create one from a branch of your repository. There will be a template guiding you once you choose a branch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1292#issuecomment-655742038
https://github.com/qutip/qutip/issues/1293#issuecomment-645272426:335,Availability,down,down,335,"The scipy Laguerre polynomial will be very inefficient for constructing the entries because it's linear in various inputs, and we need a quadratic number of entries for it, so it ends up being cubic. I have some code for an old project of mine which calculates them all as a nice recurrence relation though, which cuts the timing back down to quadratic. There was an issue on the Google groups recently about something similar: https://groups.google.com/forum/#!topic/qutip/ZtOiO7e9zNk, though the code I supplied there doesn't save the actual recurrence terms, so it would still be cubic (and I'm pretty sure there's still a complex number sign-error bug in it still, because I didn't take very much care when I did it...). You have to be careful, though, because constructing the displacement operator that way will result in an operator which is not unitary for any truncated subspace.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645272426
https://github.com/qutip/qutip/issues/1293#issuecomment-645272426:646,Availability,error,error,646,"The scipy Laguerre polynomial will be very inefficient for constructing the entries because it's linear in various inputs, and we need a quadratic number of entries for it, so it ends up being cubic. I have some code for an old project of mine which calculates them all as a nice recurrence relation though, which cuts the timing back down to quadratic. There was an issue on the Google groups recently about something similar: https://groups.google.com/forum/#!topic/qutip/ZtOiO7e9zNk, though the code I supplied there doesn't save the actual recurrence terms, so it would still be cubic (and I'm pretty sure there's still a complex number sign-error bug in it still, because I didn't take very much care when I did it...). You have to be careful, though, because constructing the displacement operator that way will result in an operator which is not unitary for any truncated subspace.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645272426
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:2015,Availability,toler,tolerance,2015,"st sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a totally fair test, and simply replicate the full functionality of `qutip.displace` (including creating a `Qobj` at the end), my method is ~4x faster on small matrices (`1 <= dim <= 20`) and it only goes up from there (I found it's about ~10x faster at `dim = 1000`, and beyond that `qutip.displace` is too slow to bother). If I store the calculation of the eigensystem, and output an `ndarray` instead of converting to `csr_matrix` (and so don't produce a `Qobj`), then I find speed ups in getting the operator for a new `alpha` as ~100x for small matr",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:225,Energy Efficiency,efficient,efficient,225,"I was just thinking about this again and came up with a good speed up for the truncated Hilbert space. I can't think of any method to get analytic closed-form solutions for the truncated space, though, so this is just a more efficient numerical method. First we take the generator of the displacement operator `G`, such that `exp(G)` is the displacement operator we're looking for. `G` is anti-Hermitian, and so it shares its eigensystem (up to scaling of the eigenvalues) with the Hermitian `i G` and consequently is diagonalised by a unitary formed of its eigenvectors. Now `S = i G / abs(alpha)` is a tridiagonal Hermitian, and with a similarity transformation we can find a _real-symmetric_ tridiagonal `T = P^-1 . S . P` for some diagonal unitary `P` (which is easy to calculate). The reason for scaling out `alpha` here should become clear at the end. The main diagonal of `T` is all zeros, and the first sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equival",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:1353,Integrability,wrap,wrapped,1353,"rator we're looking for. `G` is anti-Hermitian, and so it shares its eigensystem (up to scaling of the eigenvalues) with the Hermitian `i G` and consequently is diagonalised by a unitary formed of its eigenvectors. Now `S = i G / abs(alpha)` is a tridiagonal Hermitian, and with a similarity transformation we can find a _real-symmetric_ tridiagonal `T = P^-1 . S . P` for some diagonal unitary `P` (which is easy to calculate). The reason for scaling out `alpha` here should become clear at the end. The main diagonal of `T` is all zeros, and the first sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:1361,Security,access,access,1361,"rator we're looking for. `G` is anti-Hermitian, and so it shares its eigensystem (up to scaling of the eigenvalues) with the Hermitian `i G` and consequently is diagonalised by a unitary formed of its eigenvectors. Now `S = i G / abs(alpha)` is a tridiagonal Hermitian, and with a similarity transformation we can find a _real-symmetric_ tridiagonal `T = P^-1 . S . P` for some diagonal unitary `P` (which is easy to calculate). The reason for scaling out `alpha` here should become clear at the end. The main diagonal of `T` is all zeros, and the first sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:2369,Testability,test,test,2369,"y.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a totally fair test, and simply replicate the full functionality of `qutip.displace` (including creating a `Qobj` at the end), my method is ~4x faster on small matrices (`1 <= dim <= 20`) and it only goes up from there (I found it's about ~10x faster at `dim = 1000`, and beyond that `qutip.displace` is too slow to bother). If I store the calculation of the eigensystem, and output an `ndarray` instead of converting to `csr_matrix` (and so don't produce a `Qobj`), then I find speed ups in getting the operator for a new `alpha` as ~100x for small matrices and ~25x for large ones. The larger a matrix is, the more the computational time is dominated by the dense dot product at the end. Code:; ```python; class Displacer:; def __init__(self, n):; # The off-diagonal of the real-symmetric similar matrix T.; sym = (2*(np.arange(1, n)%2) - 1) * np.sqrt(np.arange(1, n)); # Solve the eigensystem.; self.evals, self.evecs = scipy.linalg.eigh_tridiagonal(np.zeros(n), sym); self.range = np.arange(n); self.t_scale = 1j**(self.range % ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:840,Usability,clear,clear,840,"I was just thinking about this again and came up with a good speed up for the truncated Hilbert space. I can't think of any method to get analytic closed-form solutions for the truncated space, though, so this is just a more efficient numerical method. First we take the generator of the displacement operator `G`, such that `exp(G)` is the displacement operator we're looking for. `G` is anti-Hermitian, and so it shares its eigensystem (up to scaling of the eigenvalues) with the Hermitian `i G` and consequently is diagonalised by a unitary formed of its eigenvectors. Now `S = i G / abs(alpha)` is a tridiagonal Hermitian, and with a similarity transformation we can find a _real-symmetric_ tridiagonal `T = P^-1 . S . P` for some diagonal unitary `P` (which is easy to calculate). The reason for scaling out `alpha` here should become clear at the end. The main diagonal of `T` is all zeros, and the first sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equival",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:1894,Usability,simpl,simpler,1894,"st sub- and super-diagonals look like; ```[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]```; and the diagonal of `P` looks like; ```[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]```. Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. `?stemr`), which allow us to pass only the main diagonal and the first subdiagonal. Scipy provides convenient wrapped access in Python by `scipy.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a totally fair test, and simply replicate the full functionality of `qutip.displace` (including creating a `Qobj` at the end), my method is ~4x faster on small matrices (`1 <= dim <= 20`) and it only goes up from there (I found it's about ~10x faster at `dim = 1000`, and beyond that `qutip.displace` is too slow to bother). If I store the calculation of the eigensystem, and output an `ndarray` instead of converting to `csr_matrix` (and so don't produce a `Qobj`), then I find speed ups in getting the operator for a new `alpha` as ~100x for small matr",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645685030:2379,Usability,simpl,simply,2379,"y.linalg.eigh_tridiagonal`. This lets us get the full eigensystem of `T`, which is related to that of `G` by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by `P` to transform them into the correct basis. We now have a diagonalised matrix `G = Q^-1 . D . Q`, so `exp(G) = Q^-1 . exp(D) . Q`, which is now trivial because `D` is diagonal. Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14). Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out `alpha` at the start, so we can do a good chunk _without fixing alpha_. That means we can pay the computational cost only once at the start, and then get faster calculations from then on. If I make a totally fair test, and simply replicate the full functionality of `qutip.displace` (including creating a `Qobj` at the end), my method is ~4x faster on small matrices (`1 <= dim <= 20`) and it only goes up from there (I found it's about ~10x faster at `dim = 1000`, and beyond that `qutip.displace` is too slow to bother). If I store the calculation of the eigensystem, and output an `ndarray` instead of converting to `csr_matrix` (and so don't produce a `Qobj`), then I find speed ups in getting the operator for a new `alpha` as ~100x for small matrices and ~25x for large ones. The larger a matrix is, the more the computational time is dominated by the dense dot product at the end. Code:; ```python; class Displacer:; def __init__(self, n):; # The off-diagonal of the real-symmetric similar matrix T.; sym = (2*(np.arange(1, n)%2) - 1) * np.sqrt(np.arange(1, n)); # Solve the eigensystem.; self.evals, self.evecs = scipy.linalg.eigh_tridiagonal(np.zeros(n), sym); self.range = np.arange(n); self.t_scale = 1j**(self.range % ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645685030
https://github.com/qutip/qutip/issues/1293#issuecomment-645697111:81,Usability,usab,usable,81,"My GSoC project will end up meaning that dense matrices can be happily stored as usable data types within `Qobj`, so QuTiP won't have to pay the nonsensical dense-to-sparse penalty for this kind of extremely dense system any more.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-645697111
https://github.com/qutip/qutip/issues/1293#issuecomment-646090490:404,Integrability,rout,routines,404,"Thanks Jake this is brilliant. This conveniently lets us construct the displacement operator repeatedly for new alphas with the one-time cost incurred in the beginning to solve the eigenvector problem. I think if we fix the Hilbert space cutoff in the beginning of a calculation, this should be fine. Actually, the reason why my colleagues (and even myself) are interested in this is to let optimisation routines run on a series of displacement operations. I suppose now it will become easier to compute gradients wrt ""alpha"" using some automatic differentiation tool such as Jax which was previously kind of complicated : https://github.com/google/jax/pull/2062",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646090490
https://github.com/qutip/qutip/issues/1293#issuecomment-646100632:1281,Availability,error,error,1281,"For large matrices (`dim > ~500`), the dense matrix dot product is still a pretty large cost, but you're still saving a fair amount. That said, at that kind of dimension, the analytical formula may do you well enough. If you want derivatives wrt alpha, you should be able to get analytic ones from my method - there's no ""black box"" numerical work that goes on in `__call__`, everything is just matrix multiplication. Given that it appears non-linearly in a possibly large multiplication, though, and I would imagine the derivatives are pretty smooth, you may well just be faster just numerically approximating it with finite differences (I don't know anything about autodifferentiation). If you're so inclined, you can sacrifice some speed for higher accuracy in the eigenvector calculations, as we can find the eigenvalues semi-analytically. There are a few places in numpy and scipy that can find the roots of the Hermite polynomials for you (i.e. get the eigenvalues), which will be found exactly wrt double precision (I believe). You can then call out to the LAPACK routine `dstein` to get the eigenvectors from the eigenvalues. `dstein` is slower than `dstemr`/`dsteqr` (which is what scipy uses, I think), but it allows us to supply the eigenvalues, removing some numerical error. I didn't test that very thoroughly though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646100632
https://github.com/qutip/qutip/issues/1293#issuecomment-646100632:1071,Integrability,rout,routine,1071,"For large matrices (`dim > ~500`), the dense matrix dot product is still a pretty large cost, but you're still saving a fair amount. That said, at that kind of dimension, the analytical formula may do you well enough. If you want derivatives wrt alpha, you should be able to get analytic ones from my method - there's no ""black box"" numerical work that goes on in `__call__`, everything is just matrix multiplication. Given that it appears non-linearly in a possibly large multiplication, though, and I would imagine the derivatives are pretty smooth, you may well just be faster just numerically approximating it with finite differences (I don't know anything about autodifferentiation). If you're so inclined, you can sacrifice some speed for higher accuracy in the eigenvector calculations, as we can find the eigenvalues semi-analytically. There are a few places in numpy and scipy that can find the roots of the Hermite polynomials for you (i.e. get the eigenvalues), which will be found exactly wrt double precision (I believe). You can then call out to the LAPACK routine `dstein` to get the eigenvectors from the eigenvalues. `dstein` is slower than `dstemr`/`dsteqr` (which is what scipy uses, I think), but it allows us to supply the eigenvalues, removing some numerical error. I didn't test that very thoroughly though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646100632
https://github.com/qutip/qutip/issues/1293#issuecomment-646100632:1297,Testability,test,test,1297,"For large matrices (`dim > ~500`), the dense matrix dot product is still a pretty large cost, but you're still saving a fair amount. That said, at that kind of dimension, the analytical formula may do you well enough. If you want derivatives wrt alpha, you should be able to get analytic ones from my method - there's no ""black box"" numerical work that goes on in `__call__`, everything is just matrix multiplication. Given that it appears non-linearly in a possibly large multiplication, though, and I would imagine the derivatives are pretty smooth, you may well just be faster just numerically approximating it with finite differences (I don't know anything about autodifferentiation). If you're so inclined, you can sacrifice some speed for higher accuracy in the eigenvector calculations, as we can find the eigenvalues semi-analytically. There are a few places in numpy and scipy that can find the roots of the Hermite polynomials for you (i.e. get the eigenvalues), which will be found exactly wrt double precision (I believe). You can then call out to the LAPACK routine `dstein` to get the eigenvectors from the eigenvalues. `dstein` is slower than `dstemr`/`dsteqr` (which is what scipy uses, I think), but it allows us to supply the eigenvalues, removing some numerical error. I didn't test that very thoroughly though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646100632
https://github.com/qutip/qutip/issues/1293#issuecomment-646612460:833,Testability,assert,assert,833,"Thanks @jakelishman. I think for now we can use your method and move ahead. @araza6 would like to make a PR about this and probably we should link this discussion in the documentation and make you a co-author (https://medium.com/faun/how-to-give-credit-in-git-commits-ccd6485678c3). . A technical issue here is QuTiP mostly has function based API. This presents lots of problems when you want to re-use objects, e.g., in this displace function. I had proposed to slowly move to classes, eg., Solver class (https://github.com/qutip/qutip/pull/962). A possible implementation here would be making a fresh `Displace` class in `qutip.operators` which would work like this:. ```; import numpy as np. from qutip.operators import Displace, displace. N = 32; alpha = 1 + 1j. d = Displace(N=32); d_new = d(alpha); d_old = displace(N, alpha). assert (np.allclose(d_new.full() == d_old.full()); ```. @qutip/core-workers What do you think about making some class based operators?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646612460
https://github.com/qutip/qutip/issues/1293#issuecomment-646616290:29,Integrability,interface,interface,29,"I wouldn't fracture the user-interface like that, personally. Instead, make the `alpha` parameter in `qutip.displace` optional, such that `qutip.displace` now effectively supports partial application:. ```python; class _displace:; def __init__(self, n):; [same as before]; def __call__(self, alpha):; [same as before]. def displace(N, alpha=None):; out = _displace(N); return out if alpha is None else out(alpha); ```. Now there's a single entry point for the user, but you get all the same benefits as before. The user can now do `qutip.displace(100)` and get a reusable partially applied object, or do `qutip.displace(100, 0.5j)` if they only need the one number.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646616290
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:470,Integrability,interface,interface,470,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:819,Performance,bottleneck,bottleneck,819,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:1525,Security,access,access,1525,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:371,Usability,simpl,simple,371,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:610,Usability,simpl,simple,610,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646631332:1532,Usability,simpl,simple,1532,"I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a ""function"" at every stage. This kind of partial application is classic part of functional programming. Perhaps I don't understand _why_ you want to move to a class-based API? I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators. Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more ""Pythonic"". For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide ""should I use `displace` or `Displacer`?"", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain. A lot of operators have no meaningful reason to live in a class, like `sigmax` and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do; ```python; sx_builder = qutip.operators.SigmaX(); sx = sx_builder.get_operator(); sy_builder = qutip.operators.SigmaY(); sy = sy_builder.get_operator(); sz_builder = qutip.operators.SigmaZ(); sz = sz_builder.get_operator(); ```; when all they wanted was `qutip.sigmax(), qutip.sigmay(), qutip.sigmaz()`. Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?. All the operators already share a class in `Qobj`, and things like `displace` and `sigmax` are factory methods of `Qobj`. What shared functionality do the factory methods possess that means they should be classes?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646631332
https://github.com/qutip/qutip/issues/1293#issuecomment-646667559:323,Integrability,interface,interface,323,"Hi @jakelishman, I like your implementation but this will sometimes return a Qobj and other times a class instance when you call `displace()`. I am not in favour of that just out of the principle that functions should be simple and do one thing only as you also point out. . I would say if we do not want to break the user-interface, we keep the same implementation as `displace()` returning a `Qobj` (even if internally it calls the faster private `_Displace` method). . Users who want to use the class anyway can dig in and find `_Displace`. The use case here for moving to classes is rather specific and related to optimisation/control. We want to compute this operator very fast with multiple values of `alpha`, independently, on multiple cores (this was why we needed the faster implementation to run a GPU optimisation routine). Of course for sigmax(), or sigmay() we do not have any parameters to optimise and it is overkill to make them into classes. I do not suggest that at all. . I understand the inclination to be `functional`. It is how QuTiP was written and is supposed to be used, mostly. But one of the arguments for classes is that for some solvers, or operations we needed to re-use information, eg. qutip.piqs or the heom solvers where we had to make classes anyways. . I would propose just having a private `_Displace` method which is called by `displace` but not changing the output to be conditioned on `alpha`. Later on, if we incline a bit more towards classes we can make `Displace` public. Any other thoughts and opinions? @qutip/core-workers",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646667559
https://github.com/qutip/qutip/issues/1293#issuecomment-646667559:825,Integrability,rout,routine,825,"Hi @jakelishman, I like your implementation but this will sometimes return a Qobj and other times a class instance when you call `displace()`. I am not in favour of that just out of the principle that functions should be simple and do one thing only as you also point out. . I would say if we do not want to break the user-interface, we keep the same implementation as `displace()` returning a `Qobj` (even if internally it calls the faster private `_Displace` method). . Users who want to use the class anyway can dig in and find `_Displace`. The use case here for moving to classes is rather specific and related to optimisation/control. We want to compute this operator very fast with multiple values of `alpha`, independently, on multiple cores (this was why we needed the faster implementation to run a GPU optimisation routine). Of course for sigmax(), or sigmay() we do not have any parameters to optimise and it is overkill to make them into classes. I do not suggest that at all. . I understand the inclination to be `functional`. It is how QuTiP was written and is supposed to be used, mostly. But one of the arguments for classes is that for some solvers, or operations we needed to re-use information, eg. qutip.piqs or the heom solvers where we had to make classes anyways. . I would propose just having a private `_Displace` method which is called by `displace` but not changing the output to be conditioned on `alpha`. Later on, if we incline a bit more towards classes we can make `Displace` public. Any other thoughts and opinions? @qutip/core-workers",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646667559
https://github.com/qutip/qutip/issues/1293#issuecomment-646667559:221,Usability,simpl,simple,221,"Hi @jakelishman, I like your implementation but this will sometimes return a Qobj and other times a class instance when you call `displace()`. I am not in favour of that just out of the principle that functions should be simple and do one thing only as you also point out. . I would say if we do not want to break the user-interface, we keep the same implementation as `displace()` returning a `Qobj` (even if internally it calls the faster private `_Displace` method). . Users who want to use the class anyway can dig in and find `_Displace`. The use case here for moving to classes is rather specific and related to optimisation/control. We want to compute this operator very fast with multiple values of `alpha`, independently, on multiple cores (this was why we needed the faster implementation to run a GPU optimisation routine). Of course for sigmax(), or sigmay() we do not have any parameters to optimise and it is overkill to make them into classes. I do not suggest that at all. . I understand the inclination to be `functional`. It is how QuTiP was written and is supposed to be used, mostly. But one of the arguments for classes is that for some solvers, or operations we needed to re-use information, eg. qutip.piqs or the heom solvers where we had to make classes anyways. . I would propose just having a private `_Displace` method which is called by `displace` but not changing the output to be conditioned on `alpha`. Later on, if we incline a bit more towards classes we can make `Displace` public. Any other thoughts and opinions? @qutip/core-workers",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1293#issuecomment-646667559
https://github.com/qutip/qutip/issues/1294#issuecomment-646626641:187,Usability,guid,guide,187,"@tesla-cat this is because of the convention between how the bosonic basis and the two-level-system basis, the way ground states are set, as explained [here](http://qutip.org/docs/latest/guide/guide-states.html#qubit-two-level-systems) in the documentation.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1294#issuecomment-646626641
https://github.com/qutip/qutip/issues/1294#issuecomment-646626641:193,Usability,guid,guide-states,193,"@tesla-cat this is because of the convention between how the bosonic basis and the two-level-system basis, the way ground states are set, as explained [here](http://qutip.org/docs/latest/guide/guide-states.html#qubit-two-level-systems) in the documentation.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1294#issuecomment-646626641
https://github.com/qutip/qutip/pull/1296#issuecomment-647628082:24,Availability,error,error,24,"Ooo, that's an annoying error in the CI run on 7732470 (though the actual issue is in f42d9f9). Looks like gcc (which I'm using on Mac) does something different to the default clang. Should be a straightforward solution.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-647628082
https://github.com/qutip/qutip/pull/1296#issuecomment-648255315:297,Modifiability,layers,layers,297,"A few comments and questions. 1. Why are file separated by function and not by datatype? So adding a new datatype will result in modification im a lot of file making support (PR evaluation) harder.; 2. `__repr__` return a very clean output in `Qobj`. `CSR`'s is quite simple. This is because data layers are never meant to be printed directly?; 3. For solver states, we mostly use Fortran ordered array, not C ordered. Will you support both?; 4. In matmul, you use `malloc`, `calloc`, `free`. It is better to use the python PyDataMem_NEW. I never had any issue, but there can be some on windows: https://github.com/numpy/numpy/issues/8253; 5. `mat_mul` can be used inplace, but no `add_csr`. ; 6. It would be good to have inplace multiplication with a scalar instead of always making a copy.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648255315
https://github.com/qutip/qutip/pull/1296#issuecomment-648255315:268,Usability,simpl,simple,268,"A few comments and questions. 1. Why are file separated by function and not by datatype? So adding a new datatype will result in modification im a lot of file making support (PR evaluation) harder.; 2. `__repr__` return a very clean output in `Qobj`. `CSR`'s is quite simple. This is because data layers are never meant to be printed directly?; 3. For solver states, we mostly use Fortran ordered array, not C ordered. Will you support both?; 4. In matmul, you use `malloc`, `calloc`, `free`. It is better to use the python PyDataMem_NEW. I never had any issue, but there can be some on windows: https://github.com/numpy/numpy/issues/8253; 5. `mat_mul` can be used inplace, but no `add_csr`. ; 6. It would be good to have inplace multiplication with a scalar instead of always making a copy.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648255315
https://github.com/qutip/qutip/pull/1296#issuecomment-648259130:168,Performance,optimiz,optimized,168,"One more.; For dense matrix operation, do you intend to write the code or use blas/lapack? Using the libraries is less work and leave advanced user the ability to link optimized version for there systems, or gpu accelerated one if they want, with no more effort on our side.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648259130
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:1964,Deployability,release,released,1964," module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exactly what I was doing. 6. Yeah, I'm going to add additional `imul`, `ineg` and `idiv` routines as dispatched operations. 7. LAPACK/BLAS as far as we can. I've no pretense to being able to write faster code than hardware-specific optimised stuff for matrices. I haven't actually written most of the numerical code in this PR either - it's just ported from current `qutip`, with the variable names changed to be more descriptive.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:1618,Energy Efficiency,allocate,allocates,1618," then setting up the dispatcher will be the last item in the `matmul` file. It also means the files stay a bit smaller and easier to manage within themselves - you're less likely to ""lose"" code when each module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exactly what I was doing. 6. Yeah, I'm going to add additional `imul`, `ineg` and `idiv` routines as dispatched operations. 7. LAPACK/BLAS as far as we can. I've no pretense to being able to write faster code than hardware-spec",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:2309,Energy Efficiency,allocate,allocate,2309," module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exactly what I was doing. 6. Yeah, I'm going to add additional `imul`, `ineg` and `idiv` routines as dispatched operations. 7. LAPACK/BLAS as far as we can. I've no pretense to being able to write faster code than hardware-specific optimised stuff for matrices. I haven't actually written most of the numerical code in this PR either - it's just ported from current `qutip`, with the variable names changed to be more descriptive.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:1415,Integrability,rout,routine,1415," is ok when all operations are like `matmul(CSR, CSR) -> CSR`, but which file should the operation `matmul(CSR, Dense) -> COO` go into? Much easier to find what you're looking for if all `matmul` functions are together, and then setting up the dispatcher will be the last item in the `matmul` file. It also means the files stay a bit smaller and easier to manage within themselves - you're less likely to ""lose"" code when each module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exac",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:2508,Integrability,rout,routines,2508," module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exactly what I was doing. 6. Yeah, I'm going to add additional `imul`, `ineg` and `idiv` routines as dispatched operations. 7. LAPACK/BLAS as far as we can. I've no pretense to being able to write faster code than hardware-specific optimised stuff for matrices. I haven't actually written most of the numerical code in this PR either - it's just ported from current `qutip`, with the variable names changed to be more descriptive.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:2803,Modifiability,variab,variable,2803," module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so I just did what they did. I can change it - it's not important. When allocating space that _may_ be passed to numpy, I always use `PyDataMem_NEW` (or friends). 5. That's a mistake - I meant to take out that ability in `matmul_csr` because it's just asking for trouble (the user won't know how much space to allocate, and we're basically just asking for a segfault). I did `matmul_csr` first, and I hadn't decided yet exactly what I was doing. 6. Yeah, I'm going to add additional `imul`, `ineg` and `idiv` routines as dispatched operations. 7. LAPACK/BLAS as far as we can. I've no pretense to being able to write faster code than hardware-specific optimised stuff for matrices. I haven't actually written most of the numerical code in this PR either - it's just ported from current `qutip`, with the variable names changed to be more descriptive.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648270004:167,Usability,simpl,simple,167,"1. Adding a new data type is a large undertaking which will likely be very infrequent, so it's perhaps not so sensible to optimise in favour of making this especially simple. More likely is that new operations will be added to the data layer more frequently (e.g. you found that you wanted specific things for `CQobjEvo`), and this format makes _those_ PRs much easier to review. But mostly, because organising by file type is ok when all operations are like `matmul(CSR, CSR) -> CSR`, but which file should the operation `matmul(CSR, Dense) -> COO` go into? Much easier to find what you're looking for if all `matmul` functions are together, and then setting up the dispatcher will be the last item in the `matmul` file. It also means the files stay a bit smaller and easier to manage within themselves - you're less likely to ""lose"" code when each module is small and very focussed. 2. Exactly - it's more of an internal type. Currently `Qobj` converts the underlying data object to dense `ndarray` and prints it for its `repr` method - I don't have any plans to change that, so `Qobj` will still be full and user-facing. My `CSR` repr actually just tells you the same information that `scipy.sparse.csr_matrix` does, just in a slightly more Python-looking form. 3. Yes, in some form or another. Perhaps we could talk about the best way to do that in a future meeting?. 4. `PyDataMem_NEW` isn't actually a Python routine, it's a numpy one, but that's largely irrelevant. The Python equivalent is `cpython.mem.PyMem_Malloc` and family. The reason I don't use the latter in general is because sometimes `PyMem_Malloc` allocates into Python-reserved stack-space, and if we subsequently pass the pointer to numpy, it will try to free it and cause a segfault. The reason for using `malloc` and `free` here is mostly just because there was a comment in the code I copied it from saying that raw `malloc` and `free` were slightly faster for allocating heap space to be released within the same function, so",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648270004
https://github.com/qutip/qutip/pull/1296#issuecomment-648371869:154,Safety,safe,safe,154,"Ok, yeah, I definitely see the use-case here. I'll leave it removed from `matmul` for the time being because I hadn't really organised that code to allow safe calling of the function with an `out` parameter, but I'll look to re-instate it, similarly with `add`. For `add`: I envisage a nice possibility for `QobjEvo` using `CSR` backing along the vein of `CQobjEvoTdMatched`: on instantiation we add together all the matrices, then we `memset` all zeroes along the `data` array and store it as `self._structure`. Then each time we `__call__` the object, we simply do `out = self._structure.copy()`, and use that as the output matrix, because we guarantee we'll always have enough space and the correct structure. There's a couple of minor kinks in the logic of `add_csr` that we might have to iron out in order to avoid an additional matrix addition, but the savings in memory allocation could be good. You're absolutely right about the `pxd` files - I haven't taken enough care to make sure they've got all the definitions in yet. Basically everything that isn't prefixed with an underscore in the `.pyx` files _should_ be in the `.pxd` files. I'll add them in tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648371869
https://github.com/qutip/qutip/pull/1296#issuecomment-648371869:814,Safety,avoid,avoid,814,"Ok, yeah, I definitely see the use-case here. I'll leave it removed from `matmul` for the time being because I hadn't really organised that code to allow safe calling of the function with an `out` parameter, but I'll look to re-instate it, similarly with `add`. For `add`: I envisage a nice possibility for `QobjEvo` using `CSR` backing along the vein of `CQobjEvoTdMatched`: on instantiation we add together all the matrices, then we `memset` all zeroes along the `data` array and store it as `self._structure`. Then each time we `__call__` the object, we simply do `out = self._structure.copy()`, and use that as the output matrix, because we guarantee we'll always have enough space and the correct structure. There's a couple of minor kinks in the logic of `add_csr` that we might have to iron out in order to avoid an additional matrix addition, but the savings in memory allocation could be good. You're absolutely right about the `pxd` files - I haven't taken enough care to make sure they've got all the definitions in yet. Basically everything that isn't prefixed with an underscore in the `.pyx` files _should_ be in the `.pxd` files. I'll add them in tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648371869
https://github.com/qutip/qutip/pull/1296#issuecomment-648371869:752,Testability,log,logic,752,"Ok, yeah, I definitely see the use-case here. I'll leave it removed from `matmul` for the time being because I hadn't really organised that code to allow safe calling of the function with an `out` parameter, but I'll look to re-instate it, similarly with `add`. For `add`: I envisage a nice possibility for `QobjEvo` using `CSR` backing along the vein of `CQobjEvoTdMatched`: on instantiation we add together all the matrices, then we `memset` all zeroes along the `data` array and store it as `self._structure`. Then each time we `__call__` the object, we simply do `out = self._structure.copy()`, and use that as the output matrix, because we guarantee we'll always have enough space and the correct structure. There's a couple of minor kinks in the logic of `add_csr` that we might have to iron out in order to avoid an additional matrix addition, but the savings in memory allocation could be good. You're absolutely right about the `pxd` files - I haven't taken enough care to make sure they've got all the definitions in yet. Basically everything that isn't prefixed with an underscore in the `.pyx` files _should_ be in the `.pxd` files. I'll add them in tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648371869
https://github.com/qutip/qutip/pull/1296#issuecomment-648371869:557,Usability,simpl,simply,557,"Ok, yeah, I definitely see the use-case here. I'll leave it removed from `matmul` for the time being because I hadn't really organised that code to allow safe calling of the function with an `out` parameter, but I'll look to re-instate it, similarly with `add`. For `add`: I envisage a nice possibility for `QobjEvo` using `CSR` backing along the vein of `CQobjEvoTdMatched`: on instantiation we add together all the matrices, then we `memset` all zeroes along the `data` array and store it as `self._structure`. Then each time we `__call__` the object, we simply do `out = self._structure.copy()`, and use that as the output matrix, because we guarantee we'll always have enough space and the correct structure. There's a couple of minor kinks in the logic of `add_csr` that we might have to iron out in order to avoid an additional matrix addition, but the savings in memory allocation could be good. You're absolutely right about the `pxd` files - I haven't taken enough care to make sure they've got all the definitions in yet. Basically everything that isn't prefixed with an underscore in the `.pyx` files _should_ be in the `.pxd` files. I'll add them in tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-648371869
https://github.com/qutip/qutip/pull/1296#issuecomment-667324781:84,Testability,test,tests,84,"Whoops! Yeah, absolutely. I'll fix it in the other PR. It only affects the names of tests at least. I got it right in `test_mathematics` at least...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1296#issuecomment-667324781
https://github.com/qutip/qutip/pull/1297#issuecomment-651144540:198,Availability,toler,tolerances,198,"Yeah, that's good. There are plenty of cases (like in the tests) where we want to change something like `ntraj` on-the-fly within the same script. Even just in regular REPL work, I mess around with tolerances and things like that, and it's much much easier to be able to do that case-by-case, rather than having to set global state, which often ends up with boilerplate when you're trying to be safe - you can't do quick checks as one-liners, and you have to use `try/finally` if you only want to temporarily set it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1297#issuecomment-651144540
https://github.com/qutip/qutip/pull/1297#issuecomment-651144540:395,Safety,safe,safe,395,"Yeah, that's good. There are plenty of cases (like in the tests) where we want to change something like `ntraj` on-the-fly within the same script. Even just in regular REPL work, I mess around with tolerances and things like that, and it's much much easier to be able to do that case-by-case, rather than having to set global state, which often ends up with boilerplate when you're trying to be safe - you can't do quick checks as one-liners, and you have to use `try/finally` if you only want to temporarily set it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1297#issuecomment-651144540
https://github.com/qutip/qutip/pull/1297#issuecomment-651144540:58,Testability,test,tests,58,"Yeah, that's good. There are plenty of cases (like in the tests) where we want to change something like `ntraj` on-the-fly within the same script. Even just in regular REPL work, I mess around with tolerances and things like that, and it's much much easier to be able to do that case-by-case, rather than having to set global state, which often ends up with boilerplate when you're trying to be safe - you can't do quick checks as one-liners, and you have to use `try/finally` if you only want to temporarily set it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1297#issuecomment-651144540
https://github.com/qutip/qutip/pull/1298#issuecomment-649502147:34,Availability,error,error,34,This second commit fixes the test error in `test_ptrace.py` - the commit message in 6c85261 explains what I've done. The errors in `brtools` are due to a much more difficult fix to implement. See #1299.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1298#issuecomment-649502147
https://github.com/qutip/qutip/pull/1298#issuecomment-649502147:121,Availability,error,errors,121,This second commit fixes the test error in `test_ptrace.py` - the commit message in 6c85261 explains what I've done. The errors in `brtools` are due to a much more difficult fix to implement. See #1299.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1298#issuecomment-649502147
https://github.com/qutip/qutip/pull/1298#issuecomment-649502147:73,Integrability,message,message,73,This second commit fixes the test error in `test_ptrace.py` - the commit message in 6c85261 explains what I've done. The errors in `brtools` are due to a much more difficult fix to implement. See #1299.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1298#issuecomment-649502147
https://github.com/qutip/qutip/pull/1298#issuecomment-649502147:29,Testability,test,test,29,This second commit fixes the test error in `test_ptrace.py` - the commit message in 6c85261 explains what I've done. The errors in `brtools` are due to a much more difficult fix to implement. See #1299.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1298#issuecomment-649502147
https://github.com/qutip/qutip/issues/1299#issuecomment-649523632:170,Availability,resilien,resilient,170,"In `brtools`'s tests, we could check that the results `eigenvector` are mathematically right, without matching `scipy`'s result. Should be quite simple and we would more resilient to changes in scipy. . Did anybody check if it solves the segfault issues on Mac yet?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649523632
https://github.com/qutip/qutip/issues/1299#issuecomment-649523632:15,Testability,test,tests,15,"In `brtools`'s tests, we could check that the results `eigenvector` are mathematically right, without matching `scipy`'s result. Should be quite simple and we would more resilient to changes in scipy. . Did anybody check if it solves the segfault issues on Mac yet?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649523632
https://github.com/qutip/qutip/issues/1299#issuecomment-649523632:145,Usability,simpl,simple,145,"In `brtools`'s tests, we could check that the results `eigenvector` are mathematically right, without matching `scipy`'s result. Should be quite simple and we would more resilient to changes in scipy. . Did anybody check if it solves the segfault issues on Mac yet?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649523632
https://github.com/qutip/qutip/issues/1299#issuecomment-649525934:714,Safety,detect,detected,714,"Certainly the `zheevr` segfaults on my machine with scipy < 1.5 and _doesn't_ with scipy 1.5, but that's hardly a perfect test - segfaults are pretty intermittent at the best of times. It's easy to test that all eigenvectors are mathematically actually eigenvectors with the correct eigenvalue, but the harder bit is ensuring that we've actually found _all_ the eigenvectors, especially when we're dealing with a lot of eigenvalues that look like `(0, 0, 0, 1e-17, -1.1e-17, ...)`. Degeneracy is a more annoying to check that we've got the full spanning set of the degenerate basis, and it's even harder when we've got eigenvalues like `1e-17` which is almost certainly actually degenerate with 0, but hasn't been detected as such. This is roughly what I was trying to get at with method 2.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649525934
https://github.com/qutip/qutip/issues/1299#issuecomment-649525934:122,Testability,test,test,122,"Certainly the `zheevr` segfaults on my machine with scipy < 1.5 and _doesn't_ with scipy 1.5, but that's hardly a perfect test - segfaults are pretty intermittent at the best of times. It's easy to test that all eigenvectors are mathematically actually eigenvectors with the correct eigenvalue, but the harder bit is ensuring that we've actually found _all_ the eigenvectors, especially when we're dealing with a lot of eigenvalues that look like `(0, 0, 0, 1e-17, -1.1e-17, ...)`. Degeneracy is a more annoying to check that we've got the full spanning set of the degenerate basis, and it's even harder when we've got eigenvalues like `1e-17` which is almost certainly actually degenerate with 0, but hasn't been detected as such. This is roughly what I was trying to get at with method 2.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649525934
https://github.com/qutip/qutip/issues/1299#issuecomment-649525934:198,Testability,test,test,198,"Certainly the `zheevr` segfaults on my machine with scipy < 1.5 and _doesn't_ with scipy 1.5, but that's hardly a perfect test - segfaults are pretty intermittent at the best of times. It's easy to test that all eigenvectors are mathematically actually eigenvectors with the correct eigenvalue, but the harder bit is ensuring that we've actually found _all_ the eigenvectors, especially when we're dealing with a lot of eigenvalues that look like `(0, 0, 0, 1e-17, -1.1e-17, ...)`. Degeneracy is a more annoying to check that we've got the full spanning set of the degenerate basis, and it's even harder when we've got eigenvalues like `1e-17` which is almost certainly actually degenerate with 0, but hasn't been detected as such. This is roughly what I was trying to get at with method 2.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649525934
https://github.com/qutip/qutip/issues/1299#issuecomment-649527490:84,Testability,test,test,84,"Actually, I suppose it's much easier than I was fearing - we don't actually need to test the degeneracy or anything. We know they're the eigenvectors of a Hermitian matrix, so taken all together they should span the Hilbert space. Testing that they're all linearly independent I think is a bit of an easier test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649527490
https://github.com/qutip/qutip/issues/1299#issuecomment-649527490:231,Testability,Test,Testing,231,"Actually, I suppose it's much easier than I was fearing - we don't actually need to test the degeneracy or anything. We know they're the eigenvectors of a Hermitian matrix, so taken all together they should span the Hilbert space. Testing that they're all linearly independent I think is a bit of an easier test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649527490
https://github.com/qutip/qutip/issues/1299#issuecomment-649527490:307,Testability,test,test,307,"Actually, I suppose it's much easier than I was fearing - we don't actually need to test the degeneracy or anything. We know they're the eigenvectors of a Hermitian matrix, so taken all together they should span the Hilbert space. Testing that they're all linearly independent I think is a bit of an easier test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1299#issuecomment-649527490
https://github.com/qutip/qutip/pull/1301#issuecomment-649582507:44,Testability,test,tests,44,Thank you for your quick fix.; Merging once tests pass.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649582507
https://github.com/qutip/qutip/pull/1301#issuecomment-649583979:18,Availability,failure,failures,18,"No problem - test failures are a big deal, because they prevent everyone else from seeing what might be going wrong with their own code, and lots of people are actively working on QuTiP at the moment. > Merging once tests pass. ""if"", I think - I have a mac, so I still get the segfaults!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649583979
https://github.com/qutip/qutip/pull/1301#issuecomment-649583979:13,Testability,test,test,13,"No problem - test failures are a big deal, because they prevent everyone else from seeing what might be going wrong with their own code, and lots of people are actively working on QuTiP at the moment. > Merging once tests pass. ""if"", I think - I have a mac, so I still get the segfaults!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649583979
https://github.com/qutip/qutip/pull/1301#issuecomment-649583979:216,Testability,test,tests,216,"No problem - test failures are a big deal, because they prevent everyone else from seeing what might be going wrong with their own code, and lots of people are actively working on QuTiP at the moment. > Merging once tests pass. ""if"", I think - I have a mac, so I still get the segfaults!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649583979
https://github.com/qutip/qutip/pull/1301#issuecomment-649584449:52,Deployability,update,update,52,If only the mac one fail I will merge it anyway and update #1288.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649584449
https://github.com/qutip/qutip/pull/1301#issuecomment-649616762:184,Availability,reliab,reliably,184,"Maybe we should require that at least one of the test cases requires a version of scipy pre-1.5 so we don't cause any regressions for older versions of scipy as Travis builds start to reliably pull 1.5? Perhaps we can add a requirement for scipy=1.4.1 to the Linux py3.7, MKL/OMP one?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649616762
https://github.com/qutip/qutip/pull/1301#issuecomment-649616762:49,Testability,test,test,49,"Maybe we should require that at least one of the test cases requires a version of scipy pre-1.5 so we don't cause any regressions for older versions of scipy as Travis builds start to reliably pull 1.5? Perhaps we can add a requirement for scipy=1.4.1 to the Linux py3.7, MKL/OMP one?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649616762
https://github.com/qutip/qutip/pull/1301#issuecomment-649631995:61,Deployability,release,released,61,"I agree with having a test pre 1.5.; These changes should be released quickly, but probably just to 4.5.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649631995
https://github.com/qutip/qutip/pull/1301#issuecomment-649631995:22,Testability,test,test,22,"I agree with having a test pre 1.5.; These changes should be released quickly, but probably just to 4.5.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1301#issuecomment-649631995
https://github.com/qutip/qutip/pull/1302#issuecomment-649681790:235,Testability,test,test,235,[![Coverage Status](https://coveralls.io/builds/31689108/badge)](https://coveralls.io/builds/31689108). Coverage increased (+0.02%) to 71.087% when pulling **5d9236b9192fd2fa537834c2f66afc02eb5f04fd on jakelishman:ci-enforce-scipy-1.4-test** into **52c1925ab676495e2fc0836c6d4e2c18ce812ad1 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1302#issuecomment-649681790
https://github.com/qutip/qutip/issues/1304#issuecomment-651614556:92,Deployability,patch,patch,92,"Thanks for reporting this. We've already fixed it in `master`, but haven't yet pushed a new patch release out. We hope to do that soon. You can temporarily work around it by installing SciPy 1.4 in your QuTiP environment, or building QuTiP from the latest source.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1304#issuecomment-651614556
https://github.com/qutip/qutip/issues/1304#issuecomment-651614556:98,Deployability,release,release,98,"Thanks for reporting this. We've already fixed it in `master`, but haven't yet pushed a new patch release out. We hope to do that soon. You can temporarily work around it by installing SciPy 1.4 in your QuTiP environment, or building QuTiP from the latest source.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1304#issuecomment-651614556
https://github.com/qutip/qutip/issues/1304#issuecomment-651614556:174,Deployability,install,installing,174,"Thanks for reporting this. We've already fixed it in `master`, but haven't yet pushed a new patch release out. We hope to do that soon. You can temporarily work around it by installing SciPy 1.4 in your QuTiP environment, or building QuTiP from the latest source.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1304#issuecomment-651614556
https://github.com/qutip/qutip/issues/1304#issuecomment-663613720:68,Deployability,release,releases,68,"Should be closed by QuTiP [v. 4.5.2](https://github.com/qutip/qutip/releases/tag/v4.5.2), just released.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1304#issuecomment-663613720
https://github.com/qutip/qutip/issues/1304#issuecomment-663613720:95,Deployability,release,released,95,"Should be closed by QuTiP [v. 4.5.2](https://github.com/qutip/qutip/releases/tag/v4.5.2), just released.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1304#issuecomment-663613720
https://github.com/qutip/qutip/pull/1306#issuecomment-652972473:325,Availability,fault,fault,325,"Actually on a further look, `Qobj` does _not_ do suitable checks to prevent segfaults in Python-space code (including in the old version). I'll push a new commit to fix that. Behaviour without this PR:; ```python; In [1]: import qutip; ...: k1, k2 = qutip.rand_ket(50), qutip.rand_ket(100); ...: k1.overlap(k2); Segmentation fault: 11; ```. And with this PR:; ```python; In [1]: import qutip; ...: k1, k2 = qutip.rand_ket(50), qutip.rand_ket(100); ...: k1.overlap(k2); [ traceback removed ]; TypeError: incompatible lengths 50 and 100; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1306#issuecomment-652972473
https://github.com/qutip/qutip/issues/1308#issuecomment-654284886:173,Integrability,depend,dependent,173,"You can directly call the `expm()` method on the individual `Qobj` parts you have, but I'm slightly confused as to what mathematical operation you're representing. The time-dependent list format represents the sum of several objects, and in general `exp(A + B)` isn't the same as `exp(A) + exp(B)` or `exp(A) * exp(B)`, which is why we don't have an `expm()` method for it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-654284886
https://github.com/qutip/qutip/issues/1308#issuecomment-654285852:171,Integrability,depend,dependence,171,Maybe `Qobjevo` can be of help. See this [notebook at this point](https://nbviewer.jupyter.org/github/qutip/qutip-notebooks/blob/master/examples/qobjevo.ipynb#String-time-dependence) by @ericgig and @jakelishman,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-654285852
https://github.com/qutip/qutip/issues/1308#issuecomment-739107555:76,Usability,clear,clear,76,@jakelishman my last comment was written in a bad way. I edited that. Is it clear now?,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739107555
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:465,Deployability,integrat,integration,465,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:563,Deployability,integrat,integration,563,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:56,Integrability,depend,dependent,56,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:353,Integrability,depend,dependence,353,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:465,Integrability,integrat,integration,465,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:563,Integrability,integrat,integration,563,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:528,Usability,guid,guide,528,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/issues/1308#issuecomment-739883642:605,Usability,guid,guide,605,"Actually it probably doesn't shake out to a single time-dependent operator like I thought it might at the start. You can still do the Taylor expansion to try (you can find a similar result for 3x3 spin matrices to the 2x2 case), but there's not going to be a cancellation I thought there might have been. Right now, QuTiP doesn't support arbitrary time-dependence in collapse operators, so if you can't find a way to write it in that form, you might have to do the integration manually yourself until we've added it - the QuTiP guide [explains how QuTiP does the integration](http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1308#issuecomment-739883642
https://github.com/qutip/qutip/pull/1309#issuecomment-654957169:130,Deployability,install,install,130,"Thanks for the PR @terrorfisch!. I'm not very familiar with this so I'm probably making stupid mistakes. When I try locally `pip3 install \qutip`, also on WSL actually, it still chocks at the line `from Cython.Build import cythonize` in the `setup.py`. And I don't really understand why `pyproject.toml` can help come across that. Do you understand the reason behind why it should work?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1309#issuecomment-654957169
https://github.com/qutip/qutip/pull/1309#issuecomment-654983411:207,Availability,down,downstream,207,"Ok, my bad, I specified the wrong folder. It works for me on windows (except for some tests that are known to be failing), although it takes a bit longer to solve the dependency. It might be very useful for downstream packages since these issues kept popping up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1309#issuecomment-654983411
https://github.com/qutip/qutip/pull/1309#issuecomment-654983411:167,Integrability,depend,dependency,167,"Ok, my bad, I specified the wrong folder. It works for me on windows (except for some tests that are known to be failing), although it takes a bit longer to solve the dependency. It might be very useful for downstream packages since these issues kept popping up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1309#issuecomment-654983411
https://github.com/qutip/qutip/pull/1309#issuecomment-654983411:86,Testability,test,tests,86,"Ok, my bad, I specified the wrong folder. It works for me on windows (except for some tests that are known to be failing), although it takes a bit longer to solve the dependency. It might be very useful for downstream packages since these issues kept popping up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1309#issuecomment-654983411
https://github.com/qutip/qutip/pull/1310#issuecomment-655016356:83,Testability,test,tests,83,"If you're about to publish, can you just wait and merge #1312 in too, assuming its tests pass?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1310#issuecomment-655016356
https://github.com/qutip/qutip/issues/1311#issuecomment-655011233:48,Testability,test,test,48,"Ugh, Windows sucks soooo much. Is that the only test that fails because of it?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1311#issuecomment-655011233
https://github.com/qutip/qutip/issues/1311#issuecomment-655013004:19,Testability,test,test,19,"Yeah, the `fileio` test is the only one. `tempfile` is also only used there (sofar).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1311#issuecomment-655013004
https://github.com/qutip/qutip/pull/1312#issuecomment-655032650:227,Testability,test,test-windows,227,[![Coverage Status](https://coveralls.io/builds/31916810/badge)](https://coveralls.io/builds/31916810). Coverage increased (+0.0009%) to 71.252% when pulling **4d3f9b8647b788b95621a68292ab8bc0cc09baa9 on jakelishman:fix-fileio-test-windows** into **9e82f5b81955952833e25bb3eeff3fa24d36556b on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1312#issuecomment-655032650
https://github.com/qutip/qutip/pull/1313#issuecomment-655083091:11,Testability,test,tested,11,@Ericgig I tested it on Windows. All tests pass.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655083091
https://github.com/qutip/qutip/pull/1313#issuecomment-655083091:37,Testability,test,tests,37,@Ericgig I tested it on Windows. All tests pass.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655083091
https://github.com/qutip/qutip/pull/1313#issuecomment-655137114:39,Integrability,depend,dependency,39,"I remember we also encountered this os dependency before. `np.int` is also not the same on Windows and Linux, which has its root in C long.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655137114
https://github.com/qutip/qutip/pull/1313#issuecomment-655142649:151,Availability,avail,available,151,"Yeah, using `np.int`, `np.long` or `np.longlong` when it _matters_ what size they are is a recipe for disaster. C99 guarantees that `stdint.h` will be available, so you can always safely use `np.int8`, `np.int16`, `np.int32` and `np.int64` if you know the size you need. If you just need ""at least"" whatever, then in C `int` is >= 16-bit, `long` is >= 32-bit and `long long ` is >= 64-bit.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655142649
https://github.com/qutip/qutip/pull/1313#issuecomment-655142649:180,Safety,safe,safely,180,"Yeah, using `np.int`, `np.long` or `np.longlong` when it _matters_ what size they are is a recipe for disaster. C99 guarantees that `stdint.h` will be available, so you can always safely use `np.int8`, `np.int16`, `np.int32` and `np.int64` if you know the size you need. If you just need ""at least"" whatever, then in C `int` is >= 16-bit, `long` is >= 32-bit and `long long ` is >= 64-bit.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655142649
https://github.com/qutip/qutip/pull/1313#issuecomment-655156522:66,Usability,usab,usable,66,"Don't overthink anything in lattice, it was rough to get anything usable from that GSoC. We only checked that the functions worked, but were lenient about the style and code-structure.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1313#issuecomment-655156522
https://github.com/qutip/qutip/pull/1315#issuecomment-656032256:217,Testability,test,testBranch,217,[![Coverage Status](https://coveralls.io/builds/32474905/badge)](https://coveralls.io/builds/32474905). Coverage decreased (-0.06%) to 71.407% when pulling **3677d6e5707596ad88dfcae89885c656ac7bd148 on rajathshetty20:testBranch** into **d359d9b14f4ca8c3f63e209a9745bc52a99cf90b on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1315#issuecomment-656032256
https://github.com/qutip/qutip/pull/1315#issuecomment-665487867:192,Testability,test,tested,192,"@Ericgig I have added the color option for add_points also. For the single-color method, a single color with be passed. And for the multi-color method, a list of colors will be passed. I have tested it in https://github.com/rajathshetty20/misc/blob/master/qutip%20%231292.ipynb",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1315#issuecomment-665487867
https://github.com/qutip/qutip/pull/1315#issuecomment-667491189:23,Modifiability,variab,variable,23,"@Ericgig I changed the variable names. In the example file one small change has to be made. For changing the b.point_color after points are added, we will have to set b.point_color = [colors] instead of b.point_colors = list(colors). b.point_color is a list of list of points. https://github.com/rajathshetty20/misc/blob/master/bloch_sphere_with_colorbar.ipynb",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1315#issuecomment-667491189
https://github.com/qutip/qutip/pull/1315#issuecomment-668667134:368,Deployability,release,release,368,"I would prefer it not breaking any code with master. Ideally, we should raise a deprecation warning first, then upload the change later... There is a major new version in development that would allow this kind of changes in the branch `dev.major`. ; So could you move this PR to merge to `dev.major` instead of `master`. . If you prefer not to wait for the next major release, which will take some time, you can remove the list of list in `Bloch.point_colors` so there is no need to change the examples.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1315#issuecomment-668667134
https://github.com/qutip/qutip/pull/1315#issuecomment-669995971:137,Usability,simpl,simple,137,"Yes, it would be easier that way, master and dev.major split a while ago. The bloch.py file have not been touched at all so it should be simple.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1315#issuecomment-669995971
https://github.com/qutip/qutip/pull/1318#issuecomment-657746734:0,Deployability,Update,Updates,0,"Updates:. 1. Added `str_qasm` to read QASM input from string. Added tests for export by doing export followed by import. ; 2. The only remaining issue is that of global phase with gates. Specifically, with the `SQRTNOT`, `CSIGN` gates, the global phase is distorted when exporting to QASM and then re-importing. Should we just add a warning that this might happen more generally? Furthermore, gates like iSWAP become pretty useless with this. @BoxiLi . Otherwise, the PR is mostly ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-657746734
https://github.com/qutip/qutip/pull/1318#issuecomment-657746734:68,Testability,test,tests,68,"Updates:. 1. Added `str_qasm` to read QASM input from string. Added tests for export by doing export followed by import. ; 2. The only remaining issue is that of global phase with gates. Specifically, with the `SQRTNOT`, `CSIGN` gates, the global phase is distorted when exporting to QASM and then re-importing. Should we just add a warning that this might happen more generally? Furthermore, gates like iSWAP become pretty useless with this. @BoxiLi . Otherwise, the PR is mostly ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-657746734
https://github.com/qutip/qutip/pull/1318#issuecomment-663056349:51,Deployability,update,update,51,@sarsid Could you make a commit so that GitHub can update the `files changed`? Any commit will do.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-663056349
https://github.com/qutip/qutip/pull/1318#issuecomment-663824413:331,Availability,Ping,Ping,331,"> Looks great. I suggested some changes, mainly to docstring. I wonder what is the meaning of the filename qelib1.inc? Could we find a more explicit name if relevant? Should it be added to the Manifest file? It looks fine to me, looking forward to test it and having a section in the documentation would certainly help, under QIP. Ping for review of the notebook when ready and re-request this PR review. Regarding ""qelib1.inc"", it is a ""header"" file that contains some QASM gate definitions. It is available in the OpenQASM repository (as a standard file) and I think it's always included in QASM exports (atleast by QISKIT). It's useful because we don't need to write our own definitions and can just define QuTiP gates by mapping them to ""qelib1.inc"" gates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-663824413
https://github.com/qutip/qutip/pull/1318#issuecomment-663824413:499,Availability,avail,available,499,"> Looks great. I suggested some changes, mainly to docstring. I wonder what is the meaning of the filename qelib1.inc? Could we find a more explicit name if relevant? Should it be added to the Manifest file? It looks fine to me, looking forward to test it and having a section in the documentation would certainly help, under QIP. Ping for review of the notebook when ready and re-request this PR review. Regarding ""qelib1.inc"", it is a ""header"" file that contains some QASM gate definitions. It is available in the OpenQASM repository (as a standard file) and I think it's always included in QASM exports (atleast by QISKIT). It's useful because we don't need to write our own definitions and can just define QuTiP gates by mapping them to ""qelib1.inc"" gates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-663824413
https://github.com/qutip/qutip/pull/1318#issuecomment-663824413:248,Testability,test,test,248,"> Looks great. I suggested some changes, mainly to docstring. I wonder what is the meaning of the filename qelib1.inc? Could we find a more explicit name if relevant? Should it be added to the Manifest file? It looks fine to me, looking forward to test it and having a section in the documentation would certainly help, under QIP. Ping for review of the notebook when ready and re-request this PR review. Regarding ""qelib1.inc"", it is a ""header"" file that contains some QASM gate definitions. It is available in the OpenQASM repository (as a standard file) and I think it's always included in QASM exports (atleast by QISKIT). It's useful because we don't need to write our own definitions and can just define QuTiP gates by mapping them to ""qelib1.inc"" gates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1318#issuecomment-663824413
https://github.com/qutip/qutip/issues/1320#issuecomment-657778570:73,Safety,avoid,avoid,73,"Looks like you two could have a productive conversation. It'd be good to avoid duplication and make the best use of everyone's time, even for the computer ;). Sorry, I accidentally clicked close...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1320#issuecomment-657778570
https://github.com/qutip/qutip/issues/1320#issuecomment-658094225:1239,Availability,down,down,1239,"Knowing the tensor structure is still necessary for enforcing the Hilbert spaces are of the correct dimensions, even if the resulting state can't be written as a product of states on individual spaces. I think there's a lot more design to do to work out a sensible data structure which can really take advantage of this lazy representation, but my morning-after reaction to this is that it's very non-trivial without a lot of code duplication. It's easy enough to imagine how it will work for operators of structure `[scalar, oper, scalar] * [scalar, scalar, oper] -> [scalar, oper, oper]` - in this case the final result is fully expanded in the last two states, and not in the first. It's much trickier dealing with `[oper, scalar, scalar] * [scalar, scalar, oper] -> [oper, scalar, oper]`. In this case, since there's a subspace in between them, you need a specifically ""lazy"" Kronecker product. I suspect that this would have to be supported via either a completely separate `tensor` mechanism, or the mechanisms which currently underpin the data-layer `kron` would have to be revisited. At least at first, I think that's a very large undertaking, and it would really need a lot of careful design to ensure that we don't slow anything down, or balloon the amount of code to be maintained.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1320#issuecomment-658094225
https://github.com/qutip/qutip/issues/1320#issuecomment-658138964:1253,Availability,down,down,1253,"> Knowing the tensor structure is still necessary for enforcing the Hilbert spaces are of the correct dimensions, even if the resulting state can't be written as a product of states on individual spaces. I think there's a lot more design to do to work out a sensible data structure which can really take advantage of this lazy representation, but my morning-after reaction to this is that it's very non-trivial without a lot of code duplication.; > ; > It's easy enough to imagine how it will work for operators of structure `[scalar, oper, scalar] * [scalar, scalar, oper] -> [scalar, oper, oper]` - in this case the final result is fully expanded in the last two states, and not in the first. It's much trickier dealing with `[oper, scalar, scalar] * [scalar, oper, oper] -> [oper, scalar, oper]`. In this case, since there's a subspace in between them, you need a specifically ""lazy"" Kronecker product. I suspect that this would have to be supported via either a completely separate `tensor` mechanism, or the mechanisms which currently underpin the data-layer `kron` would have to be revisited.; > ; > At least at first, I think that's a very large undertaking, and it would really need a lot of careful design to ensure that we don't slow anything down, or balloon the amount of code to be maintained. Both your and Boxi's comments point to the fact that this probably needs to be something on top of Qobj as a QIP-state object rather than part of Qobj itself! Once the details on these changes are fleshed out, I shall certainly look into this. It could potentially be very useful to have a slightly more customized/optimized QIP state layer on top of Qobj.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1320#issuecomment-658138964
https://github.com/qutip/qutip/issues/1320#issuecomment-658138964:1622,Performance,optimiz,optimized,1622,"> Knowing the tensor structure is still necessary for enforcing the Hilbert spaces are of the correct dimensions, even if the resulting state can't be written as a product of states on individual spaces. I think there's a lot more design to do to work out a sensible data structure which can really take advantage of this lazy representation, but my morning-after reaction to this is that it's very non-trivial without a lot of code duplication.; > ; > It's easy enough to imagine how it will work for operators of structure `[scalar, oper, scalar] * [scalar, scalar, oper] -> [scalar, oper, oper]` - in this case the final result is fully expanded in the last two states, and not in the first. It's much trickier dealing with `[oper, scalar, scalar] * [scalar, oper, oper] -> [oper, scalar, oper]`. In this case, since there's a subspace in between them, you need a specifically ""lazy"" Kronecker product. I suspect that this would have to be supported via either a completely separate `tensor` mechanism, or the mechanisms which currently underpin the data-layer `kron` would have to be revisited.; > ; > At least at first, I think that's a very large undertaking, and it would really need a lot of careful design to ensure that we don't slow anything down, or balloon the amount of code to be maintained. Both your and Boxi's comments point to the fact that this probably needs to be something on top of Qobj as a QIP-state object rather than part of Qobj itself! Once the details on these changes are fleshed out, I shall certainly look into this. It could potentially be very useful to have a slightly more customized/optimized QIP state layer on top of Qobj.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1320#issuecomment-658138964
https://github.com/qutip/qutip/issues/1320#issuecomment-667164574:375,Safety,safe,safety,375,"I had some more thoughts about this while responding in the Google group (see: [this post and associated email chain](https://groups.google.com/g/qutip/c/NAGU4iKZNBY/m/3i-oLXAzAgAJ)). I think perhaps a good solution is to move away from keeping track of the ""dimensions"" of each space, to keeping track of what ""basis"" each space is represented by. This actually allows more safety, and I think is probably a more natural way of thinking about the underlying physics for most people.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1320#issuecomment-667164574
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:542,Availability,toler,tolerance,542,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:942,Availability,toler,tolerance,942,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1866,Availability,degraded,degraded,1866,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:2156,Availability,toler,tolerance,2156,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1009,Deployability,rolling,rolling,1009,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1239,Integrability,wrap,wraps,1239," there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:847,Performance,cache,cache,847,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1026,Performance,cache,cache,1026,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1211,Performance,cache,cache,1211,"sh function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1309,Performance,cache,cache,1309,"q__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The pr",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1372,Performance,cache,cache,1372,"instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little un",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1470,Performance,cache,cache,1470,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1775,Performance,cache,cache,1775,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1816,Performance,cache,cache,1816,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1836,Performance,cache,cache,1836,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:1875,Performance,perform,performance,1875,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:2008,Performance,cache,cached,2008,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:2334,Performance,cache,cache,2334,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:214,Security,hash,hash,214,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:315,Security,hash,hash,315,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:328,Security,hash,hash,328,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:597,Security,hash,hash,597,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:703,Security,hash,hashing,703,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:823,Security,hash,hashable,823,"We can't implement `__hash__` for `Qobj`, sorry - it's just not possible while following the [Python data model](https://docs.python.org/3/reference/datamodel.html#object.__hash__). The two principle points that a hash function must follow from there are; 1. objects which compare equal with `__eq__` have the same hash; 2. the hash of an object cannot change after instantiation (no mutable types). Unfortunately we fail on both points. `Qobj.__eq__` is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs an",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/issues/1321#issuecomment-658078277:2345,Usability,simpl,simply,2345,"is a rounding match, because it gives a total `True` or `False` based on a floating point tolerance, not on exact equality. I'm not aware of any hash function which can handle this. Second, the `data` attribute of a `Qobj` is mutable in-place, and so hashing based on the data in the object is not valid. This is the same reason that `list` and `np.ndarray` are also not hashable types. If your cache is just for memoisation over a small number of `Qobj` where you know that floating-point tolerance will never be an issue, you may be able to get away with rolling your own cache decorator which uses linear lookup rather than constant-time. I mean something like; ```python; In [1]: import functools; ...: import qutip; ...:; ...: def linear_cache(f):; ...: cache = []; ...: @functools.wraps(f); ...: def out(*args):; ...: for cached_args, cached_value in cache:; ...: if args == cached_args:; ...: print(""Getting from cache""); ...: return cached_value; ...: print(""Computing new value""); ...: value = f(*args); ...: cache.append((args, value)); ...: return value; ...: return out; ...:; ...: @linear_cache; ...: def negate(x):; ...: return -x; ...:; ...: sx = qutip.sigmax(); ...: sy = qutip.sigmay(); ...: negate(sx); ...: negate(sx); ...: negate(sy); ...: negate(sx); ...: negate(sy); Computing new value; Getting from cache; Computing new value; Getting from cache; Getting from cache; ```; This will lead to degraded performance if you need to do it for a large number of possible inputs, but if you have a relatively small number of inputs and your cached function is computationally expensive, this may be a way to achieve what you want. Also note that this is not infallible: the floating-point tolerance used in `__eq__` means that `Qobj` does not satisfy transitive equality (i.e. `a == b and b == c` does not imply `a == c`). The primary consequence of this is that the cache will simply be a little under-zealous, and sometimes it will calculate the value twice for three similar `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1321#issuecomment-658078277
https://github.com/qutip/qutip/pull/1322#issuecomment-658689372:100,Testability,test,tests,100,"@BoxiLi I guess; https://github.com/qutip/qutip/blob/4f9b04b149734a7d81cb25ff25a844e4ee41a6ea/qutip/tests/test_processor.py#L333-L345; didn't successfully add a check for this?. I'll try get the unit tests running locally so I can add to this, but feel free to fix this up on my behalf if it's obvious to you :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-658689372
https://github.com/qutip/qutip/pull/1322#issuecomment-658689372:200,Testability,test,tests,200,"@BoxiLi I guess; https://github.com/qutip/qutip/blob/4f9b04b149734a7d81cb25ff25a844e4ee41a6ea/qutip/tests/test_processor.py#L333-L345; didn't successfully add a check for this?. I'll try get the unit tests running locally so I can add to this, but feel free to fix this up on my behalf if it's obvious to you :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-658689372
https://github.com/qutip/qutip/pull/1322#issuecomment-659003253:178,Testability,test,test,178,"Yes, you are right. Thanks for spotting this! That was a stupid mistake. I added the `mcsolve` option along with a few other small stuffs, didn't pay enough attention to it. The test just tests if the things run fine... Actually I don't really have a straightforward idea of how to test if a specific solver is used. Free free to propose any idea you have!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659003253
https://github.com/qutip/qutip/pull/1322#issuecomment-659003253:188,Testability,test,tests,188,"Yes, you are right. Thanks for spotting this! That was a stupid mistake. I added the `mcsolve` option along with a few other small stuffs, didn't pay enough attention to it. The test just tests if the things run fine... Actually I don't really have a straightforward idea of how to test if a specific solver is used. Free free to propose any idea you have!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659003253
https://github.com/qutip/qutip/pull/1322#issuecomment-659003253:282,Testability,test,test,282,"Yes, you are right. Thanks for spotting this! That was a stupid mistake. I added the `mcsolve` option along with a few other small stuffs, didn't pay enough attention to it. The test just tests if the things run fine... Actually I don't really have a straightforward idea of how to test if a specific solver is used. Free free to propose any idea you have!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659003253
https://github.com/qutip/qutip/pull/1322#issuecomment-659111222:418,Deployability,update,updated,418,"I can probably do it with [`unittest.mock.assert_called_once_with`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called_once_with), although I'm not sure what the etiquette is on using multiple different unittesting frameworks is, as I see this repo is `pytest`ed mostly. I guess `unittest` is part of the standard library so it should be okay?. I will add a commit with the unittest updated when I get the chance, though feel free to merge this 1-line fix as it might as well be in master now that it's been noticed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659111222
https://github.com/qutip/qutip/pull/1322#issuecomment-659111222:37,Testability,mock,mock,37,"I can probably do it with [`unittest.mock.assert_called_once_with`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called_once_with), although I'm not sure what the etiquette is on using multiple different unittesting frameworks is, as I see this repo is `pytest`ed mostly. I guess `unittest` is part of the standard library so it should be okay?. I will add a commit with the unittest updated when I get the chance, though feel free to merge this 1-line fix as it might as well be in master now that it's been noticed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659111222
https://github.com/qutip/qutip/pull/1322#issuecomment-659111222:111,Testability,mock,mock,111,"I can probably do it with [`unittest.mock.assert_called_once_with`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called_once_with), although I'm not sure what the etiquette is on using multiple different unittesting frameworks is, as I see this repo is `pytest`ed mostly. I guess `unittest` is part of the standard library so it should be okay?. I will add a commit with the unittest updated when I get the chance, though feel free to merge this 1-line fix as it might as well be in master now that it's been noticed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659111222
https://github.com/qutip/qutip/pull/1322#issuecomment-659111222:130,Testability,mock,mock,130,"I can probably do it with [`unittest.mock.assert_called_once_with`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called_once_with), although I'm not sure what the etiquette is on using multiple different unittesting frameworks is, as I see this repo is `pytest`ed mostly. I guess `unittest` is part of the standard library so it should be okay?. I will add a commit with the unittest updated when I get the chance, though feel free to merge this 1-line fix as it might as well be in master now that it's been noticed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659111222
https://github.com/qutip/qutip/pull/1322#issuecomment-659111222:135,Testability,Mock,Mock,135,"I can probably do it with [`unittest.mock.assert_called_once_with`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_called_once_with), although I'm not sure what the etiquette is on using multiple different unittesting frameworks is, as I see this repo is `pytest`ed mostly. I guess `unittest` is part of the standard library so it should be okay?. I will add a commit with the unittest updated when I get the chance, though feel free to merge this 1-line fix as it might as well be in master now that it's been noticed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1322#issuecomment-659111222
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:1213,Availability,down,down,1213,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:1113,Deployability,release,released,1113,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:1068,Energy Efficiency,reduce,reduce,1068,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:1002,Integrability,interface,interface,1002,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:143,Usability,clear,clearer,143,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660459774:312,Usability,simpl,simple,312,"What's wrong with just using a loop? Adding the `combine` statement is already extra work for you, and using the solver in a loop will be much clearer about what's going on. The `Qobj` object container is not meant to a vector of objects itself - use a list for that, or a numpy array if you're only going to do simple mathematical operations that you want broadcasting for (numpy will broadcast `*`, `/`, `+`, `-` and `**` correctly). The calculational complexity of the solver isn't helped by knowing you're going to do it a few times, but there are some setup costs that QuTiP already gives you the tools to alleviate. `mesolve` constructs a Liouvillian out the Hamiltonian and collapse operators; if you want to reuse the result of this, you should use `qutip.liouvillian` and `qutip.QobjEvo`, and use the `compile` method of the latter. You can pass the result of this directly as the `H` parameter of `mesolve` and it'll skip all the setup. There is some work going on about making a class-based interface to the solvers, which allows easier use of the tools to reduce setup time, but those likely won't be released for some time yet. In the meantime, just use a loop here. There will not be a notable slow down (unlike numpy maths operations) because the Python iteration over elements takes a negligible amount of time compared to single numerical intergration. As a side note, in this particular case you're doing unitary dynamics with state vectors, so this call to `mesolve` is actually translated into one to `sesolve`, which does not need to construct the Liouvillian.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660459774
https://github.com/qutip/qutip/issues/1323#issuecomment-660468848:92,Usability,learn,learning,92,"@jakelishman . - in my case it would be different; - i am using it to train a reinforcement learning agent, which is highly sample inefficient and will take so many steps that even 10 times slower is much slower for a human; - you can refer to this paper from Google's Quantum Artificial Intelligence lab: [Universal quantum control through deep reinforcement learning](https://www.nature.com/articles/s41534-019-0141-3); - it would be great if you guys can add this feature, but i think i am just gonna write my own evolution code right now",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660468848
https://github.com/qutip/qutip/issues/1323#issuecomment-660468848:360,Usability,learn,learning,360,"@jakelishman . - in my case it would be different; - i am using it to train a reinforcement learning agent, which is highly sample inefficient and will take so many steps that even 10 times slower is much slower for a human; - you can refer to this paper from Google's Quantum Artificial Intelligence lab: [Universal quantum control through deep reinforcement learning](https://www.nature.com/articles/s41534-019-0141-3); - it would be great if you guys can add this feature, but i think i am just gonna write my own evolution code right now",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660468848
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:274,Deployability,integrat,integrate,274,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:800,Deployability,integrat,integrator,800,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:26,Energy Efficiency,efficient,efficient,26,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:274,Integrability,integrat,integrate,274,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:654,Integrability,protocol,protocols,654,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:800,Integrability,integrat,integrator,800,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660471465:645,Usability,learn,learning,645,"What do you think is more efficient than doing; ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```; ?. I'm saying that to do each state independently, `mesolve` and `sesolve` have to independently integrate each state, so even if we added this functionality into those functions directly, it would be little more than that loop I just wrote if you have used the tools I described in the first comment. If you want the entire system propagator, `qutip.propagator` can calculate that for you. Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple, but if you have very specific domain knowledge of your system, you often will be able to write an integrator which is faster for your cases, rather than the full general-purposes ones in QuTiP.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660471465
https://github.com/qutip/qutip/issues/1323#issuecomment-660472157:152,Integrability,protocol,protocols,152,"thanks for the comment, I didn't know about `qutip.propagator`. > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple. cool, can i learn more about this from you?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660472157
https://github.com/qutip/qutip/issues/1323#issuecomment-660472157:143,Usability,learn,learning,143,"thanks for the comment, I didn't know about `qutip.propagator`. > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple. cool, can i learn more about this from you?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660472157
https://github.com/qutip/qutip/issues/1323#issuecomment-660472157:212,Usability,learn,learn,212,"thanks for the comment, I didn't know about `qutip.propagator`. > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple. cool, can i learn more about this from you?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660472157
https://github.com/qutip/qutip/issues/1323#issuecomment-660472577:158,Energy Efficiency,efficient,efficient,158,"are you saying . ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```. is **most** efficient?. even more efficient than. ```python; U = qutip.propagator(H, times); states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [U*state for state in states]; ```. ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660472577
https://github.com/qutip/qutip/issues/1323#issuecomment-660472577:180,Energy Efficiency,efficient,efficient,180,"are you saying . ```python; states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [qutip.sesolve(H, state, times) for state in states]; ```. is **most** efficient?. even more efficient than. ```python; U = qutip.propagator(H, times); states = [qutip.basis(2, 0), qutip.basis(2, 1)]; results = [U*state for state in states]; ```. ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660472577
https://github.com/qutip/qutip/issues/1323#issuecomment-660473253:3,Integrability,depend,depends,3,"It depends on how many states you have, and what precision you require. Constructing the whole propagator will always have a lower precision than evolving each state individually, but if you are working with a single qubit system and need to evaluate the evolution of many many different qubits under the same Hamiltonian, then using `propagator` will be faster. Really, getting the fastest speeds depends a lot on your system Hamiltonian. Typically the more you can do analytically, the better. For example, if you plan to use a piecewise-constant Hamiltonian, then you will be most accurate if you consider the individual components of the evolution and multiply them together.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660473253
https://github.com/qutip/qutip/issues/1323#issuecomment-660473253:398,Integrability,depend,depends,398,"It depends on how many states you have, and what precision you require. Constructing the whole propagator will always have a lower precision than evolving each state individually, but if you are working with a single qubit system and need to evaluate the evolution of many many different qubits under the same Hamiltonian, then using `propagator` will be faster. Really, getting the fastest speeds depends a lot on your system Hamiltonian. Typically the more you can do analytically, the better. For example, if you plan to use a piecewise-constant Hamiltonian, then you will be most accurate if you consider the individual components of the evolution and multiply them together.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660473253
https://github.com/qutip/qutip/issues/1323#issuecomment-660474276:88,Integrability,protocol,protocols,88,"> Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple. For those you worked on, do they include QOC via RL ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660474276
https://github.com/qutip/qutip/issues/1323#issuecomment-660474276:79,Usability,learn,learning,79,"> Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple. For those you worked on, do they include QOC via RL ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660474276
https://github.com/qutip/qutip/issues/1323#issuecomment-660475258:570,Energy Efficiency,adapt,adapt,570,"> thanks for the comment, I didn't know about `qutip.propagator`; > ; > > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple; > ; > cool, can i learn more about this from you?. Sorry, I don't have much experience in it myself - you'll be reading about the methods in papers/lecture note by people smarter than me. We have some tutorial notebooks about optimal control using the QuTiP optimal control package here: http://qutip.org/tutorials.html#optimal-control, which you may be able to adapt to your use case. I believe there are components in there that you can subclass so that the optimiser is RL-based rather than using standard BFGS or something else.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660475258
https://github.com/qutip/qutip/issues/1323#issuecomment-660475258:160,Integrability,protocol,protocols,160,"> thanks for the comment, I didn't know about `qutip.propagator`; > ; > > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple; > ; > cool, can i learn more about this from you?. Sorry, I don't have much experience in it myself - you'll be reading about the methods in papers/lecture note by people smarter than me. We have some tutorial notebooks about optimal control using the QuTiP optimal control package here: http://qutip.org/tutorials.html#optimal-control, which you may be able to adapt to your use case. I believe there are components in there that you can subclass so that the optimiser is RL-based rather than using standard BFGS or something else.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660475258
https://github.com/qutip/qutip/issues/1323#issuecomment-660475258:570,Modifiability,adapt,adapt,570,"> thanks for the comment, I didn't know about `qutip.propagator`; > ; > > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple; > ; > cool, can i learn more about this from you?. Sorry, I don't have much experience in it myself - you'll be reading about the methods in papers/lecture note by people smarter than me. We have some tutorial notebooks about optimal control using the QuTiP optimal control package here: http://qutip.org/tutorials.html#optimal-control, which you may be able to adapt to your use case. I believe there are components in there that you can subclass so that the optimiser is RL-based rather than using standard BFGS or something else.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660475258
https://github.com/qutip/qutip/issues/1323#issuecomment-660475258:151,Usability,learn,learning,151,"> thanks for the comment, I didn't know about `qutip.propagator`; > ; > > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple; > ; > cool, can i learn more about this from you?. Sorry, I don't have much experience in it myself - you'll be reading about the methods in papers/lecture note by people smarter than me. We have some tutorial notebooks about optimal control using the QuTiP optimal control package here: http://qutip.org/tutorials.html#optimal-control, which you may be able to adapt to your use case. I believe there are components in there that you can subclass so that the optimiser is RL-based rather than using standard BFGS or something else.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660475258
https://github.com/qutip/qutip/issues/1323#issuecomment-660475258:226,Usability,learn,learn,226,"> thanks for the comment, I didn't know about `qutip.propagator`; > ; > > Lots of people have successfully used QuTiP already as part of reinforcement learning protocols - I've worked with at least a couple; > ; > cool, can i learn more about this from you?. Sorry, I don't have much experience in it myself - you'll be reading about the methods in papers/lecture note by people smarter than me. We have some tutorial notebooks about optimal control using the QuTiP optimal control package here: http://qutip.org/tutorials.html#optimal-control, which you may be able to adapt to your use case. I believe there are components in there that you can subclass so that the optimiser is RL-based rather than using standard BFGS or something else.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660475258
https://github.com/qutip/qutip/issues/1323#issuecomment-660506344:250,Modifiability,evolve,evolves,250,"> by calculating the `qutip.propagator` we are actually solving `qutip.sesolve` for `N` basis states. Yes, propagator returns the unitary matrix of the evolution. For large system, this will be much slower than `sesolve`. Roughly speaking, `sesolve` evolves only the given initial state while propagator all the `N` basis. From a very inaccurate estimation, if you want to evolve more than `N` initial states with the same Hamiltonian, `propagator` will be a better choice. However, you might also need a bigger memory to save the unitary.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660506344
https://github.com/qutip/qutip/issues/1323#issuecomment-660506344:373,Modifiability,evolve,evolve,373,"> by calculating the `qutip.propagator` we are actually solving `qutip.sesolve` for `N` basis states. Yes, propagator returns the unitary matrix of the evolution. For large system, this will be much slower than `sesolve`. Roughly speaking, `sesolve` evolves only the given initial state while propagator all the `N` basis. From a very inaccurate estimation, if you want to evolve more than `N` initial states with the same Hamiltonian, `propagator` will be a better choice. However, you might also need a bigger memory to save the unitary.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1323#issuecomment-660506344
https://github.com/qutip/qutip/issues/1325#issuecomment-663126648:125,Testability,test,test,125,"Also, I was just quickly searching for a quick-and-dirty ""obviously correct"" method of doing the partial trace to use as the test case (rather than keeping around a legacy Cython version just to test against), and found [this StackOverflow answer](https://scicomp.stackexchange.com/questions/27496/calculating-partial-trace-of-array-in-numpy) which has like 3 people telling someone ""don't do it yourself, just use QuTiP""! Pretty neat!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1325#issuecomment-663126648
https://github.com/qutip/qutip/issues/1325#issuecomment-663126648:195,Testability,test,test,195,"Also, I was just quickly searching for a quick-and-dirty ""obviously correct"" method of doing the partial trace to use as the test case (rather than keeping around a legacy Cython version just to test against), and found [this StackOverflow answer](https://scicomp.stackexchange.com/questions/27496/calculating-partial-trace-of-array-in-numpy) which has like 3 people telling someone ""don't do it yourself, just use QuTiP""! Pretty neat!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1325#issuecomment-663126648
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:4,Availability,error,error,4,"The error seems to occur only when I use matplotlib to make some plots before using the propagator. For example, if I implement the two blocks of code as shown below in the same order, I would get the error as shown. But if I remove the first block and implement only the second block, the error disappears (of course after restarting the kernel). . Block 1:; ```ruby. import numpy as np; import matplotlib.pyplot as plt; from qutip import *. x = np.linspace(0,2*np.pi,100); y = np.sin(x); plt.plot(x,y); plt.show(); ```; output:. <img width=""407"" alt=""image"" src=""https://user-images.githubusercontent.com/53356828/88606624-00e26280-d032-11ea-97a4-107449ad8b56.png"">. Block 2:; ``` ruby; H1 = sigmaz();H2 = sigmax(); ; args = {'w': 2*2*np.pi}; H = [H1, [H2, 'cos(w * t)']]; t_list = np.linspace(0,10,100); U_list = []; for (i,t) in enumerate(t_list):; U = propagator(H,t, [], args); U_list.append(U); print(i); ```; output:; ```; 0; 1; 2; 3; 4; 5; 6; 7; ---------------------------------------------------------------------------; DistutilsExecError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 117 self.spawn(compiler_so + cc_args + [src, '-o', obj] +; --> 118 extra_postargs); 119 except DistutilsExecError as msg:. ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in spawn(self, cmd); 909 def spawn(self, cmd):; --> 910 spawn(cmd, dry_run=self.dry_run); 911 . ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in spawn(cmd, search_path, verbose, dry_run); 35 if os.name == 'posix':; ---> 36 _spawn_posix(cmd, search_path, dry_run=dry_run); 37 elif os.name == 'nt':. ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in _spawn_posix(cmd, search_path, verbose, dry_run); 148 ""command %r terminated by signal %d""; --> 149 % (cmd, os.WTERMSIG(status))); 150 elif os.WIFEXITED(status):. DistutilsExecError: command 'gcc' terminated by signal 6. During handling of the above exception, ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:201,Availability,error,error,201,"The error seems to occur only when I use matplotlib to make some plots before using the propagator. For example, if I implement the two blocks of code as shown below in the same order, I would get the error as shown. But if I remove the first block and implement only the second block, the error disappears (of course after restarting the kernel). . Block 1:; ```ruby. import numpy as np; import matplotlib.pyplot as plt; from qutip import *. x = np.linspace(0,2*np.pi,100); y = np.sin(x); plt.plot(x,y); plt.show(); ```; output:. <img width=""407"" alt=""image"" src=""https://user-images.githubusercontent.com/53356828/88606624-00e26280-d032-11ea-97a4-107449ad8b56.png"">. Block 2:; ``` ruby; H1 = sigmaz();H2 = sigmax(); ; args = {'w': 2*2*np.pi}; H = [H1, [H2, 'cos(w * t)']]; t_list = np.linspace(0,10,100); U_list = []; for (i,t) in enumerate(t_list):; U = propagator(H,t, [], args); U_list.append(U); print(i); ```; output:; ```; 0; 1; 2; 3; 4; 5; 6; 7; ---------------------------------------------------------------------------; DistutilsExecError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 117 self.spawn(compiler_so + cc_args + [src, '-o', obj] +; --> 118 extra_postargs); 119 except DistutilsExecError as msg:. ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in spawn(self, cmd); 909 def spawn(self, cmd):; --> 910 spawn(cmd, dry_run=self.dry_run); 911 . ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in spawn(cmd, search_path, verbose, dry_run); 35 if os.name == 'posix':; ---> 36 _spawn_posix(cmd, search_path, dry_run=dry_run); 37 elif os.name == 'nt':. ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in _spawn_posix(cmd, search_path, verbose, dry_run); 148 ""command %r terminated by signal %d""; --> 149 % (cmd, os.WTERMSIG(status))); 150 elif os.WIFEXITED(status):. DistutilsExecError: command 'gcc' terminated by signal 6. During handling of the above exception, ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:290,Availability,error,error,290,"The error seems to occur only when I use matplotlib to make some plots before using the propagator. For example, if I implement the two blocks of code as shown below in the same order, I would get the error as shown. But if I remove the first block and implement only the second block, the error disappears (of course after restarting the kernel). . Block 1:; ```ruby. import numpy as np; import matplotlib.pyplot as plt; from qutip import *. x = np.linspace(0,2*np.pi,100); y = np.sin(x); plt.plot(x,y); plt.show(); ```; output:. <img width=""407"" alt=""image"" src=""https://user-images.githubusercontent.com/53356828/88606624-00e26280-d032-11ea-97a4-107449ad8b56.png"">. Block 2:; ``` ruby; H1 = sigmaz();H2 = sigmax(); ; args = {'w': 2*2*np.pi}; H = [H1, [H2, 'cos(w * t)']]; t_list = np.linspace(0,10,100); U_list = []; for (i,t) in enumerate(t_list):; U = propagator(H,t, [], args); U_list.append(U); print(i); ```; output:; ```; 0; 1; 2; 3; 4; 5; 6; 7; ---------------------------------------------------------------------------; DistutilsExecError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 117 self.spawn(compiler_so + cc_args + [src, '-o', obj] +; --> 118 extra_postargs); 119 except DistutilsExecError as msg:. ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in spawn(self, cmd); 909 def spawn(self, cmd):; --> 910 spawn(cmd, dry_run=self.dry_run); 911 . ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in spawn(cmd, search_path, verbose, dry_run); 35 if os.name == 'posix':; ---> 36 _spawn_posix(cmd, search_path, dry_run=dry_run); 37 elif os.name == 'nt':. ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in _spawn_posix(cmd, search_path, verbose, dry_run); 148 ""command %r terminated by signal %d""; --> 149 % (cmd, os.WTERMSIG(status))); 150 elif os.WIFEXITED(status):. DistutilsExecError: command 'gcc' terminated by signal 6. During handling of the above exception, ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:8438,Availability,error,errors,8438,"istutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . ImportError: Building module cqobjevo_compiled_coeff_1212362029172 failed: [""distutils.errors.CompileError: command 'gcc' terminated by signal 6\n""]. The above exception was the direct cause of the following exception:. Exception Traceback (most recent call last); <ipython-input-4-773196c7ecc9> in <module>; 6 U_list = []; 7 for (i,t) in enumerate(t_list):; ----> 8 U = propagator(H,t, [], args); 9 U_list.append(U); 10 print(i). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/propagator.py in propagator(H, t, c_op_list, args, options, unitary_mode, parallel, progress_bar, _safe_mode, **kwargs); 184 output = sesolve(H2, psi0, tlist, [],; 185 args=args, options=options,; --> 186 _safe_mode=False); 187 for k, t in enumerate(tlist):; 188 u[k] = sp_reshape(output.states[k].data, (N, N)). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/sesolve.py in sesolve(H, psi0, tlist, e_ops, args, options, progress_bar, _safe_mode); 155 ss = H; 156 elif isinstance(H, (list, Qobj, QobjEvo)):; --> 157 ss = _sesolve_QobjEvo(H, tlist, args, options); 158 elif callable(H):; 159 ss = _sesolve_fun",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:11477,Deployability,Install,Installed,11477,"le_); 1561 self.coeff_files.append(file_). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _compiled_coeffs(ops, args, dyn_args, tlist); 128 code = _make_code_4_cimport(ops, args, dyn_args, tlist); 129 coeff_obj, filename = _import_str(code, ""cqobjevo_compiled_coeff_"",; --> 130 ""CompiledStrCoeff"", True); 131 return coeff_obj(ops, args, tlist, dyn_args), code, filename; 132 . ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _import_str(code, basefilename, obj_name, cythonfile); 86 if not import_list:; 87 raise Exception(""Could not convert string to importable function, ""; ---> 88 ""tmpfile:"" + try_file + ext) from err; 89 coeff_obj = import_list[0]; 90 return coeff_obj, try_file + ext. Exception: Could not convert string to importable function, tmpfile:cqobjevo_compiled_coeff_1212362029172.pyx; ```. ```ruby; about(); ```; output: ; ```; QuTiP: Quantum Toolbox in Python; ================================; Copyright (c) QuTiP team 2011 and later.; Original developers: R. J. Johansson & P. D. Nation.; Previous lead developers: Chris Granade & A. Grimsmo.; Current admin team: Alexander Pitchford, Paul D. Nation, Nathan Shammah, Shahnawaz Ahmed, Neill Lambert, Eric Gigure, and Boxi Li; Project Manager: Franco Nori.; Currently developed through wide collaboration. See https://github.com/qutip for details. QuTiP Version: 4.5.2; Numpy Version: 1.18.1; Scipy Version: 1.4.1; Cython Version: 0.29.15; Matplotlib Version: 3.1.3; Python Version: 3.7.6; Number of CPUs: 8; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: True; Platform Info: Darwin (x86_64); Installation path: /Users/tripathi/opt/anaconda3/lib/python3.7/site-packages/qutip; ==============================================================================; Please cite QuTiP in your publication.; ==============================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:11548,Deployability,Install,Installation,11548,"le_); 1561 self.coeff_files.append(file_). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _compiled_coeffs(ops, args, dyn_args, tlist); 128 code = _make_code_4_cimport(ops, args, dyn_args, tlist); 129 coeff_obj, filename = _import_str(code, ""cqobjevo_compiled_coeff_"",; --> 130 ""CompiledStrCoeff"", True); 131 return coeff_obj(ops, args, tlist, dyn_args), code, filename; 132 . ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _import_str(code, basefilename, obj_name, cythonfile); 86 if not import_list:; 87 raise Exception(""Could not convert string to importable function, ""; ---> 88 ""tmpfile:"" + try_file + ext) from err; 89 coeff_obj = import_list[0]; 90 return coeff_obj, try_file + ext. Exception: Could not convert string to importable function, tmpfile:cqobjevo_compiled_coeff_1212362029172.pyx; ```. ```ruby; about(); ```; output: ; ```; QuTiP: Quantum Toolbox in Python; ================================; Copyright (c) QuTiP team 2011 and later.; Original developers: R. J. Johansson & P. D. Nation.; Previous lead developers: Chris Granade & A. Grimsmo.; Current admin team: Alexander Pitchford, Paul D. Nation, Nathan Shammah, Shahnawaz Ahmed, Neill Lambert, Eric Gigure, and Boxi Li; Project Manager: Franco Nori.; Currently developed through wide collaboration. See https://github.com/qutip for details. QuTiP Version: 4.5.2; Numpy Version: 1.18.1; Scipy Version: 1.4.1; Cython Version: 0.29.15; Matplotlib Version: 3.1.3; Python Version: 3.7.6; Number of CPUs: 8; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: True; Platform Info: Darwin (x86_64); Installation path: /Users/tripathi/opt/anaconda3/lib/python3.7/site-packages/qutip; ==============================================================================; Please cite QuTiP in your publication.; ==============================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:4275,Integrability,depend,depends,4275,"alized(); --> 985 cmd_obj.run(); 986 self.have_run[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . CompileError: command 'gcc' terminated by signal 6. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _import_str(code, basefilename, obj_name, cythonfile); 79 import_code = compile(codeString, '<string>', 'exec'); ---> 80 exec(import_code, locals()); 81 except (ModuleNotFoundError, ImportError) as e:. <string> in <module>. ~/opt/anaconda3/lib/p",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:4287,Integrability,depend,depends,4287,"[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . CompileError: command 'gcc' terminated by signal 6. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _import_str(code, basefilename, obj_name, cythonfile); 79 import_code = compile(codeString, '<string>', 'exec'); ---> 80 exec(import_code, locals()); 81 except (ModuleNotFoundError, ImportError) as e:. <string> in <module>. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in lo",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:4454,Integrability,depend,depends,4454,"ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . CompileError: command 'gcc' terminated by signal 6. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/site-packages/qutip/qobjevo_codegen.py in _import_str(code, basefilename, obj_name, cythonfile); 79 import_code = compile(codeString, '<string>', 'exec'); ---> 80 exec(import_code, locals()); 81 except (ModuleNotFoundError, ImportError) as e:. <string> in <module>. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in load_module(self, fullname); 461 build_inplace=self.inplace,; --> 462 language_level=self.language_level); 463 return module. ~/o",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:7867,Integrability,depend,depends,7867,"alized(); --> 985 cmd_obj.run(); 986 self.have_run[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . ImportError: Building module cqobjevo_compiled_coeff_1212362029172 failed: [""distutils.errors.CompileError: command 'gcc' terminated by signal 6\n""]. The above exception was the direct cause of the following exception:. Exception Traceback (most recent call last); <ipython-input-4-773196c7ecc9> in <module>; 6 U_list = []; 7 for (i,t) in enumerate(t_list):; ----> 8 U = propagator(H,t, [], args); 9 U_list.append(U); 10 print(i). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/prop",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:7879,Integrability,depend,depends,7879,"[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . ImportError: Building module cqobjevo_compiled_coeff_1212362029172 failed: [""distutils.errors.CompileError: command 'gcc' terminated by signal 6\n""]. The above exception was the direct cause of the following exception:. Exception Traceback (most recent call last); <ipython-input-4-773196c7ecc9> in <module>; 6 U_list = []; 7 for (i,t) in enumerate(t_list):; ----> 8 U = propagator(H,t, [], args); 9 U_list.append(U); 10 print(i). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/propagator.py in propagator(H, t, c_op_list, args, opti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:8046,Integrability,depend,depends,8046,"ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in build_extensions(self); 194 # Call original build_extensions; --> 195 _build_ext.build_ext.build_extensions(self); 196 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extensions(self); 448 else:; --> 449 self._build_extensions_serial(); 450 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in _build_extensions_serial(self); 473 with self._filter_build_errors(ext):; --> 474 self.build_extension(ext); 475 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in build_extension(self, ext); 533 extra_postargs=extra_args,; --> 534 depends=ext.depends); 535 . ~/opt/anaconda3/lib/python3.7/distutils/ccompiler.py in compile(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends); 573 continue; --> 574 self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts); 575 . ~/opt/anaconda3/lib/python3.7/distutils/unixccompiler.py in _compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts); 119 except DistutilsExecError as msg:; --> 120 raise CompileError(msg); 121 . ImportError: Building module cqobjevo_compiled_coeff_1212362029172 failed: [""distutils.errors.CompileError: command 'gcc' terminated by signal 6\n""]. The above exception was the direct cause of the following exception:. Exception Traceback (most recent call last); <ipython-input-4-773196c7ecc9> in <module>; 6 U_list = []; 7 for (i,t) in enumerate(t_list):; ----> 8 U = propagator(H,t, [], args); 9 U_list.append(U); 10 print(i). ~/opt/anaconda3/lib/python3.7/site-packages/qutip/propagator.py in propagator(H, t, c_op_list, args, options, unitary_mode, parallel, progress_bar, _safe_mode, **kwargs); 184 output = sesolve(H2, psi0, tlist, [],; 185 args=args, opt",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:2636,Testability,assert,assert,2636," search_path, dry_run=dry_run); 37 elif os.name == 'nt':. ~/opt/anaconda3/lib/python3.7/distutils/spawn.py in _spawn_posix(cmd, search_path, verbose, dry_run); 148 ""command %r terminated by signal %d""; --> 149 % (cmd, os.WTERMSIG(status))); 150 elif os.WIFEXITED(status):. DistutilsExecError: command 'gcc' terminated by signal 6. During handling of the above exception, another exception occurred:. CompileError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in load_module(name, pyxfilename, pyxbuild_dir, is_package, build_inplace, language_level, so_path); 214 so_path = build_module(module_name, pyxfilename, pyxbuild_dir,; --> 215 inplace=build_inplace, language_level=language_level); 216 mod = imp.load_dynamic(name, so_path). ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in build_module(name, pyxfilename, pyxbuild_dir, inplace, language_level); 190 inplace=inplace,; --> 191 reload_support=pyxargs.reload_support); 192 assert os.path.exists(so_path), ""Cannot find: %s"" % so_path. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyxbuild.py in pyx_to_dll(filename, ext, force_rebuild, build_in_temp, pyxbuild_dir, setup_args, reload_support, inplace); 101 obj_build_ext = dist.get_command_obj(""build_ext""); --> 102 dist.run_commands(); 103 so_path = obj_build_ext.get_outputs()[0]. ~/opt/anaconda3/lib/python3.7/distutils/dist.py in run_commands(self); 965 for cmd in self.commands:; --> 966 self.run_command(cmd); 967 . ~/opt/anaconda3/lib/python3.7/distutils/dist.py in run_command(self, command); 984 cmd_obj.ensure_finalized(); --> 985 cmd_obj.run(); 986 self.have_run[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664714290:6228,Testability,assert,assert,6228," ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in load_module(self, fullname); 461 build_inplace=self.inplace,; --> 462 language_level=self.language_level); 463 return module. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in load_module(name, pyxfilename, pyxbuild_dir, is_package, build_inplace, language_level, so_path); 230 if sys.version_info[0] >= 3:; --> 231 raise exc.with_traceback(tb); 232 else:. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in load_module(name, pyxfilename, pyxbuild_dir, is_package, build_inplace, language_level, so_path); 214 so_path = build_module(module_name, pyxfilename, pyxbuild_dir,; --> 215 inplace=build_inplace, language_level=language_level); 216 mod = imp.load_dynamic(name, so_path). ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyximport.py in build_module(name, pyxfilename, pyxbuild_dir, inplace, language_level); 190 inplace=inplace,; --> 191 reload_support=pyxargs.reload_support); 192 assert os.path.exists(so_path), ""Cannot find: %s"" % so_path. ~/opt/anaconda3/lib/python3.7/site-packages/pyximport/pyxbuild.py in pyx_to_dll(filename, ext, force_rebuild, build_in_temp, pyxbuild_dir, setup_args, reload_support, inplace); 101 obj_build_ext = dist.get_command_obj(""build_ext""); --> 102 dist.run_commands(); 103 so_path = obj_build_ext.get_outputs()[0]. ~/opt/anaconda3/lib/python3.7/distutils/dist.py in run_commands(self); 965 for cmd in self.commands:; --> 966 self.run_command(cmd); 967 . ~/opt/anaconda3/lib/python3.7/distutils/dist.py in run_command(self, command); 984 cmd_obj.ensure_finalized(); --> 985 cmd_obj.run(); 986 self.have_run[command] = 1. ~/opt/anaconda3/lib/python3.7/site-packages/Cython/Distutils/old_build_ext.py in run(self); 185 ; --> 186 _build_ext.build_ext.run(self); 187 . ~/opt/anaconda3/lib/python3.7/distutils/command/build_ext.py in run(self); 339 # Now actually compile and link everything.; --> 340 self.build_extensions(); 341 . ~/opt/anaconda3",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664714290
https://github.com/qutip/qutip/issues/1326#issuecomment-664716642:124,Availability,down,downgrade,124,"Are you running on OSX? If so, this could be a known bug between multiprocessing and matplotlib for matplotlib 3.2. You can downgrade to 3.1 or upgrade to 3.3 (haven't personally validated 3.3 yet).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664716642
https://github.com/qutip/qutip/issues/1326#issuecomment-664716642:144,Deployability,upgrade,upgrade,144,"Are you running on OSX? If so, this could be a known bug between multiprocessing and matplotlib for matplotlib 3.2. You can downgrade to 3.1 or upgrade to 3.3 (haven't personally validated 3.3 yet).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664716642
https://github.com/qutip/qutip/issues/1326#issuecomment-664716642:179,Security,validat,validated,179,"Are you running on OSX? If so, this could be a known bug between multiprocessing and matplotlib for matplotlib 3.2. You can downgrade to 3.1 or upgrade to 3.3 (haven't personally validated 3.3 yet).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664716642
https://github.com/qutip/qutip/issues/1326#issuecomment-664736506:114,Availability,error,errors,114,"Yes, I am running on OS X. Thanks for the advice, it worked. I see that matplotlib 3.1.0 and 3.3.0 don't give any errors but anything in between would result into the error. ; PS: I was using 3.1.3",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664736506
https://github.com/qutip/qutip/issues/1326#issuecomment-664736506:167,Availability,error,error,167,"Yes, I am running on OS X. Thanks for the advice, it worked. I see that matplotlib 3.1.0 and 3.3.0 don't give any errors but anything in between would result into the error. ; PS: I was using 3.1.3",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-664736506
https://github.com/qutip/qutip/issues/1326#issuecomment-832382977:65,Availability,error,error,65,"Seems to be back with matplotlib 3.4.1 in my case - exactly same error, very annoying (from matplotlib's site). QuTiP Version: 4.6.0; Numpy Version: 1.20.2; Scipy Version: 1.6.3; Cython Version: 0.29.23; Matplotlib Version: 3.4.1; Python Version: 3.8.8; Number of CPUs: 32; BLAS Info: OPENBLAS; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/XXX/anaconda3/envs/qutip/lib/python3.8/site-packages/qutip. raise Exception(""Could not convert string to importable function, ""; Exception: Could not convert string to importable function, tmpfile:cqobjevo_compiled_coeff_xxxxx.pyx",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-832382977
https://github.com/qutip/qutip/issues/1326#issuecomment-832382977:302,Deployability,Install,Installed,302,"Seems to be back with matplotlib 3.4.1 in my case - exactly same error, very annoying (from matplotlib's site). QuTiP Version: 4.6.0; Numpy Version: 1.20.2; Scipy Version: 1.6.3; Cython Version: 0.29.23; Matplotlib Version: 3.4.1; Python Version: 3.8.8; Number of CPUs: 32; BLAS Info: OPENBLAS; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/XXX/anaconda3/envs/qutip/lib/python3.8/site-packages/qutip. raise Exception(""Could not convert string to importable function, ""; Exception: Could not convert string to importable function, tmpfile:cqobjevo_compiled_coeff_xxxxx.pyx",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-832382977
https://github.com/qutip/qutip/issues/1326#issuecomment-832382977:373,Deployability,Install,Installation,373,"Seems to be back with matplotlib 3.4.1 in my case - exactly same error, very annoying (from matplotlib's site). QuTiP Version: 4.6.0; Numpy Version: 1.20.2; Scipy Version: 1.6.3; Cython Version: 0.29.23; Matplotlib Version: 3.4.1; Python Version: 3.8.8; Number of CPUs: 32; BLAS Info: OPENBLAS; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/XXX/anaconda3/envs/qutip/lib/python3.8/site-packages/qutip. raise Exception(""Could not convert string to importable function, ""; Exception: Could not convert string to importable function, tmpfile:cqobjevo_compiled_coeff_xxxxx.pyx",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-832382977
https://github.com/qutip/qutip/issues/1326#issuecomment-996827395:16,Availability,error,error,16,This is also an error for me. Do I need to downconvert matplotlib for windows as well?. QuTiP Version: 4.6.2; Numpy Version: 1.21.2; Scipy Version: 1.7.1; Cython Version: 0.29.24; Matplotlib Version: 3.5.0; Python Version: 3.9.7; Number of CPUs: 12; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Windows (AMD64); Installation path: C:\Users\XXX\Anaconda3\envs\qutip\lib\site-packages\qutip,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-996827395
https://github.com/qutip/qutip/issues/1326#issuecomment-996827395:43,Availability,down,downconvert,43,This is also an error for me. Do I need to downconvert matplotlib for windows as well?. QuTiP Version: 4.6.2; Numpy Version: 1.21.2; Scipy Version: 1.7.1; Cython Version: 0.29.24; Matplotlib Version: 3.5.0; Python Version: 3.9.7; Number of CPUs: 12; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Windows (AMD64); Installation path: C:\Users\XXX\Anaconda3\envs\qutip\lib\site-packages\qutip,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-996827395
https://github.com/qutip/qutip/issues/1326#issuecomment-996827395:279,Deployability,Install,Installed,279,This is also an error for me. Do I need to downconvert matplotlib for windows as well?. QuTiP Version: 4.6.2; Numpy Version: 1.21.2; Scipy Version: 1.7.1; Cython Version: 0.29.24; Matplotlib Version: 3.5.0; Python Version: 3.9.7; Number of CPUs: 12; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Windows (AMD64); Installation path: C:\Users\XXX\Anaconda3\envs\qutip\lib\site-packages\qutip,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-996827395
https://github.com/qutip/qutip/issues/1326#issuecomment-996827395:351,Deployability,Install,Installation,351,This is also an error for me. Do I need to downconvert matplotlib for windows as well?. QuTiP Version: 4.6.2; Numpy Version: 1.21.2; Scipy Version: 1.7.1; Cython Version: 0.29.24; Matplotlib Version: 3.5.0; Python Version: 3.9.7; Number of CPUs: 12; BLAS Info: INTEL MKL; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Windows (AMD64); Installation path: C:\Users\XXX\Anaconda3\envs\qutip\lib\site-packages\qutip,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1326#issuecomment-996827395
https://github.com/qutip/qutip/issues/1330#issuecomment-794673938:227,Availability,error,error,227,"@BoxiLi I am a bit confused with the wording of this issue. Is the goal to find what other gates might be creating `ValueError` when `resolve_gates` acts on them ? Then once these gates are identified, figure out the source of error in code of `resolve_gates` ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-794673938
https://github.com/qutip/qutip/issues/1330#issuecomment-794864771:136,Availability,error,error,136,"Yep, the `resolve_gates()` function is quite messy right now and works on a case by case basis. In the FREDKIN case, it was giving this error. The issue would atleast involve resolving the FREDKIN gate properly as a starting point. . As an aside, @BoxiLi Should this issue be moved to the qutip_qip module already? Or should it wait since everything is not setup there yet?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-794864771
https://github.com/qutip/qutip/issues/1330#issuecomment-806265083:167,Availability,error,error,167,"Hi @sarsid I am having trouble reproducing this issue. When I copied above code, I get `<qutip.qip.circuit.QubitCircuit object at 0x7fe142c414f0>` and not the `value` error referenced by you. Is there something else I should be doing ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-806265083
https://github.com/qutip/qutip/issues/1330#issuecomment-806463739:34,Availability,error,error,34,"Just tried this, I still the same error. So the `resolve_gates()` function works for you? What are the gates you get in the end? Are they correct?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-806463739
https://github.com/qutip/qutip/issues/1330#issuecomment-810442694:139,Availability,error,error,139,"@BoxiLi I have the latest version installed. . I do not get any gates after applying `resolve_gates()`. My issue is I fail to get the same error type i.e. `ValueError`. When I ran the code as it is, I do not get any gates besides an indicator that the code ran successfully. So, I used `print(A.resolve_gates())` which gave me `qutip.qip.circuit.QubitCircuit object at 0x7fb64044eaf0`. This is most definitely not the expected output of `resolve_gates()` as specified [here](https://github.com/qutip/qutip/blob/8681e995c09986a4355ba16d586dd2d2f1f49657/qutip/qip/circuit.py#L1205)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810442694
https://github.com/qutip/qutip/issues/1330#issuecomment-810442694:34,Deployability,install,installed,34,"@BoxiLi I have the latest version installed. . I do not get any gates after applying `resolve_gates()`. My issue is I fail to get the same error type i.e. `ValueError`. When I ran the code as it is, I do not get any gates besides an indicator that the code ran successfully. So, I used `print(A.resolve_gates())` which gave me `qutip.qip.circuit.QubitCircuit object at 0x7fb64044eaf0`. This is most definitely not the expected output of `resolve_gates()` as specified [here](https://github.com/qutip/qutip/blob/8681e995c09986a4355ba16d586dd2d2f1f49657/qutip/qip/circuit.py#L1205)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810442694
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:235,Availability,error,error,235,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:473,Availability,error,error,473,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:161,Deployability,release,released,161,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:268,Deployability,release,released,268,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:300,Deployability,install,install,300,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:350,Deployability,install,installation,350,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:368,Deployability,install,installing-from-source,368,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:479,Integrability,message,message,479,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810554275:78,Usability,clear,clearly,78,"Interesting... You see, the gate `Gate(RY, targets=[0, 1], controls=None)` is clearly wrong because RY acts only on one qubits. I guess you are probably using a released version of QuTiP (4.5.2/3 maybe) and not the master branch. This error was hidden before in those released version. If you try to install from source (http://qutip.org/docs/latest/installation.html#installing-from-source) (which you have to if you want to contribute anyway), you will probably see this error message.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810554275
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:230,Availability,error,error,230,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:277,Availability,error,error,277,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:330,Deployability,release,released,330,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:395,Deployability,install,installing,395,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:465,Deployability,install,install,465,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:489,Integrability,depend,dependencies,489,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:357,Safety,predict,predicted,357,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/issues/1330#issuecomment-810592555:63,Usability,clear,clearly,63,"> You see, the gate Gate(RY, targets=[0, 1], controls=None) is clearly wrong because RY acts only on one qubits. Yep ! That's what I thought as well..for all the single qubit gate outputs with two targets. I knew I was getting an error but was not sure why it was not the same error as both of you. It was because I was using the released version (like you predicted). . I was trying to put off installing from source for as long as I could because I would have to install conda and other dependencies manually. Now, I did get `ValuError`. Thanks !",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1330#issuecomment-810592555
https://github.com/qutip/qutip/pull/1331#issuecomment-702203287:113,Usability,Guid,Guide,113,Well done @sarsid. Could you make sure that the documentation is still up to date? Adding something in the Users Guide about this would be very helpful.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1331#issuecomment-702203287
https://github.com/qutip/qutip/pull/1332#issuecomment-665737386:90,Usability,simpl,simplified,90,"This is the same PR as #1328, but resubmitted so the commit history and files changed are simplified after the merging of #1296.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-665737386
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:79,Availability,error,error,79,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:335,Availability,fault,faulthandler,335,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:566,Availability,error,error,566,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:680,Availability,down,down,680,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:875,Availability,error,error,875,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:228,Energy Efficiency,allocate,allocated,228,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:253,Energy Efficiency,allocate,allocated,253,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:432,Energy Efficiency,allocate,allocated,432,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-668847474:557,Security,checksum,checksum,557,"2dd4680 and b6dcc28 fix the occasional segfaults I was getting, I believe. The error in `reshape_csr` was probably the randomly appearing one - I assume that for it to cause a segfault, either the output CSR needed to have been allocated on the edge of allocated memory (and then I probably would have seen it in the stack trace with `faulthandler`), or it needed to be called on a sufficiently small matrix that `mem.PyMem_Malloc` allocated into Python stack memory such that the next byte after `out.row_index` pointed into freed Python memory, causing a checksum error on the next `PyMem_Malloc` that hit it, or `PyMem_Free` on a previously created object. I was able to track down where these were coming from by judicious use of `gcc -fsanitize`, although had we been using Cython's `typedmemoryview`, setting `boundscheck=True` would also have caught it. Likewise, the error in `permute.dimensions_csr` would have been caught by setting `cdivision=False`, but I just didn't think to try that. It's probably not worth swapping to memory views just because of this, though - I was able to find it easily enough with `AddressSanitizer`, and memory views have a very non-trivial overhead on initialisation for our use case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-668847474
https://github.com/qutip/qutip/pull/1332#issuecomment-671526504:756,Integrability,message,messages,756,"@Ericgig b7cd10a creates a new `qutip.solve` package, and I moved all the solvers and most of their utilities into there. I put Cython utility modules into the same directory, and just prefixed their names with underscores to mark them as internal, rather than making another new `cy` directory. I also moved the tests of the solvers into their own `tests/solve` directory, so we can consider having `pytest` run the tests in order at some point as well. All the names are still imported properly into the `qutip` namespace, so you can still do `qutip.mesolve` and so on. This PR is already way too long. I could put the solver package commit into a different PR if it's helpful, but to be honest, I'm not sure entirely what benefit is derived - my commit messages are usually quite descriptive (please don't squash them!), so it's not like the history will be missing in `git log`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671526504
https://github.com/qutip/qutip/pull/1332#issuecomment-671526504:313,Testability,test,tests,313,"@Ericgig b7cd10a creates a new `qutip.solve` package, and I moved all the solvers and most of their utilities into there. I put Cython utility modules into the same directory, and just prefixed their names with underscores to mark them as internal, rather than making another new `cy` directory. I also moved the tests of the solvers into their own `tests/solve` directory, so we can consider having `pytest` run the tests in order at some point as well. All the names are still imported properly into the `qutip` namespace, so you can still do `qutip.mesolve` and so on. This PR is already way too long. I could put the solver package commit into a different PR if it's helpful, but to be honest, I'm not sure entirely what benefit is derived - my commit messages are usually quite descriptive (please don't squash them!), so it's not like the history will be missing in `git log`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671526504
https://github.com/qutip/qutip/pull/1332#issuecomment-671526504:350,Testability,test,tests,350,"@Ericgig b7cd10a creates a new `qutip.solve` package, and I moved all the solvers and most of their utilities into there. I put Cython utility modules into the same directory, and just prefixed their names with underscores to mark them as internal, rather than making another new `cy` directory. I also moved the tests of the solvers into their own `tests/solve` directory, so we can consider having `pytest` run the tests in order at some point as well. All the names are still imported properly into the `qutip` namespace, so you can still do `qutip.mesolve` and so on. This PR is already way too long. I could put the solver package commit into a different PR if it's helpful, but to be honest, I'm not sure entirely what benefit is derived - my commit messages are usually quite descriptive (please don't squash them!), so it's not like the history will be missing in `git log`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671526504
https://github.com/qutip/qutip/pull/1332#issuecomment-671526504:417,Testability,test,tests,417,"@Ericgig b7cd10a creates a new `qutip.solve` package, and I moved all the solvers and most of their utilities into there. I put Cython utility modules into the same directory, and just prefixed their names with underscores to mark them as internal, rather than making another new `cy` directory. I also moved the tests of the solvers into their own `tests/solve` directory, so we can consider having `pytest` run the tests in order at some point as well. All the names are still imported properly into the `qutip` namespace, so you can still do `qutip.mesolve` and so on. This PR is already way too long. I could put the solver package commit into a different PR if it's helpful, but to be honest, I'm not sure entirely what benefit is derived - my commit messages are usually quite descriptive (please don't squash them!), so it's not like the history will be missing in `git log`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671526504
https://github.com/qutip/qutip/pull/1332#issuecomment-671526504:877,Testability,log,log,877,"@Ericgig b7cd10a creates a new `qutip.solve` package, and I moved all the solvers and most of their utilities into there. I put Cython utility modules into the same directory, and just prefixed their names with underscores to mark them as internal, rather than making another new `cy` directory. I also moved the tests of the solvers into their own `tests/solve` directory, so we can consider having `pytest` run the tests in order at some point as well. All the names are still imported properly into the `qutip` namespace, so you can still do `qutip.mesolve` and so on. This PR is already way too long. I could put the solver package commit into a different PR if it's helpful, but to be honest, I'm not sure entirely what benefit is derived - my commit messages are usually quite descriptive (please don't squash them!), so it's not like the history will be missing in `git log`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671526504
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:963,Modifiability,config,configspec,963,"Yeah, you're right, I should have done the style changes in a different PR. It was mostly a lack of thought - I have a linter hooked into my text editor, so I get gutter-marks telling me all the PEP8 inconsistencies and stuff like that, and I usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; quti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:325,Testability,assert,assert,325,"Yeah, you're right, I should have done the style changes in a different PR. It was mostly a lack of thought - I have a linter hooked into my text editor, so I get gutter-marks telling me all the PEP8 inconsistencies and stuff like that, and I usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; quti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:371,Testability,test,tests,371,"Yeah, you're right, I should have done the style changes in a different PR. It was mostly a lack of thought - I have a linter hooked into my text editor, so I get gutter-marks telling me all the PEP8 inconsistencies and stuff like that, and I usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; quti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:389,Testability,assert,assert,389,"Yeah, you're right, I should have done the style changes in a different PR. It was mostly a lack of thought - I have a linter hooked into my text editor, so I get gutter-marks telling me all the PEP8 inconsistencies and stuff like that, and I usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; quti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1545,Testability,test,tests,1545,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1578,Testability,test,tests,1578,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1603,Testability,test,tests,1603,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1628,Testability,test,tests,1628,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1652,Testability,test,tests,1652,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1695,Testability,test,tests,1695,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1738,Testability,test,tests,1738,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1778,Testability,test,tests,1778,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1821,Testability,test,tests,1821,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1859,Testability,test,tests,1859,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1906,Testability,test,tests,1906,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1946,Testability,test,tests,1946,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:1975,Testability,test,tests,1975,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2003,Testability,test,tests,2003,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2033,Testability,test,tests,2033,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2072,Testability,test,tests,2072,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2098,Testability,test,tests,2098,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2123,Testability,test,tests,2123,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-671534803:2148,Testability,test,tests,2148,"usually change them without thinking. The `assert_` usually gets changed to bare `assert` when I'm actually trying to debug the tests - the bare `assert` gives _far_ more debugging detail with `pytest`, so it's much more helpful. By the way, if you're interested, the list of files which _didn't_ change is; ```text; .codeclimate.yml; .coveragerc; .github/ISSUE_TEMPLATE/bug_report.md; .github/ISSUE_TEMPLATE/feature_request.md; .github/ISSUE_TEMPLATE/others.md; .github/pull_request_template.md; .mailmap; .travis.yml; CODE_OF_CONDUCT.md; LICENSE.txt; README.md; pyproject.toml; qutip.bib; qutip/_mkl/__init__.py; qutip/_mkl/spmv.py; qutip/_mkl/spsolve.py; qutip/_mkl/utilities.py; qutip/about.py; qutip/cite.py; qutip/configspec.ini; qutip/control/__init__.py; qutip/control/cy_grape.pyx; qutip/hardware_info.py; qutip/ipynbtools.py; qutip/logging_utils.py; qutip/matplotlib_utilities.py; qutip/orbital.py; qutip/parallel.py; qutip/qip/__init__.py; qutip/qip/algorithms/__init__.py; qutip/qip/circuit_latex.py; qutip/qip/compiler/__init__.py; qutip/qip/compiler/cavityqedcompiler.py; qutip/qip/compiler/gatecompiler.py; qutip/qip/compiler/spinchaincompiler.py; qutip/qip/device/__init__.py; qutip/qip/gates.py; qutip/qip/operations/__init__.py; qutip/qip/qasm.py; qutip/qip/qip_deprecation.py; qutip/tests/Hadamard_params.ini; qutip/tests/__init__.py; qutip/tests/conftest.py; qutip/tests/pytest.ini; qutip/tests/qasm_files/bracket_error.qasm; qutip/tests/qasm_files/command_error.qasm; qutip/tests/qasm_files/qasm_error.qasm; qutip/tests/qasm_files/teleportation.qasm; qutip/tests/qasm_files/test_add.qasm; qutip/tests/qasm_files/test_custom_gates.qasm; qutip/tests/test_control_pulseoptim.py; qutip/tests/test_entropy.py; qutip/tests/test_fileio.py; qutip/tests/test_parallel.py; qutip/tests/test_partial_transpose.py; qutip/tests/test_qasm.py; qutip/tests/test_qft.py; qutip/tests/test_qpt.py; qutip/tests/test_utilities.py; qutip/ui/__init__.py; qutip/ui/progressbar.py; qutip/utilities.py; ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-671534803
https://github.com/qutip/qutip/pull/1332#issuecomment-672831585:622,Testability,test,tested,622,"> [![Coverage Status](https://camo.githubusercontent.com/5b95d685d6392d8f3beccad1e575f46ea5187ccd/68747470733a2f2f636f766572616c6c732e696f2f6275696c64732f33323635363130332f6261646765)](https://coveralls.io/builds/32656103); > ; > Coverage decreased (-10.2%) to 60.763% when pulling **[3b09002](https://github.com/qutip/qutip/commit/3b090027a58ee842c419244920d65623d70ee4a2) on jakelishman:core-replace-fast_csr_matrix** into **[0740a04](https://github.com/qutip/qutip/commit/0740a04cf0b9286b5e13cb0bcf026de6b284c011) on qutip:dev.major**. It should be noted that the coverage drop is so large here because large tracts of tested Python source files were removed and replaced by _Cython_ source files, which Coveralls does not handle correctly. These files typically are tested (albeit not yet completely), but Coveralls reports `.pyx` files as having 7 lines of code, of which all 7 are missed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-672831585
https://github.com/qutip/qutip/pull/1332#issuecomment-672831585:770,Testability,test,tested,770,"> [![Coverage Status](https://camo.githubusercontent.com/5b95d685d6392d8f3beccad1e575f46ea5187ccd/68747470733a2f2f636f766572616c6c732e696f2f6275696c64732f33323635363130332f6261646765)](https://coveralls.io/builds/32656103); > ; > Coverage decreased (-10.2%) to 60.763% when pulling **[3b09002](https://github.com/qutip/qutip/commit/3b090027a58ee842c419244920d65623d70ee4a2) on jakelishman:core-replace-fast_csr_matrix** into **[0740a04](https://github.com/qutip/qutip/commit/0740a04cf0b9286b5e13cb0bcf026de6b284c011) on qutip:dev.major**. It should be noted that the coverage drop is so large here because large tracts of tested Python source files were removed and replaced by _Cython_ source files, which Coveralls does not handle correctly. These files typically are tested (albeit not yet completely), but Coveralls reports `.pyx` files as having 7 lines of code, of which all 7 are missed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1332#issuecomment-672831585
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:107,Availability,error,error,107,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:284,Availability,error,error,284,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:509,Availability,error,error,509,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:713,Availability,error,error,713,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:34,Deployability,install,install,34,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:335,Deployability,install,install,335,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670003770:420,Testability,test,test,420,"I couldn't reproduce this with an install into a fresh `conda` environment, _but_ I did once see that same error when I tried to make an OpenMP and a non-OpenMP `qutip` coexist in the same environment. When that previously happened, the package actually worked, it just reported that error. My guess is that this happens if `pyximport.install()` has already been activated when `qutip` is imported, and consequently the test in `__init__.py` as to whether `qutip.cy.openmp.parfuncs` is importable causes this error. It should not be able to even attempt to import it _unless_ `pyximport` has been turned on, and if it's been turned on by something other than QuTiP, then it should fail with a `numpy` header file error instead (this is something we should probably fix too, but I've not noticed it before). Is there any chance you're importing or reimporting `qutip` in a Python session in which some other version of `qutip` is already imported (like in an IPython profile file)?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670003770
https://github.com/qutip/qutip/issues/1334#issuecomment-670133651:66,Deployability,install,install,66,"Yeah, it was not a fresh conda, but one that I did not previously install QuTiP in. However, that warning is essentially telling me that it is trying to build the Cython openmp stuff at init. It should not be doing this, but will do so if it is trying to load a Cython generated file that was not built yet.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670133651
https://github.com/qutip/qutip/issues/1334#issuecomment-670133651:255,Performance,load,load,255,"Yeah, it was not a fresh conda, but one that I did not previously install QuTiP in. However, that warning is essentially telling me that it is trying to build the Cython openmp stuff at init. It should not be doing this, but will do so if it is trying to load a Cython generated file that was not built yet.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670133651
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:207,Availability,error,error,207,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:785,Availability,error,error,785,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:1105,Availability,error,error,1105,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:1255,Availability,error,error,1255,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:231,Deployability,install,install,231,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:331,Deployability,install,install,331,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:488,Testability,test,test,488,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670167290:1292,Usability,simpl,simplify,1292,"Do you get the same behaviour with QuTiP 4.5.0 in the same environment? The offending parts of `qutip/__init__.py` have been there since then, so it shouldn't be new in 4.5.2 at least. I can't reproduce the error unless `pyximport.install()` has already been run before QuTiP is imported (e.g. if I do `import pyximport; pyximport.install(); import qutip` or `importlib.reload(qutip)`). We have `qutip/__init__.py` organised so that we don't enable `pyximport` until after we've done the test for `qutip.cy.openmp.parfuncs`: first we do. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L100-L105. and only after that do we. https://github.com/qutip/qutip/blob/8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291/qutip/__init__.py#L124-L126. In your error it's trying to build `qutip.cy.openmp.parfuncs`, and the only line that ever attempts to import that (in Python space) is line 101 above in `__init__`. It can only attempt to Cythonize files if `pyximport` is activated, but `qutip` doesn't activate that til a few lines later. It's certainly still a bug that this error appears if you've manually activated `pyximport` before (which would definitely cause it), but I'm struggling to find any other reason that the error could appear. We're looking to simplify the handling of OpenMP in a later version, and this buggy check is certainly a good reason to expedite that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670167290
https://github.com/qutip/qutip/issues/1334#issuecomment-670170527:13,Safety,safe,safest,13,"Probably the safest solution for us right now is to completely elide this run-time check, and have `setup.py` hard-code the value of `settings.has_openmp` at compile time. Does that sound reasonable to you (since you wrote most of the original OpenMP stuff [and most of the current QuTiP code...])? Also checking with @Ericgig, since I know you're a heavy user of it too. Edit: I forgot, I actually already fixed the possibility of this happening in `dev.major` - it uses a much more rigorous `importlib` import to ensure that we're attempting the OpenMP bit with the natural import system, and so it doesn't conflict with relative imports elsewhere in `qutip`:. https://github.com/qutip/qutip/blob/3f5c2980cff42067c0f93b226d3f07be9ef9022a/qutip/__init__.py#L107-L117",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670170527
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:26,Availability,error,error,26,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:188,Availability,error,error,188,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:37,Deployability,install,installing,37,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:65,Deployability,install,install,65,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:115,Deployability,install,install,115,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:225,Deployability,install,install,225,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-670227091:269,Deployability,install,installation,269,"I often get these kind of error when installing manually. If you install Qutip with openmp once, the next time you install it without, you need to clean the old version or you get similar error. I never got this from a clean install. . Setting the `has_openmp` flag at installation is better, but I would let the precompiler set it instead of setup.py.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-670227091
https://github.com/qutip/qutip/issues/1334#issuecomment-671442741:28,Deployability,install,install,28,"Also, recently using `conda install qutip` seems to not locate the qutip package and one needs to add the `conda-forge` channel. Should we change the installation instructions on the website?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671442741
https://github.com/qutip/qutip/issues/1334#issuecomment-671442741:150,Deployability,install,installation,150,"Also, recently using `conda install qutip` seems to not locate the qutip package and one needs to add the `conda-forge` channel. Should we change the installation instructions on the website?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671442741
https://github.com/qutip/qutip/issues/1334#issuecomment-671444213:64,Deployability,install,installation,64,"@quantshah: This has always been the case, and it's part of the installation instructions in the user guide (http://qutip.org/docs/latest/installation.html#platform-independent-installation). If there's anywhere it's missing we should add it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671444213
https://github.com/qutip/qutip/issues/1334#issuecomment-671444213:138,Deployability,install,installation,138,"@quantshah: This has always been the case, and it's part of the installation instructions in the user guide (http://qutip.org/docs/latest/installation.html#platform-independent-installation). If there's anywhere it's missing we should add it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671444213
https://github.com/qutip/qutip/issues/1334#issuecomment-671444213:177,Deployability,install,installation,177,"@quantshah: This has always been the case, and it's part of the installation instructions in the user guide (http://qutip.org/docs/latest/installation.html#platform-independent-installation). If there's anywhere it's missing we should add it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671444213
https://github.com/qutip/qutip/issues/1334#issuecomment-671444213:102,Usability,guid,guide,102,"@quantshah: This has always been the case, and it's part of the installation instructions in the user guide (http://qutip.org/docs/latest/installation.html#platform-independent-installation). If there's anywhere it's missing we should add it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-671444213
https://github.com/qutip/qutip/issues/1334#issuecomment-809301114:78,Deployability,install,installation,78,"I'm going to close this for now because I think it's more to do with previous installation artifacts, which is something that is difficult to handle neatly without making a huge `__init__` full od all sorts of one-off special cases that only QuTiP developers ever encounter. We're doing a variant of Paul's suggestion in `dev.major` using new read-only ""installation settings"", and besides, we're going to have OpenMP built into the same C extensions and completely remove use of `pyximport` then too, so this sort of problem shouldn't appear again. It's possible we may still see very occasional bugs from QuTiP developers in the 4.x branch, but since it's mostly related to how QuTiP leaks its changes to the Python import process (via `pyximport`), which are fixed by the `Coefficient` object, it's probably not worth developer time back-porting such a major change.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-809301114
https://github.com/qutip/qutip/issues/1334#issuecomment-809301114:354,Deployability,install,installation,354,"I'm going to close this for now because I think it's more to do with previous installation artifacts, which is something that is difficult to handle neatly without making a huge `__init__` full od all sorts of one-off special cases that only QuTiP developers ever encounter. We're doing a variant of Paul's suggestion in `dev.major` using new read-only ""installation settings"", and besides, we're going to have OpenMP built into the same C extensions and completely remove use of `pyximport` then too, so this sort of problem shouldn't appear again. It's possible we may still see very occasional bugs from QuTiP developers in the 4.x branch, but since it's mostly related to how QuTiP leaks its changes to the Python import process (via `pyximport`), which are fixed by the `Coefficient` object, it's probably not worth developer time back-porting such a major change.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1334#issuecomment-809301114
https://github.com/qutip/qutip/pull/1336#issuecomment-672712550:40,Testability,test,tests,40,"> There are shims to make Pulse and qip tests work since they used QobjEvo.tlist and QobjEvo.ops.coeff.; @BoxiLi, the new QobjEvo can be added even if coefficient's tlist are different, but you cannot get back the tlist and the array from them. Also for _step_func_coeff, before the first time, Coefficient return the first value of the array, not 0 as expected in pulse.py. Thanks @Ericgig ! This is very useful!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1336#issuecomment-672712550
https://github.com/qutip/qutip/pull/1338#issuecomment-672881468:104,Integrability,depend,depend,104,"Oh, and I haven't exactly decided how the dispatchers will store their ""constructed"" methods yet. It'll depend a little on if there are major speed implications one way or the other (I'm especially concerned with the speed of binding to arbitrary function signatures), and whether they will require a huge amount of memory. I suspect that memory won't ever be too much concern - at their hearts, the dispatchers will mostly need a couple of `dict` attributes and a whole bunch of references to pre-existing objects. All that stuff is pretty light-weight.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-672881468
https://github.com/qutip/qutip/pull/1338#issuecomment-675463113:379,Availability,error,error,379,"@Ericgig: #1337 broke `mcsolve` seed reuse - it seems to be deliberate, since all the seed code has been explicitly cut. Is this something that `mcsolve` will no longer support? If so, we need to remove the tests of seeding, because they're failing the build, and if not we need to reinstate it quickly so we can have passing tests. Also options classes should probably throw an error when given an unknown key.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675463113
https://github.com/qutip/qutip/pull/1338#issuecomment-675463113:207,Testability,test,tests,207,"@Ericgig: #1337 broke `mcsolve` seed reuse - it seems to be deliberate, since all the seed code has been explicitly cut. Is this something that `mcsolve` will no longer support? If so, we need to remove the tests of seeding, because they're failing the build, and if not we need to reinstate it quickly so we can have passing tests. Also options classes should probably throw an error when given an unknown key.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675463113
https://github.com/qutip/qutip/pull/1338#issuecomment-675463113:326,Testability,test,tests,326,"@Ericgig: #1337 broke `mcsolve` seed reuse - it seems to be deliberate, since all the seed code has been explicitly cut. Is this something that `mcsolve` will no longer support? If so, we need to remove the tests of seeding, because they're failing the build, and if not we need to reinstate it quickly so we can have passing tests. Also options classes should probably throw an error when given an unknown key.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675463113
https://github.com/qutip/qutip/pull/1338#issuecomment-675510228:52,Testability,test,test,52,"Seed will be moved but not removed. Please skip the test for now.; I was surprised how easily the test where passing. If all the solver test where skipped, there may be a few fails.; I will add the KeyError in __setitem__.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675510228
https://github.com/qutip/qutip/pull/1338#issuecomment-675510228:98,Testability,test,test,98,"Seed will be moved but not removed. Please skip the test for now.; I was surprised how easily the test where passing. If all the solver test where skipped, there may be a few fails.; I will add the KeyError in __setitem__.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675510228
https://github.com/qutip/qutip/pull/1338#issuecomment-675510228:136,Testability,test,test,136,"Seed will be moved but not removed. Please skip the test for now.; I was surprised how easily the test where passing. If all the solver test where skipped, there may be a few fails.; I will add the KeyError in __setitem__.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675510228
https://github.com/qutip/qutip/pull/1338#issuecomment-675511997:268,Availability,error,error,268,"Yeah, I didn't notice before because I always run the tests locally before I push big things like that, and all the solver tests run locally, since it was just a packaging mix-up. As long as changing `__setitem__` means that `SolverOptions(seeds=[1, 2, 3])` throws an error (for now), then it's all good.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675511997
https://github.com/qutip/qutip/pull/1338#issuecomment-675511997:54,Testability,test,tests,54,"Yeah, I didn't notice before because I always run the tests locally before I push big things like that, and all the solver tests run locally, since it was just a packaging mix-up. As long as changing `__setitem__` means that `SolverOptions(seeds=[1, 2, 3])` throws an error (for now), then it's all good.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675511997
https://github.com/qutip/qutip/pull/1338#issuecomment-675511997:123,Testability,test,tests,123,"Yeah, I didn't notice before because I always run the tests locally before I push big things like that, and all the solver tests run locally, since it was just a packaging mix-up. As long as changing `__setitem__` means that `SolverOptions(seeds=[1, 2, 3])` throws an error (for now), then it's all good.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-675511997
https://github.com/qutip/qutip/pull/1338#issuecomment-676520794:752,Testability,test,tests,752,"I'm nervous because I haven't been able to work out why the segfaults in 9d67492 appeared, and I haven't been able to reproduce them at all. Running with AddressSanitizer on, I get absolutely no problems on Mac at all, and I set up a quick Linux VM and couldn't catch anything either. I had a real go at getting AddressSanitizer running on Travis on my own repo, but I wasn't successful, so couldn't get it that way either. It seems to have disappeared for now, so it _could_ just have been a one-off mess up in the environment, but that's not usually how computers work. Let's just keep an eye on it, and let me know if anyone can find a repro for it. Also note the coverage is back up to the _more_ reasonable (but still way too low) 73% now all the tests are enabled... Other than that, all the dispatchers are now in, but not yet used. This PR is ready for review, and I'll open a new one to make the switch over, because it'll involve changing a large number of files.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-676520794
https://github.com/qutip/qutip/pull/1338#issuecomment-678399544:277,Availability,fault,fault,277,"Just found what may have been the cause of the segfault. Incorrect indexing in `data.csr.Accumulator.gather` led to uninitialised memory being exposed if it encountered a zero value which in the current PR would only have been exposed by `Qobj.ptrace` on CSR to CSR, but by no fault of its own. This PR is ready for review - these last couple of patches I've just been sending could equally have gone to the next PR I'm preparing which is waiting for this one to be merged so I can rebase it on top of the new `dev.major`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-678399544
https://github.com/qutip/qutip/pull/1338#issuecomment-678399544:346,Deployability,patch,patches,346,"Just found what may have been the cause of the segfault. Incorrect indexing in `data.csr.Accumulator.gather` led to uninitialised memory being exposed if it encountered a zero value which in the current PR would only have been exposed by `Qobj.ptrace` on CSR to CSR, but by no fault of its own. This PR is ready for review - these last couple of patches I've just been sending could equally have gone to the next PR I'm preparing which is waiting for this one to be merged so I can rebase it on top of the new `dev.major`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-678399544
https://github.com/qutip/qutip/pull/1338#issuecomment-678399544:143,Security,expose,exposed,143,"Just found what may have been the cause of the segfault. Incorrect indexing in `data.csr.Accumulator.gather` led to uninitialised memory being exposed if it encountered a zero value which in the current PR would only have been exposed by `Qobj.ptrace` on CSR to CSR, but by no fault of its own. This PR is ready for review - these last couple of patches I've just been sending could equally have gone to the next PR I'm preparing which is waiting for this one to be merged so I can rebase it on top of the new `dev.major`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-678399544
https://github.com/qutip/qutip/pull/1338#issuecomment-678399544:227,Security,expose,exposed,227,"Just found what may have been the cause of the segfault. Incorrect indexing in `data.csr.Accumulator.gather` led to uninitialised memory being exposed if it encountered a zero value which in the current PR would only have been exposed by `Qobj.ptrace` on CSR to CSR, but by no fault of its own. This PR is ready for review - these last couple of patches I've just been sending could equally have gone to the next PR I'm preparing which is waiting for this one to be merged so I can rebase it on top of the new `dev.major`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-678399544
https://github.com/qutip/qutip/pull/1338#issuecomment-679246318:149,Energy Efficiency,efficient,efficient,149,"Yeah, `create` isn't fully done - it's basically the last resort for turning user input into a data-layer type, so it's not very important that it's efficient. We'll say in the documentation that it's preferable to create a `Dense` or `CSR` instance and pass that it, but have `data.create` as the backup to allow everything to ""just work"", albeit slowly. It will probably have an `add_creators` method, which will be similar to `add_specialisations` and `add_conversions`, but it'll only take an output type, a function and a priority. Then it'll probably just be a loop of `try: create(input); except: pass` until a creator succeeds. About the `*_csr` still used in `Qobj`: yes, these are deliberately left as-is in this PR, so as not to bulk up the files changed. There'll be a new PR to add those, and others to add more specialisations between `Dense` and `CSR`. Right now I'm writing a completely orthogonal PR updating the `pytest`, `coverage` and Coveralls support for `dev.major`. I'm not yet backporting that to the 4.X branch because the `sparse_routines.pxi` file complicates matters for the coverage, apparently...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1338#issuecomment-679246318
https://github.com/qutip/qutip/issues/1339#issuecomment-675449833:375,Testability,test,test,375,"Ok, so I found that Coveralls can actually handle Cython, or more, Cython can make itself check-able with coverage tools including `pytest-cov`: see https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html#enabling-line-tracing. We'll need to enable that to get better coverage reports. Also, I found that actually the particularly large drop in reported test coverage is _not_ just because of the swap to Cython, but because when I created the `qutip.solve` logical package, I moved the tests into `tests/solve`, but didn't correctly add that to the package creation portion of `setup.py`, so the tests weren't being run. Whoops. On #1338 the coverage has jumped back up to ~70% like it was before. Tag: @Ericgig.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1339#issuecomment-675449833
https://github.com/qutip/qutip/issues/1339#issuecomment-675449833:479,Testability,log,logical,479,"Ok, so I found that Coveralls can actually handle Cython, or more, Cython can make itself check-able with coverage tools including `pytest-cov`: see https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html#enabling-line-tracing. We'll need to enable that to get better coverage reports. Also, I found that actually the particularly large drop in reported test coverage is _not_ just because of the swap to Cython, but because when I created the `qutip.solve` logical package, I moved the tests into `tests/solve`, but didn't correctly add that to the package creation portion of `setup.py`, so the tests weren't being run. Whoops. On #1338 the coverage has jumped back up to ~70% like it was before. Tag: @Ericgig.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1339#issuecomment-675449833
https://github.com/qutip/qutip/issues/1339#issuecomment-675449833:508,Testability,test,tests,508,"Ok, so I found that Coveralls can actually handle Cython, or more, Cython can make itself check-able with coverage tools including `pytest-cov`: see https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html#enabling-line-tracing. We'll need to enable that to get better coverage reports. Also, I found that actually the particularly large drop in reported test coverage is _not_ just because of the swap to Cython, but because when I created the `qutip.solve` logical package, I moved the tests into `tests/solve`, but didn't correctly add that to the package creation portion of `setup.py`, so the tests weren't being run. Whoops. On #1338 the coverage has jumped back up to ~70% like it was before. Tag: @Ericgig.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1339#issuecomment-675449833
https://github.com/qutip/qutip/issues/1339#issuecomment-675449833:520,Testability,test,tests,520,"Ok, so I found that Coveralls can actually handle Cython, or more, Cython can make itself check-able with coverage tools including `pytest-cov`: see https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html#enabling-line-tracing. We'll need to enable that to get better coverage reports. Also, I found that actually the particularly large drop in reported test coverage is _not_ just because of the swap to Cython, but because when I created the `qutip.solve` logical package, I moved the tests into `tests/solve`, but didn't correctly add that to the package creation portion of `setup.py`, so the tests weren't being run. Whoops. On #1338 the coverage has jumped back up to ~70% like it was before. Tag: @Ericgig.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1339#issuecomment-675449833
https://github.com/qutip/qutip/issues/1339#issuecomment-675449833:618,Testability,test,tests,618,"Ok, so I found that Coveralls can actually handle Cython, or more, Cython can make itself check-able with coverage tools including `pytest-cov`: see https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html#enabling-line-tracing. We'll need to enable that to get better coverage reports. Also, I found that actually the particularly large drop in reported test coverage is _not_ just because of the swap to Cython, but because when I created the `qutip.solve` logical package, I moved the tests into `tests/solve`, but didn't correctly add that to the package creation portion of `setup.py`, so the tests weren't being run. Whoops. On #1338 the coverage has jumped back up to ~70% like it was before. Tag: @Ericgig.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1339#issuecomment-675449833
https://github.com/qutip/qutip/pull/1341#issuecomment-672845992:17,Availability,error,errors,17,The tests report errors because of the cancelled PR #1340 which was made to the wrong branch.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1341#issuecomment-672845992
https://github.com/qutip/qutip/pull/1341#issuecomment-672845992:4,Testability,test,tests,4,The tests report errors because of the cancelled PR #1340 which was made to the wrong branch.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1341#issuecomment-672845992
https://github.com/qutip/qutip/issues/1343#issuecomment-688294599:802,Deployability,Install,Installed,802,"Hi, thanks for the reply! My solution is never use spyder again, just use jupyter... and it works fine for me. :-); The following is what I get after running qutip.about():; QuTiP: Quantum Toolbox in Python. Copyright (c) QuTiP team 2011 and later.; Original developers: R. J. Johansson & P. D. Nation.; Previous lead developers: Chris Granade & A. Grimsmo.; Current admin team: Alexander Pitchford, Paul D. Nation, Nathan Shammah, Shahnawaz Ahmed, Neill Lambert, Eric Gigure, and Boxi Li; Project Manager: Franco Nori.; Currently developed through wide collaboration. See https://github.com/qutip for details. QuTiP Version: 4.5.2; Numpy Version: 1.19.1; Scipy Version: 1.2.0; Cython Version: 0.29.12; Matplotlib Version: 3.1.0; Python Version: 3.7.3; Number of CPUs: 4; BLAS Info: INTEL MKL; OPENMP Installed: True; INTEL MKL Ext: True; Platform Info: Windows (AMD64); Installation path: D:\python1\lib\site-packages\qutip. Please cite QuTiP in your publication. For your convenience a bibtex reference can be easily generated using `qutip.cite()`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1343#issuecomment-688294599
https://github.com/qutip/qutip/issues/1343#issuecomment-688294599:872,Deployability,Install,Installation,872,"Hi, thanks for the reply! My solution is never use spyder again, just use jupyter... and it works fine for me. :-); The following is what I get after running qutip.about():; QuTiP: Quantum Toolbox in Python. Copyright (c) QuTiP team 2011 and later.; Original developers: R. J. Johansson & P. D. Nation.; Previous lead developers: Chris Granade & A. Grimsmo.; Current admin team: Alexander Pitchford, Paul D. Nation, Nathan Shammah, Shahnawaz Ahmed, Neill Lambert, Eric Gigure, and Boxi Li; Project Manager: Franco Nori.; Currently developed through wide collaboration. See https://github.com/qutip for details. QuTiP Version: 4.5.2; Numpy Version: 1.19.1; Scipy Version: 1.2.0; Cython Version: 0.29.12; Matplotlib Version: 3.1.0; Python Version: 3.7.3; Number of CPUs: 4; BLAS Info: INTEL MKL; OPENMP Installed: True; INTEL MKL Ext: True; Platform Info: Windows (AMD64); Installation path: D:\python1\lib\site-packages\qutip. Please cite QuTiP in your publication. For your convenience a bibtex reference can be easily generated using `qutip.cite()`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1343#issuecomment-688294599
https://github.com/qutip/qutip/pull/1344#issuecomment-676162356:34,Testability,test,test,34,"Interesting, so doctest will also test docs in the code? How can I try it?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1344#issuecomment-676162356
https://github.com/qutip/qutip/pull/1344#issuecomment-676207593:36,Testability,test,test,36,"> Interesting, so doctest will also test docs in the code? How can I try it?. This are tested when you run `make doctest` as well. You can basically write the code example (like some already do) in the docstring of the function or class. For an example please check follow my other comment. It is indicated by the `>>>` and is tested unless skipped explicitly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1344#issuecomment-676207593
https://github.com/qutip/qutip/pull/1344#issuecomment-676207593:87,Testability,test,tested,87,"> Interesting, so doctest will also test docs in the code? How can I try it?. This are tested when you run `make doctest` as well. You can basically write the code example (like some already do) in the docstring of the function or class. For an example please check follow my other comment. It is indicated by the `>>>` and is tested unless skipped explicitly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1344#issuecomment-676207593
https://github.com/qutip/qutip/pull/1344#issuecomment-676207593:327,Testability,test,tested,327,"> Interesting, so doctest will also test docs in the code? How can I try it?. This are tested when you run `make doctest` as well. You can basically write the code example (like some already do) in the docstring of the function or class. For an example please check follow my other comment. It is indicated by the `>>>` and is tested unless skipped explicitly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1344#issuecomment-676207593
https://github.com/qutip/qutip/pull/1347#issuecomment-679416484:224,Testability,test,test-coverage,224,[![Coverage Status](https://coveralls.io/builds/33727290/badge)](https://coveralls.io/builds/33727290). Coverage decreased (-8.3%) to 63.214% when pulling **7ffdcd905b02144bb7fb70e7e2d86d02b63a30ba on jakelishman:master-fix-test-coverage** into **8e181cc44ceefc14ad0e4f4bcf78e1c8fcd2b291 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-679416484
https://github.com/qutip/qutip/pull/1347#issuecomment-679418397:329,Testability,test,test,329,"_Edit 2020-08-25:_ reporting to Coveralls is now fixed. As a bonus, I also fixed the tree reporting in Coveralls, so now you can get line-by-line coverage analysis within the files in the Coveralls webapp. _Orginal comment from when Coveralls reported at 0%:_; Ok, that Coveralls report is clearly broken, but you can see in the test log that the coverage reporting is correctly fixed (see the Linux, Python 3.7 report). I suspect that my directory hopping has caused the generated `.coverage` file to get lost, which I'll fix tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-679418397
https://github.com/qutip/qutip/pull/1347#issuecomment-679418397:334,Testability,log,log,334,"_Edit 2020-08-25:_ reporting to Coveralls is now fixed. As a bonus, I also fixed the tree reporting in Coveralls, so now you can get line-by-line coverage analysis within the files in the Coveralls webapp. _Orginal comment from when Coveralls reported at 0%:_; Ok, that Coveralls report is clearly broken, but you can see in the test log that the coverage reporting is correctly fixed (see the Linux, Python 3.7 report). I suspect that my directory hopping has caused the generated `.coverage` file to get lost, which I'll fix tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-679418397
https://github.com/qutip/qutip/pull/1347#issuecomment-679418397:290,Usability,clear,clearly,290,"_Edit 2020-08-25:_ reporting to Coveralls is now fixed. As a bonus, I also fixed the tree reporting in Coveralls, so now you can get line-by-line coverage analysis within the files in the Coveralls webapp. _Orginal comment from when Coveralls reported at 0%:_; Ok, that Coveralls report is clearly broken, but you can see in the test log that the coverage reporting is correctly fixed (see the Linux, Python 3.7 report). I suspect that my directory hopping has caused the generated `.coverage` file to get lost, which I'll fix tomorrow.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-679418397
https://github.com/qutip/qutip/pull/1347#issuecomment-680065748:17,Deployability,update,updates,17,"That last commit updates the versions of macOS and XCode that we test against. XCode 12 is comparatively very slow (both compile and run), so we should likely try to figure out why that's the case and improve it. We made the same commit on `dev.major` in #1348.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-680065748
https://github.com/qutip/qutip/pull/1347#issuecomment-680065748:65,Testability,test,test,65,"That last commit updates the versions of macOS and XCode that we test against. XCode 12 is comparatively very slow (both compile and run), so we should likely try to figure out why that's the case and improve it. We made the same commit on `dev.major` in #1348.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1347#issuecomment-680065748
https://github.com/qutip/qutip/pull/1348#issuecomment-679976149:9,Availability,failure,failure,9,"The test failure is unrelated; the swap to the new `CSR` type has meant that a few test tolerances have become much more fragile when considering numerical precision; since we're now using our own mathematical operations rather than scipy's, we're a bit more likely to have disagreements with them. This may also have to do with the new version of `Qobj` being more consistent about applying the `auto_tidyup` rule. This is one rule I really think we should look at removing or seriously reworking; it's basically just ""numerical imprecision as a feature, not a bug"".",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679976149
https://github.com/qutip/qutip/pull/1348#issuecomment-679976149:88,Availability,toler,tolerances,88,"The test failure is unrelated; the swap to the new `CSR` type has meant that a few test tolerances have become much more fragile when considering numerical precision; since we're now using our own mathematical operations rather than scipy's, we're a bit more likely to have disagreements with them. This may also have to do with the new version of `Qobj` being more consistent about applying the `auto_tidyup` rule. This is one rule I really think we should look at removing or seriously reworking; it's basically just ""numerical imprecision as a feature, not a bug"".",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679976149
https://github.com/qutip/qutip/pull/1348#issuecomment-679976149:4,Testability,test,test,4,"The test failure is unrelated; the swap to the new `CSR` type has meant that a few test tolerances have become much more fragile when considering numerical precision; since we're now using our own mathematical operations rather than scipy's, we're a bit more likely to have disagreements with them. This may also have to do with the new version of `Qobj` being more consistent about applying the `auto_tidyup` rule. This is one rule I really think we should look at removing or seriously reworking; it's basically just ""numerical imprecision as a feature, not a bug"".",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679976149
https://github.com/qutip/qutip/pull/1348#issuecomment-679976149:83,Testability,test,test,83,"The test failure is unrelated; the swap to the new `CSR` type has meant that a few test tolerances have become much more fragile when considering numerical precision; since we're now using our own mathematical operations rather than scipy's, we're a bit more likely to have disagreements with them. This may also have to do with the new version of `Qobj` being more consistent about applying the `auto_tidyup` rule. This is one rule I really think we should look at removing or seriously reworking; it's basically just ""numerical imprecision as a feature, not a bug"".",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679976149
https://github.com/qutip/qutip/pull/1348#issuecomment-679979350:30,Deployability,update,update,30,"While you're at it, could you update the mac test to a more recent version of mac. xcode12 is now out but we are still testing on xcode10 (https://docs.travis-ci.com/user/reference/osx). There were segfault with xcode11, thus we skipped it, but I hope it's solved with the `eigh` patch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679979350
https://github.com/qutip/qutip/pull/1348#issuecomment-679979350:280,Deployability,patch,patch,280,"While you're at it, could you update the mac test to a more recent version of mac. xcode12 is now out but we are still testing on xcode10 (https://docs.travis-ci.com/user/reference/osx). There were segfault with xcode11, thus we skipped it, but I hope it's solved with the `eigh` patch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679979350
https://github.com/qutip/qutip/pull/1348#issuecomment-679979350:45,Testability,test,test,45,"While you're at it, could you update the mac test to a more recent version of mac. xcode12 is now out but we are still testing on xcode10 (https://docs.travis-ci.com/user/reference/osx). There were segfault with xcode11, thus we skipped it, but I hope it's solved with the `eigh` patch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679979350
https://github.com/qutip/qutip/pull/1348#issuecomment-679979350:119,Testability,test,testing,119,"While you're at it, could you update the mac test to a more recent version of mac. xcode12 is now out but we are still testing on xcode10 (https://docs.travis-ci.com/user/reference/osx). There were segfault with xcode11, thus we skipped it, but I hope it's solved with the `eigh` patch.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679979350
https://github.com/qutip/qutip/pull/1348#issuecomment-679982246:143,Testability,test,test,143,"Sure. Shall I backport that change to `master` too?. For the time being I've put in one on XCode 11 and one on XCode 12. It's probably good to test both - the XCode 11 image is built on macOS 10.14 and XCode 12 on macOS 10.15. There were non-trivial changes to how development tools are handled (particularly with regards to compilers and code-signing) in 10.15, so it's probably a good idea to test both while we've got spare slots. In the future, we could perhaps look to having only one Mac test, and using the last slot to test on Windows?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679982246
https://github.com/qutip/qutip/pull/1348#issuecomment-679982246:395,Testability,test,test,395,"Sure. Shall I backport that change to `master` too?. For the time being I've put in one on XCode 11 and one on XCode 12. It's probably good to test both - the XCode 11 image is built on macOS 10.14 and XCode 12 on macOS 10.15. There were non-trivial changes to how development tools are handled (particularly with regards to compilers and code-signing) in 10.15, so it's probably a good idea to test both while we've got spare slots. In the future, we could perhaps look to having only one Mac test, and using the last slot to test on Windows?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679982246
https://github.com/qutip/qutip/pull/1348#issuecomment-679982246:494,Testability,test,test,494,"Sure. Shall I backport that change to `master` too?. For the time being I've put in one on XCode 11 and one on XCode 12. It's probably good to test both - the XCode 11 image is built on macOS 10.14 and XCode 12 on macOS 10.15. There were non-trivial changes to how development tools are handled (particularly with regards to compilers and code-signing) in 10.15, so it's probably a good idea to test both while we've got spare slots. In the future, we could perhaps look to having only one Mac test, and using the last slot to test on Windows?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679982246
https://github.com/qutip/qutip/pull/1348#issuecomment-679982246:527,Testability,test,test,527,"Sure. Shall I backport that change to `master` too?. For the time being I've put in one on XCode 11 and one on XCode 12. It's probably good to test both - the XCode 11 image is built on macOS 10.14 and XCode 12 on macOS 10.15. There were non-trivial changes to how development tools are handled (particularly with regards to compilers and code-signing) in 10.15, so it's probably a good idea to test both while we've got spare slots. In the future, we could perhaps look to having only one Mac test, and using the last slot to test on Windows?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679982246
https://github.com/qutip/qutip/pull/1348#issuecomment-679988510:7,Testability,test,tests,7,"If the tests pass with xcode12 we should activate it on `master`. But if it breaks them, we should find a solution for `dev.major` but let it go for v4. Having windows test would help a lot, but if mac change a lot between versions, maybe go with 2 linux, 2 mac, 1 windows. ; We can have python 3.6 on mac or remove it. No cython should be run on windows.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679988510
https://github.com/qutip/qutip/pull/1348#issuecomment-679988510:168,Testability,test,test,168,"If the tests pass with xcode12 we should activate it on `master`. But if it breaks them, we should find a solution for `dev.major` but let it go for v4. Having windows test would help a lot, but if mac change a lot between versions, maybe go with 2 linux, 2 mac, 1 windows. ; We can have python 3.6 on mac or remove it. No cython should be run on windows.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679988510
https://github.com/qutip/qutip/pull/1348#issuecomment-679993941:227,Testability,test,test-coverage,227,[![Coverage Status](https://coveralls.io/builds/32984225/badge)](https://coveralls.io/builds/32984225). Coverage decreased (-8.3%) to 64.813% when pulling **0a7d8a350686ffe65a3993db377561db55ce6574 on jakelishman:dev.major-fix-test-coverage** into **e8854aa9b3710486b429f1d1d9e9e9cc415e382f on qutip:dev.major**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-679993941
https://github.com/qutip/qutip/pull/1348#issuecomment-680003055:10,Testability,test,test,10,"xcode12's test quite slow, almost twice the time of other tests...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680003055
https://github.com/qutip/qutip/pull/1348#issuecomment-680003055:58,Testability,test,tests,58,"xcode12's test quite slow, almost twice the time of other tests...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680003055
https://github.com/qutip/qutip/pull/1348#issuecomment-680004224:77,Performance,perform,performance,77,I think that's a good thing that we've tested that - we need to work out why performance is so bad on mac with Python 3.8.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680004224
https://github.com/qutip/qutip/pull/1348#issuecomment-680004224:39,Testability,test,tested,39,I think that's a good thing that we've tested that - we need to work out why performance is so bad on mac with Python 3.8.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680004224
https://github.com/qutip/qutip/pull/1348#issuecomment-680004649:71,Availability,fault,fault,71,"I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680004649
https://github.com/qutip/qutip/pull/1348#issuecomment-680004649:97,Testability,test,tests,97,"I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680004649
https://github.com/qutip/qutip/pull/1348#issuecomment-680004649:168,Testability,test,test,168,"I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680004649
https://github.com/qutip/qutip/pull/1348#issuecomment-680007729:54,Deployability,install,install,54,xcode10 with python 3.8 is ~21min. ; `python setup.py install` took ~203s with xcode10 but 385s with xcode12... Compilation seems to be the issue.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680007729
https://github.com/qutip/qutip/pull/1348#issuecomment-680009340:185,Deployability,update,updates,185,"I mean, it's still a problem we can try and figure out. Unfortunately I generally don't actually use the compilers bundled with XCode, and I don't use macOS 10.15 because of the screwy updates they made to dev tools...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680009340
https://github.com/qutip/qutip/pull/1348#issuecomment-680059767:73,Availability,fault,fault,73,"> I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility. Actually, I _didn't_ introduce a bug in `isherm`! It's just also present in the release version of QuTiP, but _masked_ by the `auto_tidyup`. In ""unrelated"" news: I discovered a dumb bug in `tidyup_dense`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680059767
https://github.com/qutip/qutip/pull/1348#issuecomment-680059767:266,Deployability,release,release,266,"> I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility. Actually, I _didn't_ introduce a bug in `isherm`! It's just also present in the release version of QuTiP, but _masked_ by the `auto_tidyup`. In ""unrelated"" news: I discovered a dumb bug in `tidyup_dense`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680059767
https://github.com/qutip/qutip/pull/1348#issuecomment-680059767:99,Testability,test,tests,99,"> I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility. Actually, I _didn't_ introduce a bug in `isherm`! It's just also present in the release version of QuTiP, but _masked_ by the `auto_tidyup`. In ""unrelated"" news: I discovered a dumb bug in `tidyup_dense`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680059767
https://github.com/qutip/qutip/pull/1348#issuecomment-680059767:170,Testability,test,test,170,"> I've just spotted a bug in `isherm` on the new data layer, which is my fault for not getting the tests for that written yet. That may also be having some impact on the test fragility. Actually, I _didn't_ introduce a bug in `isherm`! It's just also present in the release version of QuTiP, but _masked_ by the `auto_tidyup`. In ""unrelated"" news: I discovered a dumb bug in `tidyup_dense`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1348#issuecomment-680059767
https://github.com/qutip/qutip/issues/1349#issuecomment-680011384:1141,Availability,down,down,1141,"The problem is recognising what a true 0 is from a small value. In your example on the new data layer, there will already be exactly 0 items explicitly stored (and `data.add_csr` is going to get faster and smarter in another PR, too) without `tidyup`, but much more concerningly `1e-15 * qutip.rand_herm(5)` will end up in a zero matrix, which is clearly absolutely wrong. The argument from Liouvillian doesn't work here - even before the new data layer, `liouvillian` never called the `tidyup` code because it accessed the `Qobj.data` field directly, rather than used `Qobj`. Since it then goes into `CQobjEvo` in most of the solvers, which also don't touch the `tidyup` code, it doesn't get called. I don't think there's any safe way to know if small values should actually be zero, or if they're just small values. It makes sense that we want to maintain as much sparsity as possible when values are truly zero, but I think having the QuTiP default be to attempt to tidy up after every addition, multiplication and matrix multiplication is quite unsafe, and for people who aren't doing very very sparse calculations, it's actually a slow down.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680011384
https://github.com/qutip/qutip/issues/1349#issuecomment-680011384:727,Safety,safe,safe,727,"The problem is recognising what a true 0 is from a small value. In your example on the new data layer, there will already be exactly 0 items explicitly stored (and `data.add_csr` is going to get faster and smarter in another PR, too) without `tidyup`, but much more concerningly `1e-15 * qutip.rand_herm(5)` will end up in a zero matrix, which is clearly absolutely wrong. The argument from Liouvillian doesn't work here - even before the new data layer, `liouvillian` never called the `tidyup` code because it accessed the `Qobj.data` field directly, rather than used `Qobj`. Since it then goes into `CQobjEvo` in most of the solvers, which also don't touch the `tidyup` code, it doesn't get called. I don't think there's any safe way to know if small values should actually be zero, or if they're just small values. It makes sense that we want to maintain as much sparsity as possible when values are truly zero, but I think having the QuTiP default be to attempt to tidy up after every addition, multiplication and matrix multiplication is quite unsafe, and for people who aren't doing very very sparse calculations, it's actually a slow down.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680011384
https://github.com/qutip/qutip/issues/1349#issuecomment-680011384:1049,Safety,unsafe,unsafe,1049,"The problem is recognising what a true 0 is from a small value. In your example on the new data layer, there will already be exactly 0 items explicitly stored (and `data.add_csr` is going to get faster and smarter in another PR, too) without `tidyup`, but much more concerningly `1e-15 * qutip.rand_herm(5)` will end up in a zero matrix, which is clearly absolutely wrong. The argument from Liouvillian doesn't work here - even before the new data layer, `liouvillian` never called the `tidyup` code because it accessed the `Qobj.data` field directly, rather than used `Qobj`. Since it then goes into `CQobjEvo` in most of the solvers, which also don't touch the `tidyup` code, it doesn't get called. I don't think there's any safe way to know if small values should actually be zero, or if they're just small values. It makes sense that we want to maintain as much sparsity as possible when values are truly zero, but I think having the QuTiP default be to attempt to tidy up after every addition, multiplication and matrix multiplication is quite unsafe, and for people who aren't doing very very sparse calculations, it's actually a slow down.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680011384
https://github.com/qutip/qutip/issues/1349#issuecomment-680011384:511,Security,access,accessed,511,"The problem is recognising what a true 0 is from a small value. In your example on the new data layer, there will already be exactly 0 items explicitly stored (and `data.add_csr` is going to get faster and smarter in another PR, too) without `tidyup`, but much more concerningly `1e-15 * qutip.rand_herm(5)` will end up in a zero matrix, which is clearly absolutely wrong. The argument from Liouvillian doesn't work here - even before the new data layer, `liouvillian` never called the `tidyup` code because it accessed the `Qobj.data` field directly, rather than used `Qobj`. Since it then goes into `CQobjEvo` in most of the solvers, which also don't touch the `tidyup` code, it doesn't get called. I don't think there's any safe way to know if small values should actually be zero, or if they're just small values. It makes sense that we want to maintain as much sparsity as possible when values are truly zero, but I think having the QuTiP default be to attempt to tidy up after every addition, multiplication and matrix multiplication is quite unsafe, and for people who aren't doing very very sparse calculations, it's actually a slow down.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680011384
https://github.com/qutip/qutip/issues/1349#issuecomment-680011384:347,Usability,clear,clearly,347,"The problem is recognising what a true 0 is from a small value. In your example on the new data layer, there will already be exactly 0 items explicitly stored (and `data.add_csr` is going to get faster and smarter in another PR, too) without `tidyup`, but much more concerningly `1e-15 * qutip.rand_herm(5)` will end up in a zero matrix, which is clearly absolutely wrong. The argument from Liouvillian doesn't work here - even before the new data layer, `liouvillian` never called the `tidyup` code because it accessed the `Qobj.data` field directly, rather than used `Qobj`. Since it then goes into `CQobjEvo` in most of the solvers, which also don't touch the `tidyup` code, it doesn't get called. I don't think there's any safe way to know if small values should actually be zero, or if they're just small values. It makes sense that we want to maintain as much sparsity as possible when values are truly zero, but I think having the QuTiP default be to attempt to tidy up after every addition, multiplication and matrix multiplication is quite unsafe, and for people who aren't doing very very sparse calculations, it's actually a slow down.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680011384
https://github.com/qutip/qutip/issues/1349#issuecomment-680020737:148,Availability,error,error,148,"QobjEvo used to tidyup once right before 'compiling'. We could tidyup values smaller than `1e-15 * norm` to differentiate small object to numerical error.; In usual operations, `matmul`, `add` etc. if you can make them smarter then and keep a reasonable sparsity without tidyup, it could replace the Qobj's auto_tidyup. And in situation where this is a slowdown, `Dense` should be used.; We could change the default to False for the beta and see how users reacts, but I would not remove the option.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680020737
https://github.com/qutip/qutip/issues/1349#issuecomment-680027055:44,Availability,toler,tolerance,44,"Switching `auto_tidyup` to being a relative tolerance not an absolute tolerance I think is a really good idea. It raises the cost of it a bit by making it a two-pass operation (and for sure let's use the max norm, not the trace norm!), but I think it's a sensible compromise. We could even have two options - `tidyup_atol` and `tidyup_rtol` to have both, and have `tidyup_atol` default to `0`. Also, fine point about `QobjEvo` - I'd forgotten that it internally called `tidyup`. I'm certainly in favour of swapping the default to `False` for the next major release. I know people may still want the option, so not a good idea to remove it completely, but I think having the default be `False` is safer numerically.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680027055
https://github.com/qutip/qutip/issues/1349#issuecomment-680027055:70,Availability,toler,tolerance,70,"Switching `auto_tidyup` to being a relative tolerance not an absolute tolerance I think is a really good idea. It raises the cost of it a bit by making it a two-pass operation (and for sure let's use the max norm, not the trace norm!), but I think it's a sensible compromise. We could even have two options - `tidyup_atol` and `tidyup_rtol` to have both, and have `tidyup_atol` default to `0`. Also, fine point about `QobjEvo` - I'd forgotten that it internally called `tidyup`. I'm certainly in favour of swapping the default to `False` for the next major release. I know people may still want the option, so not a good idea to remove it completely, but I think having the default be `False` is safer numerically.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680027055
https://github.com/qutip/qutip/issues/1349#issuecomment-680027055:557,Deployability,release,release,557,"Switching `auto_tidyup` to being a relative tolerance not an absolute tolerance I think is a really good idea. It raises the cost of it a bit by making it a two-pass operation (and for sure let's use the max norm, not the trace norm!), but I think it's a sensible compromise. We could even have two options - `tidyup_atol` and `tidyup_rtol` to have both, and have `tidyup_atol` default to `0`. Also, fine point about `QobjEvo` - I'd forgotten that it internally called `tidyup`. I'm certainly in favour of swapping the default to `False` for the next major release. I know people may still want the option, so not a good idea to remove it completely, but I think having the default be `False` is safer numerically.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680027055
https://github.com/qutip/qutip/issues/1349#issuecomment-680027055:696,Safety,safe,safer,696,"Switching `auto_tidyup` to being a relative tolerance not an absolute tolerance I think is a really good idea. It raises the cost of it a bit by making it a two-pass operation (and for sure let's use the max norm, not the trace norm!), but I think it's a sensible compromise. We could even have two options - `tidyup_atol` and `tidyup_rtol` to have both, and have `tidyup_atol` default to `0`. Also, fine point about `QobjEvo` - I'd forgotten that it internally called `tidyup`. I'm certainly in favour of swapping the default to `False` for the next major release. I know people may still want the option, so not a good idea to remove it completely, but I think having the default be `False` is safer numerically.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680027055
https://github.com/qutip/qutip/issues/1349#issuecomment-680091809:160,Availability,toler,tolerance,160,"Just some information. There were indeed issues about this, e.g. #1247 . For new users, this could lead to some confusing behaviours. In those cases, `relative tolerance` definitely helps.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-680091809
https://github.com/qutip/qutip/issues/1349#issuecomment-793761801:113,Performance,perform,performance,113,"Oh, sorry I forgot to reply to you Boxi. In theory it's not such a difficult change, but it does have quite some performance implications - doing it properly will involve writing Cython, and we need to make sure that there's no major regressions. The swap to relative amplitudes necessarily makes the code ~twice as slow (from a one-pass to two-pass algorithm), but we do need to take care that it's as fast as possible, because this code is called _all_ the time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793761801
https://github.com/qutip/qutip/issues/1349#issuecomment-793947542:177,Performance,bottleneck,bottleneck,177,"Okay, involving writing Cython itself already makes it unsuitable for most new contributors I guess. I think even if the time of tidy up doubles it still won't be a significant bottleneck for solvers? Matrix multiplication itself will be O(dim^3) in the worst case, this one is at most O(n^2). But I do agree that we need to be very careful with such a low-level function.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793947542
https://github.com/qutip/qutip/issues/1349#issuecomment-793991141:355,Availability,toler,tolerance,355,"If you're concerned about the solvers, a) they skip tidyup til the end anyway and b) _technically_ the computational complexity of CSR * dense vector is identical to tidyup (though tidyup is a little more cache efficient), but really it's the constant factors that could kill you for small systems. For example, the ""naive"" way of implementing a relative tolerance would take the absolute value of a complex number, but that involves a floating-point square root, which is a very slow operation. That's likely partly why the current version compares real and imaginary components separately, even though the sparsity structure is only improved if _both_ go to zero. In a two-pass operation you'd sqrt twice for every entry (naively - all the square roots are very avoidable), and I'd start to worry that that really _could_ dominate small system operations. Or maybe you should just ignore me when assigning ""good first issues"" - I'm probably too opinionated about performance characteristics without enough experience at managing other people's code!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793991141
https://github.com/qutip/qutip/issues/1349#issuecomment-793991141:211,Energy Efficiency,efficient,efficient,211,"If you're concerned about the solvers, a) they skip tidyup til the end anyway and b) _technically_ the computational complexity of CSR * dense vector is identical to tidyup (though tidyup is a little more cache efficient), but really it's the constant factors that could kill you for small systems. For example, the ""naive"" way of implementing a relative tolerance would take the absolute value of a complex number, but that involves a floating-point square root, which is a very slow operation. That's likely partly why the current version compares real and imaginary components separately, even though the sparsity structure is only improved if _both_ go to zero. In a two-pass operation you'd sqrt twice for every entry (naively - all the square roots are very avoidable), and I'd start to worry that that really _could_ dominate small system operations. Or maybe you should just ignore me when assigning ""good first issues"" - I'm probably too opinionated about performance characteristics without enough experience at managing other people's code!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793991141
https://github.com/qutip/qutip/issues/1349#issuecomment-793991141:205,Performance,cache,cache,205,"If you're concerned about the solvers, a) they skip tidyup til the end anyway and b) _technically_ the computational complexity of CSR * dense vector is identical to tidyup (though tidyup is a little more cache efficient), but really it's the constant factors that could kill you for small systems. For example, the ""naive"" way of implementing a relative tolerance would take the absolute value of a complex number, but that involves a floating-point square root, which is a very slow operation. That's likely partly why the current version compares real and imaginary components separately, even though the sparsity structure is only improved if _both_ go to zero. In a two-pass operation you'd sqrt twice for every entry (naively - all the square roots are very avoidable), and I'd start to worry that that really _could_ dominate small system operations. Or maybe you should just ignore me when assigning ""good first issues"" - I'm probably too opinionated about performance characteristics without enough experience at managing other people's code!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793991141
https://github.com/qutip/qutip/issues/1349#issuecomment-793991141:965,Performance,perform,performance,965,"If you're concerned about the solvers, a) they skip tidyup til the end anyway and b) _technically_ the computational complexity of CSR * dense vector is identical to tidyup (though tidyup is a little more cache efficient), but really it's the constant factors that could kill you for small systems. For example, the ""naive"" way of implementing a relative tolerance would take the absolute value of a complex number, but that involves a floating-point square root, which is a very slow operation. That's likely partly why the current version compares real and imaginary components separately, even though the sparsity structure is only improved if _both_ go to zero. In a two-pass operation you'd sqrt twice for every entry (naively - all the square roots are very avoidable), and I'd start to worry that that really _could_ dominate small system operations. Or maybe you should just ignore me when assigning ""good first issues"" - I'm probably too opinionated about performance characteristics without enough experience at managing other people's code!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793991141
https://github.com/qutip/qutip/issues/1349#issuecomment-793991141:764,Safety,avoid,avoidable,764,"If you're concerned about the solvers, a) they skip tidyup til the end anyway and b) _technically_ the computational complexity of CSR * dense vector is identical to tidyup (though tidyup is a little more cache efficient), but really it's the constant factors that could kill you for small systems. For example, the ""naive"" way of implementing a relative tolerance would take the absolute value of a complex number, but that involves a floating-point square root, which is a very slow operation. That's likely partly why the current version compares real and imaginary components separately, even though the sparsity structure is only improved if _both_ go to zero. In a two-pass operation you'd sqrt twice for every entry (naively - all the square roots are very avoidable), and I'd start to worry that that really _could_ dominate small system operations. Or maybe you should just ignore me when assigning ""good first issues"" - I'm probably too opinionated about performance characteristics without enough experience at managing other people's code!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-793991141
https://github.com/qutip/qutip/issues/1349#issuecomment-794400401:234,Availability,toler,tolerance,234,"Well, your opinion is definitely important, especially regarding core :) Performance is a top requirement there. Technically I think there is no need for square root at all because we can just compare the squared value to the squared tolerance. But I get your point that constant factor may dominate the performance of a small system. It's best to avoid Cython in ""good first issues"", so this one won't be on my list anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-794400401
https://github.com/qutip/qutip/issues/1349#issuecomment-794400401:73,Performance,Perform,Performance,73,"Well, your opinion is definitely important, especially regarding core :) Performance is a top requirement there. Technically I think there is no need for square root at all because we can just compare the squared value to the squared tolerance. But I get your point that constant factor may dominate the performance of a small system. It's best to avoid Cython in ""good first issues"", so this one won't be on my list anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-794400401
https://github.com/qutip/qutip/issues/1349#issuecomment-794400401:304,Performance,perform,performance,304,"Well, your opinion is definitely important, especially regarding core :) Performance is a top requirement there. Technically I think there is no need for square root at all because we can just compare the squared value to the squared tolerance. But I get your point that constant factor may dominate the performance of a small system. It's best to avoid Cython in ""good first issues"", so this one won't be on my list anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-794400401
https://github.com/qutip/qutip/issues/1349#issuecomment-794400401:348,Safety,avoid,avoid,348,"Well, your opinion is definitely important, especially regarding core :) Performance is a top requirement there. Technically I think there is no need for square root at all because we can just compare the squared value to the squared tolerance. But I get your point that constant factor may dominate the performance of a small system. It's best to avoid Cython in ""good first issues"", so this one won't be on my list anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1349#issuecomment-794400401
https://github.com/qutip/qutip/pull/1351#issuecomment-680168936:160,Testability,test,tests,160,"I suppose the answer is ""yes"", but there's still that huge to do list at the top that needs to be handled (including some really really important bits like the tests). I'm just rebasing it now. By the way, I'm getting a lot of `build` directories dropped in whatever my current working directory is whenever I run anything which uses the new coefficients (and there's the import warning still).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680168936
https://github.com/qutip/qutip/pull/1351#issuecomment-680175955:30,Testability,test,tests,30,That's the rebase done. Those tests _should_ pass now; they do on my machine.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680175955
https://github.com/qutip/qutip/pull/1351#issuecomment-680183199:468,Availability,error,errors,468,"```python; jake@tauros$ python; Python 3.7.7 (default, May 6 2020, 04:59:01); [Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import qutip; /Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.7/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.; ""Distutils was imported before Setuptools. This usage is discouraged ""; >>>; ```. It was caused by the original coefficients PR. Could be interplay between `pyximport` and the later import of `setuptools`, but I'm not sure (definitely the import of `setuptools` in `core/coefficient.py` is what actually triggers the warning, but I'm not sure when `distutils` is imported). I don't think you _need_ `setuptools` (which is also causing the `build` directories) - I think you can use importlib to import the result of `cythonize` directly?. At any rate, it would be very good to drop the `pyximport` dependency from BR too.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680183199
https://github.com/qutip/qutip/pull/1351#issuecomment-680183199:1152,Integrability,depend,dependency,1152,"```python; jake@tauros$ python; Python 3.7.7 (default, May 6 2020, 04:59:01); [Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import qutip; /Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.7/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.; ""Distutils was imported before Setuptools. This usage is discouraged ""; >>>; ```. It was caused by the original coefficients PR. Could be interplay between `pyximport` and the later import of `setuptools`, but I'm not sure (definitely the import of `setuptools` in `core/coefficient.py` is what actually triggers the warning, but I'm not sure when `distutils` is imported). I don't think you _need_ `setuptools` (which is also causing the `build` directories) - I think you can use importlib to import the result of `cythonize` directly?. At any rate, it would be very good to drop the `pyximport` dependency from BR too.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680183199
https://github.com/qutip/qutip/pull/1351#issuecomment-680225994:220,Availability,failure,failure,220,"I'm happy to go either way on whether to merge this now or later. I'm happy to keep adding to it, but I'm also mindful that I don't want this to turn into another +15000/-15000 PR. I possibly need to look into that test failure a little more - it's temperamental, and I'm not sure if it's something where it's just a case of a too strict tolerance, or if there is an actually numerical precision problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680225994
https://github.com/qutip/qutip/pull/1351#issuecomment-680225994:338,Availability,toler,tolerance,338,"I'm happy to go either way on whether to merge this now or later. I'm happy to keep adding to it, but I'm also mindful that I don't want this to turn into another +15000/-15000 PR. I possibly need to look into that test failure a little more - it's temperamental, and I'm not sure if it's something where it's just a case of a too strict tolerance, or if there is an actually numerical precision problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680225994
https://github.com/qutip/qutip/pull/1351#issuecomment-680225994:215,Testability,test,test,215,"I'm happy to go either way on whether to merge this now or later. I'm happy to keep adding to it, but I'm also mindful that I don't want this to turn into another +15000/-15000 PR. I possibly need to look into that test failure a little more - it's temperamental, and I'm not sure if it's something where it's just a case of a too strict tolerance, or if there is an actually numerical precision problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680225994
https://github.com/qutip/qutip/pull/1351#issuecomment-680228966:91,Testability,test,test,91,"I prefer smaller PRs, this is big enough.; Continue in another one please.; I will put the test to a to check list and review it when working on `brmesolve`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1351#issuecomment-680228966
https://github.com/qutip/qutip/issues/1354#issuecomment-684765619:51,Deployability,update,updates,51,"As discussed in #1355 , it will be fixed in future updates, so close this issue ATM.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1354#issuecomment-684765619
https://github.com/qutip/qutip/issues/1357#issuecomment-691086529:85,Availability,toler,tolerance,85,"The stochastic ode solver are not smart and do not adjust the step to meet a desired tolerance. You can manually increase the precision by increasing the number of sub-steps `nsubsteps`. ; Since you don't have any c_ops, see if you can use mcsolve instead. It accept `atol `and `rtol `options and you should be able to rebuild the measurement from the collapse.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1357#issuecomment-691086529
https://github.com/qutip/qutip/issues/1357#issuecomment-691302246:213,Integrability,depend,dependent,213,"Thanks for your suggestion! I tried to increase the sub-steps, but the optimal (a tradeoff between precision and speed) `nsubsteps` is very sensitive to the parameter of the Hamiltonian (bias). To simulate a time-dependent bias, I have to set an extremely large `nsubsteps` then practical unable to complete. Mcsolve works perfect for this setup, but I also want to add some extra c_ops later. I would like to ensure if the `nsubsteps` is the only way to control the precision? If so, I will make things simpler and use mcsolve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1357#issuecomment-691302246
https://github.com/qutip/qutip/issues/1357#issuecomment-691302246:504,Usability,simpl,simpler,504,"Thanks for your suggestion! I tried to increase the sub-steps, but the optimal (a tradeoff between precision and speed) `nsubsteps` is very sensitive to the parameter of the Hamiltonian (bias). To simulate a time-dependent bias, I have to set an extremely large `nsubsteps` then practical unable to complete. Mcsolve works perfect for this setup, but I also want to add some extra c_ops later. I would like to ensure if the `nsubsteps` is the only way to control the precision? If so, I will make things simpler and use mcsolve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1357#issuecomment-691302246
https://github.com/qutip/qutip/issues/1357#issuecomment-691366231:225,Availability,avail,available,225,"Yes `nsubsteps` and `tlist` are the only way to control precision with `photocurrent_mesolve`, `mcsolve` does not support a mix of `c_ops` and `sc_ops` so if both of them are needed `photocurrent_mesolve` is your only option available.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1357#issuecomment-691366231
https://github.com/qutip/qutip/issues/1359#issuecomment-696796867:29,Usability,guid,guide,29,"Hi Jake, ; Thank you for the guide, quite complete. If you have time, an explanation on what can be found where (core vs core.data etc.) could be nice. . I believe we decided to move all the documentation to this repository. @nathanshammah should the devguide go in a docs folder here?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1359#issuecomment-696796867
https://github.com/qutip/qutip/issues/1359#issuecomment-697377705:511,Usability,Guid,Guide,511,"Thank you @jakelishman, this is great. Fantastic effort and result!. @Ericgig, sorry, just to rememeber: we decided to fold the repo `qutip-doc` into a docs folder here in `qutip/qutip`? I was in favor of it but lost track of what we agreed upon. . In any case, in my opinion this could go with the rest of the documentation. From the user's perspective, it could be an additional element in the menu tab on the left of this html page, http://qutip.org/docs/latest/index.html. It would be on par with the Users Guide and the API doc, and more visible for the usual documentation reader. Another option would be to have it linked in the website at the top level, next to User Guide (which actually prompts to the whole documentation history page) and Tutorials, but I feel that there it may go much more unnoticed. . It seems to be good practice to have a `CONTRIBUTING.md` file in this repo, it could point to that bundle of information. We have that [file](https://github.com/qutip/qutip-doc/blob/master/CONTRIBUTING.md) indeed in `qutip-doc`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1359#issuecomment-697377705
https://github.com/qutip/qutip/issues/1359#issuecomment-697377705:675,Usability,Guid,Guide,675,"Thank you @jakelishman, this is great. Fantastic effort and result!. @Ericgig, sorry, just to rememeber: we decided to fold the repo `qutip-doc` into a docs folder here in `qutip/qutip`? I was in favor of it but lost track of what we agreed upon. . In any case, in my opinion this could go with the rest of the documentation. From the user's perspective, it could be an additional element in the menu tab on the left of this html page, http://qutip.org/docs/latest/index.html. It would be on par with the Users Guide and the API doc, and more visible for the usual documentation reader. Another option would be to have it linked in the website at the top level, next to User Guide (which actually prompts to the whole documentation history page) and Tutorials, but I feel that there it may go much more unnoticed. . It seems to be good practice to have a `CONTRIBUTING.md` file in this repo, it could point to that bundle of information. We have that [file](https://github.com/qutip/qutip-doc/blob/master/CONTRIBUTING.md) indeed in `qutip-doc`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1359#issuecomment-697377705
https://github.com/qutip/qutip/issues/1360#issuecomment-696067845:287,Usability,guid,guide,287,"I totally agree it is the right way to do numerics, but my point is that it should be written in the documentation.; For now the user have no way to answer the question ""in which unit should I express my Hamiltonian"", apart reading the source code. It is especially misleading that the [guide](http://qutip.org/docs/latest/guide/dynamics/dynamics-master.html) write hbar in the equations but never say how it is handled.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1360#issuecomment-696067845
https://github.com/qutip/qutip/issues/1360#issuecomment-696067845:323,Usability,guid,guide,323,"I totally agree it is the right way to do numerics, but my point is that it should be written in the documentation.; For now the user have no way to answer the question ""in which unit should I express my Hamiltonian"", apart reading the source code. It is especially misleading that the [guide](http://qutip.org/docs/latest/guide/dynamics/dynamics-master.html) write hbar in the equations but never say how it is handled.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1360#issuecomment-696067845
https://github.com/qutip/qutip/issues/1364#issuecomment-699652426:1048,Integrability,depend,dependent,1048,"You have a couple of ways of going about this. The simplest is to use the callback form of `e_ops` - you make a single function which looks like; ```python; def e_op(t, state):; # [...]; return expectation; ```; where `t` is the time and `state` is a `Qobj`. You can return whatever you like here, really, so you can return a tuple of values if you want to track more than one. If you do this, then you do; ```python; result = qutip.sesolve(H, psi0, times, e_ops=e_op); ```; and `result.expect` is a list of the same length as `times`, where `result.expect[k]` is the output of your function at a time `times[k]` (note that this is a slightly different output format to the normal method). Alternatively, you can do the calculation yourself without too much difficulty if your observables can be put in the form `A(t) = sum_k f_k(t) A_k`, like your example here. Because the expectation is a linear operation `expect(A(t), psi(t)) = sum_k f_k(t) expect(A_k, psi(t))`, so you can pass the list of `A_k` to `sesolve` and then just calculate the time-dependent coefficients yourself afterwards and add them up. This will generally be faster than the previous method, but it's more complicated to do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1364#issuecomment-699652426
https://github.com/qutip/qutip/issues/1364#issuecomment-699652426:51,Usability,simpl,simplest,51,"You have a couple of ways of going about this. The simplest is to use the callback form of `e_ops` - you make a single function which looks like; ```python; def e_op(t, state):; # [...]; return expectation; ```; where `t` is the time and `state` is a `Qobj`. You can return whatever you like here, really, so you can return a tuple of values if you want to track more than one. If you do this, then you do; ```python; result = qutip.sesolve(H, psi0, times, e_ops=e_op); ```; and `result.expect` is a list of the same length as `times`, where `result.expect[k]` is the output of your function at a time `times[k]` (note that this is a slightly different output format to the normal method). Alternatively, you can do the calculation yourself without too much difficulty if your observables can be put in the form `A(t) = sum_k f_k(t) A_k`, like your example here. Because the expectation is a linear operation `expect(A(t), psi(t)) = sum_k f_k(t) expect(A_k, psi(t))`, so you can pass the list of `A_k` to `sesolve` and then just calculate the time-dependent coefficients yourself afterwards and add them up. This will generally be faster than the previous method, but it's more complicated to do.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1364#issuecomment-699652426
https://github.com/qutip/qutip/issues/1368#issuecomment-704945305:17,Integrability,depend,dependant,17,"List format time dependant Hamiltonian:; ```; def f(t, args):; return np.sin(args['w']*t). H = [H0, [H1, f]]; ```; would give the same Hamiltonian and work with `mcsolve`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1368#issuecomment-704945305
https://github.com/qutip/qutip/pull/1369#issuecomment-754707095:596,Modifiability,extend,extended,596,"@gautierronan Thanks Ronan for this useful contribution. It looks good to me. I was discussing something similar with a colleague back in October, so I am going to see if I can get them to test it too.; On the subject of testing... this will need tests to be added before it can be merged. Please see https://github.com/qutip/qutip/blob/master/qutip/tests/test_control_pulseoptim.py; Ideally it would also have an example notebook. See https://github.com/qutip/qutip-notebooks/blob/master/examples/control-pulseoptim-Hadamard.ipynb for example. It could either have new notebook, or one could be extended to show this feature.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-754707095
https://github.com/qutip/qutip/pull/1369#issuecomment-754707095:189,Testability,test,test,189,"@gautierronan Thanks Ronan for this useful contribution. It looks good to me. I was discussing something similar with a colleague back in October, so I am going to see if I can get them to test it too.; On the subject of testing... this will need tests to be added before it can be merged. Please see https://github.com/qutip/qutip/blob/master/qutip/tests/test_control_pulseoptim.py; Ideally it would also have an example notebook. See https://github.com/qutip/qutip-notebooks/blob/master/examples/control-pulseoptim-Hadamard.ipynb for example. It could either have new notebook, or one could be extended to show this feature.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-754707095
https://github.com/qutip/qutip/pull/1369#issuecomment-754707095:221,Testability,test,testing,221,"@gautierronan Thanks Ronan for this useful contribution. It looks good to me. I was discussing something similar with a colleague back in October, so I am going to see if I can get them to test it too.; On the subject of testing... this will need tests to be added before it can be merged. Please see https://github.com/qutip/qutip/blob/master/qutip/tests/test_control_pulseoptim.py; Ideally it would also have an example notebook. See https://github.com/qutip/qutip-notebooks/blob/master/examples/control-pulseoptim-Hadamard.ipynb for example. It could either have new notebook, or one could be extended to show this feature.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-754707095
https://github.com/qutip/qutip/pull/1369#issuecomment-754707095:247,Testability,test,tests,247,"@gautierronan Thanks Ronan for this useful contribution. It looks good to me. I was discussing something similar with a colleague back in October, so I am going to see if I can get them to test it too.; On the subject of testing... this will need tests to be added before it can be merged. Please see https://github.com/qutip/qutip/blob/master/qutip/tests/test_control_pulseoptim.py; Ideally it would also have an example notebook. See https://github.com/qutip/qutip-notebooks/blob/master/examples/control-pulseoptim-Hadamard.ipynb for example. It could either have new notebook, or one could be extended to show this feature.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-754707095
https://github.com/qutip/qutip/pull/1369#issuecomment-754707095:350,Testability,test,tests,350,"@gautierronan Thanks Ronan for this useful contribution. It looks good to me. I was discussing something similar with a colleague back in October, so I am going to see if I can get them to test it too.; On the subject of testing... this will need tests to be added before it can be merged. Please see https://github.com/qutip/qutip/blob/master/qutip/tests/test_control_pulseoptim.py; Ideally it would also have an example notebook. See https://github.com/qutip/qutip-notebooks/blob/master/examples/control-pulseoptim-Hadamard.ipynb for example. It could either have new notebook, or one could be extended to show this feature.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-754707095
https://github.com/qutip/qutip/pull/1369#issuecomment-759365480:42,Testability,test,tests,42,Thank you for your feedback. I will write tests and documentation when I have some more time (might be in a month or so).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-759365480
https://github.com/qutip/qutip/pull/1369#issuecomment-759365480:19,Usability,feedback,feedback,19,Thank you for your feedback. I will write tests and documentation when I have some more time (might be in a month or so).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-759365480
https://github.com/qutip/qutip/pull/1369#issuecomment-893433268:128,Availability,ping,ping,128,@gautierronan Apologies for the long delay in further review of this. Could you perhaps update this branch from master and then ping me to review it again? I can them hopefully review and merge this and mark it for inclusion in QuTiP 4.7.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-893433268
https://github.com/qutip/qutip/pull/1369#issuecomment-893433268:88,Deployability,update,update,88,@gautierronan Apologies for the long delay in further review of this. Could you perhaps update this branch from master and then ping me to review it again? I can them hopefully review and merge this and mark it for inclusion in QuTiP 4.7.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-893433268
https://github.com/qutip/qutip/pull/1369#issuecomment-992981750:197,Deployability,release,released,197,"@gautierronan Just checking up on this again. Are you keen to finish the PR? If not, I can try find someone else to get it merged, but it would be good to get it merged before 4.7, which should be released in the not too distant future.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-992981750
https://github.com/qutip/qutip/pull/1369#issuecomment-1058307269:29,Deployability,update,updated,29,@ajgpitch @gautierronan I've updated this PR. I *think* it's ready to be merged (assuming tests pass in CI now) but a final look from you would be appreciated since this is not a part of QuTiP I know well yet.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-1058307269
https://github.com/qutip/qutip/pull/1369#issuecomment-1058307269:90,Testability,test,tests,90,@ajgpitch @gautierronan I've updated this PR. I *think* it's ready to be merged (assuming tests pass in CI now) but a final look from you would be appreciated since this is not a part of QuTiP I know well yet.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-1058307269
https://github.com/qutip/qutip/pull/1369#issuecomment-1096677056:127,Usability,clear,clear,127,"I ended up closing this PR because the implementation needs a significant overhaul. Now that I understand the code better it's clear that the pulse generation classes are intended to produce a single specific pulse and not a set of pulses for each control. The current implementation attempts to do the latter, resulting in having to pass the control index as an (very hacky) input to all the pulse methods. In other parts of control module, the former approach of a list of pulse instances is already taken, so this PR also results in both the ""correct"" and the ""hacky"" approach being used. This looks like an important / great feature to have, but I didn't want to rush merging the implementation for 4.7. Apologies for not writing an explanation when I closed the PR -- I was obviously rushing around too much before going on leave. :/",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1369#issuecomment-1096677056
https://github.com/qutip/qutip/issues/1370#issuecomment-705998421:153,Availability,down,down,153,"For local operators with homogeneous decay, only pumping, emission and; dephasing are supported.; For collective operators, any jump term can be written down, writing a; Liouvillian by hand using the jspin operators. On Fri, 9 Oct 2020 at 09:23, pegasus328 <notifications@github.com> wrote:. > Hi.; >; > I was wondering while playing with the permutational invariant solver, if; > there is any way to customize your Lindblad in the dicke basis. I meas,; > suppose I have a collapse of the form, J_+ + J_-. The class Dicke does not; > include any flexibility a part from the collective emission/pumping and the; > corresponding individual emission/pumping.; >; > Or am I missing something?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1370>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADPF67GNDFM56EJE5WMCRJ3SJ2T7TANCNFSM4SJVGOSA>; > .; >; -- ; Dr. Nathan Shammah; www.nathanshammah.com",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1370#issuecomment-705998421
https://github.com/qutip/qutip/issues/1371#issuecomment-711168808:450,Availability,error,error,450,"`qutip` has binary built extensions and we distribute binary releases through `conda`. These generally have to be built against a specific version of CPython, so we haven't released a cp39 candidate package yet, and `conda` will recognise that as effectively a requirement that `python<3.9`. `pip` should install from source, because we haven't yet built wheels to distribute that way (though I've been looking into that a bit more recently), so the error will likely be completely different - what sort of error do you get from that?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-711168808
https://github.com/qutip/qutip/issues/1371#issuecomment-711168808:507,Availability,error,error,507,"`qutip` has binary built extensions and we distribute binary releases through `conda`. These generally have to be built against a specific version of CPython, so we haven't released a cp39 candidate package yet, and `conda` will recognise that as effectively a requirement that `python<3.9`. `pip` should install from source, because we haven't yet built wheels to distribute that way (though I've been looking into that a bit more recently), so the error will likely be completely different - what sort of error do you get from that?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-711168808
https://github.com/qutip/qutip/issues/1371#issuecomment-711168808:61,Deployability,release,releases,61,"`qutip` has binary built extensions and we distribute binary releases through `conda`. These generally have to be built against a specific version of CPython, so we haven't released a cp39 candidate package yet, and `conda` will recognise that as effectively a requirement that `python<3.9`. `pip` should install from source, because we haven't yet built wheels to distribute that way (though I've been looking into that a bit more recently), so the error will likely be completely different - what sort of error do you get from that?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-711168808
https://github.com/qutip/qutip/issues/1371#issuecomment-711168808:173,Deployability,release,released,173,"`qutip` has binary built extensions and we distribute binary releases through `conda`. These generally have to be built against a specific version of CPython, so we haven't released a cp39 candidate package yet, and `conda` will recognise that as effectively a requirement that `python<3.9`. `pip` should install from source, because we haven't yet built wheels to distribute that way (though I've been looking into that a bit more recently), so the error will likely be completely different - what sort of error do you get from that?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-711168808
https://github.com/qutip/qutip/issues/1371#issuecomment-711168808:305,Deployability,install,install,305,"`qutip` has binary built extensions and we distribute binary releases through `conda`. These generally have to be built against a specific version of CPython, so we haven't released a cp39 candidate package yet, and `conda` will recognise that as effectively a requirement that `python<3.9`. `pip` should install from source, because we haven't yet built wheels to distribute that way (though I've been looking into that a bit more recently), so the error will likely be completely different - what sort of error do you get from that?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-711168808
https://github.com/qutip/qutip/issues/1371#issuecomment-809302975:205,Availability,failure,failures,205,"Closing this now, unless you have more problems - QuTiP has binary release candidates for 4.5.2 and 4.5.3 on `conda-forge` (I think they rebuilt 4.5.2 since this issue), and I couldn't reproduce any build failures on `pip` with 3.9.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-809302975
https://github.com/qutip/qutip/issues/1371#issuecomment-809302975:67,Deployability,release,release,67,"Closing this now, unless you have more problems - QuTiP has binary release candidates for 4.5.2 and 4.5.3 on `conda-forge` (I think they rebuilt 4.5.2 since this issue), and I couldn't reproduce any build failures on `pip` with 3.9.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1371#issuecomment-809302975
https://github.com/qutip/qutip/issues/1374#issuecomment-717351448:91,Integrability,message,message,91,thanks. can you also please run:; ```; import qutip; qutip.about(); ```; and copy here the message?,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717351448
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:92,Availability,error,errors,92,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:178,Availability,error,error,178,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:658,Availability,error,error,658,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:748,Availability,error,error,748,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:1064,Availability,error,error,1064,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:1483,Safety,detect,detected,1483,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:993,Security,access,access,993,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-717495492:969,Usability,simpl,simply,969,"Thanks for reporting this - it's an important bug that's snuck in. Right now, there's a few errors in your code that you can fix to get on your way again, but we need to fix the error on our side. You're using `sigmap()` which is the Pauli excitation operator and is only defined for a Hilbert space with dimension 2. You actually are working with a Hilbert space of dimension `nmax * nmax` (a tensor-product space), so your `e_ops` argument to `sesolve` is wrong - it's difficult to know exactly what you meant here. `destroy(2)` is equivalent to `sigmap()`, so it's possible you intended to have `e_ops` be `[qutip.tensor(a1, a2)]`?. ---. Maintainers: The error is actually a segfault, because QuTiP 4.5 (probably 4.4 too) does not do sufficient error checking on`e_ops` arguments - probably they're missing in the conversion to `CQobjEvo`. When the expectation is called, it has already sidestepped `Qobj`'s dimensions check and there is no matrix size check, so it simply segfaults on OOB access. The fix for the 4.x branch is to have a very loud Python-space error due to mismatched `Qobj` dimensions on entry to the solvers, or insert a size check within `CQobjEvo`. High priority: there's no reason we should be segfaulting here. Partially fixed in the 5.x branch; all matrix multiplications that take place in C-space have a size check and throw a Python exception, however the solvers still sidestep the `Qobj` dimension check so a tensor-product-space mismatch will not be detected.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-717495492
https://github.com/qutip/qutip/issues/1374#issuecomment-718402166:111,Integrability,message,message,111,> thanks. can you also please run:; > ; > ```; > import qutip; > qutip.about(); > ```; > ; > and copy here the message?; Here is the message; ![e38](https://user-images.githubusercontent.com/71458593/97535388-96024800-19e1-11eb-991e-2c2a578da368.PNG),MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-718402166
https://github.com/qutip/qutip/issues/1374#issuecomment-718402166:133,Integrability,message,message,133,> thanks. can you also please run:; > ; > ```; > import qutip; > qutip.about(); > ```; > ; > and copy here the message?; Here is the message; ![e38](https://user-images.githubusercontent.com/71458593/97535388-96024800-19e1-11eb-991e-2c2a578da368.PNG),MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-718402166
https://github.com/qutip/qutip/issues/1374#issuecomment-1074188292:59,Availability,error,errors,59,"Extra safety check have been added to prevent this kind of errors. #1783, #1784, #1778",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-1074188292
https://github.com/qutip/qutip/issues/1374#issuecomment-1074188292:6,Safety,safe,safety,6,"Extra safety check have been added to prevent this kind of errors. #1783, #1784, #1778",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1374#issuecomment-1074188292
https://github.com/qutip/qutip/issues/1375#issuecomment-720652251:386,Availability,error,error,386,`mcsolve` can only evolve ket states. The closest to what you want is `photocurrent_mesolve` which does master equation evolution of a density matrix with the liouvillian build from `H` and `c_ops` but using discrete jumps for `sc_ops`. It is a lot slower than mesolve since it use only basic ode method (Euler's or Heun's method) and you need to set a very small time step to keep the error resonable.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1375#issuecomment-720652251
https://github.com/qutip/qutip/issues/1375#issuecomment-720652251:19,Modifiability,evolve,evolve,19,`mcsolve` can only evolve ket states. The closest to what you want is `photocurrent_mesolve` which does master equation evolution of a density matrix with the liouvillian build from `H` and `c_ops` but using discrete jumps for `sc_ops`. It is a lot slower than mesolve since it use only basic ode method (Euler's or Heun's method) and you need to set a very small time step to keep the error resonable.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1375#issuecomment-720652251
https://github.com/qutip/qutip/issues/1376#issuecomment-721217434:126,Deployability,integrat,integrating,126,"You're trying to plot a Hamiltonian with a principle frequency of ~32 GHz, and you want to scan time over ~3ms. That involves integrating over 5 million periods of oscillation - there's little you can do to get a sensible runtime any more because you're evolving it for so long. You might want to make a frame transformation in your Hamiltonian and make a rotating-wave approximation to suppress these very high-frequency terms.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1376#issuecomment-721217434
https://github.com/qutip/qutip/issues/1376#issuecomment-721217434:126,Integrability,integrat,integrating,126,"You're trying to plot a Hamiltonian with a principle frequency of ~32 GHz, and you want to scan time over ~3ms. That involves integrating over 5 million periods of oscillation - there's little you can do to get a sensible runtime any more because you're evolving it for so long. You might want to make a frame transformation in your Hamiltonian and make a rotating-wave approximation to suppress these very high-frequency terms.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1376#issuecomment-721217434
https://github.com/qutip/qutip/issues/1377#issuecomment-721752193:36,Integrability,depend,dependent,36,"`steadystate` does not support time dependent Hamiltonian. It sees that H is a list, not a Qobj, then fails.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1377#issuecomment-721752193
https://github.com/qutip/qutip/issues/1377#issuecomment-721813998:56,Integrability,depend,dependent,56,@nwlambert didn't we fix this by natively allowing time dependent Hamiltonians in our solver? Maybe we should mention the repo here since it's relevant.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1377#issuecomment-721813998
https://github.com/qutip/qutip/issues/1377#issuecomment-722055681:971,Integrability,depend,dependent,971,"Unfortunately it doesn't really help here for the steady state stuff. I; guess generally speaking systems which are strongly driven don't have a; steady state in the normal sense, however periodic driving sometimes leads; to periodic steady states. I guess propagator_steadystate calculated the rho which satisfies. U(t)rho= rho ?. Given that in the original code snippet t=2 pi/w I suppose this gives one; part of the potentially periodic solution? (Though if the driving is weak; and on resonance this periodic oscillation will be a small modulation on; top of the rwa result). As for calculating the spectrum, I am not sure. I guess; s I would argue that the steady state used as the initial condition in the; correlation function should be the average of the periodic steady state; over one period?. On Thu, 5 Nov 2020, 00:53 Tarun Raheja, <notifications@github.com> wrote:. > @nwlambert <https://github.com/nwlambert> didn't we fix this by natively; > allowing time dependent Hamiltonians in our solver? Maybe we should mention; > the repo here since it's relevant.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1377#issuecomment-721813998>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABG3YHPABJ7DLKBEJNQYMPLSOF2GNANCNFSM4TJJWPPQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1377#issuecomment-722055681
https://github.com/qutip/qutip/issues/1378#issuecomment-808861212:53,Deployability,install,installs,53,"Sorry, this reply is very late! I was testing openmp installs on windows the other day. if you make a new conda environment, and make sure to install openmp first, it seems OK. (In once instance I did seem to have your issue, but I am not exactly sure what I did to reproduce it because it suddenly disappeared. Perhaps you had qutip already installed, and then tried to reinstall on top of it with openmp enabled?). however, you may then run into the issue currently being fixed in https://github.com/qutip/qutip/pull/1471 ; You might need to wait a little for that fix to be merged, or use Jake's branch in the mean time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-808861212
https://github.com/qutip/qutip/issues/1378#issuecomment-808861212:142,Deployability,install,install,142,"Sorry, this reply is very late! I was testing openmp installs on windows the other day. if you make a new conda environment, and make sure to install openmp first, it seems OK. (In once instance I did seem to have your issue, but I am not exactly sure what I did to reproduce it because it suddenly disappeared. Perhaps you had qutip already installed, and then tried to reinstall on top of it with openmp enabled?). however, you may then run into the issue currently being fixed in https://github.com/qutip/qutip/pull/1471 ; You might need to wait a little for that fix to be merged, or use Jake's branch in the mean time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-808861212
https://github.com/qutip/qutip/issues/1378#issuecomment-808861212:342,Deployability,install,installed,342,"Sorry, this reply is very late! I was testing openmp installs on windows the other day. if you make a new conda environment, and make sure to install openmp first, it seems OK. (In once instance I did seem to have your issue, but I am not exactly sure what I did to reproduce it because it suddenly disappeared. Perhaps you had qutip already installed, and then tried to reinstall on top of it with openmp enabled?). however, you may then run into the issue currently being fixed in https://github.com/qutip/qutip/pull/1471 ; You might need to wait a little for that fix to be merged, or use Jake's branch in the mean time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-808861212
https://github.com/qutip/qutip/issues/1378#issuecomment-808861212:38,Testability,test,testing,38,"Sorry, this reply is very late! I was testing openmp installs on windows the other day. if you make a new conda environment, and make sure to install openmp first, it seems OK. (In once instance I did seem to have your issue, but I am not exactly sure what I did to reproduce it because it suddenly disappeared. Perhaps you had qutip already installed, and then tried to reinstall on top of it with openmp enabled?). however, you may then run into the issue currently being fixed in https://github.com/qutip/qutip/pull/1471 ; You might need to wait a little for that fix to be merged, or use Jake's branch in the mean time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-808861212
https://github.com/qutip/qutip/issues/1378#issuecomment-809390058:154,Deployability,install,install,154,"#1471 is now merged into `master`, so that will be included in 4.next. To help debug this particular issue, could you post the output of `python setup.py install` or `pip install -v`, possibly repeating the `-v` up to 3 times (whichever you were using before). We need to see the compilation commands and compiler output that's being issued during the build process. After that, could you _temporarily_ change this block of code in `qutip/__init__.py`: https://github.com/qutip/qutip/blob/2aaae75d3ba52067f747dd928d67d66307fc5de9/qutip/__init__.py#L100-L107; to; ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```; (i.e. remove the entire `try/except` block and leave the import). This will cause QuTiP to throw an exception when you try to import it - could you also post the output of that exception? You'll want to revert that change right after, so you have a functioning version of non-OpenMP QuTiP at the very least.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-809390058
https://github.com/qutip/qutip/issues/1378#issuecomment-809390058:171,Deployability,install,install,171,"#1471 is now merged into `master`, so that will be included in 4.next. To help debug this particular issue, could you post the output of `python setup.py install` or `pip install -v`, possibly repeating the `-v` up to 3 times (whichever you were using before). We need to see the compilation commands and compiler output that's being issued during the build process. After that, could you _temporarily_ change this block of code in `qutip/__init__.py`: https://github.com/qutip/qutip/blob/2aaae75d3ba52067f747dd928d67d66307fc5de9/qutip/__init__.py#L100-L107; to; ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```; (i.e. remove the entire `try/except` block and leave the import). This will cause QuTiP to throw an exception when you try to import it - could you also post the output of that exception? You'll want to revert that change right after, so you have a functioning version of non-OpenMP QuTiP at the very least.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-809390058
https://github.com/qutip/qutip/issues/1378#issuecomment-892638766:24,Deployability,release,released,24,"The fixes in #1471 were released in 4.6.0, Neill reported that it worked for him, so I'm closing this issue for now. Please comment or reopen it if there is more to report.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-892638766
https://github.com/qutip/qutip/issues/1378#issuecomment-916773016:36,Deployability,install,installing,36,"Hi. I am having the same issue when installing through anaconda3 on Ubuntu20.04. The steps which I am following are:. $ conda create -n qutip python=3; $ conda activate qutip; $ conda install -c conda-forge openmp; $ conda install -c conda-forge qutip. However, when I execute qutip.about(), I get the following:. QuTiP Version: 4.6.2; Numpy Version: 1.20.3; Scipy Version: 1.6.3; Cython Version: None; Matplotlib Version: None; Python Version: 3.9.6; Number of CPUs: 6; BLAS Info: Generic; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/sourav/anaconda3/envs/qutip/lib/python3.9/site-packages/qutip; ================================================================================; Please cite QuTiP in your publication.; ================================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`. As you can see, OPENMP does not seem to be enabled. Please let me know if I am doing things incorrectly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916773016
https://github.com/qutip/qutip/issues/1378#issuecomment-916773016:184,Deployability,install,install,184,"Hi. I am having the same issue when installing through anaconda3 on Ubuntu20.04. The steps which I am following are:. $ conda create -n qutip python=3; $ conda activate qutip; $ conda install -c conda-forge openmp; $ conda install -c conda-forge qutip. However, when I execute qutip.about(), I get the following:. QuTiP Version: 4.6.2; Numpy Version: 1.20.3; Scipy Version: 1.6.3; Cython Version: None; Matplotlib Version: None; Python Version: 3.9.6; Number of CPUs: 6; BLAS Info: Generic; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/sourav/anaconda3/envs/qutip/lib/python3.9/site-packages/qutip; ================================================================================; Please cite QuTiP in your publication.; ================================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`. As you can see, OPENMP does not seem to be enabled. Please let me know if I am doing things incorrectly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916773016
https://github.com/qutip/qutip/issues/1378#issuecomment-916773016:223,Deployability,install,install,223,"Hi. I am having the same issue when installing through anaconda3 on Ubuntu20.04. The steps which I am following are:. $ conda create -n qutip python=3; $ conda activate qutip; $ conda install -c conda-forge openmp; $ conda install -c conda-forge qutip. However, when I execute qutip.about(), I get the following:. QuTiP Version: 4.6.2; Numpy Version: 1.20.3; Scipy Version: 1.6.3; Cython Version: None; Matplotlib Version: None; Python Version: 3.9.6; Number of CPUs: 6; BLAS Info: Generic; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/sourav/anaconda3/envs/qutip/lib/python3.9/site-packages/qutip; ================================================================================; Please cite QuTiP in your publication.; ================================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`. As you can see, OPENMP does not seem to be enabled. Please let me know if I am doing things incorrectly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916773016
https://github.com/qutip/qutip/issues/1378#issuecomment-916773016:498,Deployability,Install,Installed,498,"Hi. I am having the same issue when installing through anaconda3 on Ubuntu20.04. The steps which I am following are:. $ conda create -n qutip python=3; $ conda activate qutip; $ conda install -c conda-forge openmp; $ conda install -c conda-forge qutip. However, when I execute qutip.about(), I get the following:. QuTiP Version: 4.6.2; Numpy Version: 1.20.3; Scipy Version: 1.6.3; Cython Version: None; Matplotlib Version: None; Python Version: 3.9.6; Number of CPUs: 6; BLAS Info: Generic; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/sourav/anaconda3/envs/qutip/lib/python3.9/site-packages/qutip; ================================================================================; Please cite QuTiP in your publication.; ================================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`. As you can see, OPENMP does not seem to be enabled. Please let me know if I am doing things incorrectly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916773016
https://github.com/qutip/qutip/issues/1378#issuecomment-916773016:569,Deployability,Install,Installation,569,"Hi. I am having the same issue when installing through anaconda3 on Ubuntu20.04. The steps which I am following are:. $ conda create -n qutip python=3; $ conda activate qutip; $ conda install -c conda-forge openmp; $ conda install -c conda-forge qutip. However, when I execute qutip.about(), I get the following:. QuTiP Version: 4.6.2; Numpy Version: 1.20.3; Scipy Version: 1.6.3; Cython Version: None; Matplotlib Version: None; Python Version: 3.9.6; Number of CPUs: 6; BLAS Info: Generic; OPENMP Installed: False; INTEL MKL Ext: False; Platform Info: Linux (x86_64); Installation path: /home/sourav/anaconda3/envs/qutip/lib/python3.9/site-packages/qutip; ================================================================================; Please cite QuTiP in your publication.; ================================================================================; For your convenience a bibtex reference can be easily generated using `qutip.cite()`. As you can see, OPENMP does not seem to be enabled. Please let me know if I am doing things incorrectly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916773016
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:360,Deployability,install,install,360,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:424,Deployability,install,installed,424,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:468,Deployability,install,install,468,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:574,Deployability,install,installation,574,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:718,Energy Efficiency,adapt,adapting,718,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:718,Modifiability,adapt,adapting,718,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:860,Modifiability,enhance,enhancement,860,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1378#issuecomment-916822166:235,Usability,simpl,simply,235,"Hello! As @jakelishman described, you can help debug this issue by trying:. ```python; from qutip.cy.openmp.parfuncs import spmv_csr_openmp; ```. and reading the exception produced. I suspect that the `qutip.cy.openmp.*` packages will simply not have been compiled -- they're only built by QuTiP when ""--with-openmp"" is passed to `setup.py` and I think `conda install ... qutip` will not do that even when OpenMP is already installed. To correct this you will need to install QuTiP from source and pass `--with-openmp` yourself as described in https://qutip.org/docs/latest/installation.html?highlight=openmp#direct-setuptools-source-builds. We probably could make ""openmpi"" and ""no-openmpi"" builds for conda-forge by adapting the pattern in https://conda-forge.org/docs/maintainer/knowledge_base.html#openmp but that would require some work (and be a feature enhancement :).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1378#issuecomment-916822166
https://github.com/qutip/qutip/issues/1379#issuecomment-727043128:2086,Availability,error,error,2086,"ib\site-packages\qutip\stochastic.py"", line 1358, in _single_trajectory; result = ssolver.cy_sesolve_single_trajectory(i)#, sso). File ""qutip\cy\stochastic.pyx"", line 540, in qutip.cy.stochastic.StochasticSolver.cy_sesolve_single_trajectory. File ""c:\program files\python37\lib\site-packages\qutip\qobj.py"", line 303, in __init__; if not np.any(dims):. File ""<__array_function__ internals>"", line 6, in any. File ""c:\program files\python37\lib\site-packages\numpy\core\fromnumeric.py"", line 2330, in any; return _wrapreduction(a, np.logical_or, 'any', axis, None, out, keepdims=keepdims). File ""c:\program files\python37\lib\site-packages\numpy\core\fromnumeric.py"", line 87, in _wrapreduction; return ufunc.reduce(obj, axis, dtype, out, **passkwargs). VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences ; (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. ; If you meant to do this, you must specify 'dtype=object' when creating the ndarray; ```. The second problem is more serious, and I think it was the same in the my original version. The expectation values returned in `res.expect` are not the same as those computed manually from `res.states`. The values in `res.expect` gradually (but quickly) diverge away from the correct manual values that agree with theory. It is not a small error. (Note that I'm using a single trajectory so no problem of averaging over trajectories.). I would expect complete equality between the two. I would suspect that it's something to do with normalization (?) Passing kwarg `normalize=True` doesn't change anything, nor does the solver. This is how I compute the expectations:; ```; rho_list = [[vector_to_operator(u) for u in res.states[k]] for k in range(ntraj)]. for k in range(ntraj):; for i, rho in enumerate(rho_list[k]):; rho_list[k][i] = rho / rho.tr(); ```. Thanks again. I hope this is the correct venue for these kind of posts, but it does qualify as ""strange behavior"".",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1379#issuecomment-727043128
https://github.com/qutip/qutip/issues/1379#issuecomment-727043128:1426,Energy Efficiency,reduce,reduce,1426,"qutip\stochastic.py"", line 1302, in _sesolve_generic; task_args, task_kwargs, **map_kwargs). File ""c:\program files\python37\lib\site-packages\qutip\parallel.py"", line 189, in serial_map; result = task(value, *task_args, **task_kwargs). File ""c:\program files\python37\lib\site-packages\qutip\stochastic.py"", line 1358, in _single_trajectory; result = ssolver.cy_sesolve_single_trajectory(i)#, sso). File ""qutip\cy\stochastic.pyx"", line 540, in qutip.cy.stochastic.StochasticSolver.cy_sesolve_single_trajectory. File ""c:\program files\python37\lib\site-packages\qutip\qobj.py"", line 303, in __init__; if not np.any(dims):. File ""<__array_function__ internals>"", line 6, in any. File ""c:\program files\python37\lib\site-packages\numpy\core\fromnumeric.py"", line 2330, in any; return _wrapreduction(a, np.logical_or, 'any', axis, None, out, keepdims=keepdims). File ""c:\program files\python37\lib\site-packages\numpy\core\fromnumeric.py"", line 87, in _wrapreduction; return ufunc.reduce(obj, axis, dtype, out, **passkwargs). VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences ; (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. ; If you meant to do this, you must specify 'dtype=object' when creating the ndarray; ```. The second problem is more serious, and I think it was the same in the my original version. The expectation values returned in `res.expect` are not the same as those computed manually from `res.states`. The values in `res.expect` gradually (but quickly) diverge away from the correct manual values that agree with theory. It is not a small error. (Note that I'm using a single trajectory so no problem of averaging over trajectories.). I would expect complete equality between the two. I would suspect that it's something to do with normalization (?) Passing kwarg `normalize=True` doesn't change anything, nor does the solver. This is how I compute the expectations:; ```; rho_list = [[vector_to_opera",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1379#issuecomment-727043128
https://github.com/qutip/qutip/issues/1379#issuecomment-736750957:540,Availability,error,errors,540,"The code below is a (hopefully) minimum working example that demonstrates the strange behavior of the stochastic solver. I'm simulating a single trajectory using `general_stochastic` and plotting the returned expectation values along with expectation values calculated from the states. There is also a theoretical solution for the variances of X and Y, which are deterministic despite the stochastic evolution. The manually calculated expectations match the theory perfectly which means the states are correct. The returned ones accumulate errors and obviously shouldn't be used. I don't see a reason why they should be different -- I would assume the expectations are calculated internally from the states. Note that the deprecation warning from above still appears. ### Output plots. ![image](https://user-images.githubusercontent.com/13610206/100783362-f6840b00-340d-11eb-9274-09148e11cf44.png). ### Code; ```; # -*- coding: utf-8 -*-. import matplotlib.pyplot as plt; import numpy as np. from numpy import sqrt, exp. import qutip. from qutip import destroy, basis, ket2dm, expect, liouvillian, \; general_stochastic, parallel_map, \; cy, spre, spost, vector_to_operator, \; operator_to_vector. #%%%%%%%% . times = np.linspace(0, 2, 1024). N = 16. a = destroy(N) . x = (a + a.dag()) / sqrt(2); y = 1j*(a-a.dag()) / sqrt(2).  = 1 # damping rate;  = 0;  = 1 # measurement strength. H =  * a.dag()*a. c_ops = [sqrt()*a, sqrt()*x]. e_ops = [x, x*x, y, y*y]. 0 = ket2dm(basis(N)). opts = qutip.solver.Options(store_states=True). ntraj = 1; nsubsteps = 1. # defintions for the SME; #; # in literature: d(t) = i[H,(t)]dt + D[a](t)dt + dW(t) H[a](t); # in QuTiP: d(t) = i[H,(t)]dt + D1[A](t)dt + D2[A](t)dW; #; # H[A] = 0.5 * (A + A  Tr[A+A]). L = liouvillian(H, c_ops=c_ops).data; def D1_(t, _vec):; return cy.spmv(L, _vec). # D2[A](t) =  H[a](t). n_sum = spre(sqrt()*x) + spost(sqrt()*x.dag()); n_sum_data = n_sum.data. def D2_(t, _vec):; e1 = cy.cy_expect_rho_vec",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1379#issuecomment-736750957
https://github.com/qutip/qutip/issues/1379#issuecomment-736750957:2948,Usability,clear,clear,2948,"sum_data = n_sum.data. def D2_(t, _vec):; e1 = cy.cy_expect_rho_vec(n_sum_data, _vec, False); out = np.zeros((1,len(_vec)), dtype=complex); out += cy.spmv(n_sum_data, _vec) - e1 * _vec; return out. res = general_stochastic(operator_to_vector(0), times, d1=D1_, d2=D2_,; e_ops=[spre(op) for op in e_ops],; ntraj=ntraj, solver='explicit1.5',; m_ops=[spre(x)], dW_factors=[1/(2*sqrt())],; nsubsteps=nsubsteps, store_measurement=True, normalize=True,; noise=123456, options=opts). # theoretical expressions for the conditional variances. r = /. VX0 = (sqrt(1+8*r) - 1)/(8*r). VX = VX0 + 2*VX0*(1 + 1/(8*VX0*r)) / (exp((8*VX0*r+1)**times)*(1+1/(4*r*VX0))**2 - 1). VY = 0.5 + r - r*exp(-*times). #%%%%%%%% Calculate manually expectation values from states; ; rho_list = [vector_to_operator(rho) for rho in res.states[0]]. for i, rho in enumerate(rho_list):; rho_list[i] = rho / rho.tr(). my_expect = [expect(op, rho_list) for op in e_ops]. #%%%%%%%% Plotting. plt.figure('Time Evolution 2 -- Quantum State', clear=True). ax1 = plt.subplot(3,1,1, ylabel=r'$\langle X^2\rangle - \langle X\rangle^2$'); ax2 = plt.subplot(3,1,2, ylabel=r'$\langle Y^2\rangle - \langle Y\rangle^2$'); ax3 = plt.subplot(3,1,3, ylabel=r'$\langle X\rangle$', xlabel='time'). # plot expectation values calculated from states; ax1.plot(times, my_expect[1]-my_expect[0]**2, label=r'$\langle\rangle$ from stored state'); ax2.plot(times, my_expect[3]-my_expect[2]**2, label=r'$\langle\rangle$ from stored state'); ax3.plot(times, my_expect[0], label=r'$\langle\rangle$ from stored state'). # plot expectation values from result.expect; ax1.plot(times, res.expect[1]-res.expect[0]**2, label=r'$\langle\rangle$ from result.expect'); ax2.plot(times, res.expect[3]-res.expect[2]**2, label=r'$\langle\rangle$ from result.expect'); ax3.plot(times, res.expect[0], label=r'$\langle\rangle$ from result.expect'). ax1.plot(times, VX, 'k--', label='theory'); ax2.plot(times, VY, 'k--', label='theory'). ax1.legend(); ax2.legend(); ax",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1379#issuecomment-736750957
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:383,Availability,failure,failures,383,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:148,Testability,test,tests,148,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:251,Testability,test,tested,251,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:263,Testability,test,tests,263,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:378,Testability,test,test,378,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-727103648:74,Usability,clear,clearly,74,"All looks good to me. Thanks a lot for changing all of that - this is all clearly good stuff and should in principle be merged. We should the Linux tests again after #1381 is merged because there is Linux-specific code in the changes that needs to be tested (the tests fail for unrelated reasons at the moment). I can't see any reason why the changes here should cause any true test failures, though - it's more a formality.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-727103648
https://github.com/qutip/qutip/pull/1380#issuecomment-729960378:89,Availability,error,error,89,"I've rebased on top of master, now that #1381 has been merged. However there is still an error, but I don't really understand the link with my changes.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729960378
https://github.com/qutip/qutip/pull/1380#issuecomment-729963050:173,Deployability,integrat,integrate,173,"There's no link, just bad luck. This won't prevent merge - the tests clearly show your change is fine. Unfortunately our test suite isn't perfect, and sometimes it tries to integrate an insanely stiff system or something like that by accident.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729963050
https://github.com/qutip/qutip/pull/1380#issuecomment-729963050:173,Integrability,integrat,integrate,173,"There's no link, just bad luck. This won't prevent merge - the tests clearly show your change is fine. Unfortunately our test suite isn't perfect, and sometimes it tries to integrate an insanely stiff system or something like that by accident.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729963050
https://github.com/qutip/qutip/pull/1380#issuecomment-729963050:63,Testability,test,tests,63,"There's no link, just bad luck. This won't prevent merge - the tests clearly show your change is fine. Unfortunately our test suite isn't perfect, and sometimes it tries to integrate an insanely stiff system or something like that by accident.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729963050
https://github.com/qutip/qutip/pull/1380#issuecomment-729963050:121,Testability,test,test,121,"There's no link, just bad luck. This won't prevent merge - the tests clearly show your change is fine. Unfortunately our test suite isn't perfect, and sometimes it tries to integrate an insanely stiff system or something like that by accident.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729963050
https://github.com/qutip/qutip/pull/1380#issuecomment-729963050:69,Usability,clear,clearly,69,"There's no link, just bad luck. This won't prevent merge - the tests clearly show your change is fine. Unfortunately our test suite isn't perfect, and sometimes it tries to integrate an insanely stiff system or something like that by accident.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1380#issuecomment-729963050
https://github.com/qutip/qutip/issues/1382#issuecomment-728332245:113,Availability,down,down,113,"Hi Jake,. Thanks for this, yeah I started looking into it but realised it would take too long for me to track it down. And definitely I have found some speed-ups in `dev.major` for some matrix operations compared to v4.5. Actually, I have been working a bit with Eric and Nathan to make a PR soon on something related to this, where I have been doing fairly rigorous speed testing. If you like, I can loop you in on this thread (I read your blog a bit and have been using the new `Dense` data layer -- this opens up some new possibilities).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728332245
https://github.com/qutip/qutip/issues/1382#issuecomment-728332245:373,Testability,test,testing,373,"Hi Jake,. Thanks for this, yeah I started looking into it but realised it would take too long for me to track it down. And definitely I have found some speed-ups in `dev.major` for some matrix operations compared to v4.5. Actually, I have been working a bit with Eric and Nathan to make a PR soon on something related to this, where I have been doing fairly rigorous speed testing. If you like, I can loop you in on this thread (I read your blog a bit and have been using the new `Dense` data layer -- this opens up some new possibilities).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728332245
https://github.com/qutip/qutip/issues/1382#issuecomment-728373500:166,Modifiability,variab,variable,166,"https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L229-L230. `if n:` ignore it completely and assign the wrong variable... This is the main problem. https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L265. And here's the offending unchecked multiplication. That test is actually off from what I intended, which was hiding the buggy function call below it. The unchecked 32-bit overflow punched through the test and revealed the problematic function. In worse matrices, this would have actually been a huge segfault - the identity was only safe because it has the same number of elements in each row. ---. That's exciting that someone else is trying it out! I'm glad there are speed-ups. If you've got issues let me know and I can maybe help out with some of the internals (my email's in my github profile). I'm fine to wait to check out a PR if you guys are working on something between you. I still need to find the time to finish off the dispatching system and pull the OpenMP parts back into `dev.major`...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728373500
https://github.com/qutip/qutip/issues/1382#issuecomment-728373500:648,Safety,safe,safe,648,"https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L229-L230. `if n:` ignore it completely and assign the wrong variable... This is the main problem. https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L265. And here's the offending unchecked multiplication. That test is actually off from what I intended, which was hiding the buggy function call below it. The unchecked 32-bit overflow punched through the test and revealed the problematic function. In worse matrices, this would have actually been a huge segfault - the identity was only safe because it has the same number of elements in each row. ---. That's exciting that someone else is trying it out! I'm glad there are speed-ups. If you've got issues let me know and I can maybe help out with some of the internals (my email's in my github profile). I'm fine to wait to check out a PR if you guys are working on something between you. I still need to find the time to finish off the dispatching system and pull the OpenMP parts back into `dev.major`...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728373500
https://github.com/qutip/qutip/issues/1382#issuecomment-728373500:371,Testability,test,test,371,"https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L229-L230. `if n:` ignore it completely and assign the wrong variable... This is the main problem. https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L265. And here's the offending unchecked multiplication. That test is actually off from what I intended, which was hiding the buggy function call below it. The unchecked 32-bit overflow punched through the test and revealed the problematic function. In worse matrices, this would have actually been a huge segfault - the identity was only safe because it has the same number of elements in each row. ---. That's exciting that someone else is trying it out! I'm glad there are speed-ups. If you've got issues let me know and I can maybe help out with some of the internals (my email's in my github profile). I'm fine to wait to check out a PR if you guys are working on something between you. I still need to find the time to finish off the dispatching system and pull the OpenMP parts back into `dev.major`...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728373500
https://github.com/qutip/qutip/issues/1382#issuecomment-728373500:515,Testability,test,test,515,"https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L229-L230. `if n:` ignore it completely and assign the wrong variable... This is the main problem. https://github.com/qutip/qutip/blob/2ca20fb829dc67d0ee32498422bad1f8ff852a95/qutip/core/data/permute.pyx#L265. And here's the offending unchecked multiplication. That test is actually off from what I intended, which was hiding the buggy function call below it. The unchecked 32-bit overflow punched through the test and revealed the problematic function. In worse matrices, this would have actually been a huge segfault - the identity was only safe because it has the same number of elements in each row. ---. That's exciting that someone else is trying it out! I'm glad there are speed-ups. If you've got issues let me know and I can maybe help out with some of the internals (my email's in my github profile). I'm fine to wait to check out a PR if you guys are working on something between you. I still need to find the time to finish off the dispatching system and pull the OpenMP parts back into `dev.major`...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1382#issuecomment-728373500
https://github.com/qutip/qutip/pull/1384#issuecomment-728384766:4,Testability,test,tests,4,The tests will probably fail horrendously on Linux until #1383 is merged.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1384#issuecomment-728384766
https://github.com/qutip/qutip/issues/1385#issuecomment-732099730:81,Availability,down,downgrading,81,This is an issue with `matplotlib` rather than `QuTiP`. A possible workaround is downgrading to version 3.2.2.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1385#issuecomment-732099730
https://github.com/qutip/qutip/issues/1388#issuecomment-735377831:194,Availability,error,error,194,"I think i found the origin of the problem, but i don't know how to fix it correctly. I noticed that in the _essolve.py_ file (line 149) there is this instruction; ```; # check if state is below error threshold; if abs(rho0.full()).sum() < 1e-10 + 1e-24:; # enforce zero operator; return eseries(qzero(rho0.dims[0])); ```; which ( i think) should return zero eseries if the sum of all components is less than that value. However, if i increase the limit from 1e-10 to 1e-05 it work, that is it returns a zero eseries.; In the original case it doesn't enter into this _if_ and than returns an _es_ series which es.ampl[0] returns that error. ### Edit:; I replaced the `return estidy(out)` in line 205 of the same file with `return out`, and it seems to work!. ### Edit 2:; More precisely the problem is on the tolerance of tidy. I modified lines 315-316 of _eseries.py_ file with; ```; rate_tol = 1e-10; ampl_tol = 1e-13; ```; and now (with `return estidy(out)` as in origin), it's working.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1388#issuecomment-735377831
https://github.com/qutip/qutip/issues/1388#issuecomment-735377831:633,Availability,error,error,633,"I think i found the origin of the problem, but i don't know how to fix it correctly. I noticed that in the _essolve.py_ file (line 149) there is this instruction; ```; # check if state is below error threshold; if abs(rho0.full()).sum() < 1e-10 + 1e-24:; # enforce zero operator; return eseries(qzero(rho0.dims[0])); ```; which ( i think) should return zero eseries if the sum of all components is less than that value. However, if i increase the limit from 1e-10 to 1e-05 it work, that is it returns a zero eseries.; In the original case it doesn't enter into this _if_ and than returns an _es_ series which es.ampl[0] returns that error. ### Edit:; I replaced the `return estidy(out)` in line 205 of the same file with `return out`, and it seems to work!. ### Edit 2:; More precisely the problem is on the tolerance of tidy. I modified lines 315-316 of _eseries.py_ file with; ```; rate_tol = 1e-10; ampl_tol = 1e-13; ```; and now (with `return estidy(out)` as in origin), it's working.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1388#issuecomment-735377831
https://github.com/qutip/qutip/issues/1388#issuecomment-735377831:808,Availability,toler,tolerance,808,"I think i found the origin of the problem, but i don't know how to fix it correctly. I noticed that in the _essolve.py_ file (line 149) there is this instruction; ```; # check if state is below error threshold; if abs(rho0.full()).sum() < 1e-10 + 1e-24:; # enforce zero operator; return eseries(qzero(rho0.dims[0])); ```; which ( i think) should return zero eseries if the sum of all components is less than that value. However, if i increase the limit from 1e-10 to 1e-05 it work, that is it returns a zero eseries.; In the original case it doesn't enter into this _if_ and than returns an _es_ series which es.ampl[0] returns that error. ### Edit:; I replaced the `return estidy(out)` in line 205 of the same file with `return out`, and it seems to work!. ### Edit 2:; More precisely the problem is on the tolerance of tidy. I modified lines 315-316 of _eseries.py_ file with; ```; rate_tol = 1e-10; ampl_tol = 1e-13; ```; and now (with `return estidy(out)` as in origin), it's working.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1388#issuecomment-735377831
https://github.com/qutip/qutip/issues/1389#issuecomment-735296084:215,Deployability,release,releases,215,"I don't know who maintains a QuTiP package in the ubuntu repos, but wow, that's exciting that we have one!. These warnings should already be fixed in QuTiP 4.5.2 (see #1264). Whenever the maintainer of that package releases the 4.5.2 version, all of those warnings should disappear on install. At any rate, you likely won't see any actual problems because of this. It's a quirk of CPython that the string comparisons it's complaining about actually will do the intended thing in this case (due to a small-immutable-object caching optimisation). The code is still a typo despite this, but it's fixed in later releases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1389#issuecomment-735296084
https://github.com/qutip/qutip/issues/1389#issuecomment-735296084:285,Deployability,install,install,285,"I don't know who maintains a QuTiP package in the ubuntu repos, but wow, that's exciting that we have one!. These warnings should already be fixed in QuTiP 4.5.2 (see #1264). Whenever the maintainer of that package releases the 4.5.2 version, all of those warnings should disappear on install. At any rate, you likely won't see any actual problems because of this. It's a quirk of CPython that the string comparisons it's complaining about actually will do the intended thing in this case (due to a small-immutable-object caching optimisation). The code is still a typo despite this, but it's fixed in later releases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1389#issuecomment-735296084
https://github.com/qutip/qutip/issues/1389#issuecomment-735296084:608,Deployability,release,releases,608,"I don't know who maintains a QuTiP package in the ubuntu repos, but wow, that's exciting that we have one!. These warnings should already be fixed in QuTiP 4.5.2 (see #1264). Whenever the maintainer of that package releases the 4.5.2 version, all of those warnings should disappear on install. At any rate, you likely won't see any actual problems because of this. It's a quirk of CPython that the string comparisons it's complaining about actually will do the intended thing in this case (due to a small-immutable-object caching optimisation). The code is still a typo despite this, but it's fixed in later releases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1389#issuecomment-735296084
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:593,Availability,error,error,593,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:136,Deployability,install,installed,136,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:339,Deployability,install,installation,339,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:434,Deployability,install,installing,434,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:475,Deployability,install,installation,475,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:464,Testability,test,test,464,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:548,Testability,test,testing,548,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735447201:619,Testability,test,testing,619,"Hi, are you sure you are not in the QuTiP folder when you start your Python; interpreter? Please provide some information as to how you installed QuTiP.; Which Python version are you using?. You can just type the command. >> which python. To find out the Python you are using. I would suggest the best way to run; QuTiP is using the conda installation. On Sun, 29 Nov 2020 at 20:42, ZahraQI <notifications@github.com> wrote:. > After installing qutip, in order to test qutip installation, I type; > ""python"" in terminal and then type ""import qutip.testing as qt"", getteing; > to the following error.; >; > import qutip.testing as qt; > Traceback (most recent call last):; > File """", line 1, in; > ModuleNotFoundError: No module named 'qutip'; >; > qt.run(); > Traceback (most recent call last):; > File """", line 1, in; > NameError: name 'qt' is not defined; >; > If anyone can help to solve the problem?; > Thanks; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABVFIBB6E4CM7HU3CY2NT6LSSKP3PANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735447201
https://github.com/qutip/qutip/issues/1391#issuecomment-735452873:45,Deployability,install,install,45,It's very likely that the Python you used to install QuTiP was not the one you used to import it. It can happen when several Python versions/environments are present (e.g. on a server).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735452873
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:510,Availability,error,errors,510,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:671,Availability,error,error,671,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:79,Deployability,install,installed,79,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:197,Deployability,install,install,197,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:230,Deployability,install,install,230,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:487,Deployability,install,install,487,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:529,Deployability,install,installed,529,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:335,Modifiability,config,config,335,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-735554120:638,Testability,test,testing,638,"Thanks for your replies.; I did not have any python on my computer. Firstly, I installed Anaconda, then build a qutip-env. I typed ""conda activate qutip-env"" and then used the following command to install the requirements: ""conda install numpy scipy cython matplotlib pytest pytest-cov jupyter notebook spyder"" .; Then, I added ""conda config --append channels conda-forge"", getting the following warning: ""conda-forge already in channels list, moving to the bottem"".; Then, I run ""conda install qutip"" with no errors.; qutip was installed in ""/root/anaconda3/env"" and i opened a terminal in ""/root"", typed ""python"" and then ""import qutip.testing as qt"" getting the above error.; I really appreciate any help!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-735554120
https://github.com/qutip/qutip/issues/1391#issuecomment-736060302:129,Deployability,install,installed,129,"Every time you open a new terminal, you will need to activate the conda environment by `conda activate qutip-env`. QuTiP is only installed in this environment. If you are interested, you could check https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html for details.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-736060302
https://github.com/qutip/qutip/issues/1391#issuecomment-736060302:251,Usability,guid,guide,251,"Every time you open a new terminal, you will need to activate the conda environment by `conda activate qutip-env`. QuTiP is only installed in this environment. If you are interested, you could check https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html for details.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-736060302
https://github.com/qutip/qutip/issues/1391#issuecomment-736727232:138,Availability,error,error,138,"Thanks alot for your great help.; Activating conda solved the problem, but still the command ""import numpy as; np"" leads to the following error:. File ""<stdin>"", line 1; import numpy as np; ^; IndentationError: unexpected indent. Other commands like ""import matplotlib.pyplot as plt"" works fine but; something like ""r=np.random.rand(4,4)"" does not work.; My numpy version is 1.19.2. Would you please help me to solve the problem.; Many thanks. On Tue, Dec 1, 2020 at 12:44 AM Boxi Li <notifications@github.com> wrote:. > Every time you open a new terminal, you will need to activate the conda; > environment by conda activate qutip-env. QuTiP is only installed in this; > environment. If you are interested, you could check; > https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html; > for details.; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391#issuecomment-736060302>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AR53J43QBLGZO3C3WKRB7BDSSQDMJANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-736727232
https://github.com/qutip/qutip/issues/1391#issuecomment-736727232:651,Deployability,install,installed,651,"Thanks alot for your great help.; Activating conda solved the problem, but still the command ""import numpy as; np"" leads to the following error:. File ""<stdin>"", line 1; import numpy as np; ^; IndentationError: unexpected indent. Other commands like ""import matplotlib.pyplot as plt"" works fine but; something like ""r=np.random.rand(4,4)"" does not work.; My numpy version is 1.19.2. Would you please help me to solve the problem.; Many thanks. On Tue, Dec 1, 2020 at 12:44 AM Boxi Li <notifications@github.com> wrote:. > Every time you open a new terminal, you will need to activate the conda; > environment by conda activate qutip-env. QuTiP is only installed in this; > environment. If you are interested, you could check; > https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html; > for details.; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391#issuecomment-736060302>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AR53J43QBLGZO3C3WKRB7BDSSQDMJANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-736727232
https://github.com/qutip/qutip/issues/1391#issuecomment-736727232:779,Usability,guid,guide,779,"Thanks alot for your great help.; Activating conda solved the problem, but still the command ""import numpy as; np"" leads to the following error:. File ""<stdin>"", line 1; import numpy as np; ^; IndentationError: unexpected indent. Other commands like ""import matplotlib.pyplot as plt"" works fine but; something like ""r=np.random.rand(4,4)"" does not work.; My numpy version is 1.19.2. Would you please help me to solve the problem.; Many thanks. On Tue, Dec 1, 2020 at 12:44 AM Boxi Li <notifications@github.com> wrote:. > Every time you open a new terminal, you will need to activate the conda; > environment by conda activate qutip-env. QuTiP is only installed in this; > environment. If you are interested, you could check; > https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html; > for details.; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1391#issuecomment-736060302>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AR53J43QBLGZO3C3WKRB7BDSSQDMJANCNFSM4UGXA6UA>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1391#issuecomment-736727232
https://github.com/qutip/qutip/pull/1394#issuecomment-735704859:40,Testability,test,tests,40,"Thanks @jakobjakobson13. A few modules' tests fail, on all operating systems, https://travis-ci.org/github/qutip/qutip/jobs/746708587. I wonder why. By the way, what software did you use, `autoflake`?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735704859
https://github.com/qutip/qutip/pull/1394#issuecomment-735719114:235,Availability,down,down,235,"> Thanks @jakobjakobson13. A few modules' tests fail, on all operating systems, https://travis-ci.org/github/qutip/qutip/jobs/746708587. I wonder why.; > ; I think I went a bit to far. Perhaps I will close this pull request and cut it down into smaller chunks. > By the way, what software did you use, `autoflake`?; >; No, `deepcode.ai` but I don't know really know how good or bad it performs in contrast to other static code checkers.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735719114
https://github.com/qutip/qutip/pull/1394#issuecomment-735719114:385,Performance,perform,performs,385,"> Thanks @jakobjakobson13. A few modules' tests fail, on all operating systems, https://travis-ci.org/github/qutip/qutip/jobs/746708587. I wonder why.; > ; I think I went a bit to far. Perhaps I will close this pull request and cut it down into smaller chunks. > By the way, what software did you use, `autoflake`?; >; No, `deepcode.ai` but I don't know really know how good or bad it performs in contrast to other static code checkers.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735719114
https://github.com/qutip/qutip/pull/1394#issuecomment-735719114:42,Testability,test,tests,42,"> Thanks @jakobjakobson13. A few modules' tests fail, on all operating systems, https://travis-ci.org/github/qutip/qutip/jobs/746708587. I wonder why.; > ; I think I went a bit to far. Perhaps I will close this pull request and cut it down into smaller chunks. > By the way, what software did you use, `autoflake`?; >; No, `deepcode.ai` but I don't know really know how good or bad it performs in contrast to other static code checkers.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735719114
https://github.com/qutip/qutip/pull/1394#issuecomment-735738116:456,Availability,failure,failures,456,"It would maybe be good to keep everything in one PR that can be squashed into a single commit at the end - this is only a single ""logical"" change at the end of the day. Nice to get these things tidied up. You probably need to run all the tests locally before just pushing to check if everything works; QuTiP has quite a few code generation steps and indirect evaluation that can't be detected with static analysis, which is why you're seeing a lot of test failures (though that's _mostly_ `.pyx` files). Something seems wrong with the static analyser if it's not spotting that `Qobj` is used _everywhere_, though, and I notice in several commits it has a lot of false positives for removal. I can't imagine any situation where a static analyser should remove an in-library import from an `__init__.py` file, but it's done that in a couple of places. Similarly, in `cy/pyxbuilder.py` I can see that it's removed a line `import pyximport`, but I can see that that import _is_ used - it's so close it's even within the minimal diff!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735738116
https://github.com/qutip/qutip/pull/1394#issuecomment-735738116:384,Safety,detect,detected,384,"It would maybe be good to keep everything in one PR that can be squashed into a single commit at the end - this is only a single ""logical"" change at the end of the day. Nice to get these things tidied up. You probably need to run all the tests locally before just pushing to check if everything works; QuTiP has quite a few code generation steps and indirect evaluation that can't be detected with static analysis, which is why you're seeing a lot of test failures (though that's _mostly_ `.pyx` files). Something seems wrong with the static analyser if it's not spotting that `Qobj` is used _everywhere_, though, and I notice in several commits it has a lot of false positives for removal. I can't imagine any situation where a static analyser should remove an in-library import from an `__init__.py` file, but it's done that in a couple of places. Similarly, in `cy/pyxbuilder.py` I can see that it's removed a line `import pyximport`, but I can see that that import _is_ used - it's so close it's even within the minimal diff!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735738116
https://github.com/qutip/qutip/pull/1394#issuecomment-735738116:130,Testability,log,logical,130,"It would maybe be good to keep everything in one PR that can be squashed into a single commit at the end - this is only a single ""logical"" change at the end of the day. Nice to get these things tidied up. You probably need to run all the tests locally before just pushing to check if everything works; QuTiP has quite a few code generation steps and indirect evaluation that can't be detected with static analysis, which is why you're seeing a lot of test failures (though that's _mostly_ `.pyx` files). Something seems wrong with the static analyser if it's not spotting that `Qobj` is used _everywhere_, though, and I notice in several commits it has a lot of false positives for removal. I can't imagine any situation where a static analyser should remove an in-library import from an `__init__.py` file, but it's done that in a couple of places. Similarly, in `cy/pyxbuilder.py` I can see that it's removed a line `import pyximport`, but I can see that that import _is_ used - it's so close it's even within the minimal diff!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735738116
https://github.com/qutip/qutip/pull/1394#issuecomment-735738116:238,Testability,test,tests,238,"It would maybe be good to keep everything in one PR that can be squashed into a single commit at the end - this is only a single ""logical"" change at the end of the day. Nice to get these things tidied up. You probably need to run all the tests locally before just pushing to check if everything works; QuTiP has quite a few code generation steps and indirect evaluation that can't be detected with static analysis, which is why you're seeing a lot of test failures (though that's _mostly_ `.pyx` files). Something seems wrong with the static analyser if it's not spotting that `Qobj` is used _everywhere_, though, and I notice in several commits it has a lot of false positives for removal. I can't imagine any situation where a static analyser should remove an in-library import from an `__init__.py` file, but it's done that in a couple of places. Similarly, in `cy/pyxbuilder.py` I can see that it's removed a line `import pyximport`, but I can see that that import _is_ used - it's so close it's even within the minimal diff!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735738116
https://github.com/qutip/qutip/pull/1394#issuecomment-735738116:451,Testability,test,test,451,"It would maybe be good to keep everything in one PR that can be squashed into a single commit at the end - this is only a single ""logical"" change at the end of the day. Nice to get these things tidied up. You probably need to run all the tests locally before just pushing to check if everything works; QuTiP has quite a few code generation steps and indirect evaluation that can't be detected with static analysis, which is why you're seeing a lot of test failures (though that's _mostly_ `.pyx` files). Something seems wrong with the static analyser if it's not spotting that `Qobj` is used _everywhere_, though, and I notice in several commits it has a lot of false positives for removal. I can't imagine any situation where a static analyser should remove an in-library import from an `__init__.py` file, but it's done that in a couple of places. Similarly, in `cy/pyxbuilder.py` I can see that it's removed a line `import pyximport`, but I can see that that import _is_ used - it's so close it's even within the minimal diff!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1394#issuecomment-735738116
https://github.com/qutip/qutip/issues/1395#issuecomment-735863085:763,Deployability,release,releases,763,"Thanks for reporting this. This is actually a bit of a concern - as far as I know none of the developers have the new ARM chips (or even macOS 11) and I don't know how long it'll be until CI servers have them, so there may be more bugs lurking for you. Please let us know if you have any more problems, especially building from source or string-format time-dependence - I'd expect those to be the most fragile to new kernel and hardware changes. @ajgpitch This is actually going to be a nuisance for distributing wheels too. I _think_ GH actions will have the necessary Xcode 12 support, but I'm not sure the multi-wheel tool I'm using does - the new Apple silicon is ARM not x86 so it needs different compilation. We may not be able to support M1 macs in binary releases initially.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-735863085
https://github.com/qutip/qutip/issues/1395#issuecomment-735863085:357,Integrability,depend,dependence,357,"Thanks for reporting this. This is actually a bit of a concern - as far as I know none of the developers have the new ARM chips (or even macOS 11) and I don't know how long it'll be until CI servers have them, so there may be more bugs lurking for you. Please let us know if you have any more problems, especially building from source or string-format time-dependence - I'd expect those to be the most fragile to new kernel and hardware changes. @ajgpitch This is actually going to be a nuisance for distributing wheels too. I _think_ GH actions will have the necessary Xcode 12 support, but I'm not sure the multi-wheel tool I'm using does - the new Apple silicon is ARM not x86 so it needs different compilation. We may not be able to support M1 macs in binary releases initially.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-735863085
https://github.com/qutip/qutip/issues/1395#issuecomment-736660709:81,Testability,benchmark,benchmark,81,"Hardware info is only used to get the number of cpus... It may hve been used for benchmark in the past, it also fetch the cpu frequency and memsize... I would be for simply removing it in the next version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736660709
https://github.com/qutip/qutip/issues/1395#issuecomment-736660709:166,Usability,simpl,simply,166,"Hardware info is only used to get the number of cpus... It may hve been used for benchmark in the past, it also fetch the cpu frequency and memsize... I would be for simply removing it in the next version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736660709
https://github.com/qutip/qutip/issues/1395#issuecomment-736675351:403,Availability,reliab,reliable,403,"Knowing the number of CPUs in the system may help in the future in debugging OpenMP code and setting sensible OpenMP thread counts - we may want to keep that part of the detection. I don't see any need for CPU frequency or memory size, though. That said, we should probably switch to using a library (like [`psutil`](https://github.com/giampaolo/psutil)) if we're going to keep it - it'll be a lot more reliable. For example, I've no idea why the current mac hardware detection in QuTiP ignores the `hw.ncpu` entry in `sysctl`, but the FreeBSD version explicitly uses it...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736675351
https://github.com/qutip/qutip/issues/1395#issuecomment-736675351:170,Safety,detect,detection,170,"Knowing the number of CPUs in the system may help in the future in debugging OpenMP code and setting sensible OpenMP thread counts - we may want to keep that part of the detection. I don't see any need for CPU frequency or memory size, though. That said, we should probably switch to using a library (like [`psutil`](https://github.com/giampaolo/psutil)) if we're going to keep it - it'll be a lot more reliable. For example, I've no idea why the current mac hardware detection in QuTiP ignores the `hw.ncpu` entry in `sysctl`, but the FreeBSD version explicitly uses it...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736675351
https://github.com/qutip/qutip/issues/1395#issuecomment-736675351:468,Safety,detect,detection,468,"Knowing the number of CPUs in the system may help in the future in debugging OpenMP code and setting sensible OpenMP thread counts - we may want to keep that part of the detection. I don't see any need for CPU frequency or memory size, though. That said, we should probably switch to using a library (like [`psutil`](https://github.com/giampaolo/psutil)) if we're going to keep it - it'll be a lot more reliable. For example, I've no idea why the current mac hardware detection in QuTiP ignores the `hw.ncpu` entry in `sysctl`, but the FreeBSD version explicitly uses it...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736675351
https://github.com/qutip/qutip/issues/1395#issuecomment-736677888:153,Safety,detect,detection,153,"Because things worked a bit differently 10 years ago. However, psutil does do everything QuTiP needs these days. They can also come up with a smarter M1 detection method.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736677888
https://github.com/qutip/qutip/issues/1395#issuecomment-736688479:104,Testability,log,log,104,"@nonhermitian: yeah, that's why I wasn't so keen on changing the code as it is - I can see from the git log that it went through a few iterations due to old versions of mac os breaking it, and I don't want to introduce regressive bugs. I didn't know why there was a difference, and I couldn't find what the output of `sysctl` was on mac 10.9 or whatever it was in 2013 (or when/if it changed).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1395#issuecomment-736688479
https://github.com/qutip/qutip/issues/1396#issuecomment-736516068:116,Deployability,release,releases,116,"As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either. If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it. None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-736516068
https://github.com/qutip/qutip/issues/1396#issuecomment-736516068:228,Deployability,update,updated,228,"As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either. If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it. None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-736516068
https://github.com/qutip/qutip/issues/1396#issuecomment-736516068:712,Deployability,release,release,712,"As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either. If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it. None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-736516068
https://github.com/qutip/qutip/issues/1396#issuecomment-736516068:739,Deployability,update,updated,739,"As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either. If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it. None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-736516068
https://github.com/qutip/qutip/issues/1396#issuecomment-736516068:519,Safety,detect,detection,519,"As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either. If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it. None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-736516068
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:53,Availability,error,errors,53,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:247,Availability,error,error,247,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:277,Availability,error,error,277,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:464,Deployability,install,install,464,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:283,Integrability,message,message,283,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:145,Safety,detect,detection,145,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:540,Testability,test,testing,540,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-759733240:557,Testability,test,test,557,"I'm also using Anaconda on Macbook M1 and ran into 2 errors today when importing qutip. . 1. With the M1 chip, qutip had a problem with hardware detection and as @jakelishman said, commenting lines 48 and 49 on `qutip/hardware_info.py` fixed this error. 2. Then I got the same error message with ""IPYTHON not defined"" and ""'qutip' has no attribute 'settings'."" I thought my conda environment must have been missing the ipython package somehow(?) so I tried `conda install ipython` and importing qutip again and it worked! (I then ran qutip.testing.run() to test out all functions and everything worked perfectly).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-759733240
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:961,Availability,error,error,961,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:2,Deployability,Update,Update,2,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:240,Deployability,release,releases,240,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:352,Deployability,update,updated,352,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:850,Deployability,release,release,850,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:877,Deployability,update,updated,877,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:999,Deployability,install,installed,999,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-776702708:650,Safety,detect,detection,650,"**Update - Ignore this. This problem was because I called the file ""pyqtgraph"" which conflicted with the library name.**. > As I understand it, the new Mac M1 chips have an ARM-based architecture so there shouldn't be any compatible binary releases on conda yet for macos - I'm surprised conda even claimed to have solved the system. Maybe they've not updated to take the new chips into account either.; > ; > If you can, you might want to try building from source - you'll also need the Python package Cython, but this way should build all the binary components for your architecture. We know (#1395) that there's a minor problem with some hardware detection on the M1 macs at the moment, but you can comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.; > ; > None of us have one of the new macs, and I think we'll need a new release to get conda-forge updated. It might be a little while before we get that done, sorry. I have the same error on an Intel Mac (11.2.1) having installed pyqtgraph within PyCharm. ```; Connected to pydev debugger (build 203.7148.72); Traceback (most recent call last):; File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked; File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked; File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module; File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed; File ""/Users/ben/Library/Application Support/JetBrains/PyCharm2020.3/scratches/pyqtgraph.py"", line 3, in <module>; pg.mkQApp(); AttributeError: partially initialized module 'pyqtgraph' has no attribute 'mkQApp' (most likely due to a circular import). ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-776702708
https://github.com/qutip/qutip/issues/1396#issuecomment-777523352:181,Deployability,Release,Release,181,"I get the same issue on a [Travis CI build](https://travis-ci.org/github/qutech/filter_functions/jobs/757061484) with; ```; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.6 LTS; Release:	16.04; Codename:	xenial; ```; running on `amd64` with `qutip-4.5.2` installed via `pip`. The same test config runs fine on Python 3.6 and 3.7, though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777523352
https://github.com/qutip/qutip/issues/1396#issuecomment-777523352:258,Deployability,install,installed,258,"I get the same issue on a [Travis CI build](https://travis-ci.org/github/qutech/filter_functions/jobs/757061484) with; ```; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.6 LTS; Release:	16.04; Codename:	xenial; ```; running on `amd64` with `qutip-4.5.2` installed via `pip`. The same test config runs fine on Python 3.6 and 3.7, though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777523352
https://github.com/qutip/qutip/issues/1396#issuecomment-777523352:293,Modifiability,config,config,293,"I get the same issue on a [Travis CI build](https://travis-ci.org/github/qutech/filter_functions/jobs/757061484) with; ```; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.6 LTS; Release:	16.04; Codename:	xenial; ```; running on `amd64` with `qutip-4.5.2` installed via `pip`. The same test config runs fine on Python 3.6 and 3.7, though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777523352
https://github.com/qutip/qutip/issues/1396#issuecomment-777523352:288,Testability,test,test,288,"I get the same issue on a [Travis CI build](https://travis-ci.org/github/qutech/filter_functions/jobs/757061484) with; ```; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.6 LTS; Release:	16.04; Codename:	xenial; ```; running on `amd64` with `qutip-4.5.2` installed via `pip`. The same test config runs fine on Python 3.6 and 3.7, though.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777523352
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:30,Availability,error,error,30,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:361,Availability,avail,available,361,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:111,Deployability,release,released,111,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:162,Deployability,install,installing,162,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:236,Deployability,install,install,236,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:308,Deployability,install,installation,308,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:433,Deployability,install,installation,433,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:530,Deployability,release,release,530,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777556715:639,Deployability,patch,patch,639,"@thangleiter: this particular error looks possibly like it's caused by build incompatibility with the recently released numpy 1.20. I see that the environment is installing numpy 1.19, but I suspect that the build_wheels action of `pip install` is pulling in numpy 1.20. QuTiP 4.5 doesn't officially support installation from `pip` (we never had enough free CI available to build wheels) - you should be able to always get a working installation using the `conda-forge` channel of `conda`. We should have wheels in the next major release. We're currently facing a couple of problems with numpy 1.20 (#1433), but we'll be able to put out a patch when someone has time, which will include pinning numpy to a lower version when building.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777556715
https://github.com/qutip/qutip/issues/1396#issuecomment-777706377:151,Availability,down,down,151,"Unfortunately I have had some issues with `conda` in CI (for instance, it's solver uses quite a bit of memory, which had readthedocs actually shoot it down when solving the environment at some point). Also build matrices that test various combinations of optional dependencies are much cleaner when using a pure `pip` setup. I see your point though. I'll have to work around it for now. Thanks anyway!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777706377
https://github.com/qutip/qutip/issues/1396#issuecomment-777706377:264,Integrability,depend,dependencies,264,"Unfortunately I have had some issues with `conda` in CI (for instance, it's solver uses quite a bit of memory, which had readthedocs actually shoot it down when solving the environment at some point). Also build matrices that test various combinations of optional dependencies are much cleaner when using a pure `pip` setup. I see your point though. I'll have to work around it for now. Thanks anyway!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777706377
https://github.com/qutip/qutip/issues/1396#issuecomment-777706377:226,Testability,test,test,226,"Unfortunately I have had some issues with `conda` in CI (for instance, it's solver uses quite a bit of memory, which had readthedocs actually shoot it down when solving the environment at some point). Also build matrices that test various combinations of optional dependencies are much cleaner when using a pure `pip` setup. I see your point though. I'll have to work around it for now. Thanks anyway!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-777706377
https://github.com/qutip/qutip/issues/1396#issuecomment-782889136:10,Deployability,release,release,10,"As of the release of 4.5.3 the numpy 1.20 problems should have been fixed (including fixing the correct build versions when installing from `pip`), and all currently known problems with M1 Macs are solved on `master` with the merge of #1401. Closing this for now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-782889136
https://github.com/qutip/qutip/issues/1396#issuecomment-782889136:124,Deployability,install,installing,124,"As of the release of 4.5.3 the numpy 1.20 problems should have been fixed (including fixing the correct build versions when installing from `pip`), and all currently known problems with M1 Macs are solved on `master` with the merge of #1401. Closing this for now.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-782889136
https://github.com/qutip/qutip/issues/1396#issuecomment-1220250053:175,Availability,error,error,175,AttributeError Traceback (most recent call last); <ipython-input-2-82c62ef8635d> in <module>; ----> 1 from qutip import *; When I try to run ; from qutip import *. I got this error. Can anyone help to come out of this error?. ~/anaconda3/lib/python3.8/site-packages/qutip/__init__.py in <module>; 42 try:; 43 __IPYTHON__; ---> 44 qutip.settings.ipython = True; 45 except NameError:; 46 qutip.settings.ipython = False. AttributeError: partially initialized module 'qutip' has no attribute 'settings' (most likely due to a circular import),MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220250053
https://github.com/qutip/qutip/issues/1396#issuecomment-1220250053:218,Availability,error,error,218,AttributeError Traceback (most recent call last); <ipython-input-2-82c62ef8635d> in <module>; ----> 1 from qutip import *; When I try to run ; from qutip import *. I got this error. Can anyone help to come out of this error?. ~/anaconda3/lib/python3.8/site-packages/qutip/__init__.py in <module>; 42 try:; 43 __IPYTHON__; ---> 44 qutip.settings.ipython = True; 45 except NameError:; 46 qutip.settings.ipython = False. AttributeError: partially initialized module 'qutip' has no attribute 'settings' (most likely due to a circular import),MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220250053
https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689:20,Availability,error,error,20,"@Akhikar I know the error message is the same, but could you open a new issue for this and follow the issue template? This bug was addressed awhile ago, and if you open a new issue we'll know what versions of all the installed software you're using. Usually this issue arises when something went wrong while installing QuTiP, or because you have a script whose name conflicts with an existing package name.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689
https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689:217,Deployability,install,installed,217,"@Akhikar I know the error message is the same, but could you open a new issue for this and follow the issue template? This bug was addressed awhile ago, and if you open a new issue we'll know what versions of all the installed software you're using. Usually this issue arises when something went wrong while installing QuTiP, or because you have a script whose name conflicts with an existing package name.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689
https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689:308,Deployability,install,installing,308,"@Akhikar I know the error message is the same, but could you open a new issue for this and follow the issue template? This bug was addressed awhile ago, and if you open a new issue we'll know what versions of all the installed software you're using. Usually this issue arises when something went wrong while installing QuTiP, or because you have a script whose name conflicts with an existing package name.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689
https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689:26,Integrability,message,message,26,"@Akhikar I know the error message is the same, but could you open a new issue for this and follow the issue template? This bug was addressed awhile ago, and if you open a new issue we'll know what versions of all the installed software you're using. Usually this issue arises when something went wrong while installing QuTiP, or because you have a script whose name conflicts with an existing package name.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1396#issuecomment-1220411689
https://github.com/qutip/qutip/issues/1398#issuecomment-739026681:522,Availability,avail,available,522,"Right now, QuTiP doesn't support passing `c_ops` as an arbitrary function to `mcsolve`. @Ericgig might have more ideas for other things you may try, but in general to us `mcsolve` you need to have your collapse operators as constant matrices multiplied by time-dependent scalars. Depending on your collapse operators, you may be able to move to an interaction picture such that the collapse operators lose their time-dependence, or move to being scalars multiplied by constant matrices. Otherwise, if your system size and available memory permit, you can use `mesolve` to directly solve the Lindblad master equation for the full density matrix rather than single trajectories.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-739026681
https://github.com/qutip/qutip/issues/1398#issuecomment-739026681:261,Integrability,depend,dependent,261,"Right now, QuTiP doesn't support passing `c_ops` as an arbitrary function to `mcsolve`. @Ericgig might have more ideas for other things you may try, but in general to us `mcsolve` you need to have your collapse operators as constant matrices multiplied by time-dependent scalars. Depending on your collapse operators, you may be able to move to an interaction picture such that the collapse operators lose their time-dependence, or move to being scalars multiplied by constant matrices. Otherwise, if your system size and available memory permit, you can use `mesolve` to directly solve the Lindblad master equation for the full density matrix rather than single trajectories.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-739026681
https://github.com/qutip/qutip/issues/1398#issuecomment-739026681:280,Integrability,Depend,Depending,280,"Right now, QuTiP doesn't support passing `c_ops` as an arbitrary function to `mcsolve`. @Ericgig might have more ideas for other things you may try, but in general to us `mcsolve` you need to have your collapse operators as constant matrices multiplied by time-dependent scalars. Depending on your collapse operators, you may be able to move to an interaction picture such that the collapse operators lose their time-dependence, or move to being scalars multiplied by constant matrices. Otherwise, if your system size and available memory permit, you can use `mesolve` to directly solve the Lindblad master equation for the full density matrix rather than single trajectories.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-739026681
https://github.com/qutip/qutip/issues/1398#issuecomment-739026681:417,Integrability,depend,dependence,417,"Right now, QuTiP doesn't support passing `c_ops` as an arbitrary function to `mcsolve`. @Ericgig might have more ideas for other things you may try, but in general to us `mcsolve` you need to have your collapse operators as constant matrices multiplied by time-dependent scalars. Depending on your collapse operators, you may be able to move to an interaction picture such that the collapse operators lose their time-dependence, or move to being scalars multiplied by constant matrices. Otherwise, if your system size and available memory permit, you can use `mesolve` to directly solve the Lindblad master equation for the full density matrix rather than single trajectories.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-739026681
https://github.com/qutip/qutip/issues/1398#issuecomment-740001840:440,Deployability,release,release,440,"`c_ops` don't support arbitrary function, and there is no easy way to go around it for `mcsolve`. The main runner of the evolution is in cython and rewriting a python mcsolver would probably be easier than to try to force it.; In one of my old PR: #1123, I believe mcsolve and mesolve accepted arbitrary function for `c_ops` but `stochastic` was still in progress. You could try that, but there is no guaranties.; Otherwise, the next major release should accept functions, but it's still far away.; `mesolve` is probably the easiest way.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-740001840
https://github.com/qutip/qutip/issues/1398#issuecomment-740542623:63,Integrability,depend,dependent,63,How can I use QobjEvoFunc to write collapse operator with time dependent operator?could you give an example?; @Ericgig,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-740542623
https://github.com/qutip/qutip/issues/1398#issuecomment-741910743:280,Availability,down,down,280,"With that branch, you can pass any function that take time and a args dict that return a Qobj as a `c_ops`:; ```; import qutip as qt; def f(t, args):; return (qt.destroy(3)*t).expm(). res = qt.mcsolve(qt.qeye(3), qt.basis(3,1), [0,1,2,3,4,5], [f], [qt.num(3)], 10); ```; It slows down the solver a lot...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-741910743
https://github.com/qutip/qutip/issues/1398#issuecomment-1681460936:80,Integrability,depend,dependent,80,"Another approach, if your system size is not too large, is to express your time-dependent operator a time-dependent linear combination of the basis operators on the system's Hilbert space. For example if you were looking at a qubit, you would write `expm(f(t)) = sum a_i(t) * sigma_i`. Then you can pass vectorized coefficients in the form `[[a_i_list,sigma_i],...]`. This should be much faster. It's ideal if you can do this analytically, but it would be sufficient to pre-compute the collapse operator at each timestep (which will be expensive for large systems) and then project them onto your operator basis. The relaxation generators are usually Hermitian, so you can find the projections onto the Pauli basis by examining the matrix elements, rather than computing lots of inner products.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-1681460936
https://github.com/qutip/qutip/issues/1398#issuecomment-1681460936:106,Integrability,depend,dependent,106,"Another approach, if your system size is not too large, is to express your time-dependent operator a time-dependent linear combination of the basis operators on the system's Hilbert space. For example if you were looking at a qubit, you would write `expm(f(t)) = sum a_i(t) * sigma_i`. Then you can pass vectorized coefficients in the form `[[a_i_list,sigma_i],...]`. This should be much faster. It's ideal if you can do this analytically, but it would be sufficient to pre-compute the collapse operator at each timestep (which will be expensive for large systems) and then project them onto your operator basis. The relaxation generators are usually Hermitian, so you can find the projections onto the Pauli basis by examining the matrix elements, rather than computing lots of inner products.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1398#issuecomment-1681460936
https://github.com/qutip/qutip/pull/1401#issuecomment-751540091:306,Deployability,update,updated,306,"Most recent macOS Big Sur version change the output of command. ```bash; $ sysctl -n machdep.cpu.brand_string; Apple M1; ```. The output does not contains information about the frequency of CPU. To fix this problem, I use command . ```bash; $ sysctl hw.cpufrequency; hw.cpufrequency: 2400000000; ``` . The updated code should be able to get cpu frequency correctly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-751540091
https://github.com/qutip/qutip/pull/1401#issuecomment-751561367:46,Testability,test,test,46,@Ericgig I'm not sure why my changes make one test `tests/test_brtools.py::test_diag_liou_mult` fail.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-751561367
https://github.com/qutip/qutip/pull/1401#issuecomment-751561367:52,Testability,test,tests,52,@Ericgig I'm not sure why my changes make one test `tests/test_brtools.py::test_diag_liou_mult` fail.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-751561367
https://github.com/qutip/qutip/pull/1401#issuecomment-879469970:145,Availability,error,error,145,"Note: This appears broken on my M1 MacBookPro running Big Sur... there is no sysctl hw.cpufrequency at all on this machine, so it blows up (some error handling in that function would be good :-). ```$ sysctl hw; hw.ncpu: 8; hw.byteorder: 1234; hw.memsize: 17179869184; hw.activecpu: 8; hw.optional.amx_version: 2; hw.optional.arm64: 1; hw.optional.armv8_1_atomics: 1; hw.optional.armv8_2_fhm: 1; hw.optional.armv8_2_sha3: 1; hw.optional.armv8_2_sha512: 1; hw.optional.armv8_crc32: 1; hw.optional.breakpoint: 6; hw.optional.floatingpoint: 1; hw.optional.neon: 1; hw.optional.neon_fp16: 1; hw.optional.neon_hpfp: 1; hw.optional.ucnormal_mem: 1; hw.optional.watchpoint: 4; hw.cacheconfig: 8 1 1 0 0 0 0 0 0 0; hw.cachelinesize: 128; hw.cachesize: 3616980992 65536 4194304 0 0 0 0 0 0 0; hw.cpu64bit_capable: 1; hw.cpufamily: 458787763; hw.cpusubfamily: 2; hw.cpusubtype: 2; hw.cputype: 16777228; hw.ephemeral_storage: 0; hw.l1dcachesize: 65536; hw.l1icachesize: 131072; hw.l2cachesize: 4194304; hw.logicalcpu: 8; hw.logicalcpu_max: 8; hw.osenvironment: ; hw.packages: 1; hw.pagesize: 16384; hw.pagesize32: 16384; hw.physicalcpu: 8; hw.physicalcpu_max: 8; hw.serialdebugmode: 0; hw.tbfrequency: 24000000; hw.use_kernelmanagerd: 1; hw.use_recovery_securityd: 0; hw.targettype: J293; ```; Big Sur 11.4 on MacBookPro M1. Actually I'll open a separate issue...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-879469970
https://github.com/qutip/qutip/pull/1401#issuecomment-879469970:673,Performance,cache,cacheconfig,673,"Note: This appears broken on my M1 MacBookPro running Big Sur... there is no sysctl hw.cpufrequency at all on this machine, so it blows up (some error handling in that function would be good :-). ```$ sysctl hw; hw.ncpu: 8; hw.byteorder: 1234; hw.memsize: 17179869184; hw.activecpu: 8; hw.optional.amx_version: 2; hw.optional.arm64: 1; hw.optional.armv8_1_atomics: 1; hw.optional.armv8_2_fhm: 1; hw.optional.armv8_2_sha3: 1; hw.optional.armv8_2_sha512: 1; hw.optional.armv8_crc32: 1; hw.optional.breakpoint: 6; hw.optional.floatingpoint: 1; hw.optional.neon: 1; hw.optional.neon_fp16: 1; hw.optional.neon_hpfp: 1; hw.optional.ucnormal_mem: 1; hw.optional.watchpoint: 4; hw.cacheconfig: 8 1 1 0 0 0 0 0 0 0; hw.cachelinesize: 128; hw.cachesize: 3616980992 65536 4194304 0 0 0 0 0 0 0; hw.cpu64bit_capable: 1; hw.cpufamily: 458787763; hw.cpusubfamily: 2; hw.cpusubtype: 2; hw.cputype: 16777228; hw.ephemeral_storage: 0; hw.l1dcachesize: 65536; hw.l1icachesize: 131072; hw.l2cachesize: 4194304; hw.logicalcpu: 8; hw.logicalcpu_max: 8; hw.osenvironment: ; hw.packages: 1; hw.pagesize: 16384; hw.pagesize32: 16384; hw.physicalcpu: 8; hw.physicalcpu_max: 8; hw.serialdebugmode: 0; hw.tbfrequency: 24000000; hw.use_kernelmanagerd: 1; hw.use_recovery_securityd: 0; hw.targettype: J293; ```; Big Sur 11.4 on MacBookPro M1. Actually I'll open a separate issue...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-879469970
https://github.com/qutip/qutip/pull/1401#issuecomment-879469970:710,Performance,cache,cachelinesize,710,"Note: This appears broken on my M1 MacBookPro running Big Sur... there is no sysctl hw.cpufrequency at all on this machine, so it blows up (some error handling in that function would be good :-). ```$ sysctl hw; hw.ncpu: 8; hw.byteorder: 1234; hw.memsize: 17179869184; hw.activecpu: 8; hw.optional.amx_version: 2; hw.optional.arm64: 1; hw.optional.armv8_1_atomics: 1; hw.optional.armv8_2_fhm: 1; hw.optional.armv8_2_sha3: 1; hw.optional.armv8_2_sha512: 1; hw.optional.armv8_crc32: 1; hw.optional.breakpoint: 6; hw.optional.floatingpoint: 1; hw.optional.neon: 1; hw.optional.neon_fp16: 1; hw.optional.neon_hpfp: 1; hw.optional.ucnormal_mem: 1; hw.optional.watchpoint: 4; hw.cacheconfig: 8 1 1 0 0 0 0 0 0 0; hw.cachelinesize: 128; hw.cachesize: 3616980992 65536 4194304 0 0 0 0 0 0 0; hw.cpu64bit_capable: 1; hw.cpufamily: 458787763; hw.cpusubfamily: 2; hw.cpusubtype: 2; hw.cputype: 16777228; hw.ephemeral_storage: 0; hw.l1dcachesize: 65536; hw.l1icachesize: 131072; hw.l2cachesize: 4194304; hw.logicalcpu: 8; hw.logicalcpu_max: 8; hw.osenvironment: ; hw.packages: 1; hw.pagesize: 16384; hw.pagesize32: 16384; hw.physicalcpu: 8; hw.physicalcpu_max: 8; hw.serialdebugmode: 0; hw.tbfrequency: 24000000; hw.use_kernelmanagerd: 1; hw.use_recovery_securityd: 0; hw.targettype: J293; ```; Big Sur 11.4 on MacBookPro M1. Actually I'll open a separate issue...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-879469970
https://github.com/qutip/qutip/pull/1401#issuecomment-879469970:733,Performance,cache,cachesize,733,"Note: This appears broken on my M1 MacBookPro running Big Sur... there is no sysctl hw.cpufrequency at all on this machine, so it blows up (some error handling in that function would be good :-). ```$ sysctl hw; hw.ncpu: 8; hw.byteorder: 1234; hw.memsize: 17179869184; hw.activecpu: 8; hw.optional.amx_version: 2; hw.optional.arm64: 1; hw.optional.armv8_1_atomics: 1; hw.optional.armv8_2_fhm: 1; hw.optional.armv8_2_sha3: 1; hw.optional.armv8_2_sha512: 1; hw.optional.armv8_crc32: 1; hw.optional.breakpoint: 6; hw.optional.floatingpoint: 1; hw.optional.neon: 1; hw.optional.neon_fp16: 1; hw.optional.neon_hpfp: 1; hw.optional.ucnormal_mem: 1; hw.optional.watchpoint: 4; hw.cacheconfig: 8 1 1 0 0 0 0 0 0 0; hw.cachelinesize: 128; hw.cachesize: 3616980992 65536 4194304 0 0 0 0 0 0 0; hw.cpu64bit_capable: 1; hw.cpufamily: 458787763; hw.cpusubfamily: 2; hw.cpusubtype: 2; hw.cputype: 16777228; hw.ephemeral_storage: 0; hw.l1dcachesize: 65536; hw.l1icachesize: 131072; hw.l2cachesize: 4194304; hw.logicalcpu: 8; hw.logicalcpu_max: 8; hw.osenvironment: ; hw.packages: 1; hw.pagesize: 16384; hw.pagesize32: 16384; hw.physicalcpu: 8; hw.physicalcpu_max: 8; hw.serialdebugmode: 0; hw.tbfrequency: 24000000; hw.use_kernelmanagerd: 1; hw.use_recovery_securityd: 0; hw.targettype: J293; ```; Big Sur 11.4 on MacBookPro M1. Actually I'll open a separate issue...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-879469970
https://github.com/qutip/qutip/pull/1401#issuecomment-879469970:995,Testability,log,logicalcpu,995,"Note: This appears broken on my M1 MacBookPro running Big Sur... there is no sysctl hw.cpufrequency at all on this machine, so it blows up (some error handling in that function would be good :-). ```$ sysctl hw; hw.ncpu: 8; hw.byteorder: 1234; hw.memsize: 17179869184; hw.activecpu: 8; hw.optional.amx_version: 2; hw.optional.arm64: 1; hw.optional.armv8_1_atomics: 1; hw.optional.armv8_2_fhm: 1; hw.optional.armv8_2_sha3: 1; hw.optional.armv8_2_sha512: 1; hw.optional.armv8_crc32: 1; hw.optional.breakpoint: 6; hw.optional.floatingpoint: 1; hw.optional.neon: 1; hw.optional.neon_fp16: 1; hw.optional.neon_hpfp: 1; hw.optional.ucnormal_mem: 1; hw.optional.watchpoint: 4; hw.cacheconfig: 8 1 1 0 0 0 0 0 0 0; hw.cachelinesize: 128; hw.cachesize: 3616980992 65536 4194304 0 0 0 0 0 0 0; hw.cpu64bit_capable: 1; hw.cpufamily: 458787763; hw.cpusubfamily: 2; hw.cpusubtype: 2; hw.cputype: 16777228; hw.ephemeral_storage: 0; hw.l1dcachesize: 65536; hw.l1icachesize: 131072; hw.l2cachesize: 4194304; hw.logicalcpu: 8; hw.logicalcpu_max: 8; hw.osenvironment: ; hw.packages: 1; hw.pagesize: 16384; hw.pagesize32: 16384; hw.physicalcpu: 8; hw.physicalcpu_max: 8; hw.serialdebugmode: 0; hw.tbfrequency: 24000000; hw.use_kernelmanagerd: 1; hw.use_recovery_securityd: 0; hw.targettype: J293; ```; Big Sur 11.4 on MacBookPro M1. Actually I'll open a separate issue...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1401#issuecomment-879469970
https://github.com/qutip/qutip/issues/1402#issuecomment-739775446:38,Safety,avoid,avoid,38,Please consider changing your unit to avoid small terms like `e-6` and `hbar`. QuTiP uses sparse matrix and removes very small (~<e-7) matrix entries. Possible improvement was discussed in https://github.com/qutip/qutip/issues/1349.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1402#issuecomment-739775446
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:22,Deployability,install,installing,22,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:78,Deployability,release,releases,78,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:103,Deployability,install,installation,103,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:152,Deployability,install,installation,152,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:192,Deployability,install,install,192,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:401,Deployability,install,install-command-line-tools-mac-os-x,401,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:237,Modifiability,config,configure,237,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742038577:116,Usability,guid,guide,116,"You'll find it easier installing from conda-forge, since we distribute binary releases there: see the [installation guide](http://qutip.org/docs/latest/installation.html) here. If you want to install from source using `pip`, you need to configure your C++ development environment correctly - you'll probably need to enable the XCode command-line tools ([see e.g. this](https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/)).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742038577
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:332,Deployability,install,installing,332,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:391,Deployability,release,releases,391,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:415,Deployability,install,installation,415,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:467,Deployability,install,installation,467,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:513,Deployability,install,install,513,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:728,Deployability,install,install-command-line-tools-mac-os-x,728,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:556,Modifiability,config,configure,556,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/issues/1404#issuecomment-742050650:428,Usability,guid,guide,428,"Many thanks! I solved it!; Now I have this WARNING:matplotlib.animation:MovieWriter avconv; unavailable. Trying to use pillow instead.; *Many thanks*. *P**arfait Atchad*. *Tel Spain: 0034661205543*; *Tel Deutsch: 00491706659017*. On Wed, 9 Dec 2020 at 15:45, Jake Lishman <notifications@github.com> wrote:. > You'll find it easier installing from conda-forge, since we distribute; > binary releases there: see the installation guide; > <http://qutip.org/docs/latest/installation.html> here.; >; > If you want to install from source using pip, you need to configure your; > C++ development environment correctly - you'll probably need to enable the; > XCode command-line tools (see e.g. this; > <https://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>).; >; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/issues/1404#issuecomment-742038577>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AGKQN3YYS6ZYMTV4HEHFTELST7OW3ANCNFSM4UT7TWQQ>; > .; >",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1404#issuecomment-742050650
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:284,Availability,redundant,redundant,284,"Sorry I didn't get round to commenting on this PR sooner. Since it's now come up in #1579 around the subject of sorting out licensing in general in QuTiP, let me also note some stuff about that here. #1579 proposes to remove all individual-file licence text, because it is in general redundant, and makes it harder for us to centrally manage our licence. There is some concern (mostly mine), that it will be a little difficult for us to manage additional code which does not sign over copyright to the QuTiP admin team; if we accept it, we will have to keep the notice in perpetuity. This will pose a bit of a Theseus' ship problem for us if we ever want to re-organise the file that contains this code; after how many modifications is the code no longer NASA's, but QuTiP's? As long as it's not _ours_, we can't separate it out into different files, or mix it with other code (say additional implementations). I'm definitely not a lawyer, but I'm worried that will cause us code organisation problems in the future, and while the licence would give us permission to improve the code, it's the reorganisation I'm worried about. Secondly, about the code itself: this sort of local operation is something I absolutely would like to include, but I'm not certain that the form it's in right now is the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:2305,Availability,avail,available,2305,"the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:4580,Availability,down,down,4580,"e input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row about licensing primarily, and then about how we're going to handle tensor networks in general. In order to prevent headaches down the line (and again, very very sorry), would it be ok if we leave this unmerged, and don't attempt to modify it in any way? I don't want to get into a situation where we decide we can't accept non-QuTiP-licenced code, and we want to use/build on your code or implement something similar, but our hands are tied because anything we do will involve our knowledge of IP we don't control.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:1693,Deployability,release,release,1693,"seus' ship problem for us if we ever want to re-organise the file that contains this code; after how many modifications is the code no longer NASA's, but QuTiP's? As long as it's not _ours_, we can't separate it out into different files, or mix it with other code (say additional implementations). I'm definitely not a lawyer, but I'm worried that will cause us code organisation problems in the future, and while the licence would give us permission to improve the code, it's the reorganisation I'm worried about. Secondly, about the code itself: this sort of local operation is something I absolutely would like to include, but I'm not certain that the form it's in right now is the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of rou",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3376,Deployability,configurat,configuration,3376,"ocumentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being so",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3486,Deployability,install,installed,3486,"handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row ab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:4376,Deployability,release,release,4376,"e input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row about licensing primarily, and then about how we're going to handle tensor networks in general. In order to prevent headaches down the line (and again, very very sorry), would it be ok if we leave this unmerged, and don't attempt to modify it in any way? I don't want to get into a situation where we decide we can't accept non-QuTiP-licenced code, and we want to use/build on your code or implement something similar, but our hands are tied because anything we do will involve our knowledge of IP we don't control.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:1895,Integrability,interface,interface,1895," can't separate it out into different files, or mix it with other code (say additional implementations). I'm definitely not a lawyer, but I'm worried that will cause us code organisation problems in the future, and while the licence would give us permission to improve the code, it's the reorganisation I'm worried about. Secondly, about the code itself: this sort of local operation is something I absolutely would like to include, but I'm not certain that the form it's in right now is the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of li",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:2073,Integrability,contract,contraction,2073,"re, and while the licence would give us permission to improve the code, it's the reorganisation I'm worried about. Secondly, about the code itself: this sort of local operation is something I absolutely would like to include, but I'm not certain that the form it's in right now is the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:2610,Integrability,rout,routine,2610,"g we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tenso",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:2834,Integrability,wrap,wrapper,2834,"most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across t",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3717,Integrability,rout,routine,3717,"ch will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row about licensing primarily, and then about how we're going to handle tensor networks in general. In order to prevent headaches down the line (and again, very very sorry)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3376,Modifiability,config,configuration,3376,"ocumentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being so",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3452,Modifiability,plug-in,plug-in,3452,"handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row ab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:284,Safety,redund,redundant,284,"Sorry I didn't get round to commenting on this PR sooner. Since it's now come up in #1579 around the subject of sorting out licensing in general in QuTiP, let me also note some stuff about that here. #1579 proposes to remove all individual-file licence text, because it is in general redundant, and makes it harder for us to centrally manage our licence. There is some concern (mostly mine), that it will be a little difficult for us to manage additional code which does not sign over copyright to the QuTiP admin team; if we accept it, we will have to keep the notice in perpetuity. This will pose a bit of a Theseus' ship problem for us if we ever want to re-organise the file that contains this code; after how many modifications is the code no longer NASA's, but QuTiP's? As long as it's not _ours_, we can't separate it out into different files, or mix it with other code (say additional implementations). I'm definitely not a lawyer, but I'm worried that will cause us code organisation problems in the future, and while the licence would give us permission to improve the code, it's the reorganisation I'm worried about. Secondly, about the code itself: this sort of local operation is something I absolutely would like to include, but I'm not certain that the form it's in right now is the best, general way to do it. I think this is part of much larger discussion about how to handle tensor networks - for example, at the moment, `targets` is fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:2383,Safety,detect,detection,2383,"fine for states and operators, but it won't work for superoperators. I'm not sure that this is solvable in an ergonomic way with QuTiP's current dimensions specifiers, but it's something we're definitely going to look into after the initial release of 5.0. Also, there are already several disparate functions in QuTiP that provide sort-of similar functionality, and I think we need to have a proper go at tidying them all up into one cohesive interface. This includes `subsystem_apply` (most similar to this), but also `ptrace` and `partial_tranpose`, which can be seen as special cases of this exact same type of tensor contraction (not to mention `tensor_contract`!). The other thing from a code perspective is that this doesn't use the data-layer in the intended manner. A lot of this may be because our documentation of the data-layer isn't readily available yet (we weren't expecting interest this early!). It does individual detection on two different types, rather than creating a `Dispatcher` to handle the multiple dispatch over potentially different data types of the two inputs. I would imagine that a better form of organisation for this sort of routine, which will be able to handle arbitrary tensor-network operations, will end up being made up of two components:; 1. a `Dispatcher` version of something akin to `einsum`, with a couple of limitations; 2. a high-level wrapper function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864073566:3928,Usability,UX,UX,3928,"er function to handle the specific case of local multiplication, which examines the dimensions and target specifiers to produce the input to the `einsum`-like function, then calls the `Dispatcher` with this information. I think this form would likely be preferable for several reasons:; 1. it will allow arbitrary mixing of different data types (`CSR` complete space and `Dense` operator, or both `CSR`, or whatever), with the allowed conversions respecting the global dispatcher rules, not having this function use a different, special configuration; 2. it will mean that the function can also be implemented by plug-in data types (TF/CuPy/etc), installed separately to QuTiP; 3. it will be more general, and easier to maintain; the current `subsystem_apply`, `partial_transpose`, `ptrace`, `tensor_contract` and this can all become special cases of this backing `einsum`-like routine.; 4. after we've implemented new dimensions objects, we'll be able to use a more standardised description of how to refer to individual subspaces of a Hilbert space, which will provide a more consistent UX across the library. This is particularly important if we want this to work well with superoperators. Really, thank you very much for making the PR - I really am excited to see people with an interest in the new data layer! I'm sorry that I took quite so long to respond properly to it, and that when I have, I've ended up being somewhat against the implementaton as it is. I would be really interested in pursuing this, likely after the initial release of 5.0, but right now I think we might need to get our ducks in a row about licensing primarily, and then about how we're going to handle tensor networks in general. In order to prevent headaches down the line (and again, very very sorry), would it be ok if we leave this unmerged, and don't attempt to modify it in any way? I don't want to get into a situation where we decide we can't accept non-QuTiP-licenced code, and we want to use/build on your code",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864073566
https://github.com/qutip/qutip/pull/1405#issuecomment-864183224:33,Deployability,update,update,33,"Hi @jakelishman,; Thanks for the update and your detailed comments! No worries about the time, I follow the project so see everyone is busy on implementing the fundamentals for v5. I see two main points to consider:; 1) the code will need to be rewritten to make a more consistent use of the data layer with the rest of the project.; 2) the license issue. For 1, indeed, I was not so familiar with the intended use of the data layer and using a `Dispatcher` as these are all new capabilities (mostly this was collecting together some old `einsum` code I had and packaging it together to work with `Qobj`). If we think this type of thing will indeed be useful (I personally still do given the potential speed ups), I am happy to try to implement things in the way you mention when I get the time to go through this exercise (most likely will require your input also). If eventually we can converge on a design we can try to merge it into a later version than 5.0. For 2, yeah I totally understand all the points you mention. I will write to you about this issue. So overall I see this progressing as follows:; I can close this PR and will start a fresh branch implementing this in the intended manner. I expect this could take a while as I figure out how the `Dispatcher` etc. works, but also I will be doing this in my free time (I don't see this as a problem since you will release V5 without this and we can see about merging it in later). Thanks, and feel free to let me know if you have any problems with the above plan or any other questions.; Otherwise I can let you know when I have updates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864183224
https://github.com/qutip/qutip/pull/1405#issuecomment-864183224:1375,Deployability,release,release,1375,"Hi @jakelishman,; Thanks for the update and your detailed comments! No worries about the time, I follow the project so see everyone is busy on implementing the fundamentals for v5. I see two main points to consider:; 1) the code will need to be rewritten to make a more consistent use of the data layer with the rest of the project.; 2) the license issue. For 1, indeed, I was not so familiar with the intended use of the data layer and using a `Dispatcher` as these are all new capabilities (mostly this was collecting together some old `einsum` code I had and packaging it together to work with `Qobj`). If we think this type of thing will indeed be useful (I personally still do given the potential speed ups), I am happy to try to implement things in the way you mention when I get the time to go through this exercise (most likely will require your input also). If eventually we can converge on a design we can try to merge it into a later version than 5.0. For 2, yeah I totally understand all the points you mention. I will write to you about this issue. So overall I see this progressing as follows:; I can close this PR and will start a fresh branch implementing this in the intended manner. I expect this could take a while as I figure out how the `Dispatcher` etc. works, but also I will be doing this in my free time (I don't see this as a problem since you will release V5 without this and we can see about merging it in later). Thanks, and feel free to let me know if you have any problems with the above plan or any other questions.; Otherwise I can let you know when I have updates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864183224
https://github.com/qutip/qutip/pull/1405#issuecomment-864183224:1590,Deployability,update,updates,1590,"Hi @jakelishman,; Thanks for the update and your detailed comments! No worries about the time, I follow the project so see everyone is busy on implementing the fundamentals for v5. I see two main points to consider:; 1) the code will need to be rewritten to make a more consistent use of the data layer with the rest of the project.; 2) the license issue. For 1, indeed, I was not so familiar with the intended use of the data layer and using a `Dispatcher` as these are all new capabilities (mostly this was collecting together some old `einsum` code I had and packaging it together to work with `Qobj`). If we think this type of thing will indeed be useful (I personally still do given the potential speed ups), I am happy to try to implement things in the way you mention when I get the time to go through this exercise (most likely will require your input also). If eventually we can converge on a design we can try to merge it into a later version than 5.0. For 2, yeah I totally understand all the points you mention. I will write to you about this issue. So overall I see this progressing as follows:; I can close this PR and will start a fresh branch implementing this in the intended manner. I expect this could take a while as I figure out how the `Dispatcher` etc. works, but also I will be doing this in my free time (I don't see this as a problem since you will release V5 without this and we can see about merging it in later). Thanks, and feel free to let me know if you have any problems with the above plan or any other questions.; Otherwise I can let you know when I have updates.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1405#issuecomment-864183224
https://github.com/qutip/qutip/issues/1406#issuecomment-747009088:71,Availability,error,error,71,"This shouldn't segfault (we should detect it and turn it into a Python error, so that's definitely a bug), but do note that you'd need a supercomputer to actually use a system of that size - storing a single operator or state of this system would require 8GB of RAM even if it were the 0 operator.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1406#issuecomment-747009088
https://github.com/qutip/qutip/issues/1406#issuecomment-747009088:35,Safety,detect,detect,35,"This shouldn't segfault (we should detect it and turn it into a Python error, so that's definitely a bug), but do note that you'd need a supercomputer to actually use a system of that size - storing a single operator or state of this system would require 8GB of RAM even if it were the 0 operator.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1406#issuecomment-747009088
https://github.com/qutip/qutip/pull/1407#issuecomment-747703407:1052,Security,attack,attacking,1052,"I made some benchmarks timing different way to call matmul and contouring the dispatcher is worth it. ; For 10x10, CRS x Dense, it's 4x slowdown for matmul and 2x for expect.; For 1000 x 1000, it's 10% and 5%, reasonable but still felt. The easiest would be having `matmul(self, Dense in, Dense out)` method for Data layer. There is no need for all pairs of layer types to be supported by this, states in scipy's solver are always Dense. But it's a little late for that. Not having that, since 99% of users will use our data type and we only really need it for `matmul` and `expect`, we can so a manual disptach for just those. The way I did it was quite ugly, I wanted to limit the calls to `isinstance` which are not proper cython so did it once moving the type. I did not think of `type`...; `type(op) is CSR` is 15x faster than `isinstance(op, CSR)` and about as fast as comparing for enums, making have `layer_type` useless. Renamed it to `matmul_data_dense_dense` in matmul.pyx.; Still short of a c dispatcher for function pointers, but I am not attacking this.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1407#issuecomment-747703407
https://github.com/qutip/qutip/pull/1407#issuecomment-747703407:12,Testability,benchmark,benchmarks,12,"I made some benchmarks timing different way to call matmul and contouring the dispatcher is worth it. ; For 10x10, CRS x Dense, it's 4x slowdown for matmul and 2x for expect.; For 1000 x 1000, it's 10% and 5%, reasonable but still felt. The easiest would be having `matmul(self, Dense in, Dense out)` method for Data layer. There is no need for all pairs of layer types to be supported by this, states in scipy's solver are always Dense. But it's a little late for that. Not having that, since 99% of users will use our data type and we only really need it for `matmul` and `expect`, we can so a manual disptach for just those. The way I did it was quite ugly, I wanted to limit the calls to `isinstance` which are not proper cython so did it once moving the type. I did not think of `type`...; `type(op) is CSR` is 15x faster than `isinstance(op, CSR)` and about as fast as comparing for enums, making have `layer_type` useless. Renamed it to `matmul_data_dense_dense` in matmul.pyx.; Still short of a c dispatcher for function pointers, but I am not attacking this.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1407#issuecomment-747703407
https://github.com/qutip/qutip/pull/1409#issuecomment-767650176:215,Modifiability,evolve,evolve,215,[![Coverage Status](https://coveralls.io/builds/37558676/badge)](https://coveralls.io/builds/37558676). Coverage increased (+1.3%) to 66.469% when pulling **702de3ece279dc9920332467af01b58d90b73829 on Ericgig:solve.evolve** into **0ca50e9d97ce4031ca886670bed43b960c36a226 on qutip:dev.major**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1409#issuecomment-767650176
https://github.com/qutip/qutip/pull/1409#issuecomment-788726639:192,Usability,clear,clearer,192,"A great piece of work @Ericgig. This has been wanting for a long time. Such an abstraction of the ODE solver should allow for easier development of other types of solver, and make the physics clearer in the code. I should also mean that we could add in new methods for solving ODEs more easily. Thanks for taking on this massive challenge.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1409#issuecomment-788726639
https://github.com/qutip/qutip/issues/1411#issuecomment-751387226:33,Usability,simpl,simplified,33,"Please give more details, e.g. a simplified version of the problem you want to solve or an example of code. QuTiP has tutorial notebooks and documentation that you can refer to for function API.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1411#issuecomment-751387226
https://github.com/qutip/qutip/issues/1413#issuecomment-753941995:727,Deployability,release,release,727,"Thanks for the comment. I was not aware of the change, but actually I do not understand the meaning of partial trace over an object that is not made of multiple tensored objects? And the output in the previous case was the quantum object itself, i.e., there is no effect of `ptrace` if the object is already a single subspace object, right? I see it can come handy in some applications where there is an iterative process of partial tracing subsystems. Not sure of why the change was made, maybe @Ericgig knows more. I still need to understand better to have an opinion. Thanks for opening the issue. Maybe a deprecation warning could be of use, replacing the old mechanism, if the devs want to change the feature with a major release.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1413#issuecomment-753941995
https://github.com/qutip/qutip/issues/1413#issuecomment-753968404:85,Usability,clear,clear,85,"I'd call the behaviour a bug. The partial trace keeping all possible subspaces has a clear, sensible meaning; I can't think of any circumstance where it would be surprising that it's a no-op. The behaviour happens because we're not explicit about the output type of `np.prod` in a few places in `_ptrace_dense` - I think we may have seen this before but looks like we never pushed the fix. I can do that shortly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1413#issuecomment-753968404
https://github.com/qutip/qutip/pull/1414#issuecomment-754585483:57,Deployability,update,updated,57,"No, I guess we never did, at least not on `master`. I've updated this PR to do both.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1414#issuecomment-754585483
https://github.com/qutip/qutip/issues/1415#issuecomment-755211133:252,Integrability,rout,routine,252,"Yeah, that's a memory leak. It doesn't really matter how ""silly"" the method is that causes it to appear, the fact is that it shouldn't exist. It's actually not to do with `add_dense` but `Dense.copy` - I didn't set the `Dense._deallocate` flag in that routine, so when the Python object goes out of scope, the C destructor ignores the pointer and it goes stale. You can probably achieve very similar behaviour with `for _ in [None]*1_000_000: rho.copy()`, even if you force `gc.collect()` after every iteration.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1415#issuecomment-755211133
https://github.com/qutip/qutip/issues/1418#issuecomment-763377937:1644,Deployability,update,update,1644,"d. Right now,; > I am only plotting state_z_plus so I can focus on the T1 decay from 1 to; > -1. However, as the animation and graph indicate, it seems to stop short of; > -1 and I don't see why that should be happening. I appreciate any feedback.; >; > %matplotlib inline; > import matplotlib.pyplot as plt; > import numpy as np; > import qutip as q; > import cmath; > import matplotlib as mpl; > from mpl_toolkits.mplot3d import Axes3D; >; > rc_dict = {; > ""figure.subplot.bottom"": 0.11,; > ""figure.subplot.hspace"": 0.2,; > ""figure.subplot.left"": 0.125,; > ""figure.subplot.right"": 0.9,; > ""figure.subplot.top"": 0.88,; > ""figure.subplot.wspace"": 0.2,; > ""figure.figsize"":(10,10/1.61),; > ""axes.grid"": True,; > ""text.usetex"": True,; > ""grid.linestyle"": "":"",; > ""grid.color"": ""black"", #; > ""legend.fontsize"": 20,; > ""lines.linewidth"": 2.5,; > ""axes.linewidth"": 1.5,; > ""font.family"": [""serif""],; > ""font.sans-serif"": ""Times New Roman Bold"",; > ""font.size"":26,; > }; > plt.rcParams.update(rc_dict); >; > qutip_options = q.Odeoptions(; > store_states=True,; > nsteps=20000000; > ); > si, sx, sy, sz=q.qeye(2), q.sigmax(), q.sigmay(), q.sigmaz(); > sp, sm=q.sigmap(), q.sigmam(); > state_z_plus=q.basis(2,0); > state_z_minus=q.basis(2,1); > state_x_plus=1.0/cmath.sqrt(2)* (q.basis(2,0) + q.basis(2,1)); > state_x_minus=1.0/cmath.sqrt(2)* (q.basis(2,0) - q.basis(2,1)); > state_y_plus=1.0/cmath.sqrt(2)* (q.basis(2,0) + 1j* q.basis(2,1)); > state_y_minus=1.0/cmath.sqrt(2)* (q.basis(2,0) - 1j* q.basis(2,1)); >; > h = 6.62607015e-34; > b = 0.1786195317554453 #magnetic field; > b_AC = 3.572390635108906e-05 #oscillating magnetic field; > g = 2 #g-factor; > u = 9.274E-24 #bohr magneton; > w = g*u*b/h #omega; > w0 = 5e9 # omega0 is the rotating frame frequency; > print(w); > gamma_phi = 44200000; > gamma_minus = 100000000; >; > epsilon = g*u*b/h*(2; > *cmath.pi) Delta = g*u*b_AC/h*(2*cmath.pi); >; > H = ((w-w0)/(w))*epsilon/2 * sz #*+ Delta/2*sy; >; > print(abs(((w-w0)/(w)))*epsilon/2); >; > #note h",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1418#issuecomment-763377937
https://github.com/qutip/qutip/issues/1418#issuecomment-763377937:902,Usability,feedback,feedback,902,"Dear Ahmed,. One issue is the way you are sending c_ops to mesolve. It should be a list; of separate operators, like; c_ops=[cmath.sqrt(gamma_phi/2)*sz, cmath.sqrt(gamma_minus)*sm]. not sure if this fixes your issue. On Wed, Jan 20, 2021 at 12:12 AM Ahmed Malik <notifications@github.com>; wrote:. > This code produces an animation of the Bloch sphere vector evolution. I; > have implemented a rotating frame approximation as defined by H. The goal; > is to model T1 and T2 decay. I am still experimenting with different; > gamma_phi and gamma_minus values, but right now they're big enough to have; > a visible effect over the 10^-7 time scale that's being plotted. Right now,; > I am only plotting state_z_plus so I can focus on the T1 decay from 1 to; > -1. However, as the animation and graph indicate, it seems to stop short of; > -1 and I don't see why that should be happening. I appreciate any feedback.; >; > %matplotlib inline; > import matplotlib.pyplot as plt; > import numpy as np; > import qutip as q; > import cmath; > import matplotlib as mpl; > from mpl_toolkits.mplot3d import Axes3D; >; > rc_dict = {; > ""figure.subplot.bottom"": 0.11,; > ""figure.subplot.hspace"": 0.2,; > ""figure.subplot.left"": 0.125,; > ""figure.subplot.right"": 0.9,; > ""figure.subplot.top"": 0.88,; > ""figure.subplot.wspace"": 0.2,; > ""figure.figsize"":(10,10/1.61),; > ""axes.grid"": True,; > ""text.usetex"": True,; > ""grid.linestyle"": "":"",; > ""grid.color"": ""black"", #; > ""legend.fontsize"": 20,; > ""lines.linewidth"": 2.5,; > ""axes.linewidth"": 1.5,; > ""font.family"": [""serif""],; > ""font.sans-serif"": ""Times New Roman Bold"",; > ""font.size"":26,; > }; > plt.rcParams.update(rc_dict); >; > qutip_options = q.Odeoptions(; > store_states=True,; > nsteps=20000000; > ); > si, sx, sy, sz=q.qeye(2), q.sigmax(), q.sigmay(), q.sigmaz(); > sp, sm=q.sigmap(), q.sigmam(); > state_z_plus=q.basis(2,0); > state_z_minus=q.basis(2,1); > state_x_plus=1.0/cmath.sqrt(2)* (q.basis(2,0) + q.basis(2,1)); > state_x_minus=1.0/cmath.sqrt(2)* (q",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1418#issuecomment-763377937
https://github.com/qutip/qutip/issues/1418#issuecomment-763377937:3457,Usability,clear,clear,3457,"ma_minus = 100000000; >; > epsilon = g*u*b/h*(2; > *cmath.pi) Delta = g*u*b_AC/h*(2*cmath.pi); >; > H = ((w-w0)/(w))*epsilon/2 * sz #*+ Delta/2*sy; >; > print(abs(((w-w0)/(w)))*epsilon/2); >; > #note here the final time satisfies: omega*t_final = pi/2; > times=np.linspace(0, 0.0000001, 1000); >; > #our initial qubit state; > state0=(state_z_plus)/(np.sqrt(1)); >; > H/(2*cmath.pi); >; > results=q.mesolve(H, state0, times, c_ops=[cmath.sqrt(gamma_phi/2)*sz+; > cmath.sqrt(gamma_minus)*sm], e_ops=[sx, sy, sz], options=qutip_options); >; > fig, ax=plt.subplots(); > ax.plot(times, results.expect[0], label=r'$\langle \sigma_x \rangle$'); > ax.plot(times, results.expect[1], label=r'$\langle \sigma_y \rangle$'); > ax.plot(times, results.expect[2], label=r'$\langle \sigma_z \rangle$'); > ax.set_xlabel(""time""); > ax.legend();; >; > import imageio; > def animate_bloch(values):; > b = q.Bloch(); > images=[]; > b.point_marker = ['o']; > b.point_size = [30]; > for i in range(len(values)):; > b.clear(); > b.add_states(values[i]); > b.add_states(values[:(i+1)],'point'); > beans = 'beans.png'; > b.save(beans); > images.append(imageio.imread(beans)); > imageio.mimwrite('beans.gif',images); >; > values = []; > for t in range(0,len(times),30):; > values.append((results.states[t])); > animate_bloch(values); >; > from IPython.core.interactiveshell import InteractiveShell; > InteractiveShell.ast_node_interactivity = ""all""; > from IPython import display; >; > from pathlib import Path; > gifPath = Path('beans.gif'); > with open(gifPath,'rb') as f:; > display.Image(data=f.read(), format='png'); >; > [image: g]; > <https://user-images.githubusercontent.com/29261370/105053116-36429880-5a36-11eb-978b-8804dd1e679e.PNG>; > [image: sp]; > <https://user-images.githubusercontent.com/29261370/105053129-3c387980-5a36-11eb-9c0d-da3fd30bbaf5.PNG>; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/quti",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1418#issuecomment-763377937
https://github.com/qutip/qutip/pull/1420#issuecomment-809209356:40,Safety,avoid,avoid,40,"It would be good if our naming can help avoid confusion between the concept of a `dtype` (which is the type of elements within an array) and our `data backend type` (which is how the array itself is represented). I'm not sure what a good convention is, but ensuring the docstrings for the backend type have specific examples of valid inputs would definitely help (e.g. `dense` or `csr`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-809209356
https://github.com/qutip/qutip/pull/1420#issuecomment-809210105:186,Performance,perform,performance,186,This seems like a good idea to me though! It might also help with the upcoming TensorFlow backend (where we'll probably need to mostly create TF backend QObjs in order to get reasonable performance).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-809210105
https://github.com/qutip/qutip/pull/1420#issuecomment-809213365:42,Safety,avoid,avoid,42,"> It would be good if our naming can help avoid confusion between the concept of a `dtype` (which is the type of elements within an array) and our `data backend type` (which is how the array itself is represented). I'm not sure what a good convention is, but ensuring the docstrings for the backend type have specific examples of valid inputs would definitely help (e.g. `dense` or `csr`). We actually deliberately called this `dtype` to make it familiar to Numpy syntax. The concept of the Numpy `dtype` is mostly irrelevant when using QuTiP, because all data is invariably `double complex`, and this `dtype` is the larger data type of `Qobj`. I suppose it could be `fmt` instead (as a common abbreviation of `format`)? Or even the full word `format` I suppose. Agree on the docstrings - we should have an alias like Numpy's `array_like` that we define clearly in documentation in one place.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-809213365
https://github.com/qutip/qutip/pull/1420#issuecomment-809213365:854,Usability,clear,clearly,854,"> It would be good if our naming can help avoid confusion between the concept of a `dtype` (which is the type of elements within an array) and our `data backend type` (which is how the array itself is represented). I'm not sure what a good convention is, but ensuring the docstrings for the backend type have specific examples of valid inputs would definitely help (e.g. `dense` or `csr`). We actually deliberately called this `dtype` to make it familiar to Numpy syntax. The concept of the Numpy `dtype` is mostly irrelevant when using QuTiP, because all data is invariably `double complex`, and this `dtype` is the larger data type of `Qobj`. I suppose it could be `fmt` instead (as a common abbreviation of `format`)? Or even the full word `format` I suppose. Agree on the docstrings - we should have an alias like Numpy's `array_like` that we define clearly in documentation in one place.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-809213365
https://github.com/qutip/qutip/pull/1420#issuecomment-847295308:627,Usability,learn,learn,627,@jakelishman @hodgestar. I would like to merge this PR soon.; Is the only missing part is a term for `dtype : type or str`?. Numpy use `data-type` which point to https://numpy.org/doc/stable/reference/arrays.dtypes.html; The closest equivalent we have would be `qutip.core.Data`.; Here would `data-type` works if we have a page in the documentation pointing to it?; Otherwise all I can think is `layer-type` or `qdata-type` which feels wrong. I would prefer to keep the explicit; ```; dtype : type or str; Storage representation. Any data type known to `qutip.data.to` is; accepted.; ```; over creating a new term for users to learn.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-847295308
https://github.com/qutip/qutip/pull/1420#issuecomment-849867989:76,Testability,test,test,76,"I reset the `test_random`, `test_operator` and `test_states` and only added test relating to `dtype`. The others change I made will go in other PR. . I also changed `add_creator` to take only one new creator at a time and add it to the list. I re-sort each time as the list. Creators are added in `core.data.__init__`, including the fallback to numpy. I had some circular import when import data in `convert.pyx` and it fell more at it's place after `add_conversions` is called. Could you take another look and if it's good I will clean the commit history.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-849867989
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:127,Availability,toler,tolerance,127,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:137,Availability,error,error,137,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:247,Availability,toler,tolerance,247,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:451,Availability,toler,tolerance,451,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:155,Testability,test,testing,155,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/pull/1420#issuecomment-853030860:214,Testability,Assert,AssertionError,214,"@Ericgig Not sure if it's directly related to this PR, but the Travis build failed on `test_diag_liou_mult` with the following tolerance error:; ```; > np.testing.assert_allclose(target, calculated, atol=1e-12); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=1e-12; E ; E Mismatched elements: 2 / 6724 (0.0297%); E Max absolute difference: 3.36667153e-12; E Max relative difference: 1.85567862e-08; ```; Not sure if we should relax the tolerance slightly now (maybe 1e-11?), or in a separate PR later, or if there is something real to fix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1420#issuecomment-853030860
https://github.com/qutip/qutip/issues/1421#issuecomment-764066603:368,Safety,safe,safe,368,"There's maybe some tricks here to do with multiprocessing and pickle/unpickle, but since the objects are deterministic and completely immutable, I can't see anything inherently wrong with a singleton approach here. These objects are purely data; they must not have _behaviour_ attached to them (methods) only immutable state (properties), so they're inherently thread-safe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764066603
https://github.com/qutip/qutip/issues/1421#issuecomment-764826119:337,Safety,safe,safety,337,"Using singleton will certainly speed thing up. ; 1. With `subspace` to represent `enr` or other special case, it should be able to represent everything. But super operators have multiple representation (`choi`, `kraus`, `super`, etc.). So I would suggest adding a `super` subclass with that information instead of using `map`.; 2. Basis safety, if required, will make Qutip usage heavier. ; 4. Let's keep it as an inside representation only: having `Space(2)` for a ket but `Map(Space, Field)` for bra will only cause confusion and super-operator of tensor system will get very long.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764826119
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:2329,Deployability,release,release,2329,"ithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is oth",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:1480,Performance,perform,performance,1480,"; ```; Map(Space(Map(Space, Space)), Space(Map(Space, Space))); ```; to; ```; Super(Space(Map(Space, Space)), Space(Map(Space, Space)), rep='super'); ```; and I definitely like having the superop rep included in it. The user is never ever meant to write any of this themselves, so the literal length shouldn't be too much of a problem. You'd still specify dimensions using the exact same list syntax that we currently use, it's just we'd immediately parse it into this internal representation and internally operate on this, because it's much faster. Essentially what I'm describing here is an abstract syntax tree for relevant linear algebra structures. We _could_ even have the tensor index dimensions stored within the `Compound` objects, to help with `ptrace`, `permute`, the future `local_multiply` algorithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. Y",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:1455,Safety,safe,safety,1455,"; ```; Map(Space(Map(Space, Space)), Space(Map(Space, Space))); ```; to; ```; Super(Space(Map(Space, Space)), Space(Map(Space, Space)), rep='super'); ```; and I definitely like having the superop rep included in it. The user is never ever meant to write any of this themselves, so the literal length shouldn't be too much of a problem. You'd still specify dimensions using the exact same list syntax that we currently use, it's just we'd immediately parse it into this internal representation and internally operate on this, because it's much faster. Essentially what I'm describing here is an abstract syntax tree for relevant linear algebra structures. We _could_ even have the tensor index dimensions stored within the `Compound` objects, to help with `ptrace`, `permute`, the future `local_multiply` algorithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. Y",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:2021,Safety,safe,safe,2021,"t into this internal representation and internally operate on this, because it's much faster. Essentially what I'm describing here is an abstract syntax tree for relevant linear algebra structures. We _could_ even have the tensor index dimensions stored within the `Compound` objects, to help with `ptrace`, `permute`, the future `local_multiply` algorithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:2265,Safety,safe,safety,2265,"the tensor index dimensions stored within the `Compound` objects, to help with `ptrace`, `permute`, the future `local_multiply` algorithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:1591,Testability,test,test,1591,"; ```; Map(Space(Map(Space, Space)), Space(Map(Space, Space))); ```; to; ```; Super(Space(Map(Space, Space)), Space(Map(Space, Space)), rep='super'); ```; and I definitely like having the superop rep included in it. The user is never ever meant to write any of this themselves, so the literal length shouldn't be too much of a problem. You'd still specify dimensions using the exact same list syntax that we currently use, it's just we'd immediately parse it into this internal representation and internally operate on this, because it's much faster. Essentially what I'm describing here is an abstract syntax tree for relevant linear algebra structures. We _could_ even have the tensor index dimensions stored within the `Compound` objects, to help with `ptrace`, `permute`, the future `local_multiply` algorithms and so on. I wouldn't want to add that immediately, though - no need to complicate things. #### Point 2. Basis safety wouldn't have any performance cost here - `Space(2, basis='x')` and `Space(2, basis='y')` would referentially be unequal, so the test would be free. It's basically the same thing as checking superoperator representations. I would worry about user ergonomics for creating these though. I'd propose that all QuTiP functions maintain their current behaviour of creating everything in the number basis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. Y",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:2921,Testability,test,test,2921,"sis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is other; or (; isinstance(other, Space); and self.size == other.size; and self.basis == other.basis; ); ); ```; so we'll almost invariably get the benefits right now, but we're rather more future-proof in the code. By analogy, it's clearly wrong to do `(1, 2) is (1, 2)` to compare tuples, even though `tuple` produces singletons in CPython (and that code will generally be `True`). The Python `tuple` class is basically what inspired me, and I'm 100% certain that the Python devs are smarter than I am, so we should probab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:2993,Testability,test,test,2993,"sis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is other; or (; isinstance(other, Space); and self.size == other.size; and self.basis == other.basis; ); ); ```; so we'll almost invariably get the benefits right now, but we're rather more future-proof in the code. By analogy, it's clearly wrong to do `(1, 2) is (1, 2)` to compare tuples, even though `tuple` produces singletons in CPython (and that code will generally be `True`). The Python `tuple` class is basically what inspired me, and I'm 100% certain that the Python devs are smarter than I am, so we should probab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:3041,Testability,log,logic,3041,"sis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is other; or (; isinstance(other, Space); and self.size == other.size; and self.basis == other.basis; ); ); ```; so we'll almost invariably get the benefits right now, but we're rather more future-proof in the code. By analogy, it's clearly wrong to do `(1, 2) is (1, 2)` to compare tuples, even though `tuple` produces singletons in CPython (and that code will generally be `True`). The Python `tuple` class is basically what inspired me, and I'm 100% certain that the Python devs are smarter than I am, so we should probab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:3026,Usability,simpl,simplifies,3026,"sis (`sigmaz()`, `num()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is other; or (; isinstance(other, Space); and self.size == other.size; and self.basis == other.basis; ); ); ```; so we'll almost invariably get the benefits right now, but we're rather more future-proof in the code. By analogy, it's clearly wrong to do `(1, 2) is (1, 2)` to compare tuples, even though `tuple` produces singletons in CPython (and that code will generally be `True`). The Python `tuple` class is basically what inspired me, and I'm 100% certain that the Python devs are smarter than I am, so we should probab",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1421#issuecomment-764870661:3566,Usability,clear,clearly,3566,"m()` and so on all imply a particular basis). Beyond that, the ENR functions would attach some basis information onto their outputs to make them safe, and functions like `Qobj.transform` could take a required argument to name the new basis. . I'm certainly not considering this a priority, just a possible solution to the ENR problem and a couple of people had expressed interest in basis safety in the google group. We can always tack it on in a later release if it ever seems like a good idea in the future. #### Point 3. Yeah, this is absolutely all intended to be internal only. We wouldn't even print out this form in `Qobj.__repr__`, to my mind. You'd still type `dims=[[2], [1]]` to get a qubit ket and `dims=[[1], [2]]` for a qubit bra, so I don't think there's any confusion there. The reason there's not a special ""bra"" structure internally is because it's not necessary; a bra really is just a linear mapping from a particular vector space to the field, so having a special case for that makes more complex - the matmul compatibility test with `Map(Space, Field)` and `Map(Space, Space)` is the exact same test as for two operators, which simplifies the logic. ---. After sleeping on it, I still generally like the singleton pattern for this, but I think _completely_ relying on referential equality is probably a bit short-sighted. We can define, for example, `Space.__eq__` as; ```python; class Space:; def __eq__(self, other):; return (; self is other; or (; isinstance(other, Space); and self.size == other.size; and self.basis == other.basis; ); ); ```; so we'll almost invariably get the benefits right now, but we're rather more future-proof in the code. By analogy, it's clearly wrong to do `(1, 2) is (1, 2)` to compare tuples, even though `tuple` produces singletons in CPython (and that code will generally be `True`). The Python `tuple` class is basically what inspired me, and I'm 100% certain that the Python devs are smarter than I am, so we should probably stick with them.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1421#issuecomment-764870661
https://github.com/qutip/qutip/issues/1422#issuecomment-764772713:318,Deployability,install,install,318,"Looks like there were breaking changes introduced in CVXPY 1.1 that changed some sort of matrix handling? I think the entirely of the `dnorm` function was written by Chris Granade about 5 years ago, and they're off at Microsoft now. As an immediate workaround, you can pin the version of CVXPY in conda to 1.0 (`conda install 'cvxpy=1.0'`) to fix it. Otherwise, probably there's a solution in swapping over a load of `*` to `@` in `qutip/semidefinite.py` and `qutip/metrics.py`, but that might be a bit nontrivial to solve. If you succeed, please do make a pull request. The reason that the ""simple"" cases work is that QuTiP detects them as known results and has fast paths avoiding `cvxpy`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-764772713
https://github.com/qutip/qutip/issues/1422#issuecomment-764772713:409,Performance,load,load,409,"Looks like there were breaking changes introduced in CVXPY 1.1 that changed some sort of matrix handling? I think the entirely of the `dnorm` function was written by Chris Granade about 5 years ago, and they're off at Microsoft now. As an immediate workaround, you can pin the version of CVXPY in conda to 1.0 (`conda install 'cvxpy=1.0'`) to fix it. Otherwise, probably there's a solution in swapping over a load of `*` to `@` in `qutip/semidefinite.py` and `qutip/metrics.py`, but that might be a bit nontrivial to solve. If you succeed, please do make a pull request. The reason that the ""simple"" cases work is that QuTiP detects them as known results and has fast paths avoiding `cvxpy`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-764772713
https://github.com/qutip/qutip/issues/1422#issuecomment-764772713:625,Safety,detect,detects,625,"Looks like there were breaking changes introduced in CVXPY 1.1 that changed some sort of matrix handling? I think the entirely of the `dnorm` function was written by Chris Granade about 5 years ago, and they're off at Microsoft now. As an immediate workaround, you can pin the version of CVXPY in conda to 1.0 (`conda install 'cvxpy=1.0'`) to fix it. Otherwise, probably there's a solution in swapping over a load of `*` to `@` in `qutip/semidefinite.py` and `qutip/metrics.py`, but that might be a bit nontrivial to solve. If you succeed, please do make a pull request. The reason that the ""simple"" cases work is that QuTiP detects them as known results and has fast paths avoiding `cvxpy`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-764772713
https://github.com/qutip/qutip/issues/1422#issuecomment-764772713:674,Safety,avoid,avoiding,674,"Looks like there were breaking changes introduced in CVXPY 1.1 that changed some sort of matrix handling? I think the entirely of the `dnorm` function was written by Chris Granade about 5 years ago, and they're off at Microsoft now. As an immediate workaround, you can pin the version of CVXPY in conda to 1.0 (`conda install 'cvxpy=1.0'`) to fix it. Otherwise, probably there's a solution in swapping over a load of `*` to `@` in `qutip/semidefinite.py` and `qutip/metrics.py`, but that might be a bit nontrivial to solve. If you succeed, please do make a pull request. The reason that the ""simple"" cases work is that QuTiP detects them as known results and has fast paths avoiding `cvxpy`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-764772713
https://github.com/qutip/qutip/issues/1422#issuecomment-764772713:592,Usability,simpl,simple,592,"Looks like there were breaking changes introduced in CVXPY 1.1 that changed some sort of matrix handling? I think the entirely of the `dnorm` function was written by Chris Granade about 5 years ago, and they're off at Microsoft now. As an immediate workaround, you can pin the version of CVXPY in conda to 1.0 (`conda install 'cvxpy=1.0'`) to fix it. Otherwise, probably there's a solution in swapping over a load of `*` to `@` in `qutip/semidefinite.py` and `qutip/metrics.py`, but that might be a bit nontrivial to solve. If you succeed, please do make a pull request. The reason that the ""simple"" cases work is that QuTiP detects them as known results and has fast paths avoiding `cvxpy`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-764772713
https://github.com/qutip/qutip/issues/1422#issuecomment-794422644:23,Availability,down,down,23,"I think I have tracked down the problem to this issue https://github.com/cvxgrp/cvxpy/issues/1159, we could patch it using dense matrices instead of sparse ones.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-794422644
https://github.com/qutip/qutip/issues/1422#issuecomment-794422644:108,Deployability,patch,patch,108,"I think I have tracked down the problem to this issue https://github.com/cvxgrp/cvxpy/issues/1159, we could patch it using dense matrices instead of sparse ones.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1422#issuecomment-794422644
https://github.com/qutip/qutip/issues/1423#issuecomment-767739076:635,Performance,concurren,concurrence,635,"Partially tracing either system out of a maximally mixed state _should_ be the same matrix (and is, in QuTiP), so the fidelity being 1 is correct from a matrix view. QuTiP doesn't track what systems used to exist before a partial trace, so a partial trace from 2 qubits to 1 qubit appears to live in the same Hilbert space no matter which qubit is traced out. This is the expected behaviour - it's generally the most convenient, rather than doing something odd like giving back the remaining systems tensored with a maximally mixed state on the parts we just traced out. I'm not sure of the relation between quantum state fidelity and concurrence that you're referring to, so I can't really comment on that. By the way, your code doesn't actually use a maximally mixed state, but the result is the same anyway. Being able to write (|00> + |01> + |10> + |11>)/2 in ket form like that shows it's pure over the basis you've defined. The maximally mixed state over this complete basis would be (|00><00| + |01><01| + |10><10| + |11><11|)/4, which isn't the same as the projector onto your state (which also has crossterms like |00><11| and so on).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1423#issuecomment-767739076
https://github.com/qutip/qutip/issues/1425#issuecomment-769829077:227,Usability,guid,guide,227,"It is possible, using a tensor structure for the Hilbert space, with a subsystem assigned to each player. You can have a look at the documentation, where it shows the case of [three coupled qubits](http://qutip.org/docs/latest/guide/guide-tensor.html#three-coupled-qubits). A library that specifically tackles quantum games is [toqito](https://toqito.readthedocs.io/en/latest/), by @vprusso. You can ask more support in the google group [forum](https://groups.google.com/forum/#!forum/qutip), I am closing the issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1425#issuecomment-769829077
https://github.com/qutip/qutip/issues/1425#issuecomment-769829077:233,Usability,guid,guide-tensor,233,"It is possible, using a tensor structure for the Hilbert space, with a subsystem assigned to each player. You can have a look at the documentation, where it shows the case of [three coupled qubits](http://qutip.org/docs/latest/guide/guide-tensor.html#three-coupled-qubits). A library that specifically tackles quantum games is [toqito](https://toqito.readthedocs.io/en/latest/), by @vprusso. You can ask more support in the google group [forum](https://groups.google.com/forum/#!forum/qutip), I am closing the issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1425#issuecomment-769829077
https://github.com/qutip/qutip/pull/1427#issuecomment-770189215:119,Availability,error,error,119,"The docstring can come live in its usual place, but otherwise that looks good to me! I'm always in favour of improving error meesages.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1427#issuecomment-770189215
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:632,Availability,error,error,632,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:764,Availability,down,down,764,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:24,Deployability,install,install,24,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:93,Deployability,install,install,93,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:275,Deployability,install,install,275,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:314,Deployability,release,released,314,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:465,Deployability,install,install,465,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:873,Deployability,release,release,873,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1037,Deployability,update,updates,1037,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1292,Deployability,release,released,1292,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1582,Deployability,release,release,1582,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:357,Integrability,depend,dependencies,357,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1115,Modifiability,variab,variability,1115,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:47,Testability,test,test,47,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:112,Testability,test,test,112,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:423,Testability,test,testing,423,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1577,Testability,test,test,1577,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:1664,Testability,test,testing,1664,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770459519:126,Usability,simpl,simple,126,"Note: in theory you can install QuTiP from the test PyPI server right now by doing; ```; pip install -i https://test.pypi.org/simple qutip-jakelishman; ```; (that's just the name - you still do `import qutip`) but since it's on the ""wrong"" server, you first have to manually install `numpy` and `scipy`. When it's released properly on PyPI it'll handle the dependencies correctly - this is only an artifact of being on the testing server. Running that command will install a binary version with no compilation, and should work on any (reasonable) Linux machine, Mac (possibly not M1 chips) and Windows. It's possible you may get an error about `ndarray size changed ... this may indicate binary incompatibility` - if so, either force `numpy` up to the new 1.20 or down to 1.19 (whichever one you don't have). This was a breaking change in numpy 1.20. Per my reading of the release notes, it won't be an issue provided in the future we always build against `numpy>=1.20` (even when using lower `numpy` at runtime) because the new version updates a certain C-API macro to take into account the possibility of runtime variability. I have pushed an additional change to the build requirements to ensure this always happens. This has another knock-on effect: numpy 1.20 only supports Python 3.7+ (released June 2017). Currently, officially QuTiP supports Python 3.6, but I think it's reasonable to follow numpy's footsteps and **drop support for python 3.6 from qutip 5.0**. It's offset by gaining support for 3.9. (Apologies for all the force-pushing - whenever I want to re-run a test release on my own branch I have to temporarily add an extra commit to swap to the testing server, then force-push a rewind of this PR's branch.)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770459519
https://github.com/qutip/qutip/pull/1429#issuecomment-770477015:288,Deployability,release,release,288,"Ok, I'm not sure that enforcing numpy >= 1.20 at compile time is sufficient. I don't know if it's a Cython thing, a numpy thing or an us thing, but I'll figure it out later when I've got more time. The distribution changes here are still good here, and if it ends up that for the initial release of 5.0 we only support numpy 1.20+, that's unfortunate but not really the end of the world.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770477015
https://github.com/qutip/qutip/pull/1429#issuecomment-770779664:149,Deployability,release,release,149,"Thanks! I'll work out how to handle this numpy 1.20 C-API change properly before this is ready to merge, I think - turns out my reading of the numpy release notes was wrong, or (possibly) Cython is generating some compile-time-constant code it should be deciding at runtime (as of the latest numpy). Hopefully it's just a configuration change on our end that I can work out somewhere.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770779664
https://github.com/qutip/qutip/pull/1429#issuecomment-770779664:322,Deployability,configurat,configuration,322,"Thanks! I'll work out how to handle this numpy 1.20 C-API change properly before this is ready to merge, I think - turns out my reading of the numpy release notes was wrong, or (possibly) Cython is generating some compile-time-constant code it should be deciding at runtime (as of the latest numpy). Hopefully it's just a configuration change on our end that I can work out somewhere.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770779664
https://github.com/qutip/qutip/pull/1429#issuecomment-770779664:322,Modifiability,config,configuration,322,"Thanks! I'll work out how to handle this numpy 1.20 C-API change properly before this is ready to merge, I think - turns out my reading of the numpy release notes was wrong, or (possibly) Cython is generating some compile-time-constant code it should be deciding at runtime (as of the latest numpy). Hopefully it's just a configuration change on our end that I can work out somewhere.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-770779664
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:33,Deployability,release,release,33,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:194,Deployability,update,updated,194,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:471,Deployability,install,installing,471,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:591,Deployability,install,install,591,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:810,Deployability,install,install,810,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:846,Deployability,install,install,846,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:1263,Deployability,deploy,deployments,1263,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:1544,Deployability,release,release,1544,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:697,Integrability,depend,dependencies,697,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:491,Testability,test,test,491,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:661,Testability,test,test,661,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:798,Testability,test,test,798,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:865,Testability,test,test,865,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-774353158:879,Usability,simpl,simple,879,"Ok, it turns out I got the numpy release notes the wrong way round; we have to build our binaries with `1.16.6 <= numpy < 1.20` to maintain ABI compatibility no matter the numpy version. I have updated the compiler infrastructure to take this into account - this is in some ways a temporary restriction until two or three years in the future when we can drop support for all numpy versions less than 1.20. This is ready for final review. If you're fast, you can also try installing from the test PyPI server to see if the wheels work for you. While it's on the temporary server, you need to install `numpy` and `scipy` manually yourself (as they don't exist on test.pypi.org), but pip will do the dependencies correctly for you once it's publishing to the full repo.; ```bash; conda create -n pypi-test; conda install python pip numpy scipy; pip install -i https://test.pypi.org/simple qutip-jakelishman; python -c 'import qutip; qutip.about()'; ```. @hodgestar, @nathanshammah: perhaps you could just glance over this again and make sure everything looks right to you? Simon, I know you already looked over it once, so if you've not got time again, no problem - barely anything has changed since you last saw it. Nathan: in theory once we're in a position where deployments push to PyPI I think I can write an action for qutip/qutip.github.io to push a commit updating the website with the new information too. However, with the docs currently using a completely separate build process in a different repo, they can't really be triggered by a release here. I wrote this PR against `dev.major`, but I suppose in theory I could backport it to the 4.x branch if that's absolutely required. I think some parts of the setup changed for `dev.major`, which is why I didn't originally try to make it to the current version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-774353158
https://github.com/qutip/qutip/pull/1429#issuecomment-779700849:32,Availability,down,downstream,32,Will this also restrict all the downstream packages to only use NumPy <1.20 or is it just a restriction when compiling `qutip`?,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-779700849
https://github.com/qutip/qutip/pull/1429#issuecomment-779704400:36,Deployability,Install,Installation,36,"@BoxiLi purely a build requirement. Installation allows any numpy >= 1.12, and with wheels being distributed, very few users will need to build QuTiP themselves.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-779704400
https://github.com/qutip/qutip/pull/1429#issuecomment-786544691:107,Usability,clear,clear,107,"Still looks good to me. We could put some of the code in `setup.py` into functions so that it's a bit more clear what is temporary state and how the code is organized, but we don't have to fix everything in one PR.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-786544691
https://github.com/qutip/qutip/pull/1429#issuecomment-801289045:893,Availability,down,download,893,"1. inside the ""Actions"" tab at the top of the GitHub page, you will only see workflows that are present in the code in the default git branch. `dev.major` isn't QuTiP's default branch, so the workflows won't appear immediately after this is merged, only when the `.github/workflows/build.yml` file also exists in `master`. 2. nothing prevents you from running the workflow on a fork, and there's no way and no reason to prevent this - it's also how I tested it. If you did run it on a fork, you'd be using your own GitHub Actions credits (it doesn't cost us anything because we're an open-source project). Only qutip/qutip knows the secret to publish to PyPI, so no fork can succeed on that. The branch check here serves two purposes: the first is that I needed some ""tickbox"" to let the admin decide at runtime whether they needed to publish the package or just build the wheels for personal download; the second is that we release off release branches, not master, so there needed to be an input to say _which_ branch should be built. 3. it's not 100% necessary, but it's the right thing to do. It decouples the project data from the setup code, which makes it much easier to modify both, and allows other tools to access the data. There are other PEPs in the works as well that will move all this data into `pyproject.toml`, rather than just `setup.cfg`. 4. oh, that's useful. I didn't really know or look into it, because it was only a temporary thing anyway. I might actually retire this PR and make it against `master` instead. It's functionally the same as this one, and most of the diff is the same, except that its `setup.py` is better organised, like Simon suggested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801289045
https://github.com/qutip/qutip/pull/1429#issuecomment-801289045:925,Deployability,release,release,925,"1. inside the ""Actions"" tab at the top of the GitHub page, you will only see workflows that are present in the code in the default git branch. `dev.major` isn't QuTiP's default branch, so the workflows won't appear immediately after this is merged, only when the `.github/workflows/build.yml` file also exists in `master`. 2. nothing prevents you from running the workflow on a fork, and there's no way and no reason to prevent this - it's also how I tested it. If you did run it on a fork, you'd be using your own GitHub Actions credits (it doesn't cost us anything because we're an open-source project). Only qutip/qutip knows the secret to publish to PyPI, so no fork can succeed on that. The branch check here serves two purposes: the first is that I needed some ""tickbox"" to let the admin decide at runtime whether they needed to publish the package or just build the wheels for personal download; the second is that we release off release branches, not master, so there needed to be an input to say _which_ branch should be built. 3. it's not 100% necessary, but it's the right thing to do. It decouples the project data from the setup code, which makes it much easier to modify both, and allows other tools to access the data. There are other PEPs in the works as well that will move all this data into `pyproject.toml`, rather than just `setup.cfg`. 4. oh, that's useful. I didn't really know or look into it, because it was only a temporary thing anyway. I might actually retire this PR and make it against `master` instead. It's functionally the same as this one, and most of the diff is the same, except that its `setup.py` is better organised, like Simon suggested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801289045
https://github.com/qutip/qutip/pull/1429#issuecomment-801289045:937,Deployability,release,release,937,"1. inside the ""Actions"" tab at the top of the GitHub page, you will only see workflows that are present in the code in the default git branch. `dev.major` isn't QuTiP's default branch, so the workflows won't appear immediately after this is merged, only when the `.github/workflows/build.yml` file also exists in `master`. 2. nothing prevents you from running the workflow on a fork, and there's no way and no reason to prevent this - it's also how I tested it. If you did run it on a fork, you'd be using your own GitHub Actions credits (it doesn't cost us anything because we're an open-source project). Only qutip/qutip knows the secret to publish to PyPI, so no fork can succeed on that. The branch check here serves two purposes: the first is that I needed some ""tickbox"" to let the admin decide at runtime whether they needed to publish the package or just build the wheels for personal download; the second is that we release off release branches, not master, so there needed to be an input to say _which_ branch should be built. 3. it's not 100% necessary, but it's the right thing to do. It decouples the project data from the setup code, which makes it much easier to modify both, and allows other tools to access the data. There are other PEPs in the works as well that will move all this data into `pyproject.toml`, rather than just `setup.cfg`. 4. oh, that's useful. I didn't really know or look into it, because it was only a temporary thing anyway. I might actually retire this PR and make it against `master` instead. It's functionally the same as this one, and most of the diff is the same, except that its `setup.py` is better organised, like Simon suggested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801289045
https://github.com/qutip/qutip/pull/1429#issuecomment-801289045:1217,Security,access,access,1217,"1. inside the ""Actions"" tab at the top of the GitHub page, you will only see workflows that are present in the code in the default git branch. `dev.major` isn't QuTiP's default branch, so the workflows won't appear immediately after this is merged, only when the `.github/workflows/build.yml` file also exists in `master`. 2. nothing prevents you from running the workflow on a fork, and there's no way and no reason to prevent this - it's also how I tested it. If you did run it on a fork, you'd be using your own GitHub Actions credits (it doesn't cost us anything because we're an open-source project). Only qutip/qutip knows the secret to publish to PyPI, so no fork can succeed on that. The branch check here serves two purposes: the first is that I needed some ""tickbox"" to let the admin decide at runtime whether they needed to publish the package or just build the wheels for personal download; the second is that we release off release branches, not master, so there needed to be an input to say _which_ branch should be built. 3. it's not 100% necessary, but it's the right thing to do. It decouples the project data from the setup code, which makes it much easier to modify both, and allows other tools to access the data. There are other PEPs in the works as well that will move all this data into `pyproject.toml`, rather than just `setup.cfg`. 4. oh, that's useful. I didn't really know or look into it, because it was only a temporary thing anyway. I might actually retire this PR and make it against `master` instead. It's functionally the same as this one, and most of the diff is the same, except that its `setup.py` is better organised, like Simon suggested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801289045
https://github.com/qutip/qutip/pull/1429#issuecomment-801289045:451,Testability,test,tested,451,"1. inside the ""Actions"" tab at the top of the GitHub page, you will only see workflows that are present in the code in the default git branch. `dev.major` isn't QuTiP's default branch, so the workflows won't appear immediately after this is merged, only when the `.github/workflows/build.yml` file also exists in `master`. 2. nothing prevents you from running the workflow on a fork, and there's no way and no reason to prevent this - it's also how I tested it. If you did run it on a fork, you'd be using your own GitHub Actions credits (it doesn't cost us anything because we're an open-source project). Only qutip/qutip knows the secret to publish to PyPI, so no fork can succeed on that. The branch check here serves two purposes: the first is that I needed some ""tickbox"" to let the admin decide at runtime whether they needed to publish the package or just build the wheels for personal download; the second is that we release off release branches, not master, so there needed to be an input to say _which_ branch should be built. 3. it's not 100% necessary, but it's the right thing to do. It decouples the project data from the setup code, which makes it much easier to modify both, and allows other tools to access the data. There are other PEPs in the works as well that will move all this data into `pyproject.toml`, rather than just `setup.cfg`. 4. oh, that's useful. I didn't really know or look into it, because it was only a temporary thing anyway. I might actually retire this PR and make it against `master` instead. It's functionally the same as this one, and most of the diff is the same, except that its `setup.py` is better organised, like Simon suggested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801289045
https://github.com/qutip/qutip/pull/1429#issuecomment-801459634:127,Deployability,release,release,127,"I think it might be a good idea to obsolete this pull request, and merge in #1465 instead, so we can use in for the next 4.6.0 release.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1429#issuecomment-801459634
https://github.com/qutip/qutip/pull/1430#issuecomment-770963331:238,Testability,test,tests,238,[![Coverage Status](https://coveralls.io/builds/36757585/badge)](https://coveralls.io/builds/36757585). Coverage remained the same at 63.449% when pulling **f9ac0ae6935b3a6fee188768792bbe7c93ecef6d on jakelishman:fix-consumable-iteration-tests** into **b67ac6418a450524aeb08a3b408c57592148b525 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1430#issuecomment-770963331
https://github.com/qutip/qutip/issues/1433#issuecomment-772330954:13,Performance,perform,performing,13,"I agree that performing a ufunc like `np.sin(...)` on a `QObj` and getting an `np.array` back is not that useful since presumably one would like a QObj back (otherwise why not just call `.full()` and work with the resulting numpy array directly). Likely this is a breaking change for some people, so we should document whatever approach we take.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772330954
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:1891,Availability,fault,fault,1891,"You still wouldn't be able to put `Qobj` into numpy arrays except by doing something like; ```python; qobjs = np.empty(3, dtype=object); qobjs[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; ```; but probably that's not _too_ much of a big deal. Leaving QuTiP as it is right now would require that anyway. My main problem is actually just with allowing ufuncs and other numpy interfaces to act directly on `Qobj` without an explicit conversion step, because it promotes the idea that it's ok to act elementwise on a `Qobj`. I don't think we should allow ufuncs at all - `Qobj` is not meant to be like an `ndarray` and ufunc semantics don't make sense. We can set `Qobj.__array_ufunc__ = None` and `Qobj.__array_function__ = None` to disable numpy functions acting on `Qobj` directly. Example with this in place:; ```python; >>> import qutip; >>> import numpy as np; >>> np.array(qutip.qeye(2)); array([[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]); >>> np.array([qutip.qeye(2), qutip.qeye(2)]) # Not ideal, but not our fault.; array([[[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]],. [[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]]); >>> np.sin(qutip.qeye(2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: operand 'Qobj' does not support ufuncs (__array_ufunc__=None); >>> np.sin(np.array(qutip.qeye(2))); array([[0.84147098+0.j, 0. +0.j],; [0. +0.j, 0.84147098+0.j]]); ```; Alternatively, if people _really_ want to be able to use ufuncs on `Qobj`, it is possible to define `__array_ufunc__` in such a way that we allow only some `ufuncs` to operate. Doing this leaves us susceptible to problems interacting with other libraries that implement this, though, beacuse whichever class has the highest `__array_priority__` gets to dictate what makes sense. Unless there's a really clear _need_ for this, I don't think it's a good idea. For completeness, the rest of this comment is stuff I find out while researching. ## The `__array__()` and `__array_wrap__()` methods. These have been s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:4838,Energy Efficiency,adapt,adaptive,4838,"ever, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make sense on quantum objects, which are arrays only as an implementation detail - the `Qobj` class is meant to represent an abstract linear algebra object, not specifically a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (m",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:1256,Integrability,interface,interfaces,1256,". We can also fix QuTiP library code by removing all times we try and put `Qobj` inside numpy arrays on our end, which would also be a fix. I've actually mellowed on my total opposition to `Qobj.__array__`. Thinking more, I'm not actually super unhappy with the idea of deprecating `Qobj.full()` in QuTiP 5.0 (not removing until at least 6.0, since it's such a major function) and promoting `np.array(qobj)` to be the de jure method of getting the dense array out of a `Qobj`. Qiskit recently (Qiskit/qiskit-terra#5402) changed their behaviour to do something very similar to this. You still wouldn't be able to put `Qobj` into numpy arrays except by doing something like; ```python; qobjs = np.empty(3, dtype=object); qobjs[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; ```; but probably that's not _too_ much of a big deal. Leaving QuTiP as it is right now would require that anyway. My main problem is actually just with allowing ufuncs and other numpy interfaces to act directly on `Qobj` without an explicit conversion step, because it promotes the idea that it's ok to act elementwise on a `Qobj`. I don't think we should allow ufuncs at all - `Qobj` is not meant to be like an `ndarray` and ufunc semantics don't make sense. We can set `Qobj.__array_ufunc__ = None` and `Qobj.__array_function__ = None` to disable numpy functions acting on `Qobj` directly. Example with this in place:; ```python; >>> import qutip; >>> import numpy as np; >>> np.array(qutip.qeye(2)); array([[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]); >>> np.array([qutip.qeye(2), qutip.qeye(2)]) # Not ideal, but not our fault.; array([[[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]],. [[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]]); >>> np.sin(qutip.qeye(2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: operand 'Qobj' does not support ufuncs (__array_ufunc__=None); >>> np.sin(np.array(qutip.qeye(2))); array([[0.84147098+0.j, 0. +0.j],; [0. +0.j, 0.84147098+0.j]]); ```; Alternatively, if people _r",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:3198,Integrability,interface,interface,3198,"tip.qeye(2))); array([[0.84147098+0.j, 0. +0.j],; [0. +0.j, 0.84147098+0.j]]); ```; Alternatively, if people _really_ want to be able to use ufuncs on `Qobj`, it is possible to define `__array_ufunc__` in such a way that we allow only some `ufuncs` to operate. Doing this leaves us susceptible to problems interacting with other libraries that implement this, though, beacuse whichever class has the highest `__array_priority__` gets to dictate what makes sense. Unless there's a really clear _need_ for this, I don't think it's a good idea. For completeness, the rest of this comment is stuff I find out while researching. ## The `__array__()` and `__array_wrap__()` methods. These have been special methods understood by numpy since at least 1.3 (2009 - the oldest docs still on scipy.org), and I imagine long before then too. `__array__` is mentioned (and still is) in the documentation of `np.array`, which is unchanged since 2009 and says that its argument should be; > An array, any object exposing the array interface, an object whose `__array__` method returns an array, or any (nested) sequence. and `__array_wrap__` is like the reverse - it's for coercing numpy arrays back into this class. If we were to keep `__array__` in `Qobj`, we should also implement `__array_wrap__` for coercion back (something that isn't currently implemented). At the time and up to inclusively 1.19, the presence of `__array__` caused otherwise scalar types passed alone to `np.array` to return the output of `input.__array__(*args, **kwargs)`, instead of becoming a 0D numpy array (like `np.array(1)` does). Taken purely alone, that could make sense as something we implement. However, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:3919,Integrability,interface,interface,3919,"ast 1.3 (2009 - the oldest docs still on scipy.org), and I imagine long before then too. `__array__` is mentioned (and still is) in the documentation of `np.array`, which is unchanged since 2009 and says that its argument should be; > An array, any object exposing the array interface, an object whose `__array__` method returns an array, or any (nested) sequence. and `__array_wrap__` is like the reverse - it's for coercing numpy arrays back into this class. If we were to keep `__array__` in `Qobj`, we should also implement `__array_wrap__` for coercion back (something that isn't currently implemented). At the time and up to inclusively 1.19, the presence of `__array__` caused otherwise scalar types passed alone to `np.array` to return the output of `input.__array__(*args, **kwargs)`, instead of becoming a 0D numpy array (like `np.array(1)` does). Taken purely alone, that could make sense as something we implement. However, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make sense on quantum objects, which are arrays only as an implementation detail - the `Qobj` class is meant to represent an abstract linear algebra object, not specifically a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra obje",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:4134,Integrability,interface,interface,4134," says that its argument should be; > An array, any object exposing the array interface, an object whose `__array__` method returns an array, or any (nested) sequence. and `__array_wrap__` is like the reverse - it's for coercing numpy arrays back into this class. If we were to keep `__array__` in `Qobj`, we should also implement `__array_wrap__` for coercion back (something that isn't currently implemented). At the time and up to inclusively 1.19, the presence of `__array__` caused otherwise scalar types passed alone to `np.array` to return the output of `input.__array__(*args, **kwargs)`, instead of becoming a 0D numpy array (like `np.array(1)` does). Taken purely alone, that could make sense as something we implement. However, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make sense on quantum objects, which are arrays only as an implementation detail - the `Qobj` class is meant to represent an abstract linear algebra object, not specifically a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as the",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:5358,Integrability,protocol,protocol,5358,"cally a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions). Several libraries implement only these, but _not_ `__array__`, but given my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostl",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:6032,Integrability,rout,route,6032,"rray. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions). Several libraries implement only these, but _not_ `__array__`, but given my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:6366,Integrability,interface,interface,6366,"and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions). Several libraries implement only these, but _not_ `__array__`, but given my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are try",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7727,Integrability,interface,interface,7727,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7767,Integrability,interface,interface,7767,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7837,Integrability,interface,interface,7837,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:4838,Modifiability,adapt,adaptive,4838,"ever, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make sense on quantum objects, which are arrays only as an implementation detail - the `Qobj` class is meant to represent an abstract linear algebra object, not specifically a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (m",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:5574,Modifiability,extend,extended,5574,"rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-array-function.html). Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like `tensordot`. These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions). Several libraries implement only these, but _not_ `__array__`, but given my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out m",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:6688,Modifiability,extend,extends,6688,"uld still follow the `ufunc` spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions). Several libraries implement only these, but _not_ `__array__`, but given my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interfa",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7542,Modifiability,variab,variable,7542,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7126,Performance,perform,performance,7126,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:7464,Performance,perform,performance,7464,"n my points 1 and 2 above, I don't think QuTiP should go this route. You can, however, set these properties to `None` to unconditionally tell Numpy that the object is incompatible with ufuncs. I think this might be a good way for us to go. ## What other libraries do. Provide everything:; - Dask: mostly trying to provide a numpy-like distributed array class. Its arrays mostly support the numpy interface, including how ufuncs should act on them. Providing `__array__` seems odd to me here in the context of other libraries, since that may easily blow out memory.; - PyTorch: CPU/GPU accelerated tensors for ML. This is a bit beyond my experience to comment on why they made the choices they did.; - Xarray: strongly extends the idea of structured arrays; this to me is the best example of how `__array__` was intended to be used.; ; Provide some things:; - Qiskit: (just changed behaviour in Qiskit/qiskit-terra#5402) implements `__array__` (but nothing else) for things that are like our `Qobj`. Discussed more at the top.; - CuPy (CUDA operations on ndarray-likes) explicitly does not allow implicit conversion to `np.ndarray` (see cupy/cupy#3421) for performance reasons, but does implement `__array_ufunc__` and `__array_function__`.; - pydata/sparse (nd-sparse _arrays_ instead of scipy.sparse's sparse _matrices_): always implement `__array_ufunc__` and `__array_function__` because they are trying to be a sparse version of `ndarray`. By default, they do not implement `__array__` for performance/memory reasons, but they do allow turning it on by an environment variable. Do not implement anything:; - JAX (autodiff) tries really hard to replace numpy rather than interoperate with it; - scipy.sparse matrices are intended for use with a _matrix_ interface, not a broadcast-able _array_ interface. They specifically document that they will not provide this interface (see scipy/scipy#12279). Somewhat weirdly, they do have custom methods for some elementwise ufuncs, though (like `np.sin`).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:4420,Testability,test,test,4420,"`__array_wrap__` for coercion back (something that isn't currently implemented). At the time and up to inclusively 1.19, the presence of `__array__` caused otherwise scalar types passed alone to `np.array` to return the output of `input.__array__(*args, **kwargs)`, instead of becoming a 0D numpy array (like `np.array(1)` does). Taken purely alone, that could make sense as something we implement. However, this also implies that `Qobj` should fulfil the numpy ufunc interface; `Qobj` would be a container for data such that operations like `np.sin` is the elementwise sin, or (most notably) `np.multiply` is the *elementwise* multiplication. Our `Qobj` _does not_ fulfil the ufunc interface:; 1. elementwise operations don't make sense on quantum objects, which are arrays only as an implementation detail - the `Qobj` class is meant to represent an abstract linear algebra object, not specifically a matrix.; 2. we don't honour the `shape` guarantees of numpy as we test compatibility based on `dims`, which are not 1D (superoperators) so cannot follow numpy's broadcasting rules; 3. we treat multiplication as matrix multiplication, violating how `np.multiply` should behave. My main concern is point 1: I don't think that `Qobj` provides a similar object to an `ndarray` at all. Right now we _do_ use matrices underneath, but proposed additions to QuTiP such as symbolic `Qobj` and adaptive Hilbert spaces are compatible with the idea of ""abstract linear algebra objects"", but do not necessarily have a backing array. Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions. ## More control over dispatch: `__array_ufunc__` and `__array_function__`. See [NEP 13](https://numpy.org/neps/nep-0013-ufunc-overrides.html), [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html) and [NEP 35](https://numpy.org/neps/nep-0035-array-creation-dispatch-with-arra",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-772608902:2670,Usability,clear,clear,2670," place:; ```python; >>> import qutip; >>> import numpy as np; >>> np.array(qutip.qeye(2)); array([[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]); >>> np.array([qutip.qeye(2), qutip.qeye(2)]) # Not ideal, but not our fault.; array([[[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]],. [[1.+0.j, 0.+0.j],; [0.+0.j, 1.+0.j]]]); >>> np.sin(qutip.qeye(2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: operand 'Qobj' does not support ufuncs (__array_ufunc__=None); >>> np.sin(np.array(qutip.qeye(2))); array([[0.84147098+0.j, 0. +0.j],; [0. +0.j, 0.84147098+0.j]]); ```; Alternatively, if people _really_ want to be able to use ufuncs on `Qobj`, it is possible to define `__array_ufunc__` in such a way that we allow only some `ufuncs` to operate. Doing this leaves us susceptible to problems interacting with other libraries that implement this, though, beacuse whichever class has the highest `__array_priority__` gets to dictate what makes sense. Unless there's a really clear _need_ for this, I don't think it's a good idea. For completeness, the rest of this comment is stuff I find out while researching. ## The `__array__()` and `__array_wrap__()` methods. These have been special methods understood by numpy since at least 1.3 (2009 - the oldest docs still on scipy.org), and I imagine long before then too. `__array__` is mentioned (and still is) in the documentation of `np.array`, which is unchanged since 2009 and says that its argument should be; > An array, any object exposing the array interface, an object whose `__array__` method returns an array, or any (nested) sequence. and `__array_wrap__` is like the reverse - it's for coercing numpy arrays back into this class. If we were to keep `__array__` in `Qobj`, we should also implement `__array_wrap__` for coercion back (something that isn't currently implemented). At the time and up to inclusively 1.19, the presence of `__array__` caused otherwise scalar types passed alone to `np.array` to return the output of `inp",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-772608902
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:2653,Availability,error,error,2653,"ect about it:. ```python; >>> arr = np.empty((3,), dtype=object); >>> arr[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; >>> arr.shape; (3,); >>> arr[0]; Quantum object: dims = [[2], [2]], shape = (2, 2), type = oper, isherm = True; Qobj data =; [[1. 0.]; [0. 1.]]; ```. The reason numpy does this now is because (my understanding is that) defining `__array__` was meant to be a much stronger guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort of `ndarray`-like type, because it satisfies matrix semantics, not array semantics. That's the reason `scipy.sparse` types don't implement `__array__`. There always was a sanctioned method for converting `Qobj` to `ndarray` - `Qobj.full()`, similar to `scipy`'s `spmatrix.toarray()` - so `Qobj.__array__` was never a _necessity_, just a convenience in some workflows. Given the tools we can use to suppr",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:3159,Integrability,interface,interface,3159,"r guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort of `ndarray`-like type, because it satisfies matrix semantics, not array semantics. That's the reason `scipy.sparse` types don't implement `__array__`. There always was a sanctioned method for converting `Qobj` to `ndarray` - `Qobj.full()`, similar to `scipy`'s `spmatrix.toarray()` - so `Qobj.__array__` was never a _necessity_, just a convenience in some workflows. Given the tools we can use to suppress the ufunc behaviour, the only question we need to decide on is whether that particular convenience (converting a single `Qobj` to `ndarray` with `np.array` rather than `Qobj.full`) is worth the loss of another (it's now rather faffy to put `Qobj` into an `ndarray`). Both have simple alternatives and I'll go along with either, though my personal preference is not to define `Qobj.__array__`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:2129,Safety,safe,safely,2129," (3,); >>> arr[0]; Quantum object: dims = [[2], [2]], shape = (2, 2), type = oper, isherm = True; Qobj data =; [[1. 0.]; [0. 1.]]; ```. This change purely affects `np.array` and similar constructors when passed sequences of objects that all implement `__array__`. It is still possible to make a Numpy array of `Qobj` even with `Qobj.__array__` defined in Numpy 1.20, but you have to be rather more indirect about it:. ```python; >>> arr = np.empty((3,), dtype=object); >>> arr[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; >>> arr.shape; (3,); >>> arr[0]; Quantum object: dims = [[2], [2]], shape = (2, 2), type = oper, isherm = True; Qobj data =; [[1. 0.]; [0. 1.]]; ```. The reason numpy does this now is because (my understanding is that) defining `__array__` was meant to be a much stronger guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:2381,Safety,safe,safely,2381,"nstructors when passed sequences of objects that all implement `__array__`. It is still possible to make a Numpy array of `Qobj` even with `Qobj.__array__` defined in Numpy 1.20, but you have to be rather more indirect about it:. ```python; >>> arr = np.empty((3,), dtype=object); >>> arr[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; >>> arr.shape; (3,); >>> arr[0]; Quantum object: dims = [[2], [2]], shape = (2, 2), type = oper, isherm = True; Qobj data =; [[1. 0.]; [0. 1.]]; ```. The reason numpy does this now is because (my understanding is that) defining `__array__` was meant to be a much stronger guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort of `ndarray`-like type, because it satisfies matrix semantics, not array semantics. That's the reason `scipy.sparse` types don't implement `__array__`. There always was a sanctioned method",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:2422,Usability,clear,clearly,2422,"nstructors when passed sequences of objects that all implement `__array__`. It is still possible to make a Numpy array of `Qobj` even with `Qobj.__array__` defined in Numpy 1.20, but you have to be rather more indirect about it:. ```python; >>> arr = np.empty((3,), dtype=object); >>> arr[:] = [qutip.qeye(2), qutip.qeye(2), qutip.qeye(2)]; >>> arr.shape; (3,); >>> arr[0]; Quantum object: dims = [[2], [2]], shape = (2, 2), type = oper, isherm = True; Qobj data =; [[1. 0.]; [0. 1.]]; ```. The reason numpy does this now is because (my understanding is that) defining `__array__` was meant to be a much stronger guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort of `ndarray`-like type, because it satisfies matrix semantics, not array semantics. That's the reason `scipy.sparse` types don't implement `__array__`. There always was a sanctioned method",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773992094:3876,Usability,simpl,simple,3876,"r guarantee than just ""it's convenient to let `np.array` know about this object"". It was meant to be an indication that your class can be safely coerced into `ndarray` (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of `Qobj`. That means that arrays of things implementing `__array__` should be safely representable as `ndarray`, which clearly isn't true for us. Similarly, ever since `Qobj.__array__` was first defined you could use Numpy ufuncs on `Qobj`, which would get implicitly converted to `ndarray` and then return complete nonsense, rather than throwing an error like ""what you're doing is silly"":; ```python; >>> np.sin(qutip.basis(2, 1)); array([[0. ],; [0.84147098]]); ```; (imo that should really be a `TypeError` if done without an explicit conversion into Numpy semantics). There is a way around that latter point in modern Numpy - defining `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` - but it does raise the question of whether we _should_ define `Qobj.__array__`; we have no intention of implying that `Qobj` satisfies the general Numpy ufunc interface, and it isn't any sort of `ndarray`-like type, because it satisfies matrix semantics, not array semantics. That's the reason `scipy.sparse` types don't implement `__array__`. There always was a sanctioned method for converting `Qobj` to `ndarray` - `Qobj.full()`, similar to `scipy`'s `spmatrix.toarray()` - so `Qobj.__array__` was never a _necessity_, just a convenience in some workflows. Given the tools we can use to suppress the ufunc behaviour, the only question we need to decide on is whether that particular convenience (converting a single `Qobj` to `ndarray` with `np.array` rather than `Qobj.full`) is worth the loss of another (it's now rather faffy to put `Qobj` into an `ndarray`). Both have simple alternatives and I'll go along with either, though my personal preference is not to define `Qobj.__array__`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773992094
https://github.com/qutip/qutip/issues/1433#issuecomment-773997386:182,Deployability,patch,patch,182,"Of course, Python does in general allow users to override whatever behaviour we choose - a user can always define `Qobj.__array__` or any of the others themselves, which will monkey-patch QuTiP into doing what that user wants. Similarly, we _could_ have `Qobj.__array__` defined conditionally on a global QuTiP option; pydata/sparse takes this approach, although theirs is a slightly different case semantically because they are trying to make sparse equivalents of `ndarray`, rather than sparse matrices.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-773997386
https://github.com/qutip/qutip/issues/1433#issuecomment-774058408:607,Availability,fail-safe,fail-safe,607,"To me this is a question of what guarantees our primary type makes, so it's quite a big decision to be taken. I'm not sure I agree that implementing `__array_wrap__` is a good idea - `Qobj` does not support ufunc semantics, and implementing that implies that we're a similar class to `ndarray`, which I don't think we are. I don't think `np.sin(qobj)` should return `ndarray` _or_ `Qobj`; I think it should be a TypeError. To me, we should be rather conservative about adding features like that when there's little tangible benefit - when there's a slightly more explicit alternative syntax, it's better to fail-safe than add potential ""gotchas"". The fact that elementwise operations are not part of the algebra of `Qobj` should be enough of a reason to cause you to have to explicitly ask for it, otherwise it tacitly _becomes_ part of the algebra. For your point three, if that's the case, I'd argue you're doing something wrong: are you constructing the `Qobj` before you've finalised your data? Shouldn't it be; ```python; incomplete_data = np.array([[theta, 0, 0], ...]); return Qobj(np.sin(incomplete_data)); ```; not; ```python; return np.sin(Qobj(incomplete_data)); ```. As a compromise, we could ensure that all our data-layer types (`CSR`, `Dense`, whatever else) will support ufuncs with ndarray syntax; then you could do `Qobj(np.sin(qobj.data))` to be explicitly elementwise if you really wanted, rather than absolutely requiring you to produce a full dense matrix. I'm still not sure I see the use case there, though. I'm in favour of removing `np.array([qobj1, qobj2, ...], dtype=object)` usage inside QuTiP no matter which way we come down on this, though. As far as I recall from seeing it, there no reason to use `ndarray` over a regular Python list in any of our internal use, and it's rarely (if ever) actually returned out of a QuTiP function. Given it might cause subtle differences between different numpy versions, probably best to avoid it. If GSoC applications are imminent, ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774058408
https://github.com/qutip/qutip/issues/1433#issuecomment-774058408:1651,Availability,down,down,1651,"ken. I'm not sure I agree that implementing `__array_wrap__` is a good idea - `Qobj` does not support ufunc semantics, and implementing that implies that we're a similar class to `ndarray`, which I don't think we are. I don't think `np.sin(qobj)` should return `ndarray` _or_ `Qobj`; I think it should be a TypeError. To me, we should be rather conservative about adding features like that when there's little tangible benefit - when there's a slightly more explicit alternative syntax, it's better to fail-safe than add potential ""gotchas"". The fact that elementwise operations are not part of the algebra of `Qobj` should be enough of a reason to cause you to have to explicitly ask for it, otherwise it tacitly _becomes_ part of the algebra. For your point three, if that's the case, I'd argue you're doing something wrong: are you constructing the `Qobj` before you've finalised your data? Shouldn't it be; ```python; incomplete_data = np.array([[theta, 0, 0], ...]); return Qobj(np.sin(incomplete_data)); ```; not; ```python; return np.sin(Qobj(incomplete_data)); ```. As a compromise, we could ensure that all our data-layer types (`CSR`, `Dense`, whatever else) will support ufuncs with ndarray syntax; then you could do `Qobj(np.sin(qobj.data))` to be explicitly elementwise if you really wanted, rather than absolutely requiring you to produce a full dense matrix. I'm still not sure I see the use case there, though. I'm in favour of removing `np.array([qobj1, qobj2, ...], dtype=object)` usage inside QuTiP no matter which way we come down on this, though. As far as I recall from seeing it, there no reason to use `ndarray` over a regular Python list in any of our internal use, and it's rarely (if ever) actually returned out of a QuTiP function. Given it might cause subtle differences between different numpy versions, probably best to avoid it. If GSoC applications are imminent, we could open an issue and tag it with ""good first issue"" to give prospective applicants a potential PR?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774058408
https://github.com/qutip/qutip/issues/1433#issuecomment-774058408:612,Safety,safe,safe,612,"To me this is a question of what guarantees our primary type makes, so it's quite a big decision to be taken. I'm not sure I agree that implementing `__array_wrap__` is a good idea - `Qobj` does not support ufunc semantics, and implementing that implies that we're a similar class to `ndarray`, which I don't think we are. I don't think `np.sin(qobj)` should return `ndarray` _or_ `Qobj`; I think it should be a TypeError. To me, we should be rather conservative about adding features like that when there's little tangible benefit - when there's a slightly more explicit alternative syntax, it's better to fail-safe than add potential ""gotchas"". The fact that elementwise operations are not part of the algebra of `Qobj` should be enough of a reason to cause you to have to explicitly ask for it, otherwise it tacitly _becomes_ part of the algebra. For your point three, if that's the case, I'd argue you're doing something wrong: are you constructing the `Qobj` before you've finalised your data? Shouldn't it be; ```python; incomplete_data = np.array([[theta, 0, 0], ...]); return Qobj(np.sin(incomplete_data)); ```; not; ```python; return np.sin(Qobj(incomplete_data)); ```. As a compromise, we could ensure that all our data-layer types (`CSR`, `Dense`, whatever else) will support ufuncs with ndarray syntax; then you could do `Qobj(np.sin(qobj.data))` to be explicitly elementwise if you really wanted, rather than absolutely requiring you to produce a full dense matrix. I'm still not sure I see the use case there, though. I'm in favour of removing `np.array([qobj1, qobj2, ...], dtype=object)` usage inside QuTiP no matter which way we come down on this, though. As far as I recall from seeing it, there no reason to use `ndarray` over a regular Python list in any of our internal use, and it's rarely (if ever) actually returned out of a QuTiP function. Given it might cause subtle differences between different numpy versions, probably best to avoid it. If GSoC applications are imminent, ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774058408
https://github.com/qutip/qutip/issues/1433#issuecomment-774058408:1956,Safety,avoid,avoid,1956,"ken. I'm not sure I agree that implementing `__array_wrap__` is a good idea - `Qobj` does not support ufunc semantics, and implementing that implies that we're a similar class to `ndarray`, which I don't think we are. I don't think `np.sin(qobj)` should return `ndarray` _or_ `Qobj`; I think it should be a TypeError. To me, we should be rather conservative about adding features like that when there's little tangible benefit - when there's a slightly more explicit alternative syntax, it's better to fail-safe than add potential ""gotchas"". The fact that elementwise operations are not part of the algebra of `Qobj` should be enough of a reason to cause you to have to explicitly ask for it, otherwise it tacitly _becomes_ part of the algebra. For your point three, if that's the case, I'd argue you're doing something wrong: are you constructing the `Qobj` before you've finalised your data? Shouldn't it be; ```python; incomplete_data = np.array([[theta, 0, 0], ...]); return Qobj(np.sin(incomplete_data)); ```; not; ```python; return np.sin(Qobj(incomplete_data)); ```. As a compromise, we could ensure that all our data-layer types (`CSR`, `Dense`, whatever else) will support ufuncs with ndarray syntax; then you could do `Qobj(np.sin(qobj.data))` to be explicitly elementwise if you really wanted, rather than absolutely requiring you to produce a full dense matrix. I'm still not sure I see the use case there, though. I'm in favour of removing `np.array([qobj1, qobj2, ...], dtype=object)` usage inside QuTiP no matter which way we come down on this, though. As far as I recall from seeing it, there no reason to use `ndarray` over a regular Python list in any of our internal use, and it's rarely (if ever) actually returned out of a QuTiP function. Given it might cause subtle differences between different numpy versions, probably best to avoid it. If GSoC applications are imminent, we could open an issue and tag it with ""good first issue"" to give prospective applicants a potential PR?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774058408
https://github.com/qutip/qutip/issues/1433#issuecomment-774106830:373,Integrability,interface,interface,373,"Oh yeah, that's a good point we should push out the change sooner rather than later. With how the data-layer classes are implemented, ufunc handling on them wouldn't actually add any memory footprint, but it does add complexity whenever someone wants to implement a new data-layer class. It's hard to fit general ufunc machinery into the Dispatcher spec, because the ufunc interface is rather general, and we don't want to entirely reimplement numpy. You also can't dispatch on ""unary"" / ""binary"" / ""arbitrary"" ufuncs as groups (could have been an alternative), because (e.g.) `sin` has very different performance characteristics to `cos` on sparse matrices. If the dispatchers aren't in use, then having a separate function (`apply_ufunc`) doesn't make a performance difference over defining `__array_ufunc__` in a Cython class in speed or memory, but it does make it harder for a user. Class functions like that in Cython are actually implemented as separate C-backed functions - you can't override them on an instance-by-instance basis, so the instances aren't carrying around extra vtables or anything like that. One option for user convenience there could be to allow unary ufuncs on data-layer objects and forbid binary+ ones. We can do that with `__array_ufunc__`. It's not so difficult to keep track of the few numpy ufuncs that have f(0) = 0 so different sparse structures can optimise based on that. *Edit*: oh, I think I misunderstood what you were saying about ""lightness"" - do you mean the spec of what they have to support is light, or their memory impact is light?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774106830
https://github.com/qutip/qutip/issues/1433#issuecomment-774106830:602,Performance,perform,performance,602,"Oh yeah, that's a good point we should push out the change sooner rather than later. With how the data-layer classes are implemented, ufunc handling on them wouldn't actually add any memory footprint, but it does add complexity whenever someone wants to implement a new data-layer class. It's hard to fit general ufunc machinery into the Dispatcher spec, because the ufunc interface is rather general, and we don't want to entirely reimplement numpy. You also can't dispatch on ""unary"" / ""binary"" / ""arbitrary"" ufuncs as groups (could have been an alternative), because (e.g.) `sin` has very different performance characteristics to `cos` on sparse matrices. If the dispatchers aren't in use, then having a separate function (`apply_ufunc`) doesn't make a performance difference over defining `__array_ufunc__` in a Cython class in speed or memory, but it does make it harder for a user. Class functions like that in Cython are actually implemented as separate C-backed functions - you can't override them on an instance-by-instance basis, so the instances aren't carrying around extra vtables or anything like that. One option for user convenience there could be to allow unary ufuncs on data-layer objects and forbid binary+ ones. We can do that with `__array_ufunc__`. It's not so difficult to keep track of the few numpy ufuncs that have f(0) = 0 so different sparse structures can optimise based on that. *Edit*: oh, I think I misunderstood what you were saying about ""lightness"" - do you mean the spec of what they have to support is light, or their memory impact is light?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774106830
https://github.com/qutip/qutip/issues/1433#issuecomment-774106830:756,Performance,perform,performance,756,"Oh yeah, that's a good point we should push out the change sooner rather than later. With how the data-layer classes are implemented, ufunc handling on them wouldn't actually add any memory footprint, but it does add complexity whenever someone wants to implement a new data-layer class. It's hard to fit general ufunc machinery into the Dispatcher spec, because the ufunc interface is rather general, and we don't want to entirely reimplement numpy. You also can't dispatch on ""unary"" / ""binary"" / ""arbitrary"" ufuncs as groups (could have been an alternative), because (e.g.) `sin` has very different performance characteristics to `cos` on sparse matrices. If the dispatchers aren't in use, then having a separate function (`apply_ufunc`) doesn't make a performance difference over defining `__array_ufunc__` in a Cython class in speed or memory, but it does make it harder for a user. Class functions like that in Cython are actually implemented as separate C-backed functions - you can't override them on an instance-by-instance basis, so the instances aren't carrying around extra vtables or anything like that. One option for user convenience there could be to allow unary ufuncs on data-layer objects and forbid binary+ ones. We can do that with `__array_ufunc__`. It's not so difficult to keep track of the few numpy ufuncs that have f(0) = 0 so different sparse structures can optimise based on that. *Edit*: oh, I think I misunderstood what you were saying about ""lightness"" - do you mean the spec of what they have to support is light, or their memory impact is light?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774106830
https://github.com/qutip/qutip/issues/1433#issuecomment-774128466:113,Availability,avail,available,113,"Yeah, that's a very fair point. If you absolutely want to do it in a sparse manner too, there's `CSR.as_scipy()` available as well that'll let you munge our data however you like. I'm still not a fan of `Qobj.__array__`, but happy enough to go with it since it seems everyone else likes it (we should also reinstate it in `dev.major`). We can set `Qobj.__array_ufunc__ = Qobj.__array_function__ = None` to disable ufuncs and other numpy functions unconditionally. It's unlikely this will annoy anyone, since we've not had a complaint that ufuncs on `Qobj` does something super weird since `Qobj.__array__` was implemented. We can leave it unless Simon wants to make some more of the case for allowing ufuncs on `Qobj`, or happy to go with this? (tag @hodgestar.). We can also give it a day or two for Michael (tag @goerz), but it seems people are generally resolved to keeping the functionality he originally wanted anyway, even with numpy 1.20 changing its behaviour.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-774128466
https://github.com/qutip/qutip/issues/1433#issuecomment-778512258:932,Energy Efficiency,reduce,reduce,932,"Further notes: in numpy 1.20 defining `__array__` breaks `np.asarray`, except in the case where the user explicitly defines `np.asarray([qutip.qeye(2)], dtype=object)`. This is actually a very very common function in numpy operations; things like `np.shape` or `np.all` implicitly call `np.asarray` _without_ a `dtype`, which will result in a `TypeError`:; ```python; >>> import qutip; >>> import numpy as np; >>> np.all([qutip.qeye(2)]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<__array_function__ internals>"", line 5, in all; File ""/Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py"", line 2411, in all; return _wrapreduction(a, np.logical_and, 'all', axis, None, out, keepdims=keepdims); File ""/Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py"", line 87, in _wrapreduction; return ufunc.reduce(obj, axis, dtype, out, **passkwargs); TypeError: must be real number, not Qobj; ```. I think we may be able to get around this with a suitable definition of `Qobj.__array_function__`, though I am a little worried that we'll keep turning up these knock-on effects of `Qobj.__array__`. One major problem is that I'm not sure how we'll define `__array_function__` to satisfy this case, without having to manually disable every single numpy function. We can't have `np.asarray()` not work on `Qobj` because that would break parity with `np.array(qobj)`, however we also can't implicitly convert ourselves to an array if we're in a nested sequence, because then `np.all([qobj])` will pretty much always be false; it will have implicitly become an element-wise operation, even though the user _probably_ meant to check if every object in the array was not the zero operator. This isn't just `np.all`, it's also `np.shape`, `np.any`, and several more that make up the non-ufunc interface of numpy.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-778512258
https://github.com/qutip/qutip/issues/1433#issuecomment-778512258:1910,Integrability,interface,interface,1910,"Further notes: in numpy 1.20 defining `__array__` breaks `np.asarray`, except in the case where the user explicitly defines `np.asarray([qutip.qeye(2)], dtype=object)`. This is actually a very very common function in numpy operations; things like `np.shape` or `np.all` implicitly call `np.asarray` _without_ a `dtype`, which will result in a `TypeError`:; ```python; >>> import qutip; >>> import numpy as np; >>> np.all([qutip.qeye(2)]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<__array_function__ internals>"", line 5, in all; File ""/Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py"", line 2411, in all; return _wrapreduction(a, np.logical_and, 'all', axis, None, out, keepdims=keepdims); File ""/Users/jake/.anaconda3/anaconda3/envs/qutip-dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py"", line 87, in _wrapreduction; return ufunc.reduce(obj, axis, dtype, out, **passkwargs); TypeError: must be real number, not Qobj; ```. I think we may be able to get around this with a suitable definition of `Qobj.__array_function__`, though I am a little worried that we'll keep turning up these knock-on effects of `Qobj.__array__`. One major problem is that I'm not sure how we'll define `__array_function__` to satisfy this case, without having to manually disable every single numpy function. We can't have `np.asarray()` not work on `Qobj` because that would break parity with `np.array(qobj)`, however we also can't implicitly convert ourselves to an array if we're in a nested sequence, because then `np.all([qobj])` will pretty much always be false; it will have implicitly become an element-wise operation, even though the user _probably_ meant to check if every object in the array was not the zero operator. This isn't just `np.all`, it's also `np.shape`, `np.any`, and several more that make up the non-ufunc interface of numpy.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-778512258
https://github.com/qutip/qutip/issues/1433#issuecomment-778863114:10,Deployability,patch,patch,10,We have a patch already written in #1440 - just needs a review before we merge and hopefully push out a new version to conda.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1433#issuecomment-778863114
https://github.com/qutip/qutip/pull/1434#issuecomment-772656180:90,Testability,test,tests,90,"Actually I'm going to close this for now pending further discussion on #1433. The failing tests are using the implicit array coercion, which we may or may not want, but regardless, there's a bigger decision to be made.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1434#issuecomment-772656180
https://github.com/qutip/qutip/pull/1434#issuecomment-772665656:1185,Availability,fault,fault,1185,"He did - he's the original feature requester, but given super super weird interactions with ufuncs (see #1433), it's not so clear to me that it was _necessarily_ the right idea to implement especially now it's causing problems with how numpy arrays are used in the library. There always was a work-around; allowing `np.array(qobj)` was more to save him from writing `x = x.full() if isinstance(x, Qobj) else np.asarray(x)`. That said, I came round to the idea more as I read more about the control we can have over the rest of the numpy infrastructure. We can allow `np.array` on `Qobj` (satisfying Michael's original request), and with a little bit of extra code we can prevent all the super weird ufunc/implicit casting behaviour, because `Qobj` shouldn't be able to implicitly interoperate with raw arrays. I know in my personal code I'd rather use `Qobj.full()`, but I no longer think it's _wrong_ to allow `np.array(qobj)` given that other people like it, even with these numpy 1.20 problems. It does make it difficult to put `Qobj` in arrays, but numpy 1.20 has ruled out being able to have `np.array(qobj)` and `np.array([qobj1, qobj2], dtype=object)`, so that's not really our fault.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1434#issuecomment-772665656
https://github.com/qutip/qutip/pull/1434#issuecomment-772665656:124,Usability,clear,clear,124,"He did - he's the original feature requester, but given super super weird interactions with ufuncs (see #1433), it's not so clear to me that it was _necessarily_ the right idea to implement especially now it's causing problems with how numpy arrays are used in the library. There always was a work-around; allowing `np.array(qobj)` was more to save him from writing `x = x.full() if isinstance(x, Qobj) else np.asarray(x)`. That said, I came round to the idea more as I read more about the control we can have over the rest of the numpy infrastructure. We can allow `np.array` on `Qobj` (satisfying Michael's original request), and with a little bit of extra code we can prevent all the super weird ufunc/implicit casting behaviour, because `Qobj` shouldn't be able to implicitly interoperate with raw arrays. I know in my personal code I'd rather use `Qobj.full()`, but I no longer think it's _wrong_ to allow `np.array(qobj)` given that other people like it, even with these numpy 1.20 problems. It does make it difficult to put `Qobj` in arrays, but numpy 1.20 has ruled out being able to have `np.array(qobj)` and `np.array([qobj1, qobj2], dtype=object)`, so that's not really our fault.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1434#issuecomment-772665656
https://github.com/qutip/qutip/issues/1435#issuecomment-773936300:396,Energy Efficiency,efficient,efficient,396,"The `c_ops` argument to `mesolve` expects operators in Lindblad form, but you can also construct your own Liouvillian and pass that as the first argument. To construct the non-Lindblad components you want, you may find `spre` and `spost` useful, which respectively turn an operator into a superoperator which multiplies from the left and from the right. There is also `sprepost`, which is a more efficient way to combine `spre` and `spost`. To construct the operators (if you only work on qubits - if not, you need to do it manually as @quantshah showed), you can use `expand_operator`. So you can do something like; ```python; L = qutip.liouvillian(H); n_qubits = 5; for n in range(n_qubits - 1):; c_op_left = qutip.expand_operator(qutip.sigmap(), n_qubits, n); c_op_right = qutip.expand_operator(qutip.sigmam(), n_qubits, n + 1); L += qutip.sprepost(c_op_left, c_op_right); both = -0.5 * c_op_right * c_op_left; L += qutip.spre(both); L += qutip.spost(both); res = qutip.mesolve(L, rho0, times, e_ops=...); ```. I've not seen equations in that form myself, but that's how you could go about if that's what you've got.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1435#issuecomment-773936300
https://github.com/qutip/qutip/issues/1435#issuecomment-774022545:398,Energy Efficiency,efficient,efficient,398,"> The `c_ops` argument to `mesolve` expects operators in Lindblad form, but you can also construct your own Liouvillian and pass that as the first argument. To construct the non-Lindblad components you want, you may find `spre` and `spost` useful, which respectively turn an operator into a superoperator which multiplies from the left and from the right. There is also `sprepost`, which is a more efficient way to combine `spre` and `spost`. To construct the operators (if you only work on qubits - if not, you need to do it manually as @quantshah showed), you can use `expand_operator`. So you can do something like; > ; > ```python; > L = qutip.liouvillian(H); > n_qubits = 5; > for n in range(n_qubits - 1):; > c_op_left = qutip.expand_operator(qutip.sigmap(), n_qubits, n); > c_op_right = qutip.expand_operator(qutip.sigmam(), n_qubits, n + 1); > L += qutip.sprepost(c_op_left, c_op_right); > both = -0.5 * c_op_right * c_op_left; > L += qutip.spre(both); > L += qutip.spost(both); > res = qutip.mesolve(L, rho0, times, e_ops=...); > ```; > ; > I've not seen equations in that form myself, but that's how you could go about if that's what you've got. Thank you very very much for your help. As you know, the Liuvillian contains a term like [H,rho]. So if i put my operators in Hamiltonian, as you say, Does not contribute to the commutator?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1435#issuecomment-774022545
https://github.com/qutip/qutip/issues/1435#issuecomment-774026381:160,Usability,simpl,simply,160,"`qutip.liouvillian` takes a Hamiltonian `H` and transforms it into the Liouvillian superoperator, which if no Lindbladian `c_ops` are supplied `liouvillian` is simply the `[H, .]` term you want. This is what `mesolve` does internally, if its first argument is an operator. The subsequent additions I made to the Liouvillian afterwards in that loop add on your non-Lindbladian collapse operators - `mesolve` will recognise that you have passed a superoperator and the only further processing it will to is to add any further Lindblad-form collapse operators found in the `c_ops` list.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1435#issuecomment-774026381
https://github.com/qutip/qutip/issues/1435#issuecomment-774028841:170,Safety,safe,safe,170,"So beside that if i have also normal collapse operators, i just need to define and put them at the fourth argument of mesolve. I thank you very much dear Jakelishman. Be safe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1435#issuecomment-774028841
https://github.com/qutip/qutip/pull/1436#issuecomment-774315439:51,Testability,test,tests,51,"oh man, I don't know what I did locally to have my tests work but everything fail on Travis...",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1436#issuecomment-774315439
https://github.com/qutip/qutip/pull/1436#issuecomment-774359132:332,Availability,error,error,332,"Ok, the problem was a dumb change I made in the name of ""neatness"", and didn't test locally. For some reason I decided to change my original `cdef int _safe_multiply(int a, int b) except -1` into `except 0`, completely eschewing 50 proud years of C tradition _and_ forgetting that 0 is a normal, valid return value and can't be the error condition.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1436#issuecomment-774359132
https://github.com/qutip/qutip/pull/1436#issuecomment-774359132:79,Testability,test,test,79,"Ok, the problem was a dumb change I made in the name of ""neatness"", and didn't test locally. For some reason I decided to change my original `cdef int _safe_multiply(int a, int b) except -1` into `except 0`, completely eschewing 50 proud years of C tradition _and_ forgetting that 0 is a normal, valid return value and can't be the error condition.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1436#issuecomment-774359132
https://github.com/qutip/qutip/issues/1437#issuecomment-775216732:495,Safety,safe,safe,495,"This is expected. I don't see any reason to compute the state at a time if you don't want the state or and expectation value... If you only want the last state use tlist=[0, t_last]. Also `tlist` does not have to be a linear space, if you want to save only the few last values you can do: `tlist=[0,990,1000]`, etc. If you need to use an array coefficient and this is your restriction on `tlist`, use `qutip.Cubic_spline` (or build the `QobjEvo` before the solver, but I don't remember if it is safe in v4).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775216732
https://github.com/qutip/qutip/issues/1437#issuecomment-775216824:154,Deployability,integrat,integrator,154,"We probably shouldn't mutate the given `Options` object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. That said, if we're going to do something different to what the user requested we should at least emit a warning. There's also interplay with `store_final_state` here too; it's questionable technique to do `e_ops=None, store_final_state=True` with a `tlist` with more than two elements, but probably people who aren't familiar with `nsteps` will do something like that, and it seems a bit picky to prevent/warn on that when the intention seems clear. I think that the current behaviour doesn't take this case into account when falling back - it'll store all states, which in the 4.x branch is a fairly major time sink (but much much faster in 5.0). What behaviour would you expect for your use case? I'd probably do something like:; 1. if we change the `Options`, we have to clone it first to prevent leaking our mutations; 2. if we're not going to save anything, we should warn the user but then do it anyway - maybe their time-dependence functions leak state, and they're just doing something weird with that; 3. `store_final_state` should count as ""storing something"", so no need to set `store_states` if `store_final_states=True` and there are no `e_ops`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775216824
https://github.com/qutip/qutip/issues/1437#issuecomment-775216824:154,Integrability,integrat,integrator,154,"We probably shouldn't mutate the given `Options` object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. That said, if we're going to do something different to what the user requested we should at least emit a warning. There's also interplay with `store_final_state` here too; it's questionable technique to do `e_ops=None, store_final_state=True` with a `tlist` with more than two elements, but probably people who aren't familiar with `nsteps` will do something like that, and it seems a bit picky to prevent/warn on that when the intention seems clear. I think that the current behaviour doesn't take this case into account when falling back - it'll store all states, which in the 4.x branch is a fairly major time sink (but much much faster in 5.0). What behaviour would you expect for your use case? I'd probably do something like:; 1. if we change the `Options`, we have to clone it first to prevent leaking our mutations; 2. if we're not going to save anything, we should warn the user but then do it anyway - maybe their time-dependence functions leak state, and they're just doing something weird with that; 3. `store_final_state` should count as ""storing something"", so no need to set `store_states` if `store_final_states=True` and there are no `e_ops`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775216824
https://github.com/qutip/qutip/issues/1437#issuecomment-775216824:1172,Integrability,depend,dependence,1172,"We probably shouldn't mutate the given `Options` object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. That said, if we're going to do something different to what the user requested we should at least emit a warning. There's also interplay with `store_final_state` here too; it's questionable technique to do `e_ops=None, store_final_state=True` with a `tlist` with more than two elements, but probably people who aren't familiar with `nsteps` will do something like that, and it seems a bit picky to prevent/warn on that when the intention seems clear. I think that the current behaviour doesn't take this case into account when falling back - it'll store all states, which in the 4.x branch is a fairly major time sink (but much much faster in 5.0). What behaviour would you expect for your use case? I'd probably do something like:; 1. if we change the `Options`, we have to clone it first to prevent leaking our mutations; 2. if we're not going to save anything, we should warn the user but then do it anyway - maybe their time-dependence functions leak state, and they're just doing something weird with that; 3. `store_final_state` should count as ""storing something"", so no need to set `store_states` if `store_final_states=True` and there are no `e_ops`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775216824
https://github.com/qutip/qutip/issues/1437#issuecomment-775216824:687,Usability,clear,clear,687,"We probably shouldn't mutate the given `Options` object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. That said, if we're going to do something different to what the user requested we should at least emit a warning. There's also interplay with `store_final_state` here too; it's questionable technique to do `e_ops=None, store_final_state=True` with a `tlist` with more than two elements, but probably people who aren't familiar with `nsteps` will do something like that, and it seems a bit picky to prevent/warn on that when the intention seems clear. I think that the current behaviour doesn't take this case into account when falling back - it'll store all states, which in the 4.x branch is a fairly major time sink (but much much faster in 5.0). What behaviour would you expect for your use case? I'd probably do something like:; 1. if we change the `Options`, we have to clone it first to prevent leaking our mutations; 2. if we're not going to save anything, we should warn the user but then do it anyway - maybe their time-dependence functions leak state, and they're just doing something weird with that; 3. `store_final_state` should count as ""storing something"", so no need to set `store_states` if `store_final_states=True` and there are no `e_ops`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775216824
https://github.com/qutip/qutip/issues/1437#issuecomment-775319207:895,Deployability,integrat,integrator,895,"Thanks!. @Ericgig ; > If you need to use an array coefficient and this is your restriction on tlist, use qutip.Cubic_spline (or build the QobjEvo before the solver, but I don't remember if it is safe in v4). This is exactly my case. I see, I can just give mesolve a Cubic_spline object, very nice. I didn't know that give `tlist` to mesolve is same as asking these intermediate results. I was using it just as a match for array coefficient. Actually, I've been using array coefficient for a while and I don't even know such functionality exists. And I remember someone else mentioned this to me before, so I shouldn't be the only one. I see in the doc there is a section mentioning it. Probably we could stress it a bit more. @jakelishman ; > We probably shouldn't mutate the given Options object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. Sorry, my post was a bit unclear. I only need the final result. So I set `store_final_state=True`, but that doesn't change the behaviour of `store_state` at all. Indeed, I'm doing so just because I didn't know the solution Eric pointed out before. For me a warning before changing `Options` would be nice. And probably pointing out the solution Eric mentioned?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775319207
https://github.com/qutip/qutip/issues/1437#issuecomment-775319207:895,Integrability,integrat,integrator,895,"Thanks!. @Ericgig ; > If you need to use an array coefficient and this is your restriction on tlist, use qutip.Cubic_spline (or build the QobjEvo before the solver, but I don't remember if it is safe in v4). This is exactly my case. I see, I can just give mesolve a Cubic_spline object, very nice. I didn't know that give `tlist` to mesolve is same as asking these intermediate results. I was using it just as a match for array coefficient. Actually, I've been using array coefficient for a while and I don't even know such functionality exists. And I remember someone else mentioned this to me before, so I shouldn't be the only one. I see in the doc there is a section mentioning it. Probably we could stress it a bit more. @jakelishman ; > We probably shouldn't mutate the given Options object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. Sorry, my post was a bit unclear. I only need the final result. So I set `store_final_state=True`, but that doesn't change the behaviour of `store_state` at all. Indeed, I'm doing so just because I didn't know the solution Eric pointed out before. For me a warning before changing `Options` would be nice. And probably pointing out the solution Eric mentioned?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775319207
https://github.com/qutip/qutip/issues/1437#issuecomment-775319207:195,Safety,safe,safe,195,"Thanks!. @Ericgig ; > If you need to use an array coefficient and this is your restriction on tlist, use qutip.Cubic_spline (or build the QobjEvo before the solver, but I don't remember if it is safe in v4). This is exactly my case. I see, I can just give mesolve a Cubic_spline object, very nice. I didn't know that give `tlist` to mesolve is same as asking these intermediate results. I was using it just as a match for array coefficient. Actually, I've been using array coefficient for a while and I don't even know such functionality exists. And I remember someone else mentioned this to me before, so I shouldn't be the only one. I see in the doc there is a section mentioning it. Probably we could stress it a bit more. @jakelishman ; > We probably shouldn't mutate the given Options object, but the call as written here doesn't make a huge amount of sense - why would you want to run the integrator but not have any output stored at all? You'd just be spinning your processor. Sorry, my post was a bit unclear. I only need the final result. So I set `store_final_state=True`, but that doesn't change the behaviour of `store_state` at all. Indeed, I'm doing so just because I didn't know the solution Eric pointed out before. For me a warning before changing `Options` would be nice. And probably pointing out the solution Eric mentioned?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775319207
https://github.com/qutip/qutip/issues/1437#issuecomment-775332513:415,Integrability,depend,dependence,415,"Ok, cool. I don't think there's any situation we should be mutating the `Options` class we're passed in though - I'd consider that a bug no matter what, since that leaks like your print statement shows. We can just duplicate it on entry, then modify that. To me it's not clear that passing several items in `tlist` should override an explicit `store_states=False` - as long as we allow you to pass an array as time-dependence, there is a sensible reason to pass more items in `tlist` than you need results for. Sure, you may also be able to use `Cubic_Spline`, but if we punish you for using arrays by swapping your options, why do we provide them? I think we should only warn and change the settings if _nothing_ is going to be stored - `store_final_state` should be enough to suppress it and not store the intermediate states, even if that implies the user might not be doing the fastest possible thing. I don't necessarily think we should try to promote ideal usage through runtime warnings if that's more verbose to type - that's what documentation is for, and some people will do stuff because it's faster to type, since they work interactively.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775332513
https://github.com/qutip/qutip/issues/1437#issuecomment-775332513:271,Usability,clear,clear,271,"Ok, cool. I don't think there's any situation we should be mutating the `Options` class we're passed in though - I'd consider that a bug no matter what, since that leaks like your print statement shows. We can just duplicate it on entry, then modify that. To me it's not clear that passing several items in `tlist` should override an explicit `store_states=False` - as long as we allow you to pass an array as time-dependence, there is a sensible reason to pass more items in `tlist` than you need results for. Sure, you may also be able to use `Cubic_Spline`, but if we punish you for using arrays by swapping your options, why do we provide them? I think we should only warn and change the settings if _nothing_ is going to be stored - `store_final_state` should be enough to suppress it and not store the intermediate states, even if that implies the user might not be doing the fastest possible thing. I don't necessarily think we should try to promote ideal usage through runtime warnings if that's more verbose to type - that's what documentation is for, and some people will do stuff because it's faster to type, since they work interactively.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775332513
https://github.com/qutip/qutip/issues/1437#issuecomment-775976194:506,Integrability,depend,dependence,506,"When no options and no e_ops are given, the solver should store the states, otherwise nothing is done. Since the default value si `store_states=False`, the solver don't know that the value was explicitly given or the default. We should have `store_states=None` as the default. This allow us to respect an explicit False while keeping the expected behaviour when no options are given. I will make this change in the v5 solver (And make sure no Options are modified). `tlist` was never meant to control time dependence, it represent the time at which the solver look at the state (+ first and last times). I added array support as coefficient as a shortcut to Cubic_Spline and I used the already existing tlist, but this is clearly a limitation and in v5 they will be controlled independently.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775976194
https://github.com/qutip/qutip/issues/1437#issuecomment-775976194:722,Usability,clear,clearly,722,"When no options and no e_ops are given, the solver should store the states, otherwise nothing is done. Since the default value si `store_states=False`, the solver don't know that the value was explicitly given or the default. We should have `store_states=None` as the default. This allow us to respect an explicit False while keeping the expected behaviour when no options are given. I will make this change in the v5 solver (And make sure no Options are modified). `tlist` was never meant to control time dependence, it represent the time at which the solver look at the state (+ first and last times). I added array support as coefficient as a shortcut to Cubic_Spline and I used the already existing tlist, but this is clearly a limitation and in v5 they will be controlled independently.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1437#issuecomment-775976194
https://github.com/qutip/qutip/issues/1439#issuecomment-778615974:4,Testability,log,loganbvh,4,"Hi @loganbvh. Thanks for the interest!. The package you developed looks very nice. It does have some overlap with `qutip.qip`, but more following the perspective of experimentalists as you said. The start point of `qutip.qip` is a framework of simulating quantum circuit with more realistic noise. We are considering building an ecosystem around `qutip`, as described in a [roadmap discussion](https://github.com/qutip/qutip-doc/pull/125/files). If you are interested, we could propagate it as a ""QuTiP affilliated packages"" (packages that developed upon qutip but not maintained by the QuTiP team). We are also very interested in building APIs for importation and exportation pulses defined in other libraries. A possible GSoC project is listed [here](https://github.com/qutip/qutip/wiki//Google-Summer-of-Code-2021#4-pulse-level-description-of-quantum-circuits). Best; Boxi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1439#issuecomment-778615974
https://github.com/qutip/qutip/issues/1439#issuecomment-778671906:146,Usability,clear,clear,146,"Hi Boxi, thanks for the response. > If you are interested, we could propagate it as a ""QuTiP affilliated packages"". That would be great! It's not clear from the roadmap document exactly what ""QuTiP affiliated"" means in practice. I guess there will just be a list in the qutip docs/website with links to such packages?. The GSoC project looks interesting. I may apply if it looks like I will have time this summer.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1439#issuecomment-778671906
https://github.com/qutip/qutip/issues/1439#issuecomment-779766759:243,Modifiability,enhance,enhancement,243,"Yes, how that will look like is still under discussion and a list in the qutip docs/website is indeed a good candidate. It will probably come along with QuTiP 5.0 later this year. I'm closing the issue as issues are meant for ongoing bugs and enhancement in code. Free feel to discuss further in our [Google group](https://groups.google.com/g/qutip) or per emails!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1439#issuecomment-779766759
https://github.com/qutip/qutip/issues/1442#issuecomment-780017025:291,Deployability,release,released,291,"Thanks for this. We've already merged a fix to master (#1440), and we'll be releasing a new version of QuTiP in the coming days that will officially support Numpy 1.20. In the meantime, you can work around by pinning your Numpy version 1.19 (there are some other problems within all current released QuTiP versions when dealing with Numpy 1.20 as well).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1442#issuecomment-780017025
https://github.com/qutip/qutip/pull/1444#issuecomment-781749400:12,Testability,test,test,12,The failing test has nothing to do with this PR,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-781749400
https://github.com/qutip/qutip/pull/1444#issuecomment-810016097:161,Usability,clear,clear,161,@jakelishman Shall I rebase it after the review or better merge the master into this branch now to resolve the conflicts? The conflicts are minor and I'm pretty clear what caused them.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-810016097
https://github.com/qutip/qutip/pull/1444#issuecomment-810110009:54,Testability,test,tests,54,"I guess you need to fix the merge conflict before the tests can run. I won't have time to look through this today, so there's plenty of time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-810110009
https://github.com/qutip/qutip/pull/1444#issuecomment-815033004:567,Integrability,depend,dependence,567,"I'll have to trust you mostly on actual operation of the code, but it looks like you've covered everything I could see as particular problems. I don't use this part of QuTiP, so I'm really not the best placed person to talk about how natural the APIs seem or anything like that. I'm still a fan of fixing the issues CodeClimate is complaining about because I think the cognitive complexity tests are a semi-decent indicator of maintainability, but at the end of the day, you're the code owner and that's your call. The other seemingly major potential headache is the dependence on that internal `_EvoElement` API in `QobjEvo` - I know for sure that that's going to go to hell in 5.0 - but I get that this PR didn't really cause this, so that's maybe a problem for another time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-815033004
https://github.com/qutip/qutip/pull/1444#issuecomment-815033004:427,Modifiability,maintainab,maintainability,427,"I'll have to trust you mostly on actual operation of the code, but it looks like you've covered everything I could see as particular problems. I don't use this part of QuTiP, so I'm really not the best placed person to talk about how natural the APIs seem or anything like that. I'm still a fan of fixing the issues CodeClimate is complaining about because I think the cognitive complexity tests are a semi-decent indicator of maintainability, but at the end of the day, you're the code owner and that's your call. The other seemingly major potential headache is the dependence on that internal `_EvoElement` API in `QobjEvo` - I know for sure that that's going to go to hell in 5.0 - but I get that this PR didn't really cause this, so that's maybe a problem for another time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-815033004
https://github.com/qutip/qutip/pull/1444#issuecomment-815033004:390,Testability,test,tests,390,"I'll have to trust you mostly on actual operation of the code, but it looks like you've covered everything I could see as particular problems. I don't use this part of QuTiP, so I'm really not the best placed person to talk about how natural the APIs seem or anything like that. I'm still a fan of fixing the issues CodeClimate is complaining about because I think the cognitive complexity tests are a semi-decent indicator of maintainability, but at the end of the day, you're the code owner and that's your call. The other seemingly major potential headache is the dependence on that internal `_EvoElement` API in `QobjEvo` - I know for sure that that's going to go to hell in 5.0 - but I get that this PR didn't really cause this, so that's maybe a problem for another time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-815033004
https://github.com/qutip/qutip/pull/1444#issuecomment-815048230:255,Modifiability,refactor,refactor,255,"Thanks, @jakelishman. Even you say that you didn't look into very details, your comments were very inspiring and helpful!. What code climate is complaining about is mostly left from the previous code structure. I do plan on further cleaning them. Another refactor probably. Actually, the `_EvoElement` here is a simplified ""copy"" of the `EvoElement` in `QobjEvo`, not directly referring to that. Switch to `dev.major` won't break it. I did this long ago because I was having problems initialize `QobjEvo` in my particular use case. But indeed exposing a private class is fragile and dangerous. Planning on remove it too.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-815048230
https://github.com/qutip/qutip/pull/1444#issuecomment-815048230:312,Usability,simpl,simplified,312,"Thanks, @jakelishman. Even you say that you didn't look into very details, your comments were very inspiring and helpful!. What code climate is complaining about is mostly left from the previous code structure. I do plan on further cleaning them. Another refactor probably. Actually, the `_EvoElement` here is a simplified ""copy"" of the `EvoElement` in `QobjEvo`, not directly referring to that. Switch to `dev.major` won't break it. I did this long ago because I was having problems initialize `QobjEvo` in my particular use case. But indeed exposing a private class is fragile and dangerous. Planning on remove it too.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1444#issuecomment-815048230
https://github.com/qutip/qutip/pull/1446#issuecomment-805773343:19,Testability,test,test,19,"There is a failing test for mesolve coeff, which I don't think is relevant to this PR.; And another test failing in `test_zheevr`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1446#issuecomment-805773343
https://github.com/qutip/qutip/pull/1446#issuecomment-805773343:100,Testability,test,test,100,"There is a failing test for mesolve coeff, which I don't think is relevant to this PR.; And another test failing in `test_zheevr`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1446#issuecomment-805773343
https://github.com/qutip/qutip/pull/1446#issuecomment-805888167:21,Availability,failure,failure,21,I never saw the test failure in `test_zheevr`. That's odd - I thought we'd merged a change that fixed that. I certainly haven't seen one for a very long time personally - it's all `test_diag_liou_mult`.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1446#issuecomment-805888167
https://github.com/qutip/qutip/pull/1446#issuecomment-805888167:16,Testability,test,test,16,I never saw the test failure in `test_zheevr`. That's odd - I thought we'd merged a change that fixed that. I certainly haven't seen one for a very long time personally - it's all `test_diag_liou_mult`.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1446#issuecomment-805888167
https://github.com/qutip/qutip/pull/1447#issuecomment-781976727:136,Energy Efficiency,efficient,efficient,136,"> Seems to me that the whole thing should first decide the kind of gate, then loop over only the necessary qubits - that'd be both more efficient and easier to read. I feel the same. Indeed it is just something I encountered when writing the doc. I guess this structure to make use of similarity among those gates. Many have one control and one target. Those gates work well. SWAP just happens to not be one of this... Also, ISWAP doesn't work very well if it acts on qubits not next to each other. The gates need to be classified better. Maybe completely rewrite it at some point.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-781976727
https://github.com/qutip/qutip/pull/1447#issuecomment-781976727:556,Modifiability,rewrite,rewrite,556,"> Seems to me that the whole thing should first decide the kind of gate, then loop over only the necessary qubits - that'd be both more efficient and easier to read. I feel the same. Indeed it is just something I encountered when writing the doc. I guess this structure to make use of similarity among those gates. Many have one control and one target. Those gates work well. SWAP just happens to not be one of this... Also, ISWAP doesn't work very well if it acts on qubits not next to each other. The gates need to be classified better. Maybe completely rewrite it at some point.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-781976727
https://github.com/qutip/qutip/pull/1447#issuecomment-782249555:3256,Availability,down,down,3256," 50-branch `if/elif` (in the bad cases) based on the name. `QubitCircuit` shouldn't need the million `_gate_resolved` functions - if there's a `Gate` class, instances of that (whether done by subclass or composition) should be supplying it (though the lookup table is a good choice under the circumstances). Given how `circuit.py` currently organises its data, it feels like you have to introduce some seemingly arbitrary splits to keep CodeClimate happy, but I'd argue the problem is the data structure, and CodeClimate is right to complain about the complexity. In stuff like compilers, there's a reason code compilers do parsing->verification->optimisation, with several passes in the last one, and transform things internally into a very strict intermediate representation at every step. `Qobj._repr_latex_` was like this - the `master` version is claimed to be like ""78"" complexity, but I'd be prepared to bet CodeClimate would have the `dev.major` version less than 10 and I think the output is near byte-for-byte identical. The change is that the `master` version basically reimplements the same algorithm 4 times with complex, split up for loops (not to mention that for some reason the alignment and new-line characters are considered part of formatting a number?). The `dev.major` version first decides if it's going to truncate the rows and/or columns, then it just calls a formatter on each row it decided it wants rendering with a special value to say when it should output a truncation character, and then joins the rows together. Obviously it's not _always_ the data structure - e.g. in `propagator` the branching to choose an evaluation method is fine, but once it's chosen, it should delegate to specialised methods. That way, the maintainer can verify the branching paths with a nice top-down overview without 50 lines of specialised logic inbetween each one, then you can verify each specialised path independently. If you did that, I'm sure the ""complexity"" would drop to like 10.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782249555
https://github.com/qutip/qutip/pull/1447#issuecomment-782249555:3302,Testability,log,logic,3302," 50-branch `if/elif` (in the bad cases) based on the name. `QubitCircuit` shouldn't need the million `_gate_resolved` functions - if there's a `Gate` class, instances of that (whether done by subclass or composition) should be supplying it (though the lookup table is a good choice under the circumstances). Given how `circuit.py` currently organises its data, it feels like you have to introduce some seemingly arbitrary splits to keep CodeClimate happy, but I'd argue the problem is the data structure, and CodeClimate is right to complain about the complexity. In stuff like compilers, there's a reason code compilers do parsing->verification->optimisation, with several passes in the last one, and transform things internally into a very strict intermediate representation at every step. `Qobj._repr_latex_` was like this - the `master` version is claimed to be like ""78"" complexity, but I'd be prepared to bet CodeClimate would have the `dev.major` version less than 10 and I think the output is near byte-for-byte identical. The change is that the `master` version basically reimplements the same algorithm 4 times with complex, split up for loops (not to mention that for some reason the alignment and new-line characters are considered part of formatting a number?). The `dev.major` version first decides if it's going to truncate the rows and/or columns, then it just calls a formatter on each row it decided it wants rendering with a special value to say when it should output a truncation character, and then joins the rows together. Obviously it's not _always_ the data structure - e.g. in `propagator` the branching to choose an evaluation method is fine, but once it's chosen, it should delegate to specialised methods. That way, the maintainer can verify the branching paths with a nice top-down overview without 50 lines of specialised logic inbetween each one, then you can verify each specialised path independently. If you did that, I'm sure the ""complexity"" would drop to like 10.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782249555
https://github.com/qutip/qutip/pull/1447#issuecomment-782267965:35,Modifiability,config,configured,35,"actually, just realised my fork is configured to do CodeClimate on `dev.major`. For say `qobj.py`, the `master` version has [maintainability F](https://codeclimate.com/github/qutip/qutip/qutip/qobj.py), while `dev.major` has [maintainability A](https://codeclimate.com/github/jakelishman/qutip/qutip/core/qobj.py) with the only issues being TODOs and like 5 pep8s.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782267965
https://github.com/qutip/qutip/pull/1447#issuecomment-782267965:125,Modifiability,maintainab,maintainability,125,"actually, just realised my fork is configured to do CodeClimate on `dev.major`. For say `qobj.py`, the `master` version has [maintainability F](https://codeclimate.com/github/qutip/qutip/qutip/qobj.py), while `dev.major` has [maintainability A](https://codeclimate.com/github/jakelishman/qutip/qutip/core/qobj.py) with the only issues being TODOs and like 5 pep8s.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782267965
https://github.com/qutip/qutip/pull/1447#issuecomment-782267965:226,Modifiability,maintainab,maintainability,226,"actually, just realised my fork is configured to do CodeClimate on `dev.major`. For say `qobj.py`, the `master` version has [maintainability F](https://codeclimate.com/github/qutip/qutip/qutip/qobj.py), while `dev.major` has [maintainability A](https://codeclimate.com/github/jakelishman/qutip/qutip/core/qobj.py) with the only issues being TODOs and like 5 pep8s.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782267965
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:350,Modifiability,refactor,refactoring,350,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:592,Modifiability,refactor,refactoring,592,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:831,Modifiability,maintainab,maintainability,831,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:872,Modifiability,maintainab,maintainability,872,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:990,Modifiability,maintainab,maintainability,990,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1447#issuecomment-782599642:92,Testability,log,logistic,92,"Oh, I completely agree with the argument nested loops/if/else. I was more talking about the logistic depth requirement (edit: wrong again, it is called Cognitive Complexity) of code climate. I just realized that is not the climate issue here. But, anyway, indeed `circuit.py` is quite messy. And the Gate class is more or less just a place holder. A refactoring to define each gate as a subclass should make things much easier. Also for this latex method. I like it very much what is going on in `dev.major`!. Tbh the millions of `_gate_resolved` functions are actually already after a short refactoring last year by a brave volunteer. It used to be 400-line functions. That was horrible. Just like the `adjacent_gates` method in `spinchain.py` (another F). I haven't dared to touch it... > For say qobj.py, the master version has maintainability F, while `dev.major` has maintainability A with the only issues being TODOs and like 5 pep8s. That's amazing! When I joined QuTiP, the overall maintainability was D, as I remember. Now it is B. I'm keen to see it becomes A after `dev.major` got merged :)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1447#issuecomment-782599642
https://github.com/qutip/qutip/pull/1448#issuecomment-782084299:16,Testability,test,tests,16,Just fixing the tests - the lattice module got deleted in a separate feature on `master` before the Numpy 1.20 changes. My mistake for not running them before making the PR.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782084299
https://github.com/qutip/qutip/pull/1448#issuecomment-782105359:9,Availability,failure,failure,9,"The test failure on Python 3.6 appears to be due to some exceptionally weird behaviour by `conda` in the Travis setup - if you look closely, you can see that when it runs `conda uninstall cython`, it _downgrades_ `numpy` to 1.14.2. This would not be a problem in a `conda-forge` release build, because the `numpy` API dependency is pinned in the feedstock, but it is a potential problem on `pip` source builds. It's possible this super odd behaviour of `conda` is the cause of people's complaints on the email lists about failed imports. I will push a change to the requirements here to try and enforce `numpy >= 1.16.6`, which ought to solve the dependency issues. I will make a similar change on `master` and in #1429 (which I will likely back-port to master before 4.6).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782105359
https://github.com/qutip/qutip/pull/1448#issuecomment-782105359:279,Deployability,release,release,279,"The test failure on Python 3.6 appears to be due to some exceptionally weird behaviour by `conda` in the Travis setup - if you look closely, you can see that when it runs `conda uninstall cython`, it _downgrades_ `numpy` to 1.14.2. This would not be a problem in a `conda-forge` release build, because the `numpy` API dependency is pinned in the feedstock, but it is a potential problem on `pip` source builds. It's possible this super odd behaviour of `conda` is the cause of people's complaints on the email lists about failed imports. I will push a change to the requirements here to try and enforce `numpy >= 1.16.6`, which ought to solve the dependency issues. I will make a similar change on `master` and in #1429 (which I will likely back-port to master before 4.6).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782105359
https://github.com/qutip/qutip/pull/1448#issuecomment-782105359:318,Integrability,depend,dependency,318,"The test failure on Python 3.6 appears to be due to some exceptionally weird behaviour by `conda` in the Travis setup - if you look closely, you can see that when it runs `conda uninstall cython`, it _downgrades_ `numpy` to 1.14.2. This would not be a problem in a `conda-forge` release build, because the `numpy` API dependency is pinned in the feedstock, but it is a potential problem on `pip` source builds. It's possible this super odd behaviour of `conda` is the cause of people's complaints on the email lists about failed imports. I will push a change to the requirements here to try and enforce `numpy >= 1.16.6`, which ought to solve the dependency issues. I will make a similar change on `master` and in #1429 (which I will likely back-port to master before 4.6).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782105359
https://github.com/qutip/qutip/pull/1448#issuecomment-782105359:647,Integrability,depend,dependency,647,"The test failure on Python 3.6 appears to be due to some exceptionally weird behaviour by `conda` in the Travis setup - if you look closely, you can see that when it runs `conda uninstall cython`, it _downgrades_ `numpy` to 1.14.2. This would not be a problem in a `conda-forge` release build, because the `numpy` API dependency is pinned in the feedstock, but it is a potential problem on `pip` source builds. It's possible this super odd behaviour of `conda` is the cause of people's complaints on the email lists about failed imports. I will push a change to the requirements here to try and enforce `numpy >= 1.16.6`, which ought to solve the dependency issues. I will make a similar change on `master` and in #1429 (which I will likely back-port to master before 4.6).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782105359
https://github.com/qutip/qutip/pull/1448#issuecomment-782105359:4,Testability,test,test,4,"The test failure on Python 3.6 appears to be due to some exceptionally weird behaviour by `conda` in the Travis setup - if you look closely, you can see that when it runs `conda uninstall cython`, it _downgrades_ `numpy` to 1.14.2. This would not be a problem in a `conda-forge` release build, because the `numpy` API dependency is pinned in the feedstock, but it is a potential problem on `pip` source builds. It's possible this super odd behaviour of `conda` is the cause of people's complaints on the email lists about failed imports. I will push a change to the requirements here to try and enforce `numpy >= 1.16.6`, which ought to solve the dependency issues. I will make a similar change on `master` and in #1429 (which I will likely back-port to master before 4.6).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782105359
https://github.com/qutip/qutip/pull/1448#issuecomment-782174452:59,Availability,down,downgrades,59,"> you can see that when it runs conda uninstall cython, it downgrades numpy to 1.14.2. This is really strange. > This would not be a problem in a conda-forge release build, because the numpy API dependency is pinned in the feedstock, but it is a potential problem on pip source builds. I was setting up a GitHub Action test for `qutip_qip` https://github.com/qutip/qutip-qip/pull/6. `pip installation` works well there, but it could be that I don't use any run-time compiling.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782174452
https://github.com/qutip/qutip/pull/1448#issuecomment-782174452:158,Deployability,release,release,158,"> you can see that when it runs conda uninstall cython, it downgrades numpy to 1.14.2. This is really strange. > This would not be a problem in a conda-forge release build, because the numpy API dependency is pinned in the feedstock, but it is a potential problem on pip source builds. I was setting up a GitHub Action test for `qutip_qip` https://github.com/qutip/qutip-qip/pull/6. `pip installation` works well there, but it could be that I don't use any run-time compiling.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782174452
https://github.com/qutip/qutip/pull/1448#issuecomment-782174452:388,Deployability,install,installation,388,"> you can see that when it runs conda uninstall cython, it downgrades numpy to 1.14.2. This is really strange. > This would not be a problem in a conda-forge release build, because the numpy API dependency is pinned in the feedstock, but it is a potential problem on pip source builds. I was setting up a GitHub Action test for `qutip_qip` https://github.com/qutip/qutip-qip/pull/6. `pip installation` works well there, but it could be that I don't use any run-time compiling.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782174452
https://github.com/qutip/qutip/pull/1448#issuecomment-782174452:195,Integrability,depend,dependency,195,"> you can see that when it runs conda uninstall cython, it downgrades numpy to 1.14.2. This is really strange. > This would not be a problem in a conda-forge release build, because the numpy API dependency is pinned in the feedstock, but it is a potential problem on pip source builds. I was setting up a GitHub Action test for `qutip_qip` https://github.com/qutip/qutip-qip/pull/6. `pip installation` works well there, but it could be that I don't use any run-time compiling.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782174452
https://github.com/qutip/qutip/pull/1448#issuecomment-782174452:319,Testability,test,test,319,"> you can see that when it runs conda uninstall cython, it downgrades numpy to 1.14.2. This is really strange. > This would not be a problem in a conda-forge release build, because the numpy API dependency is pinned in the feedstock, but it is a potential problem on pip source builds. I was setting up a GitHub Action test for `qutip_qip` https://github.com/qutip/qutip-qip/pull/6. `pip installation` works well there, but it could be that I don't use any run-time compiling.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782174452
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:45,Deployability,install,installation,45,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:263,Deployability,install,installed,263,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:428,Deployability,install,installing,428,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:768,Deployability,install,installed,768,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:461,Integrability,depend,dependencies,461,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:609,Integrability,depend,dependency,609,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:205,Testability,test,test,205,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1448#issuecomment-782177609:942,Usability,simpl,simpler,942,"Yeah, `qutip-qip` is a much easier build and installation process because you don't need to be concerned about compiler infrastructure, ABI compatibility or stuff like that. In addition in that particular test run, there were three individual calls to change the installed packages, which meant plenty of space for stuff to go wrong. In this case, I think it was a strange interaction between the old `.travis.yml` specifically installing `numpy` and all other dependencies from `conda-forge`, without the channel being in the defaults list. Since `conda uninstall` doesn't specify an additional channel, the dependency calculator considers `defaults` to be higher priority, so it sets various packages to arbitrary allowed ones from `defaults`, which with `openblas` installed like this meant numpy `1.14`. That's my guess at least - it's a pretty weird set up circumstances, but the new `.travis.yml` file that's already in `master` is far simpler about the build process.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1448#issuecomment-782177609
https://github.com/qutip/qutip/pull/1449#issuecomment-782561040:209,Deployability,patch,patch-,209,[![Coverage Status](https://coveralls.io/builds/37292804/badge)](https://coveralls.io/builds/37292804). Coverage remained the same at 63.189% when pulling **8645164cfed7b1f7055c49cca80cb6de25dcc796 on cgohlke:patch-1** into **469b18c879b8e46b765caf4d6637e4d61b99747d on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782561040
https://github.com/qutip/qutip/pull/1449#issuecomment-782608343:175,Deployability,install,install,175,"Can you fully show your build process, and did this work with a previous version of QuTiP? It builds fine for me from pip sdist on all major platforms with a simple; ```; pip install qutip; ```; and the sdist of 4.5.2 seems to be missing the same file. Officially we don't support building with OpenMP from pip sdist (only git), but to be fair, it should have worked. In the interests of better semantics, can you change the new line in `MANIFEST.in` to; ```; graft qutip/**/src; ```; Technically there's only the one file that doesn't get tagged in (I hope), but logically the principle is that anything in a `src` directory should be distributed in the `sdist`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782608343
https://github.com/qutip/qutip/pull/1449#issuecomment-782608343:564,Testability,log,logically,564,"Can you fully show your build process, and did this work with a previous version of QuTiP? It builds fine for me from pip sdist on all major platforms with a simple; ```; pip install qutip; ```; and the sdist of 4.5.2 seems to be missing the same file. Officially we don't support building with OpenMP from pip sdist (only git), but to be fair, it should have worked. In the interests of better semantics, can you change the new line in `MANIFEST.in` to; ```; graft qutip/**/src; ```; Technically there's only the one file that doesn't get tagged in (I hope), but logically the principle is that anything in a `src` directory should be distributed in the `sdist`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782608343
https://github.com/qutip/qutip/pull/1449#issuecomment-782608343:158,Usability,simpl,simple,158,"Can you fully show your build process, and did this work with a previous version of QuTiP? It builds fine for me from pip sdist on all major platforms with a simple; ```; pip install qutip; ```; and the sdist of 4.5.2 seems to be missing the same file. Officially we don't support building with OpenMP from pip sdist (only git), but to be fair, it should have worked. In the interests of better semantics, can you change the new line in `MANIFEST.in` to; ```; graft qutip/**/src; ```; Technically there's only the one file that doesn't get tagged in (I hope), but logically the principle is that anything in a `src` directory should be distributed in the `sdist`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782608343
https://github.com/qutip/qutip/pull/1449#issuecomment-782615652:122,Deployability,release,release,122,"Ah ok, that makes it easier to understand what happened - the `MANIFEST.in` file got added at some point before the 4.5.2 release, but its mere presence overrides the content of `setuptools`' `package_data` option, in which we _do_ add the requisite files. If it's not desperately urgent, are you able to build from the `git` branch at 4.5.3 instead temporarily? I can merge this PR, but we're hoping to put out 4.6.0 in about two weeks' time (which I'll make sure has this patch), and our release process is still very manual - I'd rather not have to repeat it another time if I can avoid it!. Sorry this file got lost when `MANIFEST.in` turned up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782615652
https://github.com/qutip/qutip/pull/1449#issuecomment-782615652:474,Deployability,patch,patch,474,"Ah ok, that makes it easier to understand what happened - the `MANIFEST.in` file got added at some point before the 4.5.2 release, but its mere presence overrides the content of `setuptools`' `package_data` option, in which we _do_ add the requisite files. If it's not desperately urgent, are you able to build from the `git` branch at 4.5.3 instead temporarily? I can merge this PR, but we're hoping to put out 4.6.0 in about two weeks' time (which I'll make sure has this patch), and our release process is still very manual - I'd rather not have to repeat it another time if I can avoid it!. Sorry this file got lost when `MANIFEST.in` turned up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782615652
https://github.com/qutip/qutip/pull/1449#issuecomment-782615652:490,Deployability,release,release,490,"Ah ok, that makes it easier to understand what happened - the `MANIFEST.in` file got added at some point before the 4.5.2 release, but its mere presence overrides the content of `setuptools`' `package_data` option, in which we _do_ add the requisite files. If it's not desperately urgent, are you able to build from the `git` branch at 4.5.3 instead temporarily? I can merge this PR, but we're hoping to put out 4.6.0 in about two weeks' time (which I'll make sure has this patch), and our release process is still very manual - I'd rather not have to repeat it another time if I can avoid it!. Sorry this file got lost when `MANIFEST.in` turned up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782615652
https://github.com/qutip/qutip/pull/1449#issuecomment-782615652:584,Safety,avoid,avoid,584,"Ah ok, that makes it easier to understand what happened - the `MANIFEST.in` file got added at some point before the 4.5.2 release, but its mere presence overrides the content of `setuptools`' `package_data` option, in which we _do_ add the requisite files. If it's not desperately urgent, are you able to build from the `git` branch at 4.5.3 instead temporarily? I can merge this PR, but we're hoping to put out 4.6.0 in about two weeks' time (which I'll make sure has this patch), and our release process is still very manual - I'd rather not have to repeat it another time if I can avoid it!. Sorry this file got lost when `MANIFEST.in` turned up.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1449#issuecomment-782615652
https://github.com/qutip/qutip/issues/1451#issuecomment-784228597:165,Deployability,release,release,165,"It's probably relevant that scipy 1.6.1 fixed some problems with sparse matrices (with COO format constructor), see https://docs.scipy.org/doc/scipy-1.6.1/reference/release.1.6.1.html including PR#13403 https://github.com/scipy/scipy/pull/13403",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784228597
https://github.com/qutip/qutip/issues/1451#issuecomment-784265398:586,Integrability,contract,contract,586,"Thanks for the bug report and the detailed look into it! As a temporary work-around, in file `qutip/cy/piqs.pyx`, change lines 431 to 433 https://github.com/qutip/qutip/blob/2aaae75d3ba52067f747dd928d67d66307fc5de9/qutip/cy/piqs.pyx#L431-L433 to; ```cython; cdef lindblad_matrix = csr_matrix((lindblad_data,; (lindblad_row, lindblad_col)),; shape=(nds**2, nds**2),; dtype=np.complex128); ```; and recompile. If you want to make a PR of something similar against QuTiP, I'll accept it. I would actually file this against `scipy.sparse` - I think our usage is completely in line with the contract of `scipy.sparse.csr_matrix` and they've got a bug in their dtype handling. You currently can't construct a CSR matrix using the COO triplet format for complex data, unless the dtype is made explicit _somewhere_, but the constructor is meant to correctly infer a suitable dtype if one is not passed. Basic Scipy reproducer to illustrate the problem:; ```python; >>> import scipy.sparse; >>> scipy.__version__; '1.6.1'; >>> scipy.sparse.csr_matrix(([1+1j], ([0], [0])), shape=(2, 2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/compressed.py"", line 54, in __init__; other = self.__class__(coo_matrix(arg1, shape=shape,; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/coo.py"", line 161, in __init__; self.data = np.array(obj, copy=copy, dtype=data_dtype); TypeError: can't convert complex to float; ```. This can be fixed either by passing `dtype=np.complex128` to the constructor, or passing the data inside a NumPy array, since that'll also fix the dtype. I imagine with their implicit conversions, SciPy may also need to test the special cases where all list elements are things like `1+0j`, which have type `complex` but can be safely represented by reals - the Python call `float(1 + 0j)` is forbidden even though the imaginary part is 0. I actually ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784265398
https://github.com/qutip/qutip/issues/1451#issuecomment-784265398:1878,Safety,safe,safely,1878,"d_col)),; shape=(nds**2, nds**2),; dtype=np.complex128); ```; and recompile. If you want to make a PR of something similar against QuTiP, I'll accept it. I would actually file this against `scipy.sparse` - I think our usage is completely in line with the contract of `scipy.sparse.csr_matrix` and they've got a bug in their dtype handling. You currently can't construct a CSR matrix using the COO triplet format for complex data, unless the dtype is made explicit _somewhere_, but the constructor is meant to correctly infer a suitable dtype if one is not passed. Basic Scipy reproducer to illustrate the problem:; ```python; >>> import scipy.sparse; >>> scipy.__version__; '1.6.1'; >>> scipy.sparse.csr_matrix(([1+1j], ([0], [0])), shape=(2, 2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/compressed.py"", line 54, in __init__; other = self.__class__(coo_matrix(arg1, shape=shape,; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/coo.py"", line 161, in __init__; self.data = np.array(obj, copy=copy, dtype=data_dtype); TypeError: can't convert complex to float; ```. This can be fixed either by passing `dtype=np.complex128` to the constructor, or passing the data inside a NumPy array, since that'll also fix the dtype. I imagine with their implicit conversions, SciPy may also need to test the special cases where all list elements are things like `1+0j`, which have type `complex` but can be safely represented by reals - the Python call `float(1 + 0j)` is forbidden even though the imaginary part is 0. I actually originally thought this was the problem in this issue, since all the Lindbladian data tested is real numbers with complex type. I suppose it's up to SciPy to decide how they want to handle that case - either always maintaining `complex` or putting in a special-case cast (`np.real(x)`) for known-safe complex -> float conversions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784265398
https://github.com/qutip/qutip/issues/1451#issuecomment-784265398:2297,Safety,safe,safe,2297,"d_col)),; shape=(nds**2, nds**2),; dtype=np.complex128); ```; and recompile. If you want to make a PR of something similar against QuTiP, I'll accept it. I would actually file this against `scipy.sparse` - I think our usage is completely in line with the contract of `scipy.sparse.csr_matrix` and they've got a bug in their dtype handling. You currently can't construct a CSR matrix using the COO triplet format for complex data, unless the dtype is made explicit _somewhere_, but the constructor is meant to correctly infer a suitable dtype if one is not passed. Basic Scipy reproducer to illustrate the problem:; ```python; >>> import scipy.sparse; >>> scipy.__version__; '1.6.1'; >>> scipy.sparse.csr_matrix(([1+1j], ([0], [0])), shape=(2, 2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/compressed.py"", line 54, in __init__; other = self.__class__(coo_matrix(arg1, shape=shape,; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/coo.py"", line 161, in __init__; self.data = np.array(obj, copy=copy, dtype=data_dtype); TypeError: can't convert complex to float; ```. This can be fixed either by passing `dtype=np.complex128` to the constructor, or passing the data inside a NumPy array, since that'll also fix the dtype. I imagine with their implicit conversions, SciPy may also need to test the special cases where all list elements are things like `1+0j`, which have type `complex` but can be safely represented by reals - the Python call `float(1 + 0j)` is forbidden even though the imaginary part is 0. I actually originally thought this was the problem in this issue, since all the Lindbladian data tested is real numbers with complex type. I suppose it's up to SciPy to decide how they want to handle that case - either always maintaining `complex` or putting in a special-case cast (`np.real(x)`) for known-safe complex -> float conversions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784265398
https://github.com/qutip/qutip/issues/1451#issuecomment-784265398:1770,Testability,test,test,1770,"d_col)),; shape=(nds**2, nds**2),; dtype=np.complex128); ```; and recompile. If you want to make a PR of something similar against QuTiP, I'll accept it. I would actually file this against `scipy.sparse` - I think our usage is completely in line with the contract of `scipy.sparse.csr_matrix` and they've got a bug in their dtype handling. You currently can't construct a CSR matrix using the COO triplet format for complex data, unless the dtype is made explicit _somewhere_, but the constructor is meant to correctly infer a suitable dtype if one is not passed. Basic Scipy reproducer to illustrate the problem:; ```python; >>> import scipy.sparse; >>> scipy.__version__; '1.6.1'; >>> scipy.sparse.csr_matrix(([1+1j], ([0], [0])), shape=(2, 2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/compressed.py"", line 54, in __init__; other = self.__class__(coo_matrix(arg1, shape=shape,; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/coo.py"", line 161, in __init__; self.data = np.array(obj, copy=copy, dtype=data_dtype); TypeError: can't convert complex to float; ```. This can be fixed either by passing `dtype=np.complex128` to the constructor, or passing the data inside a NumPy array, since that'll also fix the dtype. I imagine with their implicit conversions, SciPy may also need to test the special cases where all list elements are things like `1+0j`, which have type `complex` but can be safely represented by reals - the Python call `float(1 + 0j)` is forbidden even though the imaginary part is 0. I actually originally thought this was the problem in this issue, since all the Lindbladian data tested is real numbers with complex type. I suppose it's up to SciPy to decide how they want to handle that case - either always maintaining `complex` or putting in a special-case cast (`np.real(x)`) for known-safe complex -> float conversions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784265398
https://github.com/qutip/qutip/issues/1451#issuecomment-784265398:2087,Testability,test,tested,2087,"d_col)),; shape=(nds**2, nds**2),; dtype=np.complex128); ```; and recompile. If you want to make a PR of something similar against QuTiP, I'll accept it. I would actually file this against `scipy.sparse` - I think our usage is completely in line with the contract of `scipy.sparse.csr_matrix` and they've got a bug in their dtype handling. You currently can't construct a CSR matrix using the COO triplet format for complex data, unless the dtype is made explicit _somewhere_, but the constructor is meant to correctly infer a suitable dtype if one is not passed. Basic Scipy reproducer to illustrate the problem:; ```python; >>> import scipy.sparse; >>> scipy.__version__; '1.6.1'; >>> scipy.sparse.csr_matrix(([1+1j], ([0], [0])), shape=(2, 2)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/compressed.py"", line 54, in __init__; other = self.__class__(coo_matrix(arg1, shape=shape,; File ""/Users/jake/.anaconda3/envs/qutip-dev/lib/python3.8/site-packages/scipy/sparse/coo.py"", line 161, in __init__; self.data = np.array(obj, copy=copy, dtype=data_dtype); TypeError: can't convert complex to float; ```. This can be fixed either by passing `dtype=np.complex128` to the constructor, or passing the data inside a NumPy array, since that'll also fix the dtype. I imagine with their implicit conversions, SciPy may also need to test the special cases where all list elements are things like `1+0j`, which have type `complex` but can be safely represented by reals - the Python call `float(1 + 0j)` is forbidden even though the imaginary part is 0. I actually originally thought this was the problem in this issue, since all the Lindbladian data tested is real numbers with complex type. I suppose it's up to SciPy to decide how they want to handle that case - either always maintaining `complex` or putting in a special-case cast (`np.real(x)`) for known-safe complex -> float conversions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784265398
https://github.com/qutip/qutip/issues/1451#issuecomment-784354122:8,Safety,safe,safer,8,"Agreed, safer to make it explicit. I'll prepare a PR.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-784354122
https://github.com/qutip/qutip/issues/1451#issuecomment-785001605:360,Deployability,release,release,360,"Numpy interprets the Python base type `complex` as equal to `np.complex128` when passed as a dtype. Personally I think `np.complex128` is much clearer (since it specifies the size in the name too), but I wouldn't worry too much about changing everything everywhere. `cqobjevo.pyx` in particular is going to be nearly entirely rewritten in the next major QuTiP release anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-785001605
https://github.com/qutip/qutip/issues/1451#issuecomment-785001605:143,Usability,clear,clearer,143,"Numpy interprets the Python base type `complex` as equal to `np.complex128` when passed as a dtype. Personally I think `np.complex128` is much clearer (since it specifies the size in the name too), but I wouldn't worry too much about changing everything everywhere. `cqobjevo.pyx` in particular is going to be nearly entirely rewritten in the next major QuTiP release anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1451#issuecomment-785001605
https://github.com/qutip/qutip/pull/1454#issuecomment-786076488:213,Deployability,update,update-mailmap,213,[![Coverage Status](https://coveralls.io/builds/37454317/badge)](https://coveralls.io/builds/37454317). Coverage remained the same at 63.189% when pulling **d0f4a71e606ffa0d0ce63c20c1539ba5343c23c4 on jakelishman:update-mailmap** into **f995f6f638c4a275f3b44016f22adb5fdb16845f on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1454#issuecomment-786076488
https://github.com/qutip/qutip/issues/1538#issuecomment-786988728:586,Availability,error,errors,586,"@Ericgig thanks! found the keywords. I am having some issue with the state being returned though and I am unsure how to work around them. I basically want to calculate expect(Oper, args[""state""]) which gives me a dimension mismatch, if I try doing (Oper*args[""state""]).tr() to find the expectation value, it tells me there is a shape mismatch. I initially start with Oper and psi0 shape as (8,8) but the args[""state""] returns a shape of (64,1). Any idea how to get around this issue? states in the 1d vector or the 2d matrix form also doesn't help leading to similar dimension mismatch errors. I was trying to look into the source code but couldn't figure out how to unflatten the Qobj state",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-786988728
https://github.com/qutip/qutip/issues/1538#issuecomment-1345305620:55,Usability,guid,guide,55,"The table is now present https://qutip.org/docs/latest/guide/dynamics/dynamics-time.html#accesing-the-state-from-solver. Closing this, but please let me know if I missed something.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1345305620
https://github.com/qutip/qutip/issues/1538#issuecomment-1398734865:58,Usability,guid,guide,58,"Hi everyone,. the table in [https://qutip.org/docs/latest/guide/dynamics/dynamics-time.html#accesing-the-state-from-solver](https://qutip.org/docs/latest/guide/dynamics/dynamics-time.html#accesing-the-state-from-solver) confuses me. What is 'name'? Can I chose it? I tried using custom names which did not work for me. Instead, using the keywords as explained in the section in [https://qutip.org/docs/latest/apidoc/classes.html?highlight=qobjevo#qobjevo](https://qutip.org/docs/latest/apidoc/classes.html?highlight=qobjevo#qobjevo) without any 'name' worked for me.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1398734865
https://github.com/qutip/qutip/issues/1538#issuecomment-1398734865:154,Usability,guid,guide,154,"Hi everyone,. the table in [https://qutip.org/docs/latest/guide/dynamics/dynamics-time.html#accesing-the-state-from-solver](https://qutip.org/docs/latest/guide/dynamics/dynamics-time.html#accesing-the-state-from-solver) confuses me. What is 'name'? Can I chose it? I tried using custom names which did not work for me. Instead, using the keywords as explained in the section in [https://qutip.org/docs/latest/apidoc/classes.html?highlight=qobjevo#qobjevo](https://qutip.org/docs/latest/apidoc/classes.html?highlight=qobjevo#qobjevo) without any 'name' worked for me.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1398734865
https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915:39,Integrability,interface,interface,39,"Thank you for reporting.; The feedback interface changed a few times (and will change in future version.); The documentation in guide is wrong, but the apidoc should be up to date.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915
https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915:30,Usability,feedback,feedback,30,"Thank you for reporting.; The feedback interface changed a few times (and will change in future version.); The documentation in guide is wrong, but the apidoc should be up to date.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915
https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915:128,Usability,guid,guide,128,"Thank you for reporting.; The feedback interface changed a few times (and will change in future version.); The documentation in guide is wrong, but the apidoc should be up to date.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1538#issuecomment-1398778915
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:988,Availability,down,down,988,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:368,Deployability,patch,patch,368,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:1463,Energy Efficiency,allocate,allocated,1463,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:1494,Energy Efficiency,allocate,allocated,1494,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:776,Integrability,depend,dependent,776,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:191,Safety,safe,safer,191,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:961,Safety,unsafe,unsafely,961,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:1034,Safety,sanity check,sanity checks,1034,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:386,Testability,test,test,386,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:547,Testability,test,test,547,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1456#issuecomment-791925169:48,Usability,clear,clear,48,"Ah, nice catch thanks, and thanks for the super clear repro. We're overhauling the solvers for QuTiP 5.0, which will include a lot more rigorous input checking on entry, but also it uses far safer low-level datatypes that would catch this shape mismatch in the C layer (even though the `dims` _should_ have been checked by `mesolve`). I'll check the other solvers and patch in a sanity test - probably after these lines: https://github.com/qutip/qutip/blob/d5e305513d9186df74beee4fd8da680e89f29d15/qutip/mesolve.py#L259-L261; we can just insert a test; ```python; if rho0.dims[0] != rho0.dims[1]:; raise ValueError(; ""input state must be a pure state or square density matrix""; ); ```. There may also be other segfaults lurking if you use a Python function to generate a time-dependent `Qobj` value in the Liouvillian or the expectation operators, but right now you're unlikely to use that form (because it's slow as anything). The bug slips through because we unsafely pass off a matrix down to C code (where we currently don't have sanity checks) without first verifying that it is a valid shape in Python space - the C code is working as designed, so there shouldn't be problems with correct inputs. Removing `c_ops` causes `mesolve` to delegate to `sesolve` which presumably is better at its type-checking, and I expect that a small dimension size working is likely just `malloc` having slack in the memory it gives us for small sizes or small requests being allocated into the special pre-allocated store.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1456#issuecomment-791925169
https://github.com/qutip/qutip/issues/1457#issuecomment-792274551:122,Availability,error,error-mitigation-in-qutip,122,"Hi @MrRobot2211,. indeed that project is still open, see https://github.com/qutip/qutip/wiki/Google-Summer-of-Code-2021#1-error-mitigation-in-qutip. However, compared to last year, the workload is reduced because this year GSoC reduces the required working time (now 175h in total). If you are interested in the part that is removed (e.g. concrete physical model), you are still welcome to draft a proposal according to your interest. It does not have to follow exactly the ideas proposed on the wiki page as long as it is a self-contained project and related to QuTiP. @nathanshammah in case he has comments.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1457#issuecomment-792274551
https://github.com/qutip/qutip/issues/1457#issuecomment-792274551:197,Energy Efficiency,reduce,reduced,197,"Hi @MrRobot2211,. indeed that project is still open, see https://github.com/qutip/qutip/wiki/Google-Summer-of-Code-2021#1-error-mitigation-in-qutip. However, compared to last year, the workload is reduced because this year GSoC reduces the required working time (now 175h in total). If you are interested in the part that is removed (e.g. concrete physical model), you are still welcome to draft a proposal according to your interest. It does not have to follow exactly the ideas proposed on the wiki page as long as it is a self-contained project and related to QuTiP. @nathanshammah in case he has comments.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1457#issuecomment-792274551
https://github.com/qutip/qutip/issues/1457#issuecomment-792274551:228,Energy Efficiency,reduce,reduces,228,"Hi @MrRobot2211,. indeed that project is still open, see https://github.com/qutip/qutip/wiki/Google-Summer-of-Code-2021#1-error-mitigation-in-qutip. However, compared to last year, the workload is reduced because this year GSoC reduces the required working time (now 175h in total). If you are interested in the part that is removed (e.g. concrete physical model), you are still welcome to draft a proposal according to your interest. It does not have to follow exactly the ideas proposed on the wiki page as long as it is a self-contained project and related to QuTiP. @nathanshammah in case he has comments.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1457#issuecomment-792274551
https://github.com/qutip/qutip/issues/1457#issuecomment-794421929:347,Performance,load,load,347,"Collaboration is open all the time, that's what open-source is for ;) It is required that all applicants have interaction with the community before applying so it is also kind of mandatory. And it will significantly increase the success probability of the application. Just notice that works done before GSoC won't give a reduction of the working load during the GSoC period (Google will check the process).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1457#issuecomment-794421929
https://github.com/qutip/qutip/issues/1460#issuecomment-796432374:1032,Modifiability,rewrite,rewrite,1032,"hi gary, thanks for making this an issue, i think it fell through the cracks on the google groups. . I think the problem is with how the expectation values are calculated. Mesolve() returns the correct states, but they are wrongly flagged with isherm=True, even when they are not actually hermitian, so when expect() is called it takes the real part. I think this incorrect flagging happens here for the output states; https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L520. and here for collating the expectation values; https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L510; (where only the hermiticity of the operators are checked, not the state. you can check this by setting x.isherm=False in your code example, which fixes everything). @Ericgig is there any issue with just removing this isherm=True flag here, and fixing the hermiticity check in the expectation values output call? i guess all this is getting replaced with your solver rewrite anyway, but if not it might make a good ''first issue'' for gsoc?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796432374
https://github.com/qutip/qutip/issues/1460#issuecomment-796689049:133,Safety,sanity check,sanity checks,133,"`Qobj` has some fast-path constructors that are basically the solvers saying ""this data is valid, just trust me"", causing it to skip sanity checks. There are a few slow points that can be skipped: copying unnecessary data, parsing/verifying the `dims` data, and determining the properties (`isherm`, `iscp`, etc). All of those add on very non-negligible construction time, but at most points in QuTiP we _know_ the values when passing them. Old-style code uses these magic ""fast-path"" constructors, but the new 5.0 branch gets rid of all of them - you can achieve much more, and more explicitly, by using the kwargs, and function-specific logic stays at the call location, rather than being bolted into `Qobj`. We still want to maintain passing `isherm` to `Qobj` when we know it for speed reasons, especially when we know the most common use of the `Qobj` created by `mesolve` is for finding expectation values. However, you can set the value based on the hermicity of the input density matrix; if you're passed a true density matrix, you'll always get a Hermitian matrix out, whereas you'll generally be in an unknown state if you're not. The test can be; ```python; def mesolve(H, rho0, tlist, ...):; hermicity = rho0.isherm or None; ...; for t in tlist:; output.states.append(Qobj(fdata, dims=dims, isherm=hermicity)); ```; which forces `isherm=True` if that's _known_, but leaves it unset if not. This is approximately how we handle things in 5.0, which is in part why we have huge reductions in `Qobj` construction time in the new version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796689049
https://github.com/qutip/qutip/issues/1460#issuecomment-796689049:639,Testability,log,logic,639,"`Qobj` has some fast-path constructors that are basically the solvers saying ""this data is valid, just trust me"", causing it to skip sanity checks. There are a few slow points that can be skipped: copying unnecessary data, parsing/verifying the `dims` data, and determining the properties (`isherm`, `iscp`, etc). All of those add on very non-negligible construction time, but at most points in QuTiP we _know_ the values when passing them. Old-style code uses these magic ""fast-path"" constructors, but the new 5.0 branch gets rid of all of them - you can achieve much more, and more explicitly, by using the kwargs, and function-specific logic stays at the call location, rather than being bolted into `Qobj`. We still want to maintain passing `isherm` to `Qobj` when we know it for speed reasons, especially when we know the most common use of the `Qobj` created by `mesolve` is for finding expectation values. However, you can set the value based on the hermicity of the input density matrix; if you're passed a true density matrix, you'll always get a Hermitian matrix out, whereas you'll generally be in an unknown state if you're not. The test can be; ```python; def mesolve(H, rho0, tlist, ...):; hermicity = rho0.isherm or None; ...; for t in tlist:; output.states.append(Qobj(fdata, dims=dims, isherm=hermicity)); ```; which forces `isherm=True` if that's _known_, but leaves it unset if not. This is approximately how we handle things in 5.0, which is in part why we have huge reductions in `Qobj` construction time in the new version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796689049
https://github.com/qutip/qutip/issues/1460#issuecomment-796689049:1145,Testability,test,test,1145,"`Qobj` has some fast-path constructors that are basically the solvers saying ""this data is valid, just trust me"", causing it to skip sanity checks. There are a few slow points that can be skipped: copying unnecessary data, parsing/verifying the `dims` data, and determining the properties (`isherm`, `iscp`, etc). All of those add on very non-negligible construction time, but at most points in QuTiP we _know_ the values when passing them. Old-style code uses these magic ""fast-path"" constructors, but the new 5.0 branch gets rid of all of them - you can achieve much more, and more explicitly, by using the kwargs, and function-specific logic stays at the call location, rather than being bolted into `Qobj`. We still want to maintain passing `isherm` to `Qobj` when we know it for speed reasons, especially when we know the most common use of the `Qobj` created by `mesolve` is for finding expectation values. However, you can set the value based on the hermicity of the input density matrix; if you're passed a true density matrix, you'll always get a Hermitian matrix out, whereas you'll generally be in an unknown state if you're not. The test can be; ```python; def mesolve(H, rho0, tlist, ...):; hermicity = rho0.isherm or None; ...; for t in tlist:; output.states.append(Qobj(fdata, dims=dims, isherm=hermicity)); ```; which forces `isherm=True` if that's _known_, but leaves it unset if not. This is approximately how we handle things in 5.0, which is in part why we have huge reductions in `Qobj` construction time in the new version.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796689049
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1666,Availability,down,down,1666,"obj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mcsolve.py#L525-L529 and https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L509-L511",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1976,Deployability,integrat,integration,1976,"obj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mcsolve.py#L525-L529 and https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L509-L511",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:628,Integrability,wrap,wraps,628,"Except for setting the type of the `Qobj` (which is deleted at the end of `Qobj.__init__`), there's no need for the 'mc' or 'mc-dm' fast-paths to exist in `Qobj.__init__` at all, even in `master`. If we were to fix the handling of a passed `type` - nothing else is overwritten if passed explicitly - you could achieve all the same effects at approximately the same speed with correct application of the kwargs, such as; ```python; Qobj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. W",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1102,Integrability,rout,route,1102," passed `type` - nothing else is overwritten if passed explicitly - you could achieve all the same effects at approximately the same speed with correct application of the kwargs, such as; ```python; Qobj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://gith",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1242,Integrability,wrap,wrapped,1242," passed `type` - nothing else is overwritten if passed explicitly - you could achieve all the same effects at approximately the same speed with correct application of the kwargs, such as; ```python; Qobj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://gith",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1976,Integrability,integrat,integration,1976,"obj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mcsolve.py#L525-L529 and https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L509-L511",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:1159,Performance,perform,performance,1159," passed `type` - nothing else is overwritten if passed explicitly - you could achieve all the same effects at approximately the same speed with correct application of the kwargs, such as; ```python; Qobj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://gith",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:815,Safety,avoid,avoid,815,"Except for setting the type of the `Qobj` (which is deleted at the end of `Qobj.__init__`), there's no need for the 'mc' or 'mc-dm' fast-paths to exist in `Qobj.__init__` at all, even in `master`. If we were to fix the handling of a passed `type` - nothing else is overwritten if passed explicitly - you could achieve all the same effects at approximately the same speed with correct application of the kwargs, such as; ```python; Qobj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. W",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796835048:2094,Safety,safe,safely,2094,"obj(data, dims=dims, copy=False, type='oper', isherm=...); ```; providing `data` is actually of a valid (`fast_csr_matrix`) format. Technically the `Qobj.data` attribute will be a new object that wraps the same numpy arrays as was passed, rather than the same `fast_csr_matrix`. In various forms, `expect` already does check the Hermicity, that's why `mc-dm` is careful to set it to avoid recalculating it. The expect functions in `qutip.expect` do this directly, and aren't aware of column-stacked density matrices - they'll just raise a TypeError. `mesolve` and `mcsolve` now bypass the `Qobj` stage and go direct to Cython - in 5.0 it might not be a terrible idea to route everything back through the `Qobj` form, since the performance issues there are solved (a column-stacked dense matrix can be directly wrapped by an f-ordered `Dense` type), and it's the natural central point of the code (and those parts are called from Python-space anyway, so no C concerns). Here though, the problem is actually that the expectation generator in `mesolve` correctly calculates the dtype of the output expectation array using both the state and the expectation operator, but then it does it incorrectly in the loop, and passes the hermicity down to Cython using only the expectation operator, which promptly throws out the complex part. So setting `fast='mc-dm'` in `Qobj` is a symptom of the same root cause as the problem here, rather than the cause itself. At the start of `mesolve` we don't assume that the state is Hermitian, but then inside the integration loop we do. We can still keep the speedup - if the output was created with a complex dtype, we can always safely say that we're passing in non-Hermitian operators, even if coincidentally at one timestep they happen to be anyway. See https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mcsolve.py#L525-L529 and https://github.com/qutip/qutip/blob/d285e96b3afc61afd1deceef61d9635f9d9aa505/qutip/mesolve.py#L509-L511",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796835048
https://github.com/qutip/qutip/issues/1460#issuecomment-796876592:70,Availability,down,down,70,"For a first issue, it could be solved with little changes or by going down the rabbit-hole.; There could also be a discussion about always returning complex expectation values.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796876592
https://github.com/qutip/qutip/issues/1460#issuecomment-796887930:589,Performance,load,load,589,"There's no rabbit hole - it's just a bug on line 511 of `mesolve.py` and 526 of `mcsolve.py`. The output dtype is correctly calculated, it's just a bug in generating values for the output array. There's a similar bug in the states output caused by the use of `fast='mc-dm'` that requires a more effort to fix, and should be at some point, but that's not so important right now. Having `qutip.expect` return real values for Hermitian operators and states I'd say is the correct behaviour. It's by far the most common use-case, and it allows them to be directly plotted without generating a load of warnings.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1460#issuecomment-796887930
https://github.com/qutip/qutip/pull/1461#issuecomment-809280369:10,Availability,failure,failure,10,"That test failure actually looks like a serious problem - there's a `NaN` that has crept into an output after a `copy` operation. In this case I think it's important that we really track down the root cause of how that happened, so we can be sure it can't happen again. All the other numbers are the same in that failure, so it looks like possibly memory corruption? There are 17 elements in the output (not a nice round number like 16), so maybe there's an off-by-one somewhere?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1461#issuecomment-809280369
https://github.com/qutip/qutip/pull/1461#issuecomment-809280369:187,Availability,down,down,187,"That test failure actually looks like a serious problem - there's a `NaN` that has crept into an output after a `copy` operation. In this case I think it's important that we really track down the root cause of how that happened, so we can be sure it can't happen again. All the other numbers are the same in that failure, so it looks like possibly memory corruption? There are 17 elements in the output (not a nice round number like 16), so maybe there's an off-by-one somewhere?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1461#issuecomment-809280369
https://github.com/qutip/qutip/pull/1461#issuecomment-809280369:313,Availability,failure,failure,313,"That test failure actually looks like a serious problem - there's a `NaN` that has crept into an output after a `copy` operation. In this case I think it's important that we really track down the root cause of how that happened, so we can be sure it can't happen again. All the other numbers are the same in that failure, so it looks like possibly memory corruption? There are 17 elements in the output (not a nice round number like 16), so maybe there's an off-by-one somewhere?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1461#issuecomment-809280369
https://github.com/qutip/qutip/pull/1461#issuecomment-809280369:5,Testability,test,test,5,"That test failure actually looks like a serious problem - there's a `NaN` that has crept into an output after a `copy` operation. In this case I think it's important that we really track down the root cause of how that happened, so we can be sure it can't happen again. All the other numbers are the same in that failure, so it looks like possibly memory corruption? There are 17 elements in the output (not a nice round number like 16), so maybe there's an off-by-one somewhere?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1461#issuecomment-809280369
https://github.com/qutip/qutip/pull/1462#issuecomment-805883421:14,Availability,failure,failure,14,"There's a new failure on an `mesolve` test in the Xcode 12 branch based on the relative tolerance. It's _probably_ fine, but maybe just check. Let's merge the fix for that in with this so we don't end up with the `diag_liou_mult` problem again (that I still haven't sorted out...). It's probably just a case of being a little more lenient with the test tolerance.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1462#issuecomment-805883421
https://github.com/qutip/qutip/pull/1462#issuecomment-805883421:88,Availability,toler,tolerance,88,"There's a new failure on an `mesolve` test in the Xcode 12 branch based on the relative tolerance. It's _probably_ fine, but maybe just check. Let's merge the fix for that in with this so we don't end up with the `diag_liou_mult` problem again (that I still haven't sorted out...). It's probably just a case of being a little more lenient with the test tolerance.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1462#issuecomment-805883421
https://github.com/qutip/qutip/pull/1462#issuecomment-805883421:353,Availability,toler,tolerance,353,"There's a new failure on an `mesolve` test in the Xcode 12 branch based on the relative tolerance. It's _probably_ fine, but maybe just check. Let's merge the fix for that in with this so we don't end up with the `diag_liou_mult` problem again (that I still haven't sorted out...). It's probably just a case of being a little more lenient with the test tolerance.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1462#issuecomment-805883421
https://github.com/qutip/qutip/pull/1462#issuecomment-805883421:38,Testability,test,test,38,"There's a new failure on an `mesolve` test in the Xcode 12 branch based on the relative tolerance. It's _probably_ fine, but maybe just check. Let's merge the fix for that in with this so we don't end up with the `diag_liou_mult` problem again (that I still haven't sorted out...). It's probably just a case of being a little more lenient with the test tolerance.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1462#issuecomment-805883421
https://github.com/qutip/qutip/pull/1462#issuecomment-805883421:348,Testability,test,test,348,"There's a new failure on an `mesolve` test in the Xcode 12 branch based on the relative tolerance. It's _probably_ fine, but maybe just check. Let's merge the fix for that in with this so we don't end up with the `diag_liou_mult` problem again (that I still haven't sorted out...). It's probably just a case of being a little more lenient with the test tolerance.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1462#issuecomment-805883421
https://github.com/qutip/qutip/pull/1463#issuecomment-801737359:255,Testability,test,test,255,@MrRobot2211 Thank you for this! I did a small review just of general code-cleanliness issues and left some comments. I'm hoping someone else who knows this code a bit better will come along and review the actual implementation. Could you perhaps write a test for the new code? That would help illustrate the original problem and help ensure the problem doesn't crop up again if cvxpy or the dnorm implementation change in future. The test should go at the end of `qutip/tests/test_metrics.py` (you'll see a bunch of dnorm tests already there).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-801737359
https://github.com/qutip/qutip/pull/1463#issuecomment-801737359:435,Testability,test,test,435,@MrRobot2211 Thank you for this! I did a small review just of general code-cleanliness issues and left some comments. I'm hoping someone else who knows this code a bit better will come along and review the actual implementation. Could you perhaps write a test for the new code? That would help illustrate the original problem and help ensure the problem doesn't crop up again if cvxpy or the dnorm implementation change in future. The test should go at the end of `qutip/tests/test_metrics.py` (you'll see a bunch of dnorm tests already there).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-801737359
https://github.com/qutip/qutip/pull/1463#issuecomment-801737359:471,Testability,test,tests,471,@MrRobot2211 Thank you for this! I did a small review just of general code-cleanliness issues and left some comments. I'm hoping someone else who knows this code a bit better will come along and review the actual implementation. Could you perhaps write a test for the new code? That would help illustrate the original problem and help ensure the problem doesn't crop up again if cvxpy or the dnorm implementation change in future. The test should go at the end of `qutip/tests/test_metrics.py` (you'll see a bunch of dnorm tests already there).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-801737359
https://github.com/qutip/qutip/pull/1463#issuecomment-801737359:523,Testability,test,tests,523,@MrRobot2211 Thank you for this! I did a small review just of general code-cleanliness issues and left some comments. I'm hoping someone else who knows this code a bit better will come along and review the actual implementation. Could you perhaps write a test for the new code? That would help illustrate the original problem and help ensure the problem doesn't crop up again if cvxpy or the dnorm implementation change in future. The test should go at the end of `qutip/tests/test_metrics.py` (you'll see a bunch of dnorm tests already there).,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-801737359
https://github.com/qutip/qutip/pull/1463#issuecomment-801903723:54,Testability,test,tests,54,"Hi @hodgestar thank you for yout input I will add the tests.; On further inspection it would be interesting if someone that wrote or uses this piece of code could comment if the new default settings for dnorm are correct. This specially affects the calls to Qobj.dnorm() since it does not have extra arguments, we could add a **kwargs there but I do not know if the hiding of the extra arguments was an intended feature in the original,",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-801903723
https://github.com/qutip/qutip/pull/1463#issuecomment-808812352:249,Testability,test,tests,249,"I've just pushed a couple of commits to fix up some minor remaining issues (a typo in a referenced GitHub issue and resetting the dnorm sparsity default to match the previous behaviour). Other than that, I'm happy to accept and merge this after the tests have passed again. Thank you very much for tackling this - `dnorm` has often been a problem child, so it's really good that you've taken this on and found a seemingly solid solution to this particular issue!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1463#issuecomment-808812352
https://github.com/qutip/qutip/pull/1465#issuecomment-801756430:7,Availability,failure,failure,7,"The CI failure on ` macOS, Python 3.8: XCode 12` is because the tests took too long. Not sure if this is just a Travis issue or a pre-existing problem or something new.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801756430
https://github.com/qutip/qutip/pull/1465#issuecomment-801756430:64,Testability,test,tests,64,"The CI failure on ` macOS, Python 3.8: XCode 12` is because the tests took too long. Not sure if this is just a Travis issue or a pre-existing problem or something new.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801756430
https://github.com/qutip/qutip/pull/1465#issuecomment-801774874:340,Testability,test,test,340,"The macOS Xcode 12 runners have been terminally slow for some time now. Looking at the setup time, it took nearly 9 minutes to build QuTiP, which is crazy compared to Linux and Windows build times (~2 minutes), or even Xcode 11 (~3 minutes). We noticed this starting several months ago, but the problem is that I don't have a machine I can test it on to see if it's a Travis problem or an Xcode 12 one. I'm unwilling to change my personal macOS version beyond 10.14 in part _because_ there are changes to how C compilation and debugging are handled - Apple are making it harder and harder to attach debuggers and set up sane compilers that aren't Xcode, and it took me long enough to get an actually fully featured compiler running on 10.14, let alone the next versions. Their vendored version of clang doesn't even support OpenMP!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801774874
https://github.com/qutip/qutip/pull/1465#issuecomment-801795088:208,Availability,down,down,208,"> If it's a known issue, let's leave it for when we switch CI to GitHub Actions (assuming that's the choice we end up making). It's very very difficult to tell, because Travis seem to be aggressively winding down the processing power available to us on Macs - I can't tell if there's a problem in this code, if Travis are over-stuffing their Xcode 12 machines with too many VMs, or even if it's some weird emulation (I think Azure _emulates_ PPC architectures if you ask for them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801795088
https://github.com/qutip/qutip/pull/1465#issuecomment-801795088:234,Availability,avail,available,234,"> If it's a known issue, let's leave it for when we switch CI to GitHub Actions (assuming that's the choice we end up making). It's very very difficult to tell, because Travis seem to be aggressively winding down the processing power available to us on Macs - I can't tell if there's a problem in this code, if Travis are over-stuffing their Xcode 12 machines with too many VMs, or even if it's some weird emulation (I think Azure _emulates_ PPC architectures if you ask for them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801795088
https://github.com/qutip/qutip/pull/1465#issuecomment-801795088:228,Energy Efficiency,power,power,228,"> If it's a known issue, let's leave it for when we switch CI to GitHub Actions (assuming that's the choice we end up making). It's very very difficult to tell, because Travis seem to be aggressively winding down the processing power available to us on Macs - I can't tell if there's a problem in this code, if Travis are over-stuffing their Xcode 12 machines with too many VMs, or even if it's some weird emulation (I think Azure _emulates_ PPC architectures if you ask for them!).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-801795088
https://github.com/qutip/qutip/pull/1465#issuecomment-802012836:38,Testability,test,test,38,"So I re-ran the failed macOS Xcode 12 test, and it succeeded no problems this time round, taking half the previous amount of time to build the library. I suspect Travis' Macs are just being intermittently overloaded.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-802012836
https://github.com/qutip/qutip/pull/1465#issuecomment-805920788:134,Availability,down,down,134,"About tests being very slow, I saw the following notice when I open the details:; ```; Please be aware travis-ci.org will be shutting down in several weeks, with all accounts migrating to travis-ci.com. Please stay tuned here for more information.; ```; I think we are still on `travis-ci.org`? Is this related to us? Maybe ""switch CI to GitHub Actions"" is more pressing than we thought.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-805920788
https://github.com/qutip/qutip/pull/1465#issuecomment-805920788:215,Performance,tune,tuned,215,"About tests being very slow, I saw the following notice when I open the details:; ```; Please be aware travis-ci.org will be shutting down in several weeks, with all accounts migrating to travis-ci.com. Please stay tuned here for more information.; ```; I think we are still on `travis-ci.org`? Is this related to us? Maybe ""switch CI to GitHub Actions"" is more pressing than we thought.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-805920788
https://github.com/qutip/qutip/pull/1465#issuecomment-805920788:6,Testability,test,tests,6,"About tests being very slow, I saw the following notice when I open the details:; ```; Please be aware travis-ci.org will be shutting down in several weeks, with all accounts migrating to travis-ci.com. Please stay tuned here for more information.; ```; I think we are still on `travis-ci.org`? Is this related to us? Maybe ""switch CI to GitHub Actions"" is more pressing than we thought.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-805920788
https://github.com/qutip/qutip/pull/1465#issuecomment-807184002:578,Deployability,install,installation,578,"Last review re-request, hopefully. I think everything's correct and ready now. 1. I had forgotten to build the sdist here, so it would have been missing from the pip package. That's fixed now.; 2. It's harder than you might expect to quickly fail all jobs in a GitHub Actions workflow right now. It seems that they expect you to try and continue for as long as possible for jobs on different runners, so I had to make everything depend on the confirmation verification to get the fail-fast behaviour.; 3. Hopefully neatened up the language we've been talking about.; 4. Removed installation of unnecessary VC++ tools for Python 2.7 on Windows.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-807184002
https://github.com/qutip/qutip/pull/1465#issuecomment-807184002:429,Integrability,depend,depend,429,"Last review re-request, hopefully. I think everything's correct and ready now. 1. I had forgotten to build the sdist here, so it would have been missing from the pip package. That's fixed now.; 2. It's harder than you might expect to quickly fail all jobs in a GitHub Actions workflow right now. It seems that they expect you to try and continue for as long as possible for jobs on different runners, so I had to make everything depend on the confirmation verification to get the fail-fast behaviour.; 3. Hopefully neatened up the language we've been talking about.; 4. Removed installation of unnecessary VC++ tools for Python 2.7 on Windows.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1465#issuecomment-807184002
https://github.com/qutip/qutip/issues/1466#issuecomment-804264437:250,Safety,avoid,avoid,250,"This is the same as https://github.com/qutip/qutip/issues/1247. QuTiP uses sparse matrices, so a matrix element smaller than a certain threshold (by default 1e-7) will be discarded. This can be changed in the settings. Consider changing your unit to avoid very small values, for instance, by writing the formula with h=1` and in nanosecond time unit.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-804264437
https://github.com/qutip/qutip/issues/1466#issuecomment-804906162:228,Safety,avoid,avoid,228,"> This is the same as #1247; > ; > QuTiP uses sparse matrices, so a matrix element smaller than a certain threshold (by default 1e-7) will be discarded. This can be changed in the settings.; > ; > Consider changing your unit to avoid very small values, for instance, by writing the formula with h=1` and in nanosecond time unit. Sorry which formula are you referring to when you say h=1'?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-804906162
https://github.com/qutip/qutip/issues/1466#issuecomment-805120396:342,Safety,avoid,avoid,342,"After a second look, I realize that small numbers might not be the problem here. I was thinking that the `coeffs` you computed is too small so that it gets discarded. It turned out that your `Delta` is around 10^6, which is not small at all. Apologies for the rush. ; Still, I would suggest changing the unit so that `Delta` is close to 1 to avoid this kind of pitfalls. Then, there could be the following reasons:; - In the example you give, `w-w0` is actually 0, if you then choose phi=0, the `coeffs` is always 0. But this maybe just a mistake from extracting this example.; - A more likely problem is that `pulse` function, `t` is not used at all. I guess you probably mean that the pulse is turned on at `t=t0`, which should be:; ```; def pulse(t0,t):; return np.heaviside(t - t0, 2e-9); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-805120396
https://github.com/qutip/qutip/issues/1466#issuecomment-810278045:744,Availability,down,down,744,"I tried your suggestions but unfortunately nothing changes. I think my issue is with the way the rotating frame approximation is being implemented. Prior to this, my issue was that the graph couldn't be plotted over a large time scale because w0 is so high, so I added (w-w0) to H0. That fixed it, but I'm not sure how that affects the H1_coeff function. Is it as simple as including a (w-w0) term there as well, or do I need to adjust it some other way? As you can see, the pulse does exist, but for some reason nothing I change in the code causes the pulse to affect the graphs in any way. . Also, I realized that the heaviside function may not actually be appropriate for this situation. My goal is to create a pulse that spikes up and dies down, but the heaviside function is a step function so it spikes up and stays there. Do you know if qutip has any functions for such pulses?. ![k](https://user-images.githubusercontent.com/29261370/113001273-42ce2600-9136-11eb-84f3-a4bcdd7c458f.PNG)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-810278045
https://github.com/qutip/qutip/issues/1466#issuecomment-810278045:364,Usability,simpl,simple,364,"I tried your suggestions but unfortunately nothing changes. I think my issue is with the way the rotating frame approximation is being implemented. Prior to this, my issue was that the graph couldn't be plotted over a large time scale because w0 is so high, so I added (w-w0) to H0. That fixed it, but I'm not sure how that affects the H1_coeff function. Is it as simple as including a (w-w0) term there as well, or do I need to adjust it some other way? As you can see, the pulse does exist, but for some reason nothing I change in the code causes the pulse to affect the graphs in any way. . Also, I realized that the heaviside function may not actually be appropriate for this situation. My goal is to create a pulse that spikes up and dies down, but the heaviside function is a step function so it spikes up and stays there. Do you know if qutip has any functions for such pulses?. ![k](https://user-images.githubusercontent.com/29261370/113001273-42ce2600-9136-11eb-84f3-a4bcdd7c458f.PNG)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-810278045
https://github.com/qutip/qutip/issues/1466#issuecomment-810331229:195,Availability,error,error,195,"About the simulation, the frequency of your `H0` is at the level of 10^12 (with w0=0), while your control amplitude `Delta` is only 10^6! This is a huge difference. I feel like there might be an error in the unit somewhere. The number of time steps sampled needs to be hundreds of millions. Simulate this whole process is not practical. By setting `w-w0=0` you discard the fast process and what remains is only `Delta`. With `w-w0=0`, I get reasonable oscillation with the following code; ```python; def pulse(t0,t):; return np.heaviside(t-t0,2e-9). def H1_coeff(t,args):; t0=args['t0']; phi=args['phi']; return Delta*pulse(t0,t)*np.sin((w-w0)*t+phi). H = [H0,[sx,H1_coeff]]. times=np.linspace(0, 0.00001, 1000). args = {""t0"":0, ""phi"":np.pi/2}; result = mesolve(H, basis(2,0), times, args=args, e_ops=[sz]); plt.plot(result.expect[0]); plt.show(); ```. If you want to observe the effect of RWA, you could set `w-w0` to be about 10 times `Delta`. That is, the frequency of your system's dynamics is about ten times larger than your driving. Discarding the system dynamics by RWA will lead to some visible error in the plot, but not significantly enough to destroy the driving dynamics. (Edited) About pulse that spikes up and dies down, a spike at one single time point is not well defined. Mathematically the integral will be 0 (in measures that makes sense here at least). If you want a pulse that is turned on for a certain duration and then off, you can use two Heaviside. But much easier: you can just shift your time scale and define your tlist `times` to be that time duration from `0` to `t_end`, which matches the duration of your pulse.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-810331229
https://github.com/qutip/qutip/issues/1466#issuecomment-810331229:1104,Availability,error,error,1104,"About the simulation, the frequency of your `H0` is at the level of 10^12 (with w0=0), while your control amplitude `Delta` is only 10^6! This is a huge difference. I feel like there might be an error in the unit somewhere. The number of time steps sampled needs to be hundreds of millions. Simulate this whole process is not practical. By setting `w-w0=0` you discard the fast process and what remains is only `Delta`. With `w-w0=0`, I get reasonable oscillation with the following code; ```python; def pulse(t0,t):; return np.heaviside(t-t0,2e-9). def H1_coeff(t,args):; t0=args['t0']; phi=args['phi']; return Delta*pulse(t0,t)*np.sin((w-w0)*t+phi). H = [H0,[sx,H1_coeff]]. times=np.linspace(0, 0.00001, 1000). args = {""t0"":0, ""phi"":np.pi/2}; result = mesolve(H, basis(2,0), times, args=args, e_ops=[sz]); plt.plot(result.expect[0]); plt.show(); ```. If you want to observe the effect of RWA, you could set `w-w0` to be about 10 times `Delta`. That is, the frequency of your system's dynamics is about ten times larger than your driving. Discarding the system dynamics by RWA will lead to some visible error in the plot, but not significantly enough to destroy the driving dynamics. (Edited) About pulse that spikes up and dies down, a spike at one single time point is not well defined. Mathematically the integral will be 0 (in measures that makes sense here at least). If you want a pulse that is turned on for a certain duration and then off, you can use two Heaviside. But much easier: you can just shift your time scale and define your tlist `times` to be that time duration from `0` to `t_end`, which matches the duration of your pulse.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-810331229
https://github.com/qutip/qutip/issues/1466#issuecomment-810331229:1230,Availability,down,down,1230,"About the simulation, the frequency of your `H0` is at the level of 10^12 (with w0=0), while your control amplitude `Delta` is only 10^6! This is a huge difference. I feel like there might be an error in the unit somewhere. The number of time steps sampled needs to be hundreds of millions. Simulate this whole process is not practical. By setting `w-w0=0` you discard the fast process and what remains is only `Delta`. With `w-w0=0`, I get reasonable oscillation with the following code; ```python; def pulse(t0,t):; return np.heaviside(t-t0,2e-9). def H1_coeff(t,args):; t0=args['t0']; phi=args['phi']; return Delta*pulse(t0,t)*np.sin((w-w0)*t+phi). H = [H0,[sx,H1_coeff]]. times=np.linspace(0, 0.00001, 1000). args = {""t0"":0, ""phi"":np.pi/2}; result = mesolve(H, basis(2,0), times, args=args, e_ops=[sz]); plt.plot(result.expect[0]); plt.show(); ```. If you want to observe the effect of RWA, you could set `w-w0` to be about 10 times `Delta`. That is, the frequency of your system's dynamics is about ten times larger than your driving. Discarding the system dynamics by RWA will lead to some visible error in the plot, but not significantly enough to destroy the driving dynamics. (Edited) About pulse that spikes up and dies down, a spike at one single time point is not well defined. Mathematically the integral will be 0 (in measures that makes sense here at least). If you want a pulse that is turned on for a certain duration and then off, you can use two Heaviside. But much easier: you can just shift your time scale and define your tlist `times` to be that time duration from `0` to `t_end`, which matches the duration of your pulse.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-810331229
https://github.com/qutip/qutip/issues/1466#issuecomment-811118983:427,Usability,clear,clear,427,"No, I'm using `w-w0` just to show that the code works fine with my suggested changes in `pulse(t0,t)`. It is just the numbers that are wrong. First, please check the equation you are using again because (I guess) `H0` should be `(w-w0)/2 * sz` and not the one you give in the code above. In your definition, `w-w0` and `epsilon` is the same thing. The drive frequency (in sinus function) should match with `H0`. Second, it not clear to me what you want to achieve with this. If the drive frequency matches the system frequency (both `w-w0` here), H0 is exactly 0 in the rotating frame.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-811118983
https://github.com/qutip/qutip/issues/1466#issuecomment-812760478:19,Usability,feedback,feedback,19,"Thank you for your feedback. I was able to get the results I wanted. Just to provide some closure, I'm sending a photo. ![Image from iOS](https://user-images.githubusercontent.com/29261370/113462422-67e8c000-93e6-11eb-95ef-6d20f89b3851.jpg)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1466#issuecomment-812760478
https://github.com/qutip/qutip/pull/1469#issuecomment-807669665:216,Deployability,patch,patch-,216,[![Coverage Status](https://coveralls.io/builds/44907513/badge)](https://coveralls.io/builds/44907513). Coverage decreased (-0.007%) to 68.323% when pulling **d183195b99a0312d8069b01266b929b47decd198 on madphysicist:patch-1** into **3c4110a12dbac851276e146fdebc26d2b72963a7 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1469#issuecomment-807669665
https://github.com/qutip/qutip/pull/1469#issuecomment-853281689:69,Deployability,release,release,69,"Oh, don't worry about rushing - there's no hurry. We don't expect to release 4.7 for _at least_ a month, probably two. I was just mentioning it now so you'd have time if you were still interested.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1469#issuecomment-853281689
https://github.com/qutip/qutip/pull/1469#issuecomment-875604784:22,Availability,ping,pinging,22,"@madphysicist Just re-pinging. As before, it's perfectly okay if you've run out of time a bit -- just let us know.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1469#issuecomment-875604784
https://github.com/qutip/qutip/pull/1469#issuecomment-990391024:56,Testability,test,tests,56,I think we just need to resolve the conflicts in `qutip/tests/test_states.py` and then perhaps we can merge.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1469#issuecomment-990391024
https://github.com/qutip/qutip/pull/1469#issuecomment-991004427:33,Availability,error,error,33,"@Ericgig Should we just raise an error if `offset != 0` is passed with `method=""operator""`?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1469#issuecomment-991004427
https://github.com/qutip/qutip/issues/1470#issuecomment-808297011:3,Testability,test,testing,3,"In testing.py, we made sure openmp was used even on 1 cpu for the tests. But this is no longer used with changes to travis.yml to use pytest. I believe `pytest.fixture` could be used to set `openmp_thresh` for openmp tests, but I don't see how to catch issues in `__init__.py` with that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1470#issuecomment-808297011
https://github.com/qutip/qutip/issues/1470#issuecomment-808297011:66,Testability,test,tests,66,"In testing.py, we made sure openmp was used even on 1 cpu for the tests. But this is no longer used with changes to travis.yml to use pytest. I believe `pytest.fixture` could be used to set `openmp_thresh` for openmp tests, but I don't see how to catch issues in `__init__.py` with that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1470#issuecomment-808297011
https://github.com/qutip/qutip/issues/1470#issuecomment-808297011:217,Testability,test,tests,217,"In testing.py, we made sure openmp was used even on 1 cpu for the tests. But this is no longer used with changes to travis.yml to use pytest. I believe `pytest.fixture` could be used to set `openmp_thresh` for openmp tests, but I don't see how to catch issues in `__init__.py` with that.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1470#issuecomment-808297011
https://github.com/qutip/qutip/issues/1470#issuecomment-808299865:66,Modifiability,variab,variable,66,"Also, we can ""solve"" the testing issue by forcing the environment variable `QUTIP_NUM_PROCESSES=2` before importing QuTiP, I think.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1470#issuecomment-808299865
https://github.com/qutip/qutip/issues/1470#issuecomment-808299865:25,Testability,test,testing,25,"Also, we can ""solve"" the testing issue by forcing the environment variable `QUTIP_NUM_PROCESSES=2` before importing QuTiP, I think.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1470#issuecomment-808299865
https://github.com/qutip/qutip/pull/1471#issuecomment-808877022:88,Testability,test,test,88,"@nwlambert Neill, does this fix everything for you? I'd like to have a couple of people test it if possible, since I toughened up the exception throwing, which might have caused more previously hidden problems to surface.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1471#issuecomment-808877022
https://github.com/qutip/qutip/pull/1471#issuecomment-808886693:49,Availability,error,error,49,"Yup, it installed ok, the openmp threshold check error is gone, and all tests passed ok~!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1471#issuecomment-808886693
https://github.com/qutip/qutip/pull/1471#issuecomment-808886693:8,Deployability,install,installed,8,"Yup, it installed ok, the openmp threshold check error is gone, and all tests passed ok~!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1471#issuecomment-808886693
https://github.com/qutip/qutip/pull/1471#issuecomment-808886693:72,Testability,test,tests,72,"Yup, it installed ok, the openmp threshold check error is gone, and all tests passed ok~!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1471#issuecomment-808886693
https://github.com/qutip/qutip/issues/1472#issuecomment-808413846:44,Usability,clear,clearly,44,@IamSeti please explain the feature request clearly.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808413846
https://github.com/qutip/qutip/issues/1472#issuecomment-808417826:372,Availability,error,errors,372,"If you only need the final state and you don't need any intermediate times, your `tlist` should only have two elements in it. So; ```python; import qutip; hamiltonian = qutip.sigmax(); state = qutip.basis(2, 0).proj(); times = [0, 10]; qutip.mesolve(hamiltonian, state, times); ```; should give the correct result. If you want to integrated for a long time, you might get errors about the integration not converging. If so, you will need to increase the `nsteps` solver option, such as; ```; options = qutip.Options(nsteps=10_000_000); qutip.mesolve(..., options=options); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808417826
https://github.com/qutip/qutip/issues/1472#issuecomment-808417826:330,Deployability,integrat,integrated,330,"If you only need the final state and you don't need any intermediate times, your `tlist` should only have two elements in it. So; ```python; import qutip; hamiltonian = qutip.sigmax(); state = qutip.basis(2, 0).proj(); times = [0, 10]; qutip.mesolve(hamiltonian, state, times); ```; should give the correct result. If you want to integrated for a long time, you might get errors about the integration not converging. If so, you will need to increase the `nsteps` solver option, such as; ```; options = qutip.Options(nsteps=10_000_000); qutip.mesolve(..., options=options); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808417826
https://github.com/qutip/qutip/issues/1472#issuecomment-808417826:389,Deployability,integrat,integration,389,"If you only need the final state and you don't need any intermediate times, your `tlist` should only have two elements in it. So; ```python; import qutip; hamiltonian = qutip.sigmax(); state = qutip.basis(2, 0).proj(); times = [0, 10]; qutip.mesolve(hamiltonian, state, times); ```; should give the correct result. If you want to integrated for a long time, you might get errors about the integration not converging. If so, you will need to increase the `nsteps` solver option, such as; ```; options = qutip.Options(nsteps=10_000_000); qutip.mesolve(..., options=options); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808417826
https://github.com/qutip/qutip/issues/1472#issuecomment-808417826:330,Integrability,integrat,integrated,330,"If you only need the final state and you don't need any intermediate times, your `tlist` should only have two elements in it. So; ```python; import qutip; hamiltonian = qutip.sigmax(); state = qutip.basis(2, 0).proj(); times = [0, 10]; qutip.mesolve(hamiltonian, state, times); ```; should give the correct result. If you want to integrated for a long time, you might get errors about the integration not converging. If so, you will need to increase the `nsteps` solver option, such as; ```; options = qutip.Options(nsteps=10_000_000); qutip.mesolve(..., options=options); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808417826
https://github.com/qutip/qutip/issues/1472#issuecomment-808417826:389,Integrability,integrat,integration,389,"If you only need the final state and you don't need any intermediate times, your `tlist` should only have two elements in it. So; ```python; import qutip; hamiltonian = qutip.sigmax(); state = qutip.basis(2, 0).proj(); times = [0, 10]; qutip.mesolve(hamiltonian, state, times); ```; should give the correct result. If you want to integrated for a long time, you might get errors about the integration not converging. If so, you will need to increase the `nsteps` solver option, such as; ```; options = qutip.Options(nsteps=10_000_000); qutip.mesolve(..., options=options); ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808417826
https://github.com/qutip/qutip/issues/1472#issuecomment-808459933:90,Integrability,depend,dependent,90,"Dear Qutip admin,. Thank you for your fast reply. Unfortunately, my hamiltonian is a time-dependent function which is nonanalytic. So I need to use a large number of tgrid (on the order of 1000000 grid size) for my hamiltonian. Is there a way that you can add a feature to mesolve so that it can store only the final_state without storing the states at all time even for the case where my tlist has a large grid size. Or is there a way for mesolve to evaluate the expectation operator at the final time only without having to evaluate it at all time?. Your help will be well appreciated.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808459933
https://github.com/qutip/qutip/issues/1472#issuecomment-808615925:117,Availability,error,error,117,"Dear Qutip admin,. Thank you for your fast reply. I tried the above method. However, it doesn't work. It gives me an error message saying that ""Time list does not match"". Here is one sample on how I applied it. import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; hamiltonian = qutip.sigmax(); args = {'omega':1000}; timelist = np.linspace(0, 1, 1000); omegatlist = np.cos(args['omega']*timelist); H = qutip.QobjEvo([qutip.sigmax(),[qutip.sigmax(),omegatlist]], tlist=1000); state = qutip.basis(2, 0).proj(); times = np.linspace(0, 1, 2); qutip.mesolve(H,state,times,[],qutip.sigmax(),args=args,options=options). Although in the above, I used an analytic function for my Hamiltonian, actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. Your comment on how to solve the problem associated with the above code will be much appreciated.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808615925
https://github.com/qutip/qutip/issues/1472#issuecomment-808615925:123,Integrability,message,message,123,"Dear Qutip admin,. Thank you for your fast reply. I tried the above method. However, it doesn't work. It gives me an error message saying that ""Time list does not match"". Here is one sample on how I applied it. import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; hamiltonian = qutip.sigmax(); args = {'omega':1000}; timelist = np.linspace(0, 1, 1000); omegatlist = np.cos(args['omega']*timelist); H = qutip.QobjEvo([qutip.sigmax(),[qutip.sigmax(),omegatlist]], tlist=1000); state = qutip.basis(2, 0).proj(); times = np.linspace(0, 1, 2); qutip.mesolve(H,state,times,[],qutip.sigmax(),args=args,options=options). Although in the above, I used an analytic function for my Hamiltonian, actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. Your comment on how to solve the problem associated with the above code will be much appreciated.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808615925
https://github.com/qutip/qutip/issues/1472#issuecomment-808615925:756,Integrability,depend,dependent,756,"Dear Qutip admin,. Thank you for your fast reply. I tried the above method. However, it doesn't work. It gives me an error message saying that ""Time list does not match"". Here is one sample on how I applied it. import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; hamiltonian = qutip.sigmax(); args = {'omega':1000}; timelist = np.linspace(0, 1, 1000); omegatlist = np.cos(args['omega']*timelist); H = qutip.QobjEvo([qutip.sigmax(),[qutip.sigmax(),omegatlist]], tlist=1000); state = qutip.basis(2, 0).proj(); times = np.linspace(0, 1, 2); qutip.mesolve(H,state,times,[],qutip.sigmax(),args=args,options=options). Although in the above, I used an analytic function for my Hamiltonian, actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. Your comment on how to solve the problem associated with the above code will be much appreciated.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808615925
https://github.com/qutip/qutip/issues/1472#issuecomment-808693608:41,Integrability,depend,dependent,41,"> actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. @IamSeti May I ask if your Hamiltonian can be written in the following form `sum a_i(t)*H_i` with a few different constant `H_i`, i.e. the time-dependence can be represented by a complex coefficient; Or is your Hamiltonian completely non-analytic and time-dependent?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808693608
https://github.com/qutip/qutip/issues/1472#issuecomment-808693608:258,Integrability,depend,dependence,258,"> actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. @IamSeti May I ask if your Hamiltonian can be written in the following form `sum a_i(t)*H_i` with a few different constant `H_i`, i.e. the time-dependence can be represented by a complex coefficient; Or is your Hamiltonian completely non-analytic and time-dependent?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808693608
https://github.com/qutip/qutip/issues/1472#issuecomment-808693608:370,Integrability,depend,dependent,370,"> actually my real Hamiltonian is a time-dependent non-analytic function which has to be represented by an array. @IamSeti May I ask if your Hamiltonian can be written in the following form `sum a_i(t)*H_i` with a few different constant `H_i`, i.e. the time-dependence can be represented by a complex coefficient; Or is your Hamiltonian completely non-analytic and time-dependent?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808693608
https://github.com/qutip/qutip/issues/1472#issuecomment-808726734:1859,Integrability,rout,routine,1859," compare the expectation value at the end of the simulation which is at time t = 1. . #First code:. import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; args = {'omega':1000}; time_grid = 1000; timelist = np.linspace(0, 1, time_grid); omegatlist = np.cos(args['omega']*timelist); H = qutip.QobjEvo([qutip.sigmax(),omegatlist], tlist= np.array(np.linspace(0, 1, time_grid), dtype=np.float64)); state = qutip.basis(2, 0).proj(); times = np.linspace(0, 1, 2); result = qutip.mesolve(H,state,times,[],qutip.sigmaz(),args=args,options=options); print(result.expect[0][1]). #Second code: ; import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; args = {'omega':1000}; time_grid = 1000; tlist = np.linspace(0, 1, time_grid); omegatlist = np.cos(args['omega']*tlist); H = [qutip.sigmax(),omegatlist]; state = qutip.basis(2, 0).proj(); times = tlist; result = qutip.mesolve(H,state,times,[],qutip.sigmaz(),args=args,options=options); print(result.expect[0][999]). The first code gives a value of 0.9999989185418086 and the second one returns a value of 0.9999989289570258. So, the two results are not exactly the same. For the above analytic Hamiltonian, the result seems to differ by a small decimal number. However for the non-analytic Hamiltonian that I am actually using, the result can differ by six orders of magnitude. May I know why there is a difference in the results obtained from the two methods above? Is it because when QobjEvo is used, the mesolve routine actually does not sample enough time grid points when it evolves the Hamiltonian (i.e., it does not sample all the time_grid points which is time_grid = 1000 as provided above)? If so, may you kindly tell me how to rectify this problem?. As per my original question, I would like the first code to give the same the expectation value of the operator at the final time as is in the second code but without having to evaluate the expectation value of the operator at all time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808726734
https://github.com/qutip/qutip/issues/1472#issuecomment-808726734:1924,Modifiability,evolve,evolves,1924," compare the expectation value at the end of the simulation which is at time t = 1. . #First code:. import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; args = {'omega':1000}; time_grid = 1000; timelist = np.linspace(0, 1, time_grid); omegatlist = np.cos(args['omega']*timelist); H = qutip.QobjEvo([qutip.sigmax(),omegatlist], tlist= np.array(np.linspace(0, 1, time_grid), dtype=np.float64)); state = qutip.basis(2, 0).proj(); times = np.linspace(0, 1, 2); result = qutip.mesolve(H,state,times,[],qutip.sigmaz(),args=args,options=options); print(result.expect[0][1]). #Second code: ; import qutip; import numpy as np; options = qutip.Options(); options.nsteps = 100000; args = {'omega':1000}; time_grid = 1000; tlist = np.linspace(0, 1, time_grid); omegatlist = np.cos(args['omega']*tlist); H = [qutip.sigmax(),omegatlist]; state = qutip.basis(2, 0).proj(); times = tlist; result = qutip.mesolve(H,state,times,[],qutip.sigmaz(),args=args,options=options); print(result.expect[0][999]). The first code gives a value of 0.9999989185418086 and the second one returns a value of 0.9999989289570258. So, the two results are not exactly the same. For the above analytic Hamiltonian, the result seems to differ by a small decimal number. However for the non-analytic Hamiltonian that I am actually using, the result can differ by six orders of magnitude. May I know why there is a difference in the results obtained from the two methods above? Is it because when QobjEvo is used, the mesolve routine actually does not sample enough time grid points when it evolves the Hamiltonian (i.e., it does not sample all the time_grid points which is time_grid = 1000 as provided above)? If so, may you kindly tell me how to rectify this problem?. As per my original question, I would like the first code to give the same the expectation value of the operator at the final time as is in the second code but without having to evaluate the expectation value of the operator at all time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808726734
https://github.com/qutip/qutip/issues/1472#issuecomment-808859776:71,Availability,error,error,71,"in that extreme example you gave I guess you are just seeing numerical error from the ODE solver which is sensitive to some small difference in how the Liouvillian is being constructed, if you decrease the tolerances in options the difference diminishes, I guess with something like,. options.atol=1e-15; options.rtol=1e-15. also, just fyi, when you send an array for the time-dependence mesolve() uses some cubic-spline fitting to ''fill in the gaps'' when needed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808859776
https://github.com/qutip/qutip/issues/1472#issuecomment-808859776:206,Availability,toler,tolerances,206,"in that extreme example you gave I guess you are just seeing numerical error from the ODE solver which is sensitive to some small difference in how the Liouvillian is being constructed, if you decrease the tolerances in options the difference diminishes, I guess with something like,. options.atol=1e-15; options.rtol=1e-15. also, just fyi, when you send an array for the time-dependence mesolve() uses some cubic-spline fitting to ''fill in the gaps'' when needed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808859776
https://github.com/qutip/qutip/issues/1472#issuecomment-808859776:377,Integrability,depend,dependence,377,"in that extreme example you gave I guess you are just seeing numerical error from the ODE solver which is sensitive to some small difference in how the Liouvillian is being constructed, if you decrease the tolerances in options the difference diminishes, I guess with something like,. options.atol=1e-15; options.rtol=1e-15. also, just fyi, when you send an array for the time-dependence mesolve() uses some cubic-spline fitting to ''fill in the gaps'' when needed.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808859776
https://github.com/qutip/qutip/issues/1472#issuecomment-808904001:303,Safety,detect,detect,303,"There is one pitfall I know but I'm not sure if that is the reason here:. Is your Hamiltonian mostly 0 in the time duration? QuTiP solves dynamically change the step size, if there are a lot of zeros, it may skip the non-zero part accidentally (see https://github.com/qutip/qutip/issues/1265). You will detect it by adding a small constant `H` (magntitude~10^-6) on top of your Hamiltonian (if this H does not affect your true dynamic significantly). If that's not your case, we may need more information to actually identify the problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-808904001
https://github.com/qutip/qutip/issues/1472#issuecomment-810182936:1095,Usability,simpl,simple,1095,"No, my Hamiltonian does not have a lot of zeros but it has fast oscillating term cos (omega(t)*t) where omega(t) is a non-analytic term and is a very large number compared to the 1/final time. So, to get the correct result, I have to use a large number of time_grid. I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This will not give the correct result since my Hamiltonian has fast oscillating terms which requires a lot of time steps to be given as an input for mesolve. This is why the method of using QobjEvo gives different answer than if I use my initial time grid (which is time grid = 1000000) in the mesolve. . Since I am using a very large time grid in mesolve, my program ran very slowly. I would like to speed up my simulation by having mesolve to evaluate the expectation value of the operator only at the final time and not at all time steps. My question is very simple: Is there a way that I can still use a very large time grid in evolving my Hamiltonian using mesolve but have the mesolve evaluating the expectation value of the operator ONLY at the final time? If not, is it possible to add this feature in qutip?. Thank you.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810182936
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:1616,Deployability,integrat,integration,1616,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:1616,Integrability,integrat,integration,1616,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:1342,Testability,assert,assert,1342,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:1380,Testability,assert,assert,1380,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:375,Usability,simpl,simple,375,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-810246525:1704,Usability,Clear,Clearly,1704,"> I suspect the method of using QobjEvo that was suggested above only use two time steps (initial and final time) in evolving the Hamiltonian as the seed and interpolate the Hamiltonian at the time between the initial and final time using some interpolation function. This is not the case. The answer to your question is to use `QobjEvo` as suggested. For example, here is a simple example using a fast-oscillating array function in a `QobjEvo` and a much shorter `tlist` in `mesolve`. You may need to set the solver options `nsteps`, `atol` and `rtol` to suitable values, as I have done here. ```python; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * 2.91e2 * fast_ts); # This is the behaviour you were suggesting is happening.; bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]). H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options). assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; ```. You can see that I was able to do a successful integration with only 2 times in `mesolve`, but many in a fast-oscillating Hamiltonian. Clearly the `bad_times` version (which only has the start and end points so misses all the fast oscillation behaviour) is completely different to the other two versions.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-810246525
https://github.com/qutip/qutip/issues/1472#issuecomment-811468770:415,Availability,down,down,415,"We should somehow highlight more in the documentation that:; 1. QuTiP use cubic spline and the time points in `tlist` are not the sampling points used in `mesolve`.; 2. (edited) `tlist` in `QobjEvo` and in `mesolve` do not have to be the same. The _later_ one determines only which point to save the state or calculate the expectation value. From what I experienced, quite some people don't know this. And it slows down their code a lot.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-811468770
https://github.com/qutip/qutip/issues/1472#issuecomment-812258761:242,Deployability,update,update,242,"Dear Jakelishman and BoxiLi,. Thanks a lot for your reply. I still get incorrect results from using QobjEvo for my Hamiltonian and then use only the initial and final time in the mesolve. I am still working on how to solve this problem. Will update you with the results.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-812258761
https://github.com/qutip/qutip/issues/1472#issuecomment-819524720:259,Modifiability,variab,variable,259,"Dear qutip admin,. If I wrote the Hamiltonian in terms of analytic function (Hanalytic and Hanayticevo as shown below), I got different answers from using the discretized Hamiltonian obtained by providing the list of Hamiltonian values at discrete times (the variable H) as used previously. May I know how to rectify this problem? Below is the code. ```; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); omegalist = 2.91e2*fast_ts ; fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * omegalist * fast_ts); bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]); Hanalytic = [[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']] # New line; Hanalyticevo = qutip.QobjEvo([[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']],tlist=fast_ts) # New line; H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options); analytics = qutip.mesolve(Hanalytic, rho, fast_ts, e_ops=e_ops, options=options) # New line; analyticsevo = qutip.mesolve(Hanalyticevo, rho, times, e_ops=e_ops, options=options) # New line; assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; print(analytics.expect[0][-1]) # 0.00022501347976357222; print(analyticsevo.expect[0][-1]) # 0.0002250044242251665. ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819524720
https://github.com/qutip/qutip/issues/1472#issuecomment-819524720:1439,Testability,assert,assert,1439,"Dear qutip admin,. If I wrote the Hamiltonian in terms of analytic function (Hanalytic and Hanayticevo as shown below), I got different answers from using the discretized Hamiltonian obtained by providing the list of Hamiltonian values at discrete times (the variable H) as used previously. May I know how to rectify this problem? Below is the code. ```; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); omegalist = 2.91e2*fast_ts ; fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * omegalist * fast_ts); bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]); Hanalytic = [[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']] # New line; Hanalyticevo = qutip.QobjEvo([[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']],tlist=fast_ts) # New line; H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options); analytics = qutip.mesolve(Hanalytic, rho, fast_ts, e_ops=e_ops, options=options) # New line; analyticsevo = qutip.mesolve(Hanalyticevo, rho, times, e_ops=e_ops, options=options) # New line; assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; print(analytics.expect[0][-1]) # 0.00022501347976357222; print(analyticsevo.expect[0][-1]) # 0.0002250044242251665. ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819524720
https://github.com/qutip/qutip/issues/1472#issuecomment-819524720:1477,Testability,assert,assert,1477,"Dear qutip admin,. If I wrote the Hamiltonian in terms of analytic function (Hanalytic and Hanayticevo as shown below), I got different answers from using the discretized Hamiltonian obtained by providing the list of Hamiltonian values at discrete times (the variable H) as used previously. May I know how to rectify this problem? Below is the code. ```; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); omegalist = 2.91e2*fast_ts ; fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * omegalist * fast_ts); bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]); Hanalytic = [[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']] # New line; Hanalyticevo = qutip.QobjEvo([[qutip.sigmax(),'2.9e3*pi*cos(2*pi*2.91e2*t**2)']],tlist=fast_ts) # New line; H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options); analytics = qutip.mesolve(Hanalytic, rho, fast_ts, e_ops=e_ops, options=options) # New line; analyticsevo = qutip.mesolve(Hanalyticevo, rho, times, e_ops=e_ops, options=options) # New line; assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # -0.59736575; print(many_times.expect[0][-1]) # -0.59736575; print(bad_times.expect[0][-1]) # -4.5466086e-08; print(analytics.expect[0][-1]) # 0.00022501347976357222; print(analyticsevo.expect[0][-1]) # 0.0002250044242251665. ```",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819524720
https://github.com/qutip/qutip/issues/1472#issuecomment-819549136:1171,Testability,assert,assert,1171,"Dear Jakelishman. Thank you for your answer. I have changed omega to 1 and still they do not give the same results. ```; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); omegalist = 1; fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * omegalist * fast_ts); bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]); Hanalytic = [[qutip.sigmax(),'2.9e3*pi*cos(2*pi*t)']] # New line; Hanalyticevo = qutip.QobjEvo([[qutip.sigmax(),'2.9e3*pi*cos(2*pi*t)']],tlist=fast_ts) # New line; H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options); analytics = qutip.mesolve(Hanalytic, rho, fast_ts, e_ops=e_ops, options=options) # New line; analyticsevo = qutip.mesolve(Hanalyticevo, rho, times, e_ops=e_ops, options=options) # New line; assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # 3.461676142752336e-05; print(many_times.expect[0][-1]) # 3.4618129999061035e-05; print(bad_times.expect[0][-1]) # -4.546608598637869e-08; print(analytics.expect[0][-1]) # 1.5660042880505376e-09; print(analyticsevo.expect[0][-1]) # -1.0166655253773804e-08",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819549136
https://github.com/qutip/qutip/issues/1472#issuecomment-819549136:1209,Testability,assert,assert,1209,"Dear Jakelishman. Thank you for your answer. I have changed omega to 1 and still they do not give the same results. ```; import qutip; import numpy as np. fast_ts = np.linspace(0, 1, 1001); omegalist = 1; fast_xs = 2.9e3*np.pi * np.cos(2*np.pi * omegalist * fast_ts); bad_interpolation_xs = np.array([fast_xs[0], fast_xs[-1]]); Hanalytic = [[qutip.sigmax(),'2.9e3*pi*cos(2*pi*t)']] # New line; Hanalyticevo = qutip.QobjEvo([[qutip.sigmax(),'2.9e3*pi*cos(2*pi*t)']],tlist=fast_ts) # New line; H = qutip.QobjEvo([[qutip.sigmax(), fast_xs]], tlist=fast_ts); H_bad = [[qutip.sigmax(), bad_interpolation_xs]]; rho = qutip.basis(2, 0).proj(); times = np.array([0., 1]); e_ops = [qutip.sigmay()]; options = qutip.Options(nsteps=10_000_000, atol=1e-14, rtol=1e-12). two_times = qutip.mesolve(H, rho, times, e_ops=e_ops, options=options); many_times = qutip.mesolve(H, rho, fast_ts, e_ops=e_ops, options=options); bad_times = qutip.mesolve(H_bad, rho, times, e_ops=e_ops, options=options); analytics = qutip.mesolve(Hanalytic, rho, fast_ts, e_ops=e_ops, options=options) # New line; analyticsevo = qutip.mesolve(Hanalyticevo, rho, times, e_ops=e_ops, options=options) # New line; assert len(two_times.expect[0]) == 2; assert len(many_times.expect[0]) == 1001. print(two_times.expect[0][-1]) # 3.461676142752336e-05; print(many_times.expect[0][-1]) # 3.4618129999061035e-05; print(bad_times.expect[0][-1]) # -4.546608598637869e-08; print(analytics.expect[0][-1]) # 1.5660042880505376e-09; print(analyticsevo.expect[0][-1]) # -1.0166655253773804e-08",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819549136
https://github.com/qutip/qutip/issues/1472#issuecomment-819560261:29,Availability,error,error,29,"Those do match. The absolute error is ~3.5e-5, which is the same as the error made in interpolating this particular cosine function with 1000 points. So again this comes down to considering the error inherent in making an interpolation, like I said in the previous comment.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819560261
https://github.com/qutip/qutip/issues/1472#issuecomment-819560261:72,Availability,error,error,72,"Those do match. The absolute error is ~3.5e-5, which is the same as the error made in interpolating this particular cosine function with 1000 points. So again this comes down to considering the error inherent in making an interpolation, like I said in the previous comment.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819560261
https://github.com/qutip/qutip/issues/1472#issuecomment-819560261:170,Availability,down,down,170,"Those do match. The absolute error is ~3.5e-5, which is the same as the error made in interpolating this particular cosine function with 1000 points. So again this comes down to considering the error inherent in making an interpolation, like I said in the previous comment.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819560261
https://github.com/qutip/qutip/issues/1472#issuecomment-819560261:194,Availability,error,error,194,"Those do match. The absolute error is ~3.5e-5, which is the same as the error made in interpolating this particular cosine function with 1000 points. So again this comes down to considering the error inherent in making an interpolation, like I said in the previous comment.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1472#issuecomment-819560261
https://github.com/qutip/qutip/issues/1473#issuecomment-808841158:40,Availability,down,download,40,Thank you for your reply. I used pip to download the qutip and the version of qutip is 4.5.3,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1473#issuecomment-808841158
https://github.com/qutip/qutip/issues/1473#issuecomment-808873718:163,Deployability,release,release,163,"QuTiP 4.5.3 doesn't support M1 Macs, sorry. None of us has access to one to test, and our CI didn't support them for quite a while. This will be fixed in the next release of QuTiP. In the meantime, you can either build the package from the current source code here, or you can go into your QuTiP installation folder and comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1473#issuecomment-808873718
https://github.com/qutip/qutip/issues/1473#issuecomment-808873718:296,Deployability,install,installation,296,"QuTiP 4.5.3 doesn't support M1 Macs, sorry. None of us has access to one to test, and our CI didn't support them for quite a while. This will be fixed in the next release of QuTiP. In the meantime, you can either build the package from the current source code here, or you can go into your QuTiP installation folder and comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1473#issuecomment-808873718
https://github.com/qutip/qutip/issues/1473#issuecomment-808873718:59,Security,access,access,59,"QuTiP 4.5.3 doesn't support M1 Macs, sorry. None of us has access to one to test, and our CI didn't support them for quite a while. This will be fixed in the next release of QuTiP. In the meantime, you can either build the package from the current source code here, or you can go into your QuTiP installation folder and comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1473#issuecomment-808873718
https://github.com/qutip/qutip/issues/1473#issuecomment-808873718:76,Testability,test,test,76,"QuTiP 4.5.3 doesn't support M1 Macs, sorry. None of us has access to one to test, and our CI didn't support them for quite a while. This will be fixed in the next release of QuTiP. In the meantime, you can either build the package from the current source code here, or you can go into your QuTiP installation folder and comment out lines 48 and 49 of `qutip/hardware_info.py` to work around it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1473#issuecomment-808873718
https://github.com/qutip/qutip/pull/1475#issuecomment-809358328:240,Testability,test,test,240,[![Coverage Status](https://coveralls.io/builds/38335889/badge)](https://coveralls.io/builds/38335889). Coverage decreased (-0.009%) to 63.606% when pulling **c9f77423a47ebfc967f20da7c147652ba24bb54d on jakelishman:fix-vector-operator-dims-test** into **da1f08226b078e528651b202033a107ebbb7925a on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1475#issuecomment-809358328
https://github.com/qutip/qutip/pull/1478#issuecomment-811949743:17,Availability,failure,failure,17,"The current test failure is unrelated and not your fault. It's everyone's favourite `dnorm` again, and it's not because of any _new_ problems with it, it's just because we recently re-enabled the `dnorm` tests (see #1463) that had been lying dormant due to a problem in how they were written when we swapped to `pytest` as our runner.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-811949743
https://github.com/qutip/qutip/pull/1478#issuecomment-811949743:51,Availability,fault,fault,51,"The current test failure is unrelated and not your fault. It's everyone's favourite `dnorm` again, and it's not because of any _new_ problems with it, it's just because we recently re-enabled the `dnorm` tests (see #1463) that had been lying dormant due to a problem in how they were written when we swapped to `pytest` as our runner.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-811949743
https://github.com/qutip/qutip/pull/1478#issuecomment-811949743:12,Testability,test,test,12,"The current test failure is unrelated and not your fault. It's everyone's favourite `dnorm` again, and it's not because of any _new_ problems with it, it's just because we recently re-enabled the `dnorm` tests (see #1463) that had been lying dormant due to a problem in how they were written when we swapped to `pytest` as our runner.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-811949743
https://github.com/qutip/qutip/pull/1478#issuecomment-811949743:204,Testability,test,tests,204,"The current test failure is unrelated and not your fault. It's everyone's favourite `dnorm` again, and it's not because of any _new_ problems with it, it's just because we recently re-enabled the `dnorm` tests (see #1463) that had been lying dormant due to a problem in how they were written when we swapped to `pytest` as our runner.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-811949743
https://github.com/qutip/qutip/pull/1478#issuecomment-812849410:332,Availability,error,error,332,"> Given that this PR is to fix a particular bug in `correlation`, please could you also add a reproduction for the bug in #1460 in order to ensure that it truly is fixed (I see no reason it shouldn't be from this), and to make sure that we catch any possible regressions in the future?. I modified test_correlation.py to catch this error. It was previously using a non-Hermitian expectation operator which is why it did not raise an error. I changed it to use an Hermitian operator. This means it would fail the test without the fix in mesolve. . However, I wonder now if the test should check for both Hermitian and non-Hermitian expectation operators. I did not add both tests because I did not want to make it slower. Should I make it to cover both cases?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-812849410
https://github.com/qutip/qutip/pull/1478#issuecomment-812849410:433,Availability,error,error,433,"> Given that this PR is to fix a particular bug in `correlation`, please could you also add a reproduction for the bug in #1460 in order to ensure that it truly is fixed (I see no reason it shouldn't be from this), and to make sure that we catch any possible regressions in the future?. I modified test_correlation.py to catch this error. It was previously using a non-Hermitian expectation operator which is why it did not raise an error. I changed it to use an Hermitian operator. This means it would fail the test without the fix in mesolve. . However, I wonder now if the test should check for both Hermitian and non-Hermitian expectation operators. I did not add both tests because I did not want to make it slower. Should I make it to cover both cases?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-812849410
https://github.com/qutip/qutip/pull/1478#issuecomment-812849410:512,Testability,test,test,512,"> Given that this PR is to fix a particular bug in `correlation`, please could you also add a reproduction for the bug in #1460 in order to ensure that it truly is fixed (I see no reason it shouldn't be from this), and to make sure that we catch any possible regressions in the future?. I modified test_correlation.py to catch this error. It was previously using a non-Hermitian expectation operator which is why it did not raise an error. I changed it to use an Hermitian operator. This means it would fail the test without the fix in mesolve. . However, I wonder now if the test should check for both Hermitian and non-Hermitian expectation operators. I did not add both tests because I did not want to make it slower. Should I make it to cover both cases?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-812849410
https://github.com/qutip/qutip/pull/1478#issuecomment-812849410:576,Testability,test,test,576,"> Given that this PR is to fix a particular bug in `correlation`, please could you also add a reproduction for the bug in #1460 in order to ensure that it truly is fixed (I see no reason it shouldn't be from this), and to make sure that we catch any possible regressions in the future?. I modified test_correlation.py to catch this error. It was previously using a non-Hermitian expectation operator which is why it did not raise an error. I changed it to use an Hermitian operator. This means it would fail the test without the fix in mesolve. . However, I wonder now if the test should check for both Hermitian and non-Hermitian expectation operators. I did not add both tests because I did not want to make it slower. Should I make it to cover both cases?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-812849410
https://github.com/qutip/qutip/pull/1478#issuecomment-812849410:673,Testability,test,tests,673,"> Given that this PR is to fix a particular bug in `correlation`, please could you also add a reproduction for the bug in #1460 in order to ensure that it truly is fixed (I see no reason it shouldn't be from this), and to make sure that we catch any possible regressions in the future?. I modified test_correlation.py to catch this error. It was previously using a non-Hermitian expectation operator which is why it did not raise an error. I changed it to use an Hermitian operator. This means it would fail the test without the fix in mesolve. . However, I wonder now if the test should check for both Hermitian and non-Hermitian expectation operators. I did not add both tests because I did not want to make it slower. Should I make it to cover both cases?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-812849410
https://github.com/qutip/qutip/pull/1478#issuecomment-813359081:663,Availability,robust,robust,663,"I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; ` c_ops = [np.sqrt(G1 * (n_th+1)) * a,; np.sqrt(G1 * n_th) * a.dag()]; `; However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). The new test for `correlation_2op_1t` should be very robust as it tests for a lot of different scenarios, including the one presented in #1460. I was wondering whether these were too many cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813359081
https://github.com/qutip/qutip/pull/1478#issuecomment-813359081:10,Testability,test,test,10,"I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; ` c_ops = [np.sqrt(G1 * (n_th+1)) * a,; np.sqrt(G1 * n_th) * a.dag()]; `; However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). The new test for `correlation_2op_1t` should be very robust as it tests for a lot of different scenarios, including the one presented in #1460. I was wondering whether these were too many cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813359081
https://github.com/qutip/qutip/pull/1478#issuecomment-813359081:124,Testability,test,test,124,"I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; ` c_ops = [np.sqrt(G1 * (n_th+1)) * a,; np.sqrt(G1 * n_th) * a.dag()]; `; However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). The new test for `correlation_2op_1t` should be very robust as it tests for a lot of different scenarios, including the one presented in #1460. I was wondering whether these were too many cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813359081
https://github.com/qutip/qutip/pull/1478#issuecomment-813359081:618,Testability,test,test,618,"I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; ` c_ops = [np.sqrt(G1 * (n_th+1)) * a,; np.sqrt(G1 * n_th) * a.dag()]; `; However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). The new test for `correlation_2op_1t` should be very robust as it tests for a lot of different scenarios, including the one presented in #1460. I was wondering whether these were too many cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813359081
https://github.com/qutip/qutip/pull/1478#issuecomment-813359081:676,Testability,test,tests,676,"I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; ` c_ops = [np.sqrt(G1 * (n_th+1)) * a,; np.sqrt(G1 * n_th) * a.dag()]; `; However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). The new test for `correlation_2op_1t` should be very robust as it tests for a lot of different scenarios, including the one presented in #1460. I was wondering whether these were too many cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813359081
https://github.com/qutip/qutip/pull/1478#issuecomment-813959317:829,Availability,toler,tolerance,829,"> I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; > ` c_ops = [np.sqrt(G1 * (n_th+1)) * a, np.sqrt(G1 * n_th) * a.dag()]`; > However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). I did a quick test and it seemed ok upto about n_th = 1 for N=20 and an atol of 2e-5. ; as an aside, I guess some minimal condition here is that the thermal occupation of the cut-off state should be smaller than the tolerance, which i guess you can get out of the analytic expression for the thermal state. maybe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813959317
https://github.com/qutip/qutip/pull/1478#issuecomment-813959317:12,Testability,test,test,12,"> I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; > ` c_ops = [np.sqrt(G1 * (n_th+1)) * a, np.sqrt(G1 * n_th) * a.dag()]`; > However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). I did a quick test and it seemed ok upto about n_th = 1 for N=20 and an atol of 2e-5. ; as an aside, I guess some minimal condition here is that the thermal occupation of the cut-off state should be smaller than the tolerance, which i guess you can get out of the analytic expression for the thermal state. maybe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813959317
https://github.com/qutip/qutip/pull/1478#issuecomment-813959317:126,Testability,test,test,126,"> I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; > ` c_ops = [np.sqrt(G1 * (n_th+1)) * a, np.sqrt(G1 * n_th) * a.dag()]`; > However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). I did a quick test and it seemed ok upto about n_th = 1 for N=20 and an atol of 2e-5. ; as an aside, I guess some minimal condition here is that the thermal occupation of the cut-off state should be smaller than the tolerance, which i guess you can get out of the analytic expression for the thermal state. maybe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813959317
https://github.com/qutip/qutip/pull/1478#issuecomment-813959317:627,Testability,test,test,627,"> I added a test that compares `correlation_2op_1t` to its analytical solution. I was trying to match the `c_ops` of this new test to the ones appearing in `test_correlation_solver_equivalence`, which are:; > ` c_ops = [np.sqrt(G1 * (n_th+1)) * a, np.sqrt(G1 * n_th) * a.dag()]`; > However, the analytical solution I obtained for this case did not work unless I used a very small value for `n_th = 0.1`. I was wondering whether the analytical solution I got was wrong or whether this actually makes sense. I was thinking that the difference probably comes from the cut we use for the number of states (`N = 20`). I did a quick test and it seemed ok upto about n_th = 1 for N=20 and an atol of 2e-5. ; as an aside, I guess some minimal condition here is that the thermal occupation of the cut-off state should be smaller than the tolerance, which i guess you can get out of the analytic expression for the thermal state. maybe.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-813959317
https://github.com/qutip/qutip/pull/1478#issuecomment-815021669:572,Availability,toler,tolerance,572,"In theory the `correlation_2op_1t` function is only valid when you pass in the steady state solution of the Liouvillian. However, we implement it just by calculating `<A(t) B(0)>` - it's not _immediately_ clear to me that that our output is necessarily correct when you don't pass in a steadystate (especially if `taulist` doesn't start from 0). I _think_ it's fine in all cases, but perhaps Neill you can check me on that front?. I'd agree with Neill that truncation of the thermal state basis is likely the reason you were failing to get that to work exactly right. The tolerance calculation will actually be a bit more involved because QuTiP returns a normed dm. That will cause all the values to shift by relatively the same amount, and then you've got to factor in the solver tolerance on top of those errors, but the principle is correct for sure. *edit*: I'm happy and ready to merge this, but I'll just hold off for a day or so in case Neill has chance to answer my last minor query.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-815021669
https://github.com/qutip/qutip/pull/1478#issuecomment-815021669:781,Availability,toler,tolerance,781,"In theory the `correlation_2op_1t` function is only valid when you pass in the steady state solution of the Liouvillian. However, we implement it just by calculating `<A(t) B(0)>` - it's not _immediately_ clear to me that that our output is necessarily correct when you don't pass in a steadystate (especially if `taulist` doesn't start from 0). I _think_ it's fine in all cases, but perhaps Neill you can check me on that front?. I'd agree with Neill that truncation of the thermal state basis is likely the reason you were failing to get that to work exactly right. The tolerance calculation will actually be a bit more involved because QuTiP returns a normed dm. That will cause all the values to shift by relatively the same amount, and then you've got to factor in the solver tolerance on top of those errors, but the principle is correct for sure. *edit*: I'm happy and ready to merge this, but I'll just hold off for a day or so in case Neill has chance to answer my last minor query.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-815021669
https://github.com/qutip/qutip/pull/1478#issuecomment-815021669:807,Availability,error,errors,807,"In theory the `correlation_2op_1t` function is only valid when you pass in the steady state solution of the Liouvillian. However, we implement it just by calculating `<A(t) B(0)>` - it's not _immediately_ clear to me that that our output is necessarily correct when you don't pass in a steadystate (especially if `taulist` doesn't start from 0). I _think_ it's fine in all cases, but perhaps Neill you can check me on that front?. I'd agree with Neill that truncation of the thermal state basis is likely the reason you were failing to get that to work exactly right. The tolerance calculation will actually be a bit more involved because QuTiP returns a normed dm. That will cause all the values to shift by relatively the same amount, and then you've got to factor in the solver tolerance on top of those errors, but the principle is correct for sure. *edit*: I'm happy and ready to merge this, but I'll just hold off for a day or so in case Neill has chance to answer my last minor query.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-815021669
https://github.com/qutip/qutip/pull/1478#issuecomment-815021669:205,Usability,clear,clear,205,"In theory the `correlation_2op_1t` function is only valid when you pass in the steady state solution of the Liouvillian. However, we implement it just by calculating `<A(t) B(0)>` - it's not _immediately_ clear to me that that our output is necessarily correct when you don't pass in a steadystate (especially if `taulist` doesn't start from 0). I _think_ it's fine in all cases, but perhaps Neill you can check me on that front?. I'd agree with Neill that truncation of the thermal state basis is likely the reason you were failing to get that to work exactly right. The tolerance calculation will actually be a bit more involved because QuTiP returns a normed dm. That will cause all the values to shift by relatively the same amount, and then you've got to factor in the solver tolerance on top of those errors, but the principle is correct for sure. *edit*: I'm happy and ready to merge this, but I'll just hold off for a day or so in case Neill has chance to answer my last minor query.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-815021669
https://github.com/qutip/qutip/pull/1478#issuecomment-816312032:67,Deployability,release,release,67,"Ok, I'm going to merge this now because I'm gearing up for the 4.6 release and I want to include this bugfix.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1478#issuecomment-816312032
https://github.com/qutip/qutip/pull/1480#issuecomment-811934830:23,Availability,failure,failure,23,"So this test has had a failure in `test_diag_liou_mult` again, despite the merging of #1474. I still believe the fix in that issue is correct in principle, but I'll investigate in more detail to determine the tightest allowable tolerances in another issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-811934830
https://github.com/qutip/qutip/pull/1480#issuecomment-811934830:228,Availability,toler,tolerances,228,"So this test has had a failure in `test_diag_liou_mult` again, despite the merging of #1474. I still believe the fix in that issue is correct in principle, but I'll investigate in more detail to determine the tightest allowable tolerances in another issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-811934830
https://github.com/qutip/qutip/pull/1480#issuecomment-811934830:8,Testability,test,test,8,"So this test has had a failure in `test_diag_liou_mult` again, despite the merging of #1474. I still believe the fix in that issue is correct in principle, but I'll investigate in more detail to determine the tightest allowable tolerances in another issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-811934830
https://github.com/qutip/qutip/pull/1480#issuecomment-814036449:596,Testability,test,tests,596,"Ahh, you're right. I never managed to get it to work right before now, but I just tried again and managed to get `DeprecationWarning` to show up in all of `python warn.py`, direct calls from the IPython terminal and from Jupyter notebooks. I think perhaps I learned about stacklevel _after_ the last time I tried to get that to work. My reading of the docs before that had always just ended up with me assuming that somebody using a library interactively was an ""end-user"", so `FutureWarning` was appropriate. I'll change this PR when I've got time - I needed to fix up a few warning controls in tests before it was ready anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814036449
https://github.com/qutip/qutip/pull/1480#issuecomment-814036449:258,Usability,learn,learned,258,"Ahh, you're right. I never managed to get it to work right before now, but I just tried again and managed to get `DeprecationWarning` to show up in all of `python warn.py`, direct calls from the IPython terminal and from Jupyter notebooks. I think perhaps I learned about stacklevel _after_ the last time I tried to get that to work. My reading of the docs before that had always just ended up with me assuming that somebody using a library interactively was an ""end-user"", so `FutureWarning` was appropriate. I'll change this PR when I've got time - I needed to fix up a few warning controls in tests before it was ready anyway.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814036449
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:111,Deployability,release,release,111,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:737,Deployability,release,release,737,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:945,Deployability,update,updated,945,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:1102,Deployability,release,release,1102,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:869,Energy Efficiency,schedul,scheduler,869,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:621,Integrability,wrap,wrap,621,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814937234:223,Security,access,accessible,223,"@Ericgig @hodgestar, Eric and Simon: unless there's anything else that springs to mind, I'll pencil in the 4.6 release for later this week/weekend after this is merged to `master`?. Simon in particular: there's a couple of accessible places in `correlation` that make deprecated `ode2es` calls. That particular functionality of the solvers isn't being removed in 5.0 (though maybe it should - `mesolve` is faster and better in almost every way), so they aren't themselves deprecated. Right now they don't trigger `DeprecationWarning` popups if a user calls them (since the stacklevel is 2). Despite that, should I _also_ wrap them in a warning filter to catch it? I don't really know best practices here. I kept postponing doing the 4.6 release because I'd keep thinking of little bits and bobs that I thought should go in, but at this point Boxi's (@BoxiLi) new pulse scheduler stuff is in and ready, the packaging and distribution methods are updated, and we'll have issued deprecation warnings for the things that we know are being removed. Anything beyond this can start to form the basis of a 4.7 release in a few months' time, with the Floquet changes (they might be waiting on me at the moment) and possibly some new stuff out of GSoC. Possibly that'll also include some deprecation warnings and other bits and bobs to do with packages getting moved out of qutip/qutip, and the changes to how the data-layer is going to work.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814937234
https://github.com/qutip/qutip/pull/1480#issuecomment-814963433:140,Deployability,release,release,140,Go for it. I am curious to see how it will go with the new distribution method. If it works well it will encourage us to make more frequent release.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-814963433
https://github.com/qutip/qutip/pull/1480#issuecomment-815311257:34,Integrability,wrap,wrapping,34,@jakelishman I would vote for not wrapping them right now. We should stop using `ode2es` from the correlation functions (or continue to use it but no longer expose it to users). The DeprecationWarnings will hopefully help remind us to do that.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-815311257
https://github.com/qutip/qutip/pull/1480#issuecomment-815311257:157,Security,expose,expose,157,@jakelishman I would vote for not wrapping them right now. We should stop using `ode2es` from the correlation functions (or continue to use it but no longer expose it to users). The DeprecationWarnings will hopefully help remind us to do that.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-815311257
https://github.com/qutip/qutip/pull/1480#issuecomment-815320632:280,Testability,log,logic,280,"The change to ""not"" using `ode2es` in the correlation functions is already in `dev.major` (it basically absorbs the few working parts of `ode2es` into a private function in `qutip.correlation`), so my plan had just been to leave the file as-is until that's merged to `master`. My logic in that just feels a bit questionable though, hence my asking.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-815320632
https://github.com/qutip/qutip/pull/1480#issuecomment-815581980:213,Safety,avoid,avoids,213,@jakelishman Leaving it as is sounds fine to me. Deprecation warnings are filtered out by default when running Python scripts these days (unless one runs with `-X dev`) so that and the notebook filtering probably avoids the majority of cases where someone will be annoyed or confused by the warnings.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1480#issuecomment-815581980
https://github.com/qutip/qutip/pull/1481#issuecomment-815141272:168,Safety,risk,risk,168,"About pickling. `QobjEvo` doesn't contain any cython only data and cython autopickling is working fine.; There is a test for it. (But not for windows, there is still a risk there).; But function used in `linear_map` or in coefficient etc. may cause problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-815141272
https://github.com/qutip/qutip/pull/1481#issuecomment-815141272:116,Testability,test,test,116,"About pickling. `QobjEvo` doesn't contain any cython only data and cython autopickling is working fine.; There is a test for it. (But not for windows, there is still a risk there).; But function used in `linear_map` or in coefficient etc. may cause problem.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-815141272
https://github.com/qutip/qutip/pull/1481#issuecomment-817018631:655,Availability,avail,available,655,"I made the change for immutable `Coefficient` and `_Elements`. ; `replace` is about 200ns slower than the previous inplace `arguments`.; With `_Elements` 'immutable', `QobjEvo.copy`'s default is to do a shallow copy of the `elements` list. ; The `_BaseElement._call` is not returning the (data, coeff) pair, but stores it to save on time to create of a python object.; This it may not safe with threading: if 2 copies of a `QobjEvo` are called at the same time with different `t`, both could return the same result. I am not sure how good is the GIL in this case.; I don't expect it to be an issue, in the rare case threading would be used, a deepcopy is available with `QobjEvo.copy(deepcopy=True)`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-817018631
https://github.com/qutip/qutip/pull/1481#issuecomment-817018631:385,Safety,safe,safe,385,"I made the change for immutable `Coefficient` and `_Elements`. ; `replace` is about 200ns slower than the previous inplace `arguments`.; With `_Elements` 'immutable', `QobjEvo.copy`'s default is to do a shallow copy of the `elements` list. ; The `_BaseElement._call` is not returning the (data, coeff) pair, but stores it to save on time to create of a python object.; This it may not safe with threading: if 2 copies of a `QobjEvo` are called at the same time with different `t`, both could return the same result. I am not sure how good is the GIL in this case.; I don't expect it to be an issue, in the rare case threading would be used, a deepcopy is available with `QobjEvo.copy(deepcopy=True)`.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-817018631
https://github.com/qutip/qutip/pull/1481#issuecomment-822817122:797,Integrability,depend,dependent,797,"I've lost the plot a bit with a whole load of changes to `Coefficient` now merged into this PR. Is there a chance we can split that out into its own PR?. I would expect `QobjEvo.__call__` to be thread-safe/re-entrant. The fact that coefficients seemingly don't support this immediately is worrying to me. A simple call like that changing ""global"" state of the object is dangerous; it has a habit of leaking out even in single-threaded applications, just like the bug I described previously with a call to `mesolve` modifying an existing `QobjEvo` in place. In this case I don't see an immediate bug, but it's very non-obvious behaviour and it would be easy to accidentally introduce one in it in the future (or maybe I just can't think of one now). Having `_BaseElement` be mutable makes all time-dependent operations of `QobjEvo` unresolvably thread-unsafe without copying on every operation. That said, looking again, I'm not sure I understand `_BaseElement`: it seems like `_EvoElement` and `_FuncElement` do entirely different things on `call`? What's the purpose of it, and if we put all speed considerations aside what would the signature and behaviour of `_BaseElement._call` be?. Could you write some docstrings on all the elements to explain their use-cases as well, so we've got it all stored for the future?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822817122
https://github.com/qutip/qutip/pull/1481#issuecomment-822817122:38,Performance,load,load,38,"I've lost the plot a bit with a whole load of changes to `Coefficient` now merged into this PR. Is there a chance we can split that out into its own PR?. I would expect `QobjEvo.__call__` to be thread-safe/re-entrant. The fact that coefficients seemingly don't support this immediately is worrying to me. A simple call like that changing ""global"" state of the object is dangerous; it has a habit of leaking out even in single-threaded applications, just like the bug I described previously with a call to `mesolve` modifying an existing `QobjEvo` in place. In this case I don't see an immediate bug, but it's very non-obvious behaviour and it would be easy to accidentally introduce one in it in the future (or maybe I just can't think of one now). Having `_BaseElement` be mutable makes all time-dependent operations of `QobjEvo` unresolvably thread-unsafe without copying on every operation. That said, looking again, I'm not sure I understand `_BaseElement`: it seems like `_EvoElement` and `_FuncElement` do entirely different things on `call`? What's the purpose of it, and if we put all speed considerations aside what would the signature and behaviour of `_BaseElement._call` be?. Could you write some docstrings on all the elements to explain their use-cases as well, so we've got it all stored for the future?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822817122
https://github.com/qutip/qutip/pull/1481#issuecomment-822817122:201,Safety,safe,safe,201,"I've lost the plot a bit with a whole load of changes to `Coefficient` now merged into this PR. Is there a chance we can split that out into its own PR?. I would expect `QobjEvo.__call__` to be thread-safe/re-entrant. The fact that coefficients seemingly don't support this immediately is worrying to me. A simple call like that changing ""global"" state of the object is dangerous; it has a habit of leaking out even in single-threaded applications, just like the bug I described previously with a call to `mesolve` modifying an existing `QobjEvo` in place. In this case I don't see an immediate bug, but it's very non-obvious behaviour and it would be easy to accidentally introduce one in it in the future (or maybe I just can't think of one now). Having `_BaseElement` be mutable makes all time-dependent operations of `QobjEvo` unresolvably thread-unsafe without copying on every operation. That said, looking again, I'm not sure I understand `_BaseElement`: it seems like `_EvoElement` and `_FuncElement` do entirely different things on `call`? What's the purpose of it, and if we put all speed considerations aside what would the signature and behaviour of `_BaseElement._call` be?. Could you write some docstrings on all the elements to explain their use-cases as well, so we've got it all stored for the future?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822817122
https://github.com/qutip/qutip/pull/1481#issuecomment-822817122:851,Safety,unsafe,unsafe,851,"I've lost the plot a bit with a whole load of changes to `Coefficient` now merged into this PR. Is there a chance we can split that out into its own PR?. I would expect `QobjEvo.__call__` to be thread-safe/re-entrant. The fact that coefficients seemingly don't support this immediately is worrying to me. A simple call like that changing ""global"" state of the object is dangerous; it has a habit of leaking out even in single-threaded applications, just like the bug I described previously with a call to `mesolve` modifying an existing `QobjEvo` in place. In this case I don't see an immediate bug, but it's very non-obvious behaviour and it would be easy to accidentally introduce one in it in the future (or maybe I just can't think of one now). Having `_BaseElement` be mutable makes all time-dependent operations of `QobjEvo` unresolvably thread-unsafe without copying on every operation. That said, looking again, I'm not sure I understand `_BaseElement`: it seems like `_EvoElement` and `_FuncElement` do entirely different things on `call`? What's the purpose of it, and if we put all speed considerations aside what would the signature and behaviour of `_BaseElement._call` be?. Could you write some docstrings on all the elements to explain their use-cases as well, so we've got it all stored for the future?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822817122
https://github.com/qutip/qutip/pull/1481#issuecomment-822817122:307,Usability,simpl,simple,307,"I've lost the plot a bit with a whole load of changes to `Coefficient` now merged into this PR. Is there a chance we can split that out into its own PR?. I would expect `QobjEvo.__call__` to be thread-safe/re-entrant. The fact that coefficients seemingly don't support this immediately is worrying to me. A simple call like that changing ""global"" state of the object is dangerous; it has a habit of leaking out even in single-threaded applications, just like the bug I described previously with a call to `mesolve` modifying an existing `QobjEvo` in place. In this case I don't see an immediate bug, but it's very non-obvious behaviour and it would be easy to accidentally introduce one in it in the future (or maybe I just can't think of one now). Having `_BaseElement` be mutable makes all time-dependent operations of `QobjEvo` unresolvably thread-unsafe without copying on every operation. That said, looking again, I'm not sure I understand `_BaseElement`: it seems like `_EvoElement` and `_FuncElement` do entirely different things on `call`? What's the purpose of it, and if we put all speed considerations aside what would the signature and behaviour of `_BaseElement._call` be?. Could you write some docstrings on all the elements to explain their use-cases as well, so we've got it all stored for the future?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822817122
https://github.com/qutip/qutip/pull/1481#issuecomment-822857273:523,Integrability,depend,dependant,523,"I can move a part of the changes in coefficient to another PR, but not all of them.; I removed `shift` and `norm` from `Coefficient`, they become unused only with the new `QobjEvo`.; I will move the immutable `Coefficient` changes to another PR. The signature of `_BaseElement._call` would be `cdef (double complex, Qobj) _call(self, double t, dict function_qobj)`.; `_EvoElement` would return `(coefficient(t), qobj)` with `qobj` fixed.; `_FuncElement` would return `(1., func(t, args))` with `func` a function based time dependant system.; I also keep a copy of the `Data` instead of reading it from the `Qobj` each time, since it's a python object. For example, in `expect` I do:; ```; element._call(t, ...); out += expect(element.data, state) * element.coeff; ```; If another call to `_call` arrive between the commands, the output would be wrong.; But this call all be solved by splitting `_call`...; `out += expect(element.data(t, ...), state) * element.coeff(t, ...)`",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-822857273
https://github.com/qutip/qutip/pull/1481#issuecomment-825047432:62,Safety,safe,safe,62,"I moved the Coefficient changes to #1507, all should be thead-safe and _[...]Element are better documented.; #1507 should be merged before this.; The commit history somewhat a mess... I suggest squash and merge.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-825047432
https://github.com/qutip/qutip/pull/1481#issuecomment-861615917:33,Testability,test,testing,33,"I've just made #1574 to move our testing to Travis. This will cause a merge conflict in `setup.py` for you when it's merged, but I think that will be the only conflict - you should be able to rebase on top cleanly. The reason for the conflict is because the ""new"" (`master`) `setup.py` discovers all the Cython modules to be compiled, and doesn't need to have them specified, so you shouldn't actually need to make any changes to it to have it work correctly.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-861615917
https://github.com/qutip/qutip/pull/1481#issuecomment-890217983:75,Deployability,Update,Update,75,@Ericgig Thanks for the changes! The only outstanding comments now are:. * Update comment on _expect_dense.; * Apply my docstring suggestion for the new tlist function (if you like the suggestion); * Resolve merge conflicts (not sure how those crept in -- maybe the license change -- hopefully nothing serious). And then I think we can merge! :D,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1481#issuecomment-890217983
https://github.com/qutip/qutip/issues/1482#issuecomment-814921274:268,Deployability,release,release,268,"You can compute the propagator with `mesolve` by passing it an identity matrix as the input state: ; `U = qutip.mesolve(H, qutip.qeye(H.dims), times, options=options).states`. `QobjEvo` should be supported by `propagator`, I will add it to my to-do for the next major release.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1482#issuecomment-814921274
https://github.com/qutip/qutip/pull/1484#issuecomment-813480314:226,Testability,test,test,226,[![Coverage Status](https://coveralls.io/builds/38535940/badge)](https://coveralls.io/builds/38535940). Coverage remained the same at 63.606% when pulling **8acb0258468864d337d3d14226e1bfe2eed70663 on jakelishman:fix-platform-test** into **8681e995c09986a4355ba16d586dd2d2f1f49657 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1484#issuecomment-813480314
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:332,Availability,down,down,332,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:377,Testability,log,log,377,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:1147,Testability,test,tests,1147,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:1349,Testability,test,tests,1349,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:1461,Testability,test,tests,1461,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-814998778:1589,Testability,test,tests,1589,"I know you've marked this as draft, but let me point out that you've not really aligned your `master` with ours after the merge (one of the reasons it's not a good idea to develop using `master`). You've merged in the changes from our branch, but really you needed to overwrite your local copy with ours; I squashed the previous PR down into just one commit to keep the commit log cleaner and easier to interpret. In this sort of triangular workflow where you're proposing PRs that might not be merged as-is, you need to treat our repository as the single source of truth - you should never change your `master` branch except by doing `git pull` to our repository, so you can't get out of sync. Since you've now developed on the top of an incorrect tip, it'll be a bit difficult for you to untangle if you're not very familiar with `git`. You _can_ do it with rebasing or cherry-picking techniques to keep what you've done, but in this particular case (and there's no way you could have known this), I was actually just about to publish PR #1490 that makes all these same changes in `test_metrics.py`, but also goes a lot further in rewriting the tests in a more pytest-y style. It might be better for you if you reset your repository to match ours exactly, and then start again using the proper branching structure for the superoperator and tensor tests you wanted to look at. Perhaps you could have a look at #1490 as well to see how I go about parametrising tests and organising everything to keep it tidy (not saying that my code is perfect by a long shot, and the concept of ""random"" tests is questionable overall, but it's what we've got at the moment). Remember as well that readibility is a big concern. Using an automated tool to enforce pep8 compliance often won't get you the best results - our real style requirement is that it's easy to read, so linebreaks should be in sensible places (that still abide by pep8).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-814998778
https://github.com/qutip/qutip/pull/1487#issuecomment-815030359:253,Modifiability,variab,variable,253,"Hi Jake okey will re align and pull then and focus the other modules. Let's see if I am getting this right, is it correct style to add parameter to fixtures when they are used all along the test module, but in very specific special cases just leave the variable assignment before the test definition, like here https://github.com/jakelishman/qutip/blob/862d0de844d9d5b39f0301d0ea4c47c37d995499/qutip/tests/test_metrics.py#L126 ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815030359
https://github.com/qutip/qutip/pull/1487#issuecomment-815030359:190,Testability,test,test,190,"Hi Jake okey will re align and pull then and focus the other modules. Let's see if I am getting this right, is it correct style to add parameter to fixtures when they are used all along the test module, but in very specific special cases just leave the variable assignment before the test definition, like here https://github.com/jakelishman/qutip/blob/862d0de844d9d5b39f0301d0ea4c47c37d995499/qutip/tests/test_metrics.py#L126 ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815030359
https://github.com/qutip/qutip/pull/1487#issuecomment-815030359:284,Testability,test,test,284,"Hi Jake okey will re align and pull then and focus the other modules. Let's see if I am getting this right, is it correct style to add parameter to fixtures when they are used all along the test module, but in very specific special cases just leave the variable assignment before the test definition, like here https://github.com/jakelishman/qutip/blob/862d0de844d9d5b39f0301d0ea4c47c37d995499/qutip/tests/test_metrics.py#L126 ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815030359
https://github.com/qutip/qutip/pull/1487#issuecomment-815030359:400,Testability,test,tests,400,"Hi Jake okey will re align and pull then and focus the other modules. Let's see if I am getting this right, is it correct style to add parameter to fixtures when they are used all along the test module, but in very specific special cases just leave the variable assignment before the test definition, like here https://github.com/jakelishman/qutip/blob/862d0de844d9d5b39f0301d0ea4c47c37d995499/qutip/tests/test_metrics.py#L126 ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815030359
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2376,Availability,error,error,2376,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:687,Integrability,depend,depends,687,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2382,Integrability,message,messages,2382,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:1448,Modifiability,variab,variables,1448,"ide that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:347,Performance,load,loads,347,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:378,Testability,test,test,378,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:716,Testability,test,tests,716,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:876,Testability,test,test,876,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:892,Testability,test,test,892,"In general the biggest thing you should consider is readability, and to be fair, that's a little subjective. You're welcome to comment on my PR if you think I've done anything that's unreadable. You can scope fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files s",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:1204,Testability,test,tests,1204,"e fixtures at whatever level is appropriate. In this particular case, I scoped the `dimension` fixture at the module level, because there's loads of places that needed to test varying dimensions, and it's very convenient to define it just once. In the few cases where we needed to override that (e.g. in `dnorm`), I overrode it by providing a definition in a tighter scope - either at class level or per-function (via `pytest.mark.parametrize` directly). The correct scoping just depends a lot on the type of tests you're writing - if you're going to have to overwrite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:1959,Testability,test,testing,1959,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:1986,Testability,test,testing,1986,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2438,Testability,test,tests,2438,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2455,Testability,test,testing,2455,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2587,Testability,test,tests,2587,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:2624,Testability,test,testing,2624,"en module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thing if it's passed nonsense.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815044706:1737,Usability,clear,clearly,1737,"ite something constantly then module scoping isn't good, but if you have lots of different functions to test, and every test for a given function will want the same parametrisation, then class scoping might be a good choice. If you only need the parametrisation once, then it's best to put it right next to the place it's used (like in the case of mine that you've highlighted). It means that if you've opened that file to read the tests, then everything you need to understand `Test_fidelity.test_known_cases` will be on your screen if you just scroll to it. That makes it much easier for the next person who has to come along to edit your code. I used a couple of temporary variables in that case just to aid readability - my cases wouldn't have nicely fit on one line if I'd shoved the `qutip.basis(2, 0)` stuff inside the `pytest.param` constructors, and it would be hard to read. This way you can easily verify that the code is correct bit-by-bit; you can see clearly that the names are descriptive and match exactly what they say, and that means you can trust them when they then appear in the parametrisation. I won't pretend to be perfect at any part of coding, and particularly testing. I rewrote all the testing files starting from those beginning with ""a"" up to (now) ""metrics"" while I was first getting to know the QuTiP codebase, and hopefully you can see that my early efforts weren't that great, and they get a bit better and easier to read as time went on. (The later files haven't been converted yet.) The main things are to always be thinking about readability both of the code and the error messages that are coming out, and making sure that your tests are really testing that your functions have your behaviour you want them to have. Another thing we really don't have enough of in QuTiP yet is tests for ""negative"" behaviour, i.e. testing that functions _fail_ when they're passed incorrect inputs - consequently, quite a lot of QuTiP actually will just silently do the wrong thi",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815044706
https://github.com/qutip/qutip/pull/1487#issuecomment-815046001:187,Testability,test,testing,187,"Also, sorry for stepping on your toes on the `test_metrics` thing - that really wasn't intentional, and I was only looking at it more because there are a few historic problems with dnorm testing that I'd remembered later. I didn't mean to cut you off from what you were doing, and had you had more work done on it, I'd have worked with you to merge the two together rather than suggesting you throw yours out.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815046001
https://github.com/qutip/qutip/pull/1487#issuecomment-815068400:198,Modifiability,variab,variables,198,Hi Jake no problem. I was just asking about that particular line because I faced the same issue of readability versus properly scoping and could not get to a satisfactory solution. I was geting the variables from a global function that created a dictionary and it was not clean at all.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1487#issuecomment-815068400
https://github.com/qutip/qutip/issues/1488#issuecomment-814859752:569,Usability,learn,learnpython,569,"Numpy arrays are mutable, so you're modifying `er1` every time in the loop and just appending the same object. You need to create a new `er1` array each time within the out loop, or make `er1` a 2D array of the correct size. I'm sorry, but this is not the place to be asking for generic programming advice. This question (like some of your other previous ones) does not have anything to do with QuTiP, but is related to beginner/intermediate Python concepts. You were told this on a previous issue you opened. Please take these questions to a suitable forum, like the ""learnpython"" subreddit. I'm going to close any further issues you create that aren't about QuTiP specifically, without answer.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1488#issuecomment-814859752
https://github.com/qutip/qutip/pull/1489#issuecomment-815280784:46,Testability,test,test,46,"Thanks, @BOBO1997. Could you also add a quick test for this?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815280784
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:44,Testability,test,test,44,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:59,Testability,test,testFREDKINdecompose,59,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:93,Testability,test,tests,93,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:143,Testability,test,testFREDKINdecompose,143,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:187,Testability,test,test,187,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-815845169:336,Testability,test,test,336,"Thanks a lot for the quick review!; I added test function `testFREDKINdecompose` into `qutip/tests/test_qubitcircuit.py`.; After I added this `testFREDKINdecompose` function, I found the test fails with the existing decomposition.; Therefore I totally changed the way of decomposition of FREDKIN gate, which eventually passed the quick test.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-815845169
https://github.com/qutip/qutip/pull/1489#issuecomment-817748955:396,Modifiability,refactor,refactor,396,"@BOBO1997 Sorry I forgot about your proposal above. - What is the proposed behaviour of gate insertion? I guess you mean that, in the current code, if one inserts more than one gates, the length of the list is modified during the loop. This makes the definition of `position` tricky. Is this what you mean?. - About the syntax sugar, this sounds nice indeed. However, there might be a rather big refactor in `QubiCircuit` in the near future. I had a proposed refactor of `QubiCircuit` https://github.com/qutip/qutip-qip/discussions/15 (This is a separate repo in qutip org. Big new features in qip will most likely happen there). Although no one is working on that yet. I feel like this change will be much easier to implement after that refactor?. In any case, they should be in a different PR as they don't relate to this topic of FREDKIN.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-817748955
https://github.com/qutip/qutip/pull/1489#issuecomment-817748955:459,Modifiability,refactor,refactor,459,"@BOBO1997 Sorry I forgot about your proposal above. - What is the proposed behaviour of gate insertion? I guess you mean that, in the current code, if one inserts more than one gates, the length of the list is modified during the loop. This makes the definition of `position` tricky. Is this what you mean?. - About the syntax sugar, this sounds nice indeed. However, there might be a rather big refactor in `QubiCircuit` in the near future. I had a proposed refactor of `QubiCircuit` https://github.com/qutip/qutip-qip/discussions/15 (This is a separate repo in qutip org. Big new features in qip will most likely happen there). Although no one is working on that yet. I feel like this change will be much easier to implement after that refactor?. In any case, they should be in a different PR as they don't relate to this topic of FREDKIN.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-817748955
https://github.com/qutip/qutip/pull/1489#issuecomment-817748955:738,Modifiability,refactor,refactor,738,"@BOBO1997 Sorry I forgot about your proposal above. - What is the proposed behaviour of gate insertion? I guess you mean that, in the current code, if one inserts more than one gates, the length of the list is modified during the loop. This makes the definition of `position` tricky. Is this what you mean?. - About the syntax sugar, this sounds nice indeed. However, there might be a rather big refactor in `QubiCircuit` in the near future. I had a proposed refactor of `QubiCircuit` https://github.com/qutip/qutip-qip/discussions/15 (This is a separate repo in qutip org. Big new features in qip will most likely happen there). Although no one is working on that yet. I feel like this change will be much easier to implement after that refactor?. In any case, they should be in a different PR as they don't relate to this topic of FREDKIN.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-817748955
https://github.com/qutip/qutip/pull/1489#issuecomment-817773509:330,Usability,simpl,simple,330,"> One thing to consider when you're adding syntactic sugar is making sure that you don't accidentally reuse the same syntax to mean two completely different things. Thanks @jakelishman A more elegant way is to define a meta gate like `All(X)` in ProjectQ, which acts like `Tensor`. But it is true that this syntax sugar is not as simple as it looks like.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1489#issuecomment-817773509
https://github.com/qutip/qutip/pull/1490#issuecomment-815115509:220,Modifiability,refactor,refactor-metrics,220,[![Coverage Status](https://coveralls.io/builds/38609281/badge)](https://coveralls.io/builds/38609281). Coverage increased (+0.05%) to 63.659% when pulling **862d0de844d9d5b39f0301d0ea4c47c37d995499 on jakelishman:tests-refactor-metrics** into **ee047df81e3fcb1b941d04588409c4a8de09e2c7 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815115509
https://github.com/qutip/qutip/pull/1490#issuecomment-815115509:214,Testability,test,tests-refactor-metrics,214,[![Coverage Status](https://coveralls.io/builds/38609281/badge)](https://coveralls.io/builds/38609281). Coverage increased (+0.05%) to 63.659% when pulling **862d0de844d9d5b39f0301d0ea4c47c37d995499 on jakelishman:tests-refactor-metrics** into **ee047df81e3fcb1b941d04588409c4a8de09e2c7 on qutip:master**.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815115509
https://github.com/qutip/qutip/pull/1490#issuecomment-815310190:51,Testability,test,tests,51,"@jakelishman I'm somewhat against re-running flaky tests all the time. It's inelegant and hides other possible flakiness. An alternative approach is to set the random seed before generating the random states using a small fixture, e.g.:. ```python; import numpy; import random as rand. @pytest.fixture; def random():; rand.seed(0); numpy.random.seed(0); ```; (from https://github.com/pytest-dev/pytest/issues/667#issuecomment-112206152). potentially we could also run the tests with a few different random seeds (to cover more cases). If we add hypothesis (https://hypothesis.readthedocs.io/en/latest/) one day, we could generate a broader set of cases to solve and filter out bad cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815310190
https://github.com/qutip/qutip/pull/1490#issuecomment-815310190:472,Testability,test,tests,472,"@jakelishman I'm somewhat against re-running flaky tests all the time. It's inelegant and hides other possible flakiness. An alternative approach is to set the random seed before generating the random states using a small fixture, e.g.:. ```python; import numpy; import random as rand. @pytest.fixture; def random():; rand.seed(0); numpy.random.seed(0); ```; (from https://github.com/pytest-dev/pytest/issues/667#issuecomment-112206152). potentially we could also run the tests with a few different random seeds (to cover more cases). If we add hypothesis (https://hypothesis.readthedocs.io/en/latest/) one day, we could generate a broader set of cases to solve and filter out bad cases.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815310190
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:483,Availability,failure,failures,483,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:914,Availability,error,errors,914,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1032,Availability,failure,failures,1032,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1285,Availability,mask,mask,1285,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1343,Modifiability,plugin,plugin,1343,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1392,Performance,perform,performed,1392,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:40,Testability,test,tests,40,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:151,Testability,test,testing,151,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:188,Testability,test,tests,188,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:281,Testability,test,tests,281,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:947,Testability,test,tested,947,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1021,Testability,test,test,1021,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1150,Testability,test,test,1150,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1561,Testability,test,testing,1561,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1770,Testability,test,testing,1770,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815317227:1893,Usability,learn,learning,1893,"I completely agree with you that random tests really aren't the right way to go in general, but right now our problem is that basically QuTiP's entire testing suite is based on randomised tests, and that's an awful lot of technical debt to overcome any time soon :(. . The `dnorm` tests have historically been a huge problem, even though basically nobody's worked on `dnorm` for a long long time now (for context, see in particular #880 and #874). We don't actually even know if the failures in `dnorm` are deterministic and reproducible, although it turns out that I had a brief look into this when I joined as a GSoC student about a year ago... I don't remember doing it at all!. I know this is super inelegant and not the perfect method, but it's kind of a nasty trade-off - I don't have time to really dig into `dnorm` (a topic I know almost nothing about) to work out an appropriate solution to temperamental errors, we do want `dnorm` to be tested since we're shipping it, and the slight flakiness keeps causing us test suite failures about 1 in 10 times. I'm somewhat opposed to fixing the random seed because having the variance over several test runs does actually help us cover more ground (eventually) - fixing it to a ""known good"" seed actually seems to me to be more of a mask of potential problems than this. Of note: the pytest plugin I'm using reports the number of reruns it performed in the analysis at the bottom - they show up in a yellow alongside the ""skips"" and ""xfails"" - so it's not completely hidden. I'd love to have a property-based testing suite like hypothesis up and running - that definitely seems like the proper solution to this in the end. In the meantime, I'm open to swapping to a fixed random seed if you think that's much better - testing is one place where I'm really aware of my lack of formal experience in software engineering, so I'm basically just learning as I go.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815317227
https://github.com/qutip/qutip/pull/1490#issuecomment-815592138:75,Testability,test,test,75,"@jakelishman I've approved this PR -- it's definitely worth getting rid of test flakiness right away. Re random seed: We wouldn't want to set the random seed for all tests, just those like the dnorm ones that are causing issues. But let's leave that for the future.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815592138
https://github.com/qutip/qutip/pull/1490#issuecomment-815592138:166,Testability,test,tests,166,"@jakelishman I've approved this PR -- it's definitely worth getting rid of test flakiness right away. Re random seed: We wouldn't want to set the random seed for all tests, just those like the dnorm ones that are causing issues. But let's leave that for the future.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815592138
https://github.com/qutip/qutip/pull/1490#issuecomment-815673461:179,Integrability,depend,dependence,179,"Ok, I'll merge it for now, but I'll try and return to look at `dnorm` in more detail in the future, and particularly its tests; I'm also not a huge fan of having a secondary test dependence, but for the most part that's not really an issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815673461
https://github.com/qutip/qutip/pull/1490#issuecomment-815673461:121,Testability,test,tests,121,"Ok, I'll merge it for now, but I'll try and return to look at `dnorm` in more detail in the future, and particularly its tests; I'm also not a huge fan of having a secondary test dependence, but for the most part that's not really an issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815673461
https://github.com/qutip/qutip/pull/1490#issuecomment-815673461:174,Testability,test,test,174,"Ok, I'll merge it for now, but I'll try and return to look at `dnorm` in more detail in the future, and particularly its tests; I'm also not a huge fan of having a secondary test dependence, but for the most part that's not really an issue.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1490#issuecomment-815673461
https://github.com/qutip/qutip/pull/1491#issuecomment-817211736:23,Availability,failure,failure,23,I can confirm that the failure in the CI occurs only on the `coverage` test environment and it disappears if we update scipy to 1.6,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817211736
https://github.com/qutip/qutip/pull/1491#issuecomment-817211736:112,Deployability,update,update,112,I can confirm that the failure in the CI occurs only on the `coverage` test environment and it disappears if we update scipy to 1.6,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817211736
https://github.com/qutip/qutip/pull/1491#issuecomment-817211736:71,Testability,test,test,71,I can confirm that the failure in the CI occurs only on the `coverage` test environment and it disappears if we update scipy to 1.6,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817211736
https://github.com/qutip/qutip/pull/1491#issuecomment-817212093:122,Availability,failure,failure,122,"That environment deliberately tests against Scipy 1.4 because we still officially support it. This looks like a true test failure - we need to know what's causing it, and most likely fix it in code, not in the test suite.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212093
https://github.com/qutip/qutip/pull/1491#issuecomment-817212093:30,Testability,test,tests,30,"That environment deliberately tests against Scipy 1.4 because we still officially support it. This looks like a true test failure - we need to know what's causing it, and most likely fix it in code, not in the test suite.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212093
https://github.com/qutip/qutip/pull/1491#issuecomment-817212093:117,Testability,test,test,117,"That environment deliberately tests against Scipy 1.4 because we still officially support it. This looks like a true test failure - we need to know what's causing it, and most likely fix it in code, not in the test suite.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212093
https://github.com/qutip/qutip/pull/1491#issuecomment-817212093:210,Testability,test,test,210,"That environment deliberately tests against Scipy 1.4 because we still officially support it. This looks like a true test failure - we need to know what's causing it, and most likely fix it in code, not in the test suite.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212093
https://github.com/qutip/qutip/pull/1491#issuecomment-817212665:244,Availability,error,error,244,"Everything else works correctly the issue appears when going to high dimensions only, 8 to be clear. I tried myself on other environments and as long as scipy is changed the instability in 8 dimensions disappears, I do not imagine what type of error can appear only in big dimensions and in a specific scipy version other than a numeric stability in the scipy version itself. Do you have any guess?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212665
https://github.com/qutip/qutip/pull/1491#issuecomment-817212665:94,Usability,clear,clear,94,"Everything else works correctly the issue appears when going to high dimensions only, 8 to be clear. I tried myself on other environments and as long as scipy is changed the instability in 8 dimensions disappears, I do not imagine what type of error can appear only in big dimensions and in a specific scipy version other than a numeric stability in the scipy version itself. Do you have any guess?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817212665
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:257,Availability,error,error,257,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:443,Availability,error,error,443,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:471,Availability,ERROR,ERROR,471,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:607,Availability,error,error-parameter-,607,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:993,Availability,error,errors,993,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:214,Testability,test,test,214,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-817235661:404,Testability,test,tests,404,"To illustrate the point further for dimension 8 the resulting superoperator has dims `[[[8, 8], [8, 8]], [[8, 8], [8, 8]]]` this amounts to 16777216 numbers. If the differences in each is of the order of 1e-8 this test will not pass, as the resulting total error will be well above 1e-5. . This difference is not seen in scipy versions :; - 1.5; - 1.6; - 1.6.2. Going deeper when running the 8 dimension tests in scipy 1.4 set to verbose this error is thrown. >Intel MKL ERROR: Parameter 12 was incorrect on entry to ZHBRDB. looking at it in stackoverflow ; https://stackoverflow.com/questions/54314529/mkl-error-parameter-12-for-large-matrices-with-scipy-linalg-eigvalsh-in-an. and then looking at the PR history in scipy I found this. https://github.com/scipy/scipy/pull/11304. which refers to this issue in particular. https://github.com/scipy/scipy/issues/8205. which seems in consonance with my finding. Scipy 1.4 has issues in its `linalg.eigh()` API Iam surprised this is not producing errors elsewhere. Specially when calculating the tracenorm.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-817235661
https://github.com/qutip/qutip/pull/1491#issuecomment-818701546:247,Availability,error,error,247,"Hi @jakelishman do you have any further doubts about the issues with scipy 1.4 `linallg.eigenh() API` ? To me it is clear that we have to deprecate support for it, as any code that relies on calculating eigenvalues for large matrices has this MKL error, which it often does not show, and instead of terminating returns an incorrect numeric value. This affects not just this code but any possible high dimensional calculation.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818701546
https://github.com/qutip/qutip/pull/1491#issuecomment-818701546:116,Usability,clear,clear,116,"Hi @jakelishman do you have any further doubts about the issues with scipy 1.4 `linallg.eigenh() API` ? To me it is clear that we have to deprecate support for it, as any code that relies on calculating eigenvalues for large matrices has this MKL error, which it often does not show, and instead of terminating returns an incorrect numeric value. This affects not just this code but any possible high dimensional calculation.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818701546
https://github.com/qutip/qutip/pull/1491#issuecomment-818719109:433,Availability,down,downstream,433,"Thanks for looking deeply into it. It's good to know the cause. We shouldn't remove support for SciPy 1.4 unless we _absolutely_ have to. Most users won't use matrices that large so won't be affected, and SciPy 1.5 is only a year old which is too recent to be a requirement in an academic setting. We should maintain at least a 2-year dependency window (like NumPy). Any constraints we make on allowable versions affect any packages downstream of us as well, so we want to try and stay as permissive as possible, as long as there's not new features that we absolutely must have. We already have mechanisms for working around an unstable `eigh` implementation because of problems with mac OpenBLAS `zheevr` in some cases, so we can add in this additional test when setting `eigh_unsafe` in our initialisation. The principle is that we decay to using the general-purpose `eig`, and include a specific orthonormalisation step to stabilise the eigensystem afterwards. This code is already in `qutip/sparse.py`, so it shouldn't be too hard to add an extra condition in `qutip/__init__.py`. Could you also test if the issue is also confined to MKL, or if it persists in OpenBLAS with SciPy 1.4 as well? We lose precision when swapping down to `eig` in place of `eigh`, so it's good to confine the switch to the minimum known-bad set.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818719109
https://github.com/qutip/qutip/pull/1491#issuecomment-818719109:1229,Availability,down,down,1229,"Thanks for looking deeply into it. It's good to know the cause. We shouldn't remove support for SciPy 1.4 unless we _absolutely_ have to. Most users won't use matrices that large so won't be affected, and SciPy 1.5 is only a year old which is too recent to be a requirement in an academic setting. We should maintain at least a 2-year dependency window (like NumPy). Any constraints we make on allowable versions affect any packages downstream of us as well, so we want to try and stay as permissive as possible, as long as there's not new features that we absolutely must have. We already have mechanisms for working around an unstable `eigh` implementation because of problems with mac OpenBLAS `zheevr` in some cases, so we can add in this additional test when setting `eigh_unsafe` in our initialisation. The principle is that we decay to using the general-purpose `eig`, and include a specific orthonormalisation step to stabilise the eigensystem afterwards. This code is already in `qutip/sparse.py`, so it shouldn't be too hard to add an extra condition in `qutip/__init__.py`. Could you also test if the issue is also confined to MKL, or if it persists in OpenBLAS with SciPy 1.4 as well? We lose precision when swapping down to `eig` in place of `eigh`, so it's good to confine the switch to the minimum known-bad set.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818719109
https://github.com/qutip/qutip/pull/1491#issuecomment-818719109:335,Integrability,depend,dependency,335,"Thanks for looking deeply into it. It's good to know the cause. We shouldn't remove support for SciPy 1.4 unless we _absolutely_ have to. Most users won't use matrices that large so won't be affected, and SciPy 1.5 is only a year old which is too recent to be a requirement in an academic setting. We should maintain at least a 2-year dependency window (like NumPy). Any constraints we make on allowable versions affect any packages downstream of us as well, so we want to try and stay as permissive as possible, as long as there's not new features that we absolutely must have. We already have mechanisms for working around an unstable `eigh` implementation because of problems with mac OpenBLAS `zheevr` in some cases, so we can add in this additional test when setting `eigh_unsafe` in our initialisation. The principle is that we decay to using the general-purpose `eig`, and include a specific orthonormalisation step to stabilise the eigensystem afterwards. This code is already in `qutip/sparse.py`, so it shouldn't be too hard to add an extra condition in `qutip/__init__.py`. Could you also test if the issue is also confined to MKL, or if it persists in OpenBLAS with SciPy 1.4 as well? We lose precision when swapping down to `eig` in place of `eigh`, so it's good to confine the switch to the minimum known-bad set.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818719109
https://github.com/qutip/qutip/pull/1491#issuecomment-818719109:754,Testability,test,test,754,"Thanks for looking deeply into it. It's good to know the cause. We shouldn't remove support for SciPy 1.4 unless we _absolutely_ have to. Most users won't use matrices that large so won't be affected, and SciPy 1.5 is only a year old which is too recent to be a requirement in an academic setting. We should maintain at least a 2-year dependency window (like NumPy). Any constraints we make on allowable versions affect any packages downstream of us as well, so we want to try and stay as permissive as possible, as long as there's not new features that we absolutely must have. We already have mechanisms for working around an unstable `eigh` implementation because of problems with mac OpenBLAS `zheevr` in some cases, so we can add in this additional test when setting `eigh_unsafe` in our initialisation. The principle is that we decay to using the general-purpose `eig`, and include a specific orthonormalisation step to stabilise the eigensystem afterwards. This code is already in `qutip/sparse.py`, so it shouldn't be too hard to add an extra condition in `qutip/__init__.py`. Could you also test if the issue is also confined to MKL, or if it persists in OpenBLAS with SciPy 1.4 as well? We lose precision when swapping down to `eig` in place of `eigh`, so it's good to confine the switch to the minimum known-bad set.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818719109
https://github.com/qutip/qutip/pull/1491#issuecomment-818719109:1100,Testability,test,test,1100,"Thanks for looking deeply into it. It's good to know the cause. We shouldn't remove support for SciPy 1.4 unless we _absolutely_ have to. Most users won't use matrices that large so won't be affected, and SciPy 1.5 is only a year old which is too recent to be a requirement in an academic setting. We should maintain at least a 2-year dependency window (like NumPy). Any constraints we make on allowable versions affect any packages downstream of us as well, so we want to try and stay as permissive as possible, as long as there's not new features that we absolutely must have. We already have mechanisms for working around an unstable `eigh` implementation because of problems with mac OpenBLAS `zheevr` in some cases, so we can add in this additional test when setting `eigh_unsafe` in our initialisation. The principle is that we decay to using the general-purpose `eig`, and include a specific orthonormalisation step to stabilise the eigensystem afterwards. This code is already in `qutip/sparse.py`, so it shouldn't be too hard to add an extra condition in `qutip/__init__.py`. Could you also test if the issue is also confined to MKL, or if it persists in OpenBLAS with SciPy 1.4 as well? We lose precision when swapping down to `eig` in place of `eigh`, so it's good to confine the switch to the minimum known-bad set.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-818719109
https://github.com/qutip/qutip/pull/1491#issuecomment-819063126:74,Deployability,update,update,74,"HI Jake than you for the response.; I'll open a separate PR with just the update for the failing test and the changes in `__init__.py` if you are ok with it.; With respect to the check in OpenBLAS with SciPy 1.4, yes I can try it on a linux and a macOS env just in case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-819063126
https://github.com/qutip/qutip/pull/1491#issuecomment-819063126:97,Testability,test,test,97,"HI Jake than you for the response.; I'll open a separate PR with just the update for the failing test and the changes in `__init__.py` if you are ok with it.; With respect to the check in OpenBLAS with SciPy 1.4, yes I can try it on a linux and a macOS env just in case.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-819063126
https://github.com/qutip/qutip/pull/1491#issuecomment-819601408:117,Testability,test,test,117,@jakelishman There were no issues on OpenBlas. I opened a separate PR with the changes you suggested and the failing test.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-819601408
https://github.com/qutip/qutip/pull/1491#issuecomment-827165494:288,Testability,test,tests,288,"I've just merged a change to `master` that causes a couple of minor merge conflicts with this. There's no ""real"" conflict - it's just that the `todense` calls got replaced with `toarray`, so it'll hopefully be easy to fix up. No functionality that you're touching changed in any way. Any tests you're writing will now need to make sure they're not using `todense` though, or they'll fail.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-827165494
https://github.com/qutip/qutip/pull/1491#issuecomment-827190539:255,Testability,test,tests,255,"Thank you for the heads up. Just in case I am missing something here, I pulled from master and left a todense() on purpose to see how it failed, but it doesn't.; See https://github.com/MrRobot2211/qutip/blob/f3e0651a7b203841b4ae4ededce2d5b0524abb82/qutip/tests/test_superop_reps.py#L252",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-827190539
https://github.com/qutip/qutip/pull/1491#issuecomment-827823447:44,Availability,failure,failure,44,"If you run it locally it won't appear as a ""failure"" it'll be a warning, but now on the CI server we've fixed every warning, and turned new warnings into errors. You can get the same behaviour on your computer by running the command as `pytest -We [...]` instead.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-827823447
https://github.com/qutip/qutip/pull/1491#issuecomment-827823447:154,Availability,error,errors,154,"If you run it locally it won't appear as a ""failure"" it'll be a warning, but now on the CI server we've fixed every warning, and turned new warnings into errors. You can get the same behaviour on your computer by running the command as `pytest -We [...]` instead.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-827823447
https://github.com/qutip/qutip/pull/1491#issuecomment-828002553:46,Availability,failure,failure,46,"> If you run it locally it won't appear as a ""failure"" it'll be a warning, but now on the CI server we've fixed every warning, and turned new warnings into errors. You can get the same behaviour on your computer by running the command as `pytest -We [...]` instead. If you look at the CI it ran OK and there was a `todense` call in there. Maybe there is something silencing the warning elsewhere preventing it from being caught.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-828002553
https://github.com/qutip/qutip/pull/1491#issuecomment-828002553:156,Availability,error,errors,156,"> If you run it locally it won't appear as a ""failure"" it'll be a warning, but now on the CI server we've fixed every warning, and turned new warnings into errors. You can get the same behaviour on your computer by running the command as `pytest -We [...]` instead. If you look at the CI it ran OK and there was a `todense` call in there. Maybe there is something silencing the warning elsewhere preventing it from being caught.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-828002553
https://github.com/qutip/qutip/pull/1491#issuecomment-831049708:41,Integrability,contract,contraction,41,"Hi @jakelishman you were right about the contraction, I changed the indexes as in http://qutip.org/docs/latest/guide/guide-tensor.html so that it represents a trace-like channel. On the other hand I find that mixed dimensions operator `[[m,n], [m,n ]]` appear in some of the tests that were already in place, I will try to write my thoughts on their meaning later. I am still going to refactor this a little bit more, and tell you when it is ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831049708
https://github.com/qutip/qutip/pull/1491#issuecomment-831049708:385,Modifiability,refactor,refactor,385,"Hi @jakelishman you were right about the contraction, I changed the indexes as in http://qutip.org/docs/latest/guide/guide-tensor.html so that it represents a trace-like channel. On the other hand I find that mixed dimensions operator `[[m,n], [m,n ]]` appear in some of the tests that were already in place, I will try to write my thoughts on their meaning later. I am still going to refactor this a little bit more, and tell you when it is ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831049708
https://github.com/qutip/qutip/pull/1491#issuecomment-831049708:275,Testability,test,tests,275,"Hi @jakelishman you were right about the contraction, I changed the indexes as in http://qutip.org/docs/latest/guide/guide-tensor.html so that it represents a trace-like channel. On the other hand I find that mixed dimensions operator `[[m,n], [m,n ]]` appear in some of the tests that were already in place, I will try to write my thoughts on their meaning later. I am still going to refactor this a little bit more, and tell you when it is ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831049708
https://github.com/qutip/qutip/pull/1491#issuecomment-831049708:111,Usability,guid,guide,111,"Hi @jakelishman you were right about the contraction, I changed the indexes as in http://qutip.org/docs/latest/guide/guide-tensor.html so that it represents a trace-like channel. On the other hand I find that mixed dimensions operator `[[m,n], [m,n ]]` appear in some of the tests that were already in place, I will try to write my thoughts on their meaning later. I am still going to refactor this a little bit more, and tell you when it is ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831049708
https://github.com/qutip/qutip/pull/1491#issuecomment-831049708:117,Usability,guid,guide-tensor,117,"Hi @jakelishman you were right about the contraction, I changed the indexes as in http://qutip.org/docs/latest/guide/guide-tensor.html so that it represents a trace-like channel. On the other hand I find that mixed dimensions operator `[[m,n], [m,n ]]` appear in some of the tests that were already in place, I will try to write my thoughts on their meaning later. I am still going to refactor this a little bit more, and tell you when it is ready for review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831049708
https://github.com/qutip/qutip/pull/1491#issuecomment-831514046:123,Modifiability,refactor,refactor,123,"@jakelishman , I think it is ready for a review. . There a lot of `TODOs` in the code from the before times, and a general refactor is probably needed since most of the representations are working on the assumption that the channels admit equal right and left tensors:; ![formula](https://render.githubusercontent.com/render/math?math=A_{\alpha}%20=%20B_{\alpha}) . ; This PR at least allows for different left and right tensor in the Stinespring representation, thus completing the `FIXME` in the original tests.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831514046
https://github.com/qutip/qutip/pull/1491#issuecomment-831514046:507,Testability,test,tests,507,"@jakelishman , I think it is ready for a review. . There a lot of `TODOs` in the code from the before times, and a general refactor is probably needed since most of the representations are working on the assumption that the channels admit equal right and left tensors:; ![formula](https://render.githubusercontent.com/render/math?math=A_{\alpha}%20=%20B_{\alpha}) . ; This PR at least allows for different left and right tensor in the Stinespring representation, thus completing the `FIXME` in the original tests.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-831514046
https://github.com/qutip/qutip/pull/1491#issuecomment-847744740:762,Deployability,update,update,762,"I ended up here while searching for how to apply the Choi matrix to an input state and get the output density matrix. The old code has several TODOs (https://qutip.org/docs/latest/apidoc/functions.html#module-qutip.superop_reps) and we do not have a method to act on a Qobj with a Choi matrix. If you have the Choi representation of a quantum channel and want to apply it to an input state, it is done in the following way (Aamir Anis and A I Lvovsky 2012 New J. Phys. 14 105021):. <img width=""1021"" alt=""Screen Shot 2021-05-25 at 12 14 49 PM"" src=""https://user-images.githubusercontent.com/6968324/119481285-d09f4980-bd52-11eb-8ff5-4a4d25757d0c.png"">. I guess we can open a new issue to discuss these additions. @MrRobot2211 Good work on this. Could you please update according to the changes requested by @jakelishman?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847744740
https://github.com/qutip/qutip/pull/1491#issuecomment-847759512:990,Testability,test,tests,990,"@quantshah: Simon and I had temporarily stepped back from this one at the time, because we weren't entirely confident that the physics was being handled correctly - the initial version of the PR certainly had invalid physics, and it was hard to evaluate the new stuff from that perspective. It's changed since then, and it might be ok now, but it'll be easier to re-review now we've cleared the old context from our minds. About your Choi matrices - right now, `Qobj` doesn't have an `act` method, but that could well be a useful addition. It _does_ have `Qobj.__call__` which does a similar thing in a very few cases, so we could properly beef that up, but we might want to discuss exactly what spec it should have. @MrRobot2211: I very quickly glanced through the diff of this, but there still seem to be several points where I asked for changes that haven't been changed: things like removing unnecessary calls to `np.array`, and explaining _why_ dimensions needed to be changed in some tests. Can you go back through the PR and make sure you've addressed everything? Also, since you're trying to add new functionality, please make sure you add tests of explicit, analytically known cases against the whole matrix, in addition to the properties like the dimensions (also asked above). In a super ideal world it'd be great if you could find a published reference for those tests, but if the maths is simple enough that we can verify it by hand, then showing us would be ok. It could be good practice for the rest of GSoC if you try and go through the diff yourself to spot places that might want clarifying, and fix them ahead of review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847759512
https://github.com/qutip/qutip/pull/1491#issuecomment-847759512:1148,Testability,test,tests,1148,"@quantshah: Simon and I had temporarily stepped back from this one at the time, because we weren't entirely confident that the physics was being handled correctly - the initial version of the PR certainly had invalid physics, and it was hard to evaluate the new stuff from that perspective. It's changed since then, and it might be ok now, but it'll be easier to re-review now we've cleared the old context from our minds. About your Choi matrices - right now, `Qobj` doesn't have an `act` method, but that could well be a useful addition. It _does_ have `Qobj.__call__` which does a similar thing in a very few cases, so we could properly beef that up, but we might want to discuss exactly what spec it should have. @MrRobot2211: I very quickly glanced through the diff of this, but there still seem to be several points where I asked for changes that haven't been changed: things like removing unnecessary calls to `np.array`, and explaining _why_ dimensions needed to be changed in some tests. Can you go back through the PR and make sure you've addressed everything? Also, since you're trying to add new functionality, please make sure you add tests of explicit, analytically known cases against the whole matrix, in addition to the properties like the dimensions (also asked above). In a super ideal world it'd be great if you could find a published reference for those tests, but if the maths is simple enough that we can verify it by hand, then showing us would be ok. It could be good practice for the rest of GSoC if you try and go through the diff yourself to spot places that might want clarifying, and fix them ahead of review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847759512
https://github.com/qutip/qutip/pull/1491#issuecomment-847759512:1375,Testability,test,tests,1375,"@quantshah: Simon and I had temporarily stepped back from this one at the time, because we weren't entirely confident that the physics was being handled correctly - the initial version of the PR certainly had invalid physics, and it was hard to evaluate the new stuff from that perspective. It's changed since then, and it might be ok now, but it'll be easier to re-review now we've cleared the old context from our minds. About your Choi matrices - right now, `Qobj` doesn't have an `act` method, but that could well be a useful addition. It _does_ have `Qobj.__call__` which does a similar thing in a very few cases, so we could properly beef that up, but we might want to discuss exactly what spec it should have. @MrRobot2211: I very quickly glanced through the diff of this, but there still seem to be several points where I asked for changes that haven't been changed: things like removing unnecessary calls to `np.array`, and explaining _why_ dimensions needed to be changed in some tests. Can you go back through the PR and make sure you've addressed everything? Also, since you're trying to add new functionality, please make sure you add tests of explicit, analytically known cases against the whole matrix, in addition to the properties like the dimensions (also asked above). In a super ideal world it'd be great if you could find a published reference for those tests, but if the maths is simple enough that we can verify it by hand, then showing us would be ok. It could be good practice for the rest of GSoC if you try and go through the diff yourself to spot places that might want clarifying, and fix them ahead of review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847759512
https://github.com/qutip/qutip/pull/1491#issuecomment-847759512:383,Usability,clear,cleared,383,"@quantshah: Simon and I had temporarily stepped back from this one at the time, because we weren't entirely confident that the physics was being handled correctly - the initial version of the PR certainly had invalid physics, and it was hard to evaluate the new stuff from that perspective. It's changed since then, and it might be ok now, but it'll be easier to re-review now we've cleared the old context from our minds. About your Choi matrices - right now, `Qobj` doesn't have an `act` method, but that could well be a useful addition. It _does_ have `Qobj.__call__` which does a similar thing in a very few cases, so we could properly beef that up, but we might want to discuss exactly what spec it should have. @MrRobot2211: I very quickly glanced through the diff of this, but there still seem to be several points where I asked for changes that haven't been changed: things like removing unnecessary calls to `np.array`, and explaining _why_ dimensions needed to be changed in some tests. Can you go back through the PR and make sure you've addressed everything? Also, since you're trying to add new functionality, please make sure you add tests of explicit, analytically known cases against the whole matrix, in addition to the properties like the dimensions (also asked above). In a super ideal world it'd be great if you could find a published reference for those tests, but if the maths is simple enough that we can verify it by hand, then showing us would be ok. It could be good practice for the rest of GSoC if you try and go through the diff yourself to spot places that might want clarifying, and fix them ahead of review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847759512
https://github.com/qutip/qutip/pull/1491#issuecomment-847759512:1402,Usability,simpl,simple,1402,"@quantshah: Simon and I had temporarily stepped back from this one at the time, because we weren't entirely confident that the physics was being handled correctly - the initial version of the PR certainly had invalid physics, and it was hard to evaluate the new stuff from that perspective. It's changed since then, and it might be ok now, but it'll be easier to re-review now we've cleared the old context from our minds. About your Choi matrices - right now, `Qobj` doesn't have an `act` method, but that could well be a useful addition. It _does_ have `Qobj.__call__` which does a similar thing in a very few cases, so we could properly beef that up, but we might want to discuss exactly what spec it should have. @MrRobot2211: I very quickly glanced through the diff of this, but there still seem to be several points where I asked for changes that haven't been changed: things like removing unnecessary calls to `np.array`, and explaining _why_ dimensions needed to be changed in some tests. Can you go back through the PR and make sure you've addressed everything? Also, since you're trying to add new functionality, please make sure you add tests of explicit, analytically known cases against the whole matrix, in addition to the properties like the dimensions (also asked above). In a super ideal world it'd be great if you could find a published reference for those tests, but if the maths is simple enough that we can verify it by hand, then showing us would be ok. It could be good practice for the rest of GSoC if you try and go through the diff yourself to spot places that might want clarifying, and fix them ahead of review.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-847759512
https://github.com/qutip/qutip/pull/1491#issuecomment-994994001:105,Deployability,release,release,105,"Hi @hodgestar, thank you for reviewing this.; After looking at it I think I can get it done for the next release. El lun, 13 dic 2021 a las 20:11, Simon Cross ***@***.***>); escribi:. > ***@***.**** requested changes on this pull request.; >; > @MrRobot2211 <https://github.com/MrRobot2211> I reviewed the code and it; > looks mostly good now. I've left a few suggestions and questions. Let me; > know if you have some time to finish this off before QuTiP 4.7 is released; > in a month-ish.; >; > @quantshah <https://github.com/quantshah> Could you do a review of the; > mathematics and general superoperator usage here? You're probably much more; > familiar with it than me.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768187678>:; >; > > # Remember the shape of the underlying space,; >; > # as we'll need this to make Kraus operators later.; >; > - dL, dR = map(int, map(sqrt, q_oper.shape)); >; > + from math import ceil; >; >; >  Suggested change; >; > - from math import ceil; >; >; > ceil is not used anywhere and we shouldn't import inside functions unless; > necessary -- I'm guessing this was left over from debugging?; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768188147>:; >; > > # Remember the shape of the underlying space,; >; > # as we'll need this to make Kraus operators later.; >; > - dL, dR = map(int, map(sqrt, q_oper.shape)); >; > + from math import ceil; >; > +; >; >; >  Suggested change; >; > -; >; >; > Leaving this blank line here makes the comments above it confusing.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768189423>:; >; > > # Find the SVD.; >; > U, S, V = svd(q_oper.full()); >; >; >; > # Truncate away the zero singular values, up to a threshold.; >; > - nonzero_idxs = S > thresh; >; > - dK = nonzero_idxs.sum(); >; > - U ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-994994001
https://github.com/qutip/qutip/pull/1491#issuecomment-994994001:464,Deployability,release,released,464,"Hi @hodgestar, thank you for reviewing this.; After looking at it I think I can get it done for the next release. El lun, 13 dic 2021 a las 20:11, Simon Cross ***@***.***>); escribi:. > ***@***.**** requested changes on this pull request.; >; > @MrRobot2211 <https://github.com/MrRobot2211> I reviewed the code and it; > looks mostly good now. I've left a few suggestions and questions. Let me; > know if you have some time to finish this off before QuTiP 4.7 is released; > in a month-ish.; >; > @quantshah <https://github.com/quantshah> Could you do a review of the; > mathematics and general superoperator usage here? You're probably much more; > familiar with it than me.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768187678>:; >; > > # Remember the shape of the underlying space,; >; > # as we'll need this to make Kraus operators later.; >; > - dL, dR = map(int, map(sqrt, q_oper.shape)); >; > + from math import ceil; >; >; >  Suggested change; >; > - from math import ceil; >; >; > ceil is not used anywhere and we shouldn't import inside functions unless; > necessary -- I'm guessing this was left over from debugging?; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768188147>:; >; > > # Remember the shape of the underlying space,; >; > # as we'll need this to make Kraus operators later.; >; > - dL, dR = map(int, map(sqrt, q_oper.shape)); >; > + from math import ceil; >; > +; >; >; >  Suggested change; >; > -; >; >; > Leaving this blank line here makes the comments above it confusing.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768189423>:; >; > > # Find the SVD.; >; > U, S, V = svd(q_oper.full()); >; >; >; > # Truncate away the zero singular values, up to a threshold.; >; > - nonzero_idxs = S > thresh; >; > - dK = nonzero_idxs.sum(); >; > - U ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-994994001
https://github.com/qutip/qutip/pull/1491#issuecomment-994994001:2337,Testability,test,tests,2337,"uperop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768188147>:; >; > > # Remember the shape of the underlying space,; >; > # as we'll need this to make Kraus operators later.; >; > - dL, dR = map(int, map(sqrt, q_oper.shape)); >; > + from math import ceil; >; > +; >; >; >  Suggested change; >; > -; >; >; > Leaving this blank line here makes the comments above it confusing.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768189423>:; >; > > # Find the SVD.; >; > U, S, V = svd(q_oper.full()); >; >; >; > # Truncate away the zero singular values, up to a threshold.; >; > - nonzero_idxs = S > thresh; >; > - dK = nonzero_idxs.sum(); >; > - U = U[:, nonzero_idxs]; >; > - S = sqrt(S[nonzero_idxs]); >; > +; >; > + dK = np.count_nonzero(S > thresh); >; >; > I'm just checking why this code was changed. Yes, svd returns the; > singular values in descending order, but what was wrong with previous code; > that didn't rely on that?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768191681>:; >; > > ***@***.***(scope=""function"", params=[; >; > + pytest.param(rand_super, id=""super""); >; > +]); >; > +def superoperator(request, dimension):; >; > + return request.param(dimension); >; >; > This is quite a strange function to read given that it could have just; > been:; >; > @pytest.fixture; >; > def superoperator(dimension):; >; > return rand_super(dimension); >; >; > Maybe there was a plan to do something more? Could we either add another; > param or use the simpler implementation?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768192756>:; >; > > + # FIXME: problem if Kraus index is implicitly; >; > + # ptraced!; >; >; > Could you explain the FIXME a bit more? Was this an existing issue? Can we; > just fix it?; >; > ; > ",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-994994001
https://github.com/qutip/qutip/pull/1491#issuecomment-994994001:2978,Testability,test,tests,2978,"e; >; > -; >; >; > Leaving this blank line here makes the comments above it confusing.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768189423>:; >; > > # Find the SVD.; >; > U, S, V = svd(q_oper.full()); >; >; >; > # Truncate away the zero singular values, up to a threshold.; >; > - nonzero_idxs = S > thresh; >; > - dK = nonzero_idxs.sum(); >; > - U = U[:, nonzero_idxs]; >; > - S = sqrt(S[nonzero_idxs]); >; > +; >; > + dK = np.count_nonzero(S > thresh); >; >; > I'm just checking why this code was changed. Yes, svd returns the; > singular values in descending order, but what was wrong with previous code; > that didn't rely on that?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768191681>:; >; > > ***@***.***(scope=""function"", params=[; >; > + pytest.param(rand_super, id=""super""); >; > +]); >; > +def superoperator(request, dimension):; >; > + return request.param(dimension); >; >; > This is quite a strange function to read given that it could have just; > been:; >; > @pytest.fixture; >; > def superoperator(dimension):; >; > return rand_super(dimension); >; >; > Maybe there was a plan to do something more? Could we either add another; > param or use the simpler implementation?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768192756>:; >; > > + # FIXME: problem if Kraus index is implicitly; >; > + # ptraced!; >; >; > Could you explain the FIXME a bit more? Was this an existing issue? Can we; > just fix it?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/pull/1491#pullrequestreview-830847431>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFTMVKGNCG4DDNE5NVOSMRTUQZ4STANCNFSM42RMIOQA>; > .; >. -- ; **",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-994994001
https://github.com/qutip/qutip/pull/1491#issuecomment-994994001:2905,Usability,simpl,simpler,2905,"e; >; > -; >; >; > Leaving this blank line here makes the comments above it confusing.; > ------------------------------; >; > In qutip/superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768189423>:; >; > > # Find the SVD.; >; > U, S, V = svd(q_oper.full()); >; >; >; > # Truncate away the zero singular values, up to a threshold.; >; > - nonzero_idxs = S > thresh; >; > - dK = nonzero_idxs.sum(); >; > - U = U[:, nonzero_idxs]; >; > - S = sqrt(S[nonzero_idxs]); >; > +; >; > + dK = np.count_nonzero(S > thresh); >; >; > I'm just checking why this code was changed. Yes, svd returns the; > singular values in descending order, but what was wrong with previous code; > that didn't rely on that?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768191681>:; >; > > ***@***.***(scope=""function"", params=[; >; > + pytest.param(rand_super, id=""super""); >; > +]); >; > +def superoperator(request, dimension):; >; > + return request.param(dimension); >; >; > This is quite a strange function to read given that it could have just; > been:; >; > @pytest.fixture; >; > def superoperator(dimension):; >; > return rand_super(dimension); >; >; > Maybe there was a plan to do something more? Could we either add another; > param or use the simpler implementation?; > ------------------------------; >; > In qutip/tests/test_superop_reps.py; > <https://github.com/qutip/qutip/pull/1491#discussion_r768192756>:; >; > > + # FIXME: problem if Kraus index is implicitly; >; > + # ptraced!; >; >; > Could you explain the FIXME a bit more? Was this an existing issue? Can we; > just fix it?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/qutip/qutip/pull/1491#pullrequestreview-830847431>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFTMVKGNCG4DDNE5NVOSMRTUQZ4STANCNFSM42RMIOQA>; > .; >. -- ; **",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-994994001
https://github.com/qutip/qutip/pull/1491#issuecomment-1061733545:45,Deployability,update,updates,45,"I've opened up #1825 which has just the test updates from this PR (as @Ericgig suggsted). @MrRobot2211 I'm going to close this PR, but once @Ericgig has finished the new dims support PR, I think you could revisit adding this to dev.major -- i.e. QuTiP 5 -- if you are up for it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-1061733545
https://github.com/qutip/qutip/pull/1491#issuecomment-1061733545:40,Testability,test,test,40,"I've opened up #1825 which has just the test updates from this PR (as @Ericgig suggsted). @MrRobot2211 I'm going to close this PR, but once @Ericgig has finished the new dims support PR, I think you could revisit adding this to dev.major -- i.e. QuTiP 5 -- if you are up for it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1491#issuecomment-1061733545
https://github.com/qutip/qutip/issues/1492#issuecomment-815315471:60,Availability,toler,tolerance,60,"Nevermind, sorry I was being stupid. Changed the integrator tolerance and it work :/.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1492#issuecomment-815315471
https://github.com/qutip/qutip/issues/1492#issuecomment-815315471:49,Deployability,integrat,integrator,49,"Nevermind, sorry I was being stupid. Changed the integrator tolerance and it work :/.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1492#issuecomment-815315471
https://github.com/qutip/qutip/issues/1492#issuecomment-815315471:49,Integrability,integrat,integrator,49,"Nevermind, sorry I was being stupid. Changed the integrator tolerance and it work :/.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1492#issuecomment-815315471
https://github.com/qutip/qutip/pull/1494#issuecomment-818721204:14,Availability,failure,failure,14,"Ah, this test failure reminds me I need to merge up the 4.6.0 release to `dev.major`. Documentation fix is good, merging (though ironically there's a typo in your PR name!)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1494#issuecomment-818721204
https://github.com/qutip/qutip/pull/1494#issuecomment-818721204:62,Deployability,release,release,62,"Ah, this test failure reminds me I need to merge up the 4.6.0 release to `dev.major`. Documentation fix is good, merging (though ironically there's a typo in your PR name!)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1494#issuecomment-818721204
https://github.com/qutip/qutip/pull/1494#issuecomment-818721204:9,Testability,test,test,9,"Ah, this test failure reminds me I need to merge up the 4.6.0 release to `dev.major`. Documentation fix is good, merging (though ironically there's a typo in your PR name!)",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1494#issuecomment-818721204
https://github.com/qutip/qutip/pull/1496#issuecomment-817381110:51,Deployability,release,release,51,"If only this had come an hour sooner! Making a new release of code is pretty straightforwards now, though, so we can fold this and some other bits and bobs into a patch release in a week or two's time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1496#issuecomment-817381110
https://github.com/qutip/qutip/pull/1496#issuecomment-817381110:163,Deployability,patch,patch,163,"If only this had come an hour sooner! Making a new release of code is pretty straightforwards now, though, so we can fold this and some other bits and bobs into a patch release in a week or two's time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1496#issuecomment-817381110
https://github.com/qutip/qutip/pull/1496#issuecomment-817381110:169,Deployability,release,release,169,"If only this had come an hour sooner! Making a new release of code is pretty straightforwards now, though, so we can fold this and some other bits and bobs into a patch release in a week or two's time.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1496#issuecomment-817381110
https://github.com/qutip/qutip/pull/1496#issuecomment-817381396:59,Testability,test,test,59,":laughing: Well, technically we still need to wait for the test. Glad to see 4.6.0 online!",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1496#issuecomment-817381396
https://github.com/qutip/qutip/issues/1497#issuecomment-821950406:72,Modifiability,refactor,refactoring,72,"Yes, that is one of the solutions.; This issue could be included in the refactoring task of the quantum circuit library.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-821950406
https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033:422,Deployability,Update,Update,422,"Perhaps a bit more computationally efficient solution (although, it probably wouldn't make more than a marginal difference, at any reasonable order of number of indices, at which insertion is to be performed): insert at an index `i + k` , where `i` is the original index as per the `index` list, and `k` is the number of insertions performed so far, as part of the insertion loop. I'll raise a PR with the proposed fix. **Update:** The PR in question is https://github.com/qutip/qutip/pull/1892.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033
https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033:35,Energy Efficiency,efficient,efficient,35,"Perhaps a bit more computationally efficient solution (although, it probably wouldn't make more than a marginal difference, at any reasonable order of number of indices, at which insertion is to be performed): insert at an index `i + k` , where `i` is the original index as per the `index` list, and `k` is the number of insertions performed so far, as part of the insertion loop. I'll raise a PR with the proposed fix. **Update:** The PR in question is https://github.com/qutip/qutip/pull/1892.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033
https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033:198,Performance,perform,performed,198,"Perhaps a bit more computationally efficient solution (although, it probably wouldn't make more than a marginal difference, at any reasonable order of number of indices, at which insertion is to be performed): insert at an index `i + k` , where `i` is the original index as per the `index` list, and `k` is the number of insertions performed so far, as part of the insertion loop. I'll raise a PR with the proposed fix. **Update:** The PR in question is https://github.com/qutip/qutip/pull/1892.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033
https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033:332,Performance,perform,performed,332,"Perhaps a bit more computationally efficient solution (although, it probably wouldn't make more than a marginal difference, at any reasonable order of number of indices, at which insertion is to be performed): insert at an index `i + k` , where `i` is the original index as per the `index` list, and `k` is the number of insertions performed so far, as part of the insertion loop. I'll raise a PR with the proposed fix. **Update:** The PR in question is https://github.com/qutip/qutip/pull/1892.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1123990033
https://github.com/qutip/qutip/issues/1497#issuecomment-1124338701:273,Deployability,update,updated,273,"I've just noticed that @BOBO1997's [proposed solution](https://github.com/qutip/qutip/issues/1497#issue-855992475) is effectively the same as what I've implemented in my PR. I also like that his solution takes care of possibly unsorted inputs - I've borrowed that idea and updated my PR accordingly. Thanks, @BOBO1997!. I've also noticed that there are multiple instantiations of the same `gate` object upon each loop iteration, but I suspect those probably need to be kept distinct, unless the desired behaviour would be that changing one of those objects affects equivalently the other ones. In my PR I have the gate instantiation behaviour as it originally was (i.e., not adding references to the same `gate` object, but creating a new object upon each iteration). Please, let me know if this should be changed to perform only one instantiation and insert multiple references to the same object instead. @BoxiLi, I hope my #1892 doesn't interfere with https://github.com/qutip/qutip-qip/discussions/15. Please, feel free to close/reject the PR, if it does.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1124338701
https://github.com/qutip/qutip/issues/1497#issuecomment-1124338701:817,Performance,perform,perform,817,"I've just noticed that @BOBO1997's [proposed solution](https://github.com/qutip/qutip/issues/1497#issue-855992475) is effectively the same as what I've implemented in my PR. I also like that his solution takes care of possibly unsorted inputs - I've borrowed that idea and updated my PR accordingly. Thanks, @BOBO1997!. I've also noticed that there are multiple instantiations of the same `gate` object upon each loop iteration, but I suspect those probably need to be kept distinct, unless the desired behaviour would be that changing one of those objects affects equivalently the other ones. In my PR I have the gate instantiation behaviour as it originally was (i.e., not adding references to the same `gate` object, but creating a new object upon each iteration). Please, let me know if this should be changed to perform only one instantiation and insert multiple references to the same object instead. @BoxiLi, I hope my #1892 doesn't interfere with https://github.com/qutip/qutip-qip/discussions/15. Please, feel free to close/reject the PR, if it does.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/issues/1497#issuecomment-1124338701
https://github.com/qutip/qutip/pull/1498#issuecomment-820364728:189,Testability,test,test,189,"> Also, how does this PR fit relative to #1491? They appear to make many conflicting changes with each other. Hi Jake with respect to this. The apparent conflicting changes are only in the test file, if I am not mistaken. Ideally I would like this one to get approved, and then I will rebase #1491 from master.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820364728
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:37,Testability,test,tests,37,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:114,Testability,test,test,114,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:143,Testability,test,testing,143,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:206,Testability,test,test,206,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:275,Testability,test,tests,275,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:524,Testability,test,test,524,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:551,Testability,test,test,551,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820468804:726,Testability,test,test,726,"Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests. In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820468804
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:39,Testability,test,tests,39,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:116,Testability,test,test,116,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:145,Testability,test,testing,145,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:208,Testability,test,test,208,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:277,Testability,test,tests,277,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:533,Testability,test,test,533,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:560,Testability,test,test,560,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:735,Testability,test,test,735,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1037,Testability,test,test,1037,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1064,Testability,test,testing,1064,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1360,Testability,test,tests,1360,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1469,Testability,test,test,1469,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1519,Testability,test,test,1519,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1603,Testability,test,test,1603,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1697,Testability,test,test,1697,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-820522699:1728,Testability,test,tests,1728,"> Including a dimension of 8 makes the tests very slow to run. There's no real need to expand the dimensions of the test to such massive sizes - testing the stability of `eigh` should be done using a minimal test in a more specific location, such as in our general eigensystem tests.; > ; > In this case, you're constructing several 4096x4096 matrices using a sparse format, but they're all 100% dense so you spend ~30 seconds just handling sparse overhead that's nothing to do with the function call. You need to think about what a test is actually trying to test, and how long it _should_ take. When your changes are increasing the runtime by a factor of ~100, that's something you need to consider - are you actually increasing our test coverage, or just spinning the CI for longer? What is your change meant to catch? Could it be done faster in a different place? Take your time when you're changing the code, and really think about what you're trying to achieve. Good point I did not realize it was taking this long on the last mac test. . The thing is after testing thoroughly the issue starts to show itself at `2000X2000` matrices. This is less time consuming than `4096x4096` but still big. In any case `2000X2000` is something an user will probably probe, it is the size of aproximately an 11 qubit hamiltonian.; Regarding puting it with eigensystem tests there is one main issue: the eigenvalues are calculated as well as eigenstates which make running that test on the CI totally unfeasible. We could add a test for eigenenergies there but it seems unnatural. Other options are:; - Adding a test for eigenenergies vals on `test_sp_energies` [ Which I much prefer]; - Having a separate test file where we can include tests for all the nasty numeric instabilities.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-820522699
https://github.com/qutip/qutip/pull/1498#issuecomment-821186337:318,Performance,perform,performance,318,"The current test implementation is taking 3 seconds locally. But the times are quite bigger on the CI.I am positive that the test I implemented is minimal both in dimensions and requirements, as the alternativeof limiting the number of `eigvals` claculated and checking distinct from 0 on unitary matrices impacts the performance negatively on my side.; Maybe we should ship this without tests?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-821186337
https://github.com/qutip/qutip/pull/1498#issuecomment-821186337:12,Testability,test,test,12,"The current test implementation is taking 3 seconds locally. But the times are quite bigger on the CI.I am positive that the test I implemented is minimal both in dimensions and requirements, as the alternativeof limiting the number of `eigvals` claculated and checking distinct from 0 on unitary matrices impacts the performance negatively on my side.; Maybe we should ship this without tests?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-821186337
https://github.com/qutip/qutip/pull/1498#issuecomment-821186337:125,Testability,test,test,125,"The current test implementation is taking 3 seconds locally. But the times are quite bigger on the CI.I am positive that the test I implemented is minimal both in dimensions and requirements, as the alternativeof limiting the number of `eigvals` claculated and checking distinct from 0 on unitary matrices impacts the performance negatively on my side.; Maybe we should ship this without tests?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-821186337
https://github.com/qutip/qutip/pull/1498#issuecomment-821186337:388,Testability,test,tests,388,"The current test implementation is taking 3 seconds locally. But the times are quite bigger on the CI.I am positive that the test I implemented is minimal both in dimensions and requirements, as the alternativeof limiting the number of `eigvals` claculated and checking distinct from 0 on unitary matrices impacts the performance negatively on my side.; Maybe we should ship this without tests?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-821186337
https://github.com/qutip/qutip/pull/1498#issuecomment-822574194:141,Availability,error,error,141,"Hi, thak you for the feedback it is really helpful. Using lower density matrices is reducing my time by 10%, and without the fix it produces error; it is an excellent finding.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822574194
https://github.com/qutip/qutip/pull/1498#issuecomment-822574194:21,Usability,feedback,feedback,21,"Hi, thak you for the feedback it is really helpful. Using lower density matrices is reducing my time by 10%, and without the fix it produces error; it is an excellent finding.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822574194
https://github.com/qutip/qutip/pull/1498#issuecomment-822631709:52,Availability,failure,failure,52,This is weird it is showing an apparently unrelated failure while saving and loading pickles. And the CI times seem longer.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822631709
https://github.com/qutip/qutip/pull/1498#issuecomment-822631709:77,Performance,load,loading,77,This is weird it is showing an apparently unrelated failure while saving and loading pickles. And the CI times seem longer.,MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822631709
https://github.com/qutip/qutip/pull/1498#issuecomment-822660895:206,Testability,test,test,206,"Looks like we are right at the edge of the maximum permited time on the last macos check, and it fluctuates due to all the random matrix generators. Maybe we could limit the number of repetitions for every test to 5?; Or skip some tests on some environments?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822660895
https://github.com/qutip/qutip/pull/1498#issuecomment-822660895:231,Testability,test,tests,231,"Looks like we are right at the edge of the maximum permited time on the last macos check, and it fluctuates due to all the random matrix generators. Maybe we could limit the number of repetitions for every test to 5?; Or skip some tests on some environments?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822660895
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:214,Availability,toler,tolerance,214,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:445,Availability,failure,failure,445,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:506,Availability,fault,fault,506,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:656,Availability,reliab,reliably,656,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:803,Availability,down,down,803,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:839,Availability,avail,available,839,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:1103,Availability,failure,failure,1103,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:570,Deployability,release,release,570,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:833,Energy Efficiency,power,power,833,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:242,Testability,test,test,242,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:440,Testability,test,test,440,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:473,Testability,test,test,473,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:639,Testability,test,tests,639,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:665,Testability,benchmark,benchmark,665,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:915,Testability,test,testing,915,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:1098,Testability,test,test,1098,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822688883:1237,Testability,test,test,1237,"I've just pushed a couple of commits to fix up a little bit of the formatting (it was the squashed lines I meant, rather than the particular level of indent or location of the keyword `or`) and to slightly fix the tolerance of the eigenvalue test. The individual uncertainty in any eigenvalue is allowed to be ~1e-12, so when you sum them all up to compare them, you have to propagrate the uncertainty through. Don't worry about the random test failure you got in a pickle test one time - that wasn't your fault and we know about it and have fixed it for the next major release of QuTiP already. Also don't worry about the speed of the CI tests. You can't reliably benchmark by comparing CI runs because you never know what else was running on the physical hardware at the same time. Travis are ramping down the amount of processing power available to us while they're transition business model. I'll be moving our testing infrastructure elsewhere when I've got a bit more time to sort it out, and have decided what we actually want/need/can get. In the mean time, we just live with the occasional test failure if a Mac Xcode12 machine is overloaded when we get to it. We can rerun them if we need to; it's not worth compromising on our test coverage.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822688883
https://github.com/qutip/qutip/pull/1498#issuecomment-822691415:17,Testability,test,test,17,"Also, this added test runs in less than 1 second on my machine. Even an overloaded CI machine isn't going to take excessively long on it.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822691415
https://github.com/qutip/qutip/pull/1498#issuecomment-822708414:102,Testability,assert,assert,102,"I have a couplle of questions to understande better the difference between using `assert_all_close`, `assert` and `assert_equal`. ; In this case you changed `assert_all_close` to `assert` because of the time difference right? ; Why are the other tests in the same file using `assert_equal` instead of `assert` ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822708414
https://github.com/qutip/qutip/pull/1498#issuecomment-822708414:180,Testability,assert,assert,180,"I have a couplle of questions to understande better the difference between using `assert_all_close`, `assert` and `assert_equal`. ; In this case you changed `assert_all_close` to `assert` because of the time difference right? ; Why are the other tests in the same file using `assert_equal` instead of `assert` ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822708414
https://github.com/qutip/qutip/pull/1498#issuecomment-822708414:246,Testability,test,tests,246,"I have a couplle of questions to understande better the difference between using `assert_all_close`, `assert` and `assert_equal`. ; In this case you changed `assert_all_close` to `assert` because of the time difference right? ; Why are the other tests in the same file using `assert_equal` instead of `assert` ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822708414
https://github.com/qutip/qutip/pull/1498#issuecomment-822708414:302,Testability,assert,assert,302,"I have a couplle of questions to understande better the difference between using `assert_all_close`, `assert` and `assert_equal`. ; In this case you changed `assert_all_close` to `assert` because of the time difference right? ; Why are the other tests in the same file using `assert_equal` instead of `assert` ?",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822708414
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:224,Availability,avail,available,224,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:328,Availability,failure,failures,328,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:595,Availability,error,error,595,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:909,Availability,error,error,909,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:242,Integrability,message,messages,242,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:360,Integrability,message,message,360,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:915,Integrability,message,message,915,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1193,Performance,load,load,1193,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:46,Testability,assert,assert,46,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:102,Testability,test,testing,102,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:145,Testability,test,test,145,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:318,Testability,assert,assertion,318,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:391,Testability,test,testing,391,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:523,Testability,assert,assert,523,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:630,Testability,test,testing,630,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:788,Testability,test,testing,788,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:973,Testability,test,testing,973,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1211,Testability,test,testing,1211,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1240,Testability,test,testing,1240,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1477,Testability,test,testing,1477,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1522,Testability,assert,assert,1522,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1562,Testability,test,testing,1562,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1729,Testability,assert,assert,1729,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:1793,Testability,test,test,1793,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1498#issuecomment-822737671:438,Usability,clear,clearer,438,"In general in pytest we use the bare keyword `assert` for almost everything. All the functions in `np.testing` are from the ""before times"", when test tooling wasn't as good as it is nowadays - they were a big improvement on available warning messages back before 2015. Nowadays, though, `pytest` does introspection on assertion failures, so it has even better message reporting than the `np.testing` functions, and it lets you write much clearer code. For example, `assert_equal(x, y)` is much better spelled in pytest as `assert x == y`, because it's much faster to read and pytest does better error reporting for it. Similarly, testing for exceptions is better with; ```python; with pytest.raises(ValueError):; call_that_raises(1, ""hello, world""); ```; as opposed to the numpy form `np.testing.assert_raises(ValueError, call_that_raises, 1, ""hello, world"")` - the pytest one is much easier to read, and the error message is better. The only numpy one we still use is `np.testing.assert_allclose` when we're comparing several numpy arrays. That's just because `pytest` doesn't have a good function that's aware of multidimensional arrays (at least not one that I know). This file still has a load of old numpy testing code in it (e.g. `np.testing.assert_equal`) because it was written quite a long time ago, when that was the recommended way of doing things. We're changing over slowly, so we can take advantage of all the nice features of pytest. In this case, I changed `np.testing.assert_allclose(x, y, atol=tol)` to `assert abs(x - y) < tol`. I removed `np.testing.assert_allclose`, because that gives the mistaken impression that we're comparing arrays (we're not, we're comparing two scalars). I could have changed it to `assert x == pytest.approx(y, tol=tol)`, except in this case the test file hasn't been converted to `pytest` style yet, and I wanted to keep the total change of this PR as small as possible.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1498#issuecomment-822737671
https://github.com/qutip/qutip/pull/1499#issuecomment-823754421:407,Usability,guid,guides,407,"Thanks ! I have removed the table. . Couple of questions : . - What's the preferred method to link functions not in public API ? ; I could create a [sphinx reference label](https://www.sphinx-doc.org/en/master/usage/restructuredtext/domains.html#basic-markup) to link to these functions either by using Github's permalink or [a path to such functions in the directory](https://docs.readthedocs.io/en/stable/guides/cross-referencing-with-sphinx.html#the-doc-role). You can see this when I try to link `check_isunitary` which is not in the API but is defined in `Qobj` file in the linked branch. ; - Qobj vs qobj link : ; There are problems with linking functions for `Qobj` class. For example, if I want to link to [`isoperbra`](http://qutip.org/docs/latest/apidoc/functions.html#qutip.qobj.isoper) then the only link that will work is `qutip.qobj.isoperbra` not `qutip.Qobj.isoperbra`. If latter is preferred then I will have to create `ref` labels for each of these functions as stated above. More examples can be observed in the `superrep` attributes of `Qobj` class of linked branch. I think this might be due to `qutip.qobj` in [module code](http://qutip.org/docs/latest/modules/index.html).",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-823754421
https://github.com/qutip/qutip/pull/1499#issuecomment-824624079:1111,Safety,safe,safe,1111,"> What's the preferred method to link functions that are not public APIs?. I don't think we should link to non-public API in the doc. Non-public API should not (at least no encouraged) be used outside of QuTiP because we may change it without issuing a deprecation warning. Besides, [`check_unitary`](http://qutip.org/docs/latest/apidoc/classes.html?highlight=check_isunitary#qutip.Qobj.check_isunitary) is a public API, it is a class method under `Qobj`, rather than a function, see bellow. > Qobj vs qobj link. `qutip.qobj.isoperbra` and `qutip.Qobj.isoperbra` are different. The lower case `qobj` is a submodule in QuTiP (qobj.py) while `Qobj` is a class. `isoperbra` is not a class method under `Qobj`. It is a function defined under the submodule `qobj`. So only `qutip.qobj.isoperbra` is the correct path. To make the life simpler, I would recommend to use the shortcut ``:func:`.isoperbra` `` for functions and ``:meth:`.Qobj.class_method` ``. Or even simpler: ``:obj:`.isoperbra` ``. Sphinx will automatically look for the correct match. As long as there are no two functions with the same name, we are safe. This isalso because `qutip.qobj.isoperbra` will be a wrong path in qutip 5.0. The file is moved.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-824624079
https://github.com/qutip/qutip/pull/1499#issuecomment-824624079:829,Usability,simpl,simpler,829,"> What's the preferred method to link functions that are not public APIs?. I don't think we should link to non-public API in the doc. Non-public API should not (at least no encouraged) be used outside of QuTiP because we may change it without issuing a deprecation warning. Besides, [`check_unitary`](http://qutip.org/docs/latest/apidoc/classes.html?highlight=check_isunitary#qutip.Qobj.check_isunitary) is a public API, it is a class method under `Qobj`, rather than a function, see bellow. > Qobj vs qobj link. `qutip.qobj.isoperbra` and `qutip.Qobj.isoperbra` are different. The lower case `qobj` is a submodule in QuTiP (qobj.py) while `Qobj` is a class. `isoperbra` is not a class method under `Qobj`. It is a function defined under the submodule `qobj`. So only `qutip.qobj.isoperbra` is the correct path. To make the life simpler, I would recommend to use the shortcut ``:func:`.isoperbra` `` for functions and ``:meth:`.Qobj.class_method` ``. Or even simpler: ``:obj:`.isoperbra` ``. Sphinx will automatically look for the correct match. As long as there are no two functions with the same name, we are safe. This isalso because `qutip.qobj.isoperbra` will be a wrong path in qutip 5.0. The file is moved.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-824624079
https://github.com/qutip/qutip/pull/1499#issuecomment-824624079:959,Usability,simpl,simpler,959,"> What's the preferred method to link functions that are not public APIs?. I don't think we should link to non-public API in the doc. Non-public API should not (at least no encouraged) be used outside of QuTiP because we may change it without issuing a deprecation warning. Besides, [`check_unitary`](http://qutip.org/docs/latest/apidoc/classes.html?highlight=check_isunitary#qutip.Qobj.check_isunitary) is a public API, it is a class method under `Qobj`, rather than a function, see bellow. > Qobj vs qobj link. `qutip.qobj.isoperbra` and `qutip.Qobj.isoperbra` are different. The lower case `qobj` is a submodule in QuTiP (qobj.py) while `Qobj` is a class. `isoperbra` is not a class method under `Qobj`. It is a function defined under the submodule `qobj`. So only `qutip.qobj.isoperbra` is the correct path. To make the life simpler, I would recommend to use the shortcut ``:func:`.isoperbra` `` for functions and ``:meth:`.Qobj.class_method` ``. Or even simpler: ``:obj:`.isoperbra` ``. Sphinx will automatically look for the correct match. As long as there are no two functions with the same name, we are safe. This isalso because `qutip.qobj.isoperbra` will be a wrong path in qutip 5.0. The file is moved.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-824624079
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:245,Availability,error,errors,245,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:269,Availability,error,error,269,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:351,Availability,error,errors,351,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:412,Availability,error,errors,412,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:421,Availability,error,error,421,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
https://github.com/qutip/qutip/pull/1499#issuecomment-832138853:275,Integrability,message,message,275,"> Don't put a link on a word if it doesn't specifically refer to the object you're linking to. Yeah, I was worried if linking words like ket, bra were needed or not. I'll remove them. . > The ""Raises"" section should only be for very non-obvious errors; > Don't put the error message in the description of a ""Raises"" section. No problem. I will remove errors created due to incorrect parameters and other obvious errors + error messages. I will add a parameters section if needed to clarify over ValueError. . > I saw a few places where changes in the formatting accidentally deleted a word, or hid some extra meaning. I think the accidental deletes might have been due to getting caught in some cut/copy/paste flow. . > Do you have the docs building correctly?. Yes, I do. I was a bit confused about how to try to format to functions not in API doc. So, I still tried to link a `ref` to them so that they are formatted similar to hyperlinks. I think a couple of these appear as italics.",MatchSource.ISSUE_COMMENT,qutip,qutip,v5.0.4,https://qutip.org,https://github.com/qutip/qutip/pull/1499#issuecomment-832138853
