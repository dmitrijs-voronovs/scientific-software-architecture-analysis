quality_attribute,keyword,matched_word,sentence,source,filename,author,repo,version,wiki,url
Integrability,message,messages,"""""""; Represents a span during which a single pod was backpressuring / in high I/O and not dispensing job tokens.; """"""; """"""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""; # Complete BackpressureEvent objects corresponding to a matched pair of backpressure start and stop log entries for; # a pod.; # Already-processed log entry ids to ignore duplicates in overlapping log file ranges.; # pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.; # Merge the logs so the sorting covers all log entries.; # skip duplicates; # Most of the pod name is the same across all pods, only the bit after the last '-' is unique.; # Make a backpressure event object; # Add this object to complete; # Remove the wip object from in_progress_starts_by_pod; # There are actually two timestamps in the JSON log entries which appear to represent different concepts:; # time emitted ('jsonPayload.localTimestamp') versus time added to the log ('timestamp'). Time emitted would; # seem to be preferable but that value is not specified with a timezone and is ambiguously interpreted by; # the parsing code as being EST when it's actually UTC. This can make reading the report a bit confusing or; # misleading. In practice the timestamps only seem to differ by small amounts, so no big deal to use; # 'timestamp' with its explicit UTC timezone.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
Testability,log,logs,"""""""; Represents a span during which a single pod was backpressuring / in high I/O and not dispensing job tokens.; """"""; """"""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""; # Complete BackpressureEvent objects corresponding to a matched pair of backpressure start and stop log entries for; # a pod.; # Already-processed log entry ids to ignore duplicates in overlapping log file ranges.; # pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.; # Merge the logs so the sorting covers all log entries.; # skip duplicates; # Most of the pod name is the same across all pods, only the bit after the last '-' is unique.; # Make a backpressure event object; # Add this object to complete; # Remove the wip object from in_progress_starts_by_pod; # There are actually two timestamps in the JSON log entries which appear to represent different concepts:; # time emitted ('jsonPayload.localTimestamp') versus time added to the log ('timestamp'). Time emitted would; # seem to be preferable but that value is not specified with a timezone and is ambiguously interpreted by; # the parsing code as being EST when it's actually UTC. This can make reading the report a bit confusing or; # misleading. In practice the timestamps only seem to differ by small amounts, so no big deal to use; # 'timestamp' with its explicit UTC timezone.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
Integrability,depend,dependent,"# Return 0 by default for pods that aren't in this window at all.; """"""; Generate barchart-friendly time windows with counts of backpressuring durations within each window. :param backpressure_events: a list of BackpressureEvents to be broken up into time windows; :param window_width_in_hours: how wide each time window should be in hours; :return: a dictionary with timestamp keys to list of BackpressureEvent values; """"""; # The logic below is highly dependent on events being sorted by start timestamp oldest to newest.; """"""; CSV format output generation for the specified backpressure windows.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py
Testability,log,logic,"# Return 0 by default for pods that aren't in this window at all.; """"""; Generate barchart-friendly time windows with counts of backpressuring durations within each window. :param backpressure_events: a list of BackpressureEvents to be broken up into time windows; :param window_width_in_hours: how wide each time window should be in hours; :return: a dictionary with timestamp keys to list of BackpressureEvent values; """"""; # The logic below is highly dependent on events being sorted by start timestamp oldest to newest.; """"""; CSV format output generation for the specified backpressure windows.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py
Deployability,install,install,"duced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # https://cloud.google.com/compute/vm-instance-pricing#n1_highcpu_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_highmem_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/all-pricing#n1_sharedcore_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#e2_standard_machine-types; # https://cloud.google.com/compute/vm-instance-pricing#n2_standard_machine_types; # https://cloud.google.com/compute/disks-image-pricing#persistentdisk; # https://cloud.google.com/compute/disks-image-pricing#persistentdisk; # These costs use",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
Energy Efficiency,reduce,reduces,"malization would; # result in way too many decimal places or a need for scientific notation. But normalizing disk costs to an; # hourly rate for a 500GB SSD is a *specific* case:; #; # ($0.17 / (GB * month)) * 500 GB = $85 / month; #; # A monthly rate for cost is actually kind of strange when you think about it; #; # 365 / 12 = 30.41666...; #; # Per Wikipedia https://en.wikipedia.org/wiki/Month#Julian_and_Gregorian_calendars; # ""The mean month length of the Gregorian calendar is 30.436875 days.""; # nb: Not sure this is exactly how Google does its GB month billing.; #; #; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.; # Normalize to g1-small, currently the least expensive machine type used.; # Call keys without repetitive prefixes are useful",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
Performance,perform,performance,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # https://cloud.google.com/compute/vm-instance-pricing#n1_highcpu_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_highmem_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/all-pricing#n1_sharedcore_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#e2_standard_machine-types; # https://cloud.google.com/compute/vm-instance-pricing#n2_standard_machine_types; # https://cloud.google.com/compute/disks-image-pricing#persi",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
Testability,log,login,"FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # https://cloud.google.com/compute/vm-instance-pricing#n1_highcpu_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_highmem_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types; # https://cloud.google.com/compute/all-pricing#n1_sharedcore_machine_types; # https://cloud.google.com/compute/vm-instance-pricing#e2_standard_machine-types; # https://cloud.google.com/compute/vm-instance-pricing#n2_standard_machine_types; # https://cloud.google.com/compute/disks-image-pricing#persistentdisk; # https://cloud.google.com/compute/disks-image-pricing#persistentdisk; # These costs use different units. For the *general* case of comparing disk to VM costs normalization would; # result in way too many decimal places or a need for scientific notation.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
Deployability,install,install,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # This script should only ever be pointed at successful workflow metadata. All jobs that have a backend status; # other than `Success` must have later been re-run successfully, so any un`Success`ful attempts are ignored.; # It's possible that a future version of the digester might actually want to look at these jobs since they; # may have completed some lifecycle events which could be useful in accumulating more performance data.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
Performance,perform,performance,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # This script should only ever be pointed at successful workflow metadata. All jobs that have a backend status; # other than `Success` must have later been re-run successfully, so any un`Success`ful attempts are ignored.; # It's possible that a future version of the digester might actually want to look at these jobs since they; # may have completed some lifecycle events which could be useful in accumulating more performance data.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
Testability,log,login,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; # This script should only ever be pointed at successful workflow metadata. All jobs that have a backend status; # other than `Success` must have later been re-run successfully, so any un`Success`ful attempts are ignored.; # It's possible that a future version of the digester might actually want to look at these jobs since they; # may have completed some lifecycle events which could be useful in accumulating more performance data.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
Deployability,install,install,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; """"""Fetches workflow metadata for a workflow. Returns the raw response and the dict read from json""""""; """"""Uploads metadata to cloud storage, as json""""""; """"""Finds all instances of PAPI operations IDs in a workflow""""""; # Eg given:; # {; # ""calls"": {; # ""workflow_name.task_name"": [; # {; # ""jobId"": ""projects/broad-dsde-cromwell-dev/operations/01234567891011121314"",; # ...; #; # We want to extract ""projects/broad-dsde-cromwell-dev/operations/01234567891011121314""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
Testability,log,login,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login; """"""Fetches workflow metadata for a workflow. Returns the raw response and the dict read from json""""""; """"""Uploads metadata to cloud storage, as json""""""; """"""Finds all instances of PAPI operations IDs in a workflow""""""; # Eg given:; # {; # ""calls"": {; # ""workflow_name.task_name"": [; # {; # ""jobId"": ""projects/broad-dsde-cromwell-dev/operations/01234567891011121314"",; # ...; #; # We want to extract ""projects/broad-dsde-cromwell-dev/operations/01234567891011121314""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
Modifiability,flexible,flexible,"#!/usr/bin/env python3; """"""Makes sure that a value is a valid Cromwell workflow ID then returns the workflow ID""""""; """"""; Validates then extract the root of the Cromwell URL from the various URL strings which might be provided.; Deliberately flexible because it's tedious to remember which script requires which type of format.; eg:; 'http://localhost' => 'http://localhost'; 'http://localhost:8000' => 'http://localhost:8000'; 'http://localhost:8000/' => 'http://localhost:8000'; 'http://localhost:8000/api/workflows/' => 'http://localhost:8000'; 'http://localhost:8000/custom/prefix/api/workflows/' => 'http://localhost:8000/custom/prefix'; """"""; """"""; Validates then extracts the bucket and object-path from a GS string. Returned as a pair.; eg:; 'gs://bucket/path/to/directory/' -> ('bucket', 'path/to/directory'); or; 'gs://bucket/path/to/file.ext' -> ('bucket', 'path/to/file.ext'); """"""; """"""; Validates that digester version looks like 0.0.1; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py
Integrability,interface,interface,"""""""; Abstract Base Class for Local and GCS paths sharing an interface for the purpose of PAPI metadata comparison.; There's nothing particularly ""Comparison"" about these paths, I just couldn't think of a better name.; """"""; # ick; # `/` operator, used to implement pathlib.Path style `<existing path> / <new path element>` syntax.; # Nothing to do here, ""directory structure"" is implicitly ""mkdir -p""'d in GCS.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py
Security,authenticat,authenticated,"#!/usr/bin/env python3; # Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/logging.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py
Testability,test,tests,"#!/usr/bin/env python3; # Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/logging.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py
Integrability,interface,interface,"# The various attributes of a disk have string keys and string or int values.; # A DiskDict is keyed by the name of the disk (unique within a VM) and DiskAttributes values.; # and self.disk_type == other.disk_type; # + hash(self.disk_type); """"""; Abstract Base Class for PAPI operation subclasses sharing an interface for the purpose of treating digesters; uniformly regardless of PAPI version.; """"""; # Look at `pulling_image` as that is the next lifecycle phase after startup.; # start with the boot disk and then add any others later; # start with the boot disk and then add any others later",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py
Security,hash,hash,"# The various attributes of a disk have string keys and string or int values.; # A DiskDict is keyed by the name of the disk (unique within a VM) and DiskAttributes values.; # and self.disk_type == other.disk_type; # + hash(self.disk_type); """"""; Abstract Base Class for PAPI operation subclasses sharing an interface for the purpose of treating digesters; uniformly regardless of PAPI version.; """"""; # Look at `pulling_image` as that is the next lifecycle phase after startup.; # start with the boot disk and then add any others later; # start with the boot disk and then add any others later",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py
Testability,log,logic,"#!/usr/bin/env python3; """"""; Validates then extracts from PAPI operation IDs just the final number.; eg:; papiv1: 'operations/EMj9o52aLhj78ZLxzunkiHcg0e2BmaAdKg9wcm9kdWN0aW9uUXVldWU -> EMj9o52aLhj78ZLxzunkiHcg0e2BmaAdKg9wcm9kdWN0aW9uUXVldWU'; papiv2alpha1: 'projects/project_name/operations/01234567891011121314' -> '01234567891011121314'; """"""; """"""; Examines an operation ID and returns the PAPI API version which produced it; Luckily, this is currently a 1:1 format-to-api mapping so we don't need any other clues to tell the API version.; """"""; # What a JSON Object works out to be.; """"""; Visits all PAPI operations represented in the Cromwell metadata of `json_metadata`.; There will be more operations than calls if any of the operations were preempted or were failed and retried.; For every PAPI operation, the function `call_fn` is invoked with the parameters:. - Accumulator: an object of the type specified by the caller of this function per `initial_accumulator`.; - OperationId: The PAPI operation ID of the job as a string.; - CallNameSequence: The ""breadcrumbs"" leading to this call (e.g. [grandparent_wf, parent_wf, wf, call]); - JsonObject: The JSON object representing the individual job being examined. The final Accumulator is returned as the result of this function.; """"""; # Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py
Usability,simpl,simply,"#!/usr/bin/env python3; """"""; Validates then extracts from PAPI operation IDs just the final number.; eg:; papiv1: 'operations/EMj9o52aLhj78ZLxzunkiHcg0e2BmaAdKg9wcm9kdWN0aW9uUXVldWU -> EMj9o52aLhj78ZLxzunkiHcg0e2BmaAdKg9wcm9kdWN0aW9uUXVldWU'; papiv2alpha1: 'projects/project_name/operations/01234567891011121314' -> '01234567891011121314'; """"""; """"""; Examines an operation ID and returns the PAPI API version which produced it; Luckily, this is currently a 1:1 format-to-api mapping so we don't need any other clues to tell the API version.; """"""; # What a JSON Object works out to be.; """"""; Visits all PAPI operations represented in the Cromwell metadata of `json_metadata`.; There will be more operations than calls if any of the operations were preempted or were failed and retried.; For every PAPI operation, the function `call_fn` is invoked with the parameters:. - Accumulator: an object of the type specified by the caller of this function per `initial_accumulator`.; - OperationId: The PAPI operation ID of the job as a string.; - CallNameSequence: The ""breadcrumbs"" leading to this call (e.g. [grandparent_wf, parent_wf, wf, call]); - JsonObject: The JSON object representing the individual job being examined. The final Accumulator is returned as the result of this function.; """"""; # Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py
Deployability,pipeline,pipelines,"#!/usr/bin/env python3; #; # Initializer for various PAPI clients which only creates clients for specific APIs when we need them; #; """"""Gets the relevant client for accessing a PAPI API, or makes a new instance if necessary""""""; """"""Makes a new client for accessing a specified PAPI API""""""; """"""Reads the operations metadata for a pipelines API v1 job ID. Returns a python dict""""""; """"""Reads the operations metadata for a pipelines API v2alpha1 job ID. Returns a python dict""""""; """"""Reads the operations metadata for a pipelines API v2beta job ID. Returns a python dict""""""; """"""; Reads the operations metadata for any supported pipelines API version.; Returns a python dict; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
Security,access,accessing,"#!/usr/bin/env python3; #; # Initializer for various PAPI clients which only creates clients for specific APIs when we need them; #; """"""Gets the relevant client for accessing a PAPI API, or makes a new instance if necessary""""""; """"""Makes a new client for accessing a specified PAPI API""""""; """"""Reads the operations metadata for a pipelines API v1 job ID. Returns a python dict""""""; """"""Reads the operations metadata for a pipelines API v2alpha1 job ID. Returns a python dict""""""; """"""Reads the operations metadata for a pipelines API v2beta job ID. Returns a python dict""""""; """"""; Reads the operations metadata for any supported pipelines API version.; Returns a python dict; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
Availability,down,down,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.; # insert more intelligent assertions here; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'; """"""; Return a function to filter the calls that had more than the specified number of attempts.; """"""; """"""; Return a function to filter the calls that ran for more than the specified number of minutes.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
Modifiability,variab,variable,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.; # insert more intelligent assertions here; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'; """"""; Return a function to filter the calls that had more than the specified number of attempts.; """"""; """"""; Return a function to filter the calls that ran for more than the specified number of minutes.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
Performance,perform,performance,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.; # insert more intelligent assertions here; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'; """"""; Return a function to filter the calls that had more than the specified number of attempts.; """"""; """"""; Return a function to filter the calls that ran for more than the specified number of minutes.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
Testability,test,testing,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.; # insert more intelligent assertions here; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'; """"""; Return a function to filter the calls that had more than the specified number of attempts.; """"""; """"""; Return a function to filter the calls that ran for more than the specified number of minutes.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
Availability,down,down,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
Modifiability,variab,variable,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
Performance,perform,performance,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
Testability,test,testing,"#!/usr/bin/env python3; """"""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""; # A cache of expensive-to-create GCS comparison paths.; # Skip slow GCS testing unless this environment variable is set.; # more samples if needed; # 'dev_C862.NA19238',; # 'dev_D5327.NA12878',; # 'dev_D5327.NA12891',; # 'dev_D5327.NA12892',; # 'dev_RP-1535.NA17-308'",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
Availability,down,down,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""; """"""; GcsComparisonPaths are somewhat expensive to create so cache them.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
Performance,cache,cache,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""; """"""; GcsComparisonPaths are somewhat expensive to create so cache them.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
Testability,test,test,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""; """"""; GcsComparisonPaths are somewhat expensive to create so cache them.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
Deployability,continuous,continuously,"#!/usr/bin/env python; # Explicitly reset the CPU counter, because the first call of this method always reports 0; ### Define constants; # Cromwell variables passed to the container; # through environmental variables; # GCP instance name, zone and project; # from instance introspection API; ### Detect container termination; ### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
Modifiability,variab,variables,"#!/usr/bin/env python; # Explicitly reset the CPU counter, because the first call of this method always reports 0; ### Define constants; # Cromwell variables passed to the container; # through environmental variables; # GCP instance name, zone and project; # from instance introspection API; ### Detect container termination; ### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
Safety,detect,detects,"#!/usr/bin/env python; # Explicitly reset the CPU counter, because the first call of this method always reports 0; ### Define constants; # Cromwell variables passed to the container; # through environmental variables; # GCP instance name, zone and project; # from instance introspection API; ### Detect container termination; ### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
