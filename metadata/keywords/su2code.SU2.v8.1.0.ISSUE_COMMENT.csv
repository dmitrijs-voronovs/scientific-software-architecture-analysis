quality_attribute,keyword,matched_word,sentence,source,author,repo,version,wiki,url
Usability,usab,usable,"Yes, that is roughly what I mean. When I filed the issue, I was compiling in xcode, and it threw a bunch of warnings about implicit numeric casts. This is what the isssue was about. I'm off of develop and the moment, and don't have xcode setup, so I'm sorry I can't be more specific. I think they should all be unsigned long long. The memory overhead is trivial (8 bytes per node), and if we want the code to be usable in an exascale environment we don't want to limit ourselves to 4 billion node meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/3#issuecomment-104354036
Usability,simpl,simply,"Agreed. We removed some remaining long arrays with maps (e.g., local to global mappings) in v5, so we should be consistently using unsigned long in reference to grid node index values. In the future, we will likely have an ""su2int"" data type too that we can simply typedef. Closing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/3#issuecomment-307590742
Usability,learn,learned,"Thomas,. That took some doing. I just learned more about git! I'll issue a new pull request shortly. Thanks for your interest. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/33#issuecomment-56592304
Deployability,update,updated,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983
Modifiability,config,config,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983
Usability,feedback,feedback,"Thanks a lot for your feedback, we have updated the files. ; For the time being, just remove MG_CFL_REDUCTION= 0.9 in your config file.; Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/44#issuecomment-54904983
Deployability,update,update,"The documentation is now at:; https://github.com/su2code/SU2/wiki/Mesh-File. I would assume the actual behavior is still the same. Brendan, can you please check the documentation to see if you think it is clear now, and update it if not?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104355161
Usability,clear,clear,"The documentation is now at:; https://github.com/su2code/SU2/wiki/Mesh-File. I would assume the actual behavior is still the same. Brendan, can you please check the documentation to see if you think it is clear now, and update it if not?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104355161
Deployability,update,updated,"I think the writing is clear, but inaccurate. The line I quote in the initial report is still there. . The code does seem to have been updated, and it now lives in CPhysicalGeometry::Read_SU2_Format_Parallel; Here is the relevant code (for 2D I think). Current lines 6100-6104 of geometry_structure.cpp. ```; #ifndef HAVE_MPI; point_line >> Coord_2D[0]; point_line >> Coord_2D[1];; #else; if (size > SINGLE_NODE) { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; point_line >> LocalIndex; point_line >> GlobalIndex; }; else { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; LocalIndex = iPoint; GlobalIndex = node_count; }; ```. In serial, the index is completely ignored. In parallel, both are used. Unlike what the documentation says, the node index is completely meaningless in parallel, and there is no documentation of a needed global index in parallel. . I don't know what the correct behavior should be. That is a team decision. I think that the behavior should be roughly the same in serial and parallel. Either the local indices matter, or they don't. If they don't matter, they should be removed. Actually implementing this behavior (in either direction), however, could break a lot of people's code, as in either direction mesh files that were previously working could be different. We could also just have different behavior in serial and parallel, but it should be documented as such. . Thoughts @economon @fpalacios ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104360874
Usability,clear,clear,"I think the writing is clear, but inaccurate. The line I quote in the initial report is still there. . The code does seem to have been updated, and it now lives in CPhysicalGeometry::Read_SU2_Format_Parallel; Here is the relevant code (for 2D I think). Current lines 6100-6104 of geometry_structure.cpp. ```; #ifndef HAVE_MPI; point_line >> Coord_2D[0]; point_line >> Coord_2D[1];; #else; if (size > SINGLE_NODE) { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; point_line >> LocalIndex; point_line >> GlobalIndex; }; else { point_line >> Coord_2D[0]; point_line >> Coord_2D[1]; LocalIndex = iPoint; GlobalIndex = node_count; }; ```. In serial, the index is completely ignored. In parallel, both are used. Unlike what the documentation says, the node index is completely meaningless in parallel, and there is no documentation of a needed global index in parallel. . I don't know what the correct behavior should be. That is a team decision. I think that the behavior should be roughly the same in serial and parallel. Either the local indices matter, or they don't. If they don't matter, they should be removed. Actually implementing this behavior (in either direction), however, could break a lot of people's code, as in either direction mesh files that were previously working could be different. We could also just have different behavior in serial and parallel, but it should be documented as such. . Thoughts @economon @fpalacios ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/47#issuecomment-104360874
Modifiability,variab,variables,"I have seen that it is possible to specify the number of iterations in command line (shape_optimization.py)... but, I think it is clear to have both options (number of iterations and bounds - same for all the variables- ) in the config file.; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/49#issuecomment-54920484
Usability,clear,clear,"I have seen that it is possible to specify the number of iterations in command line (shape_optimization.py)... but, I think it is clear to have both options (number of iterations and bounds - same for all the variables- ) in the config file.; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/49#issuecomment-54920484
Deployability,patch,patch,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650
Testability,log,logic,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650
Usability,progress bar,progress bar,"Here is the patch from the develop branch. As I stated before, this adds the 'increment-progress' logic to the vertex export process; this causes the sub-progress bar to shows the progress of the vertex export for a more accurate experience. Thanks again,. Ethan Alan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/72#issuecomment-56592650
Usability,clear,clear,"Can we please have different enum names than RHO and RHO_ENERGY? Those enum options are at the highest level of the code. In a random context, it's not clear that RHO is a residual. RHO_RESIDUAL and RHO_ENERGY_RESIDUAL would be better, and I personally feel that DENSITY_RESIDUAL would be better yet, though Francisco may disagree.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/87#issuecomment-58026023
Usability,guid,guide,The style guide is now posted at:; https://github.com/su2code/SU2/wiki/Style-Guide,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/89#issuecomment-102195159
Integrability,interface,interfaces,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930
Performance,optimiz,optimization,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930
Usability,clear,clear,"It's not always the case that using a restart file is continuing from a simulation. For example, if one has a simulation that has a similar solution as a seed. An example would be doing optimization and using a nearby flow solution. Here, having the iteration count start from zero is useful, because it's the more accurate measure. We would also have to this about how this interfaces with MAX_ITER. Right now it's really clear, but which does it mean when iterations don't start from zero?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103239930
Modifiability,config,config,"Hello,; As a simple user, when I forget to save the last history before continuing a simulation I am very frustrated, because it is lost forever... Since the new history file erases the previous one.; Also, making these history backups is not very practical...; I would very prefer an option in the config file like: ""when RESTART_SOL= YES append to the history or not?"".; I think it would not be difficult to set another variable like: ""max_it must be counted from the beginning or from the last launch?"".; I agree it makes it a bit more complex, but not too much I think :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103369490
Usability,simpl,simple,"Hello,; As a simple user, when I forget to save the last history before continuing a simulation I am very frustrated, because it is lost forever... Since the new history file erases the previous one.; Also, making these history backups is not very practical...; I would very prefer an option in the config file like: ""when RESTART_SOL= YES append to the history or not?"".; I think it would not be difficult to set another variable like: ""max_it must be counted from the beginning or from the last launch?"".; I agree it makes it a bit more complex, but not too much I think :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-103369490
Usability,clear,clear,The iteration number is now stored in the restart files so we should definitely have this feature. Because at the moment it is not clear when the iteration stops (because EXT_ITER is still counted from 0).,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/99#issuecomment-308412942
Performance,optimiz,optimization,"Indeed, this helps, but it could be more general, since you only get to see this in the console output. I was thinking that a simple tag in the optimization history file for the evaluations that are 'major' would make this much simpler (and easier to post-process).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/108#issuecomment-102168908
Usability,simpl,simple,"Indeed, this helps, but it could be more general, since you only get to see this in the console output. I was thinking that a simple tag in the optimization history file for the evaluations that are 'major' would make this much simpler (and easier to post-process).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/108#issuecomment-102168908
Deployability,configurat,configuration,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295
Modifiability,config,configuration,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295
Usability,simpl,simple,"I came across this when I was working on a mesh generation program that generates an extruded boundary layer. I had checks in the program to make sure I was generating elements of positive volume and that they weren't self intersecting. While some of the elements were very badly skewed, I knew I didn't want the elements to be reoriented. However, SU2 reorients several of the prisms and tries to reorient some of the pyramids as well (which isn't a defined operation in SU2). . This is why in my particular case it was easier for me to just turn off the feature. . In general though, I think that the reorientation check could be a bit better. Currently for the prism element for example, it does a volume like calculation using the top and bottom triangles separately, and reorients if either one is negative. Obviously if only one of these calculations is negative, by reorienting, the other calculation would become negative. Similar things are done for pyramids and hexas. . A simple solution would be to change the ""or"" conditions in these calculations to ""and"", so that it is only reoriented if it fails all the checks. I think a better solution would be to decide on a volume calculation method for each element type, and then use that as a criteria. . If you'd prefer to just improve the reorientation checks instead of adding this configuration option, I could submit work on a pull request for that if you'd like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/162#issuecomment-103679295
Modifiability,config,config,"Obviously it is possible to implement this, but it would significantly complicate the config parsing code. Right now the parser is very simple: Go through each line, and get the name and the tokens. As far as I can see there aren't good ways to allow this aside from either having a whitelist of options that can go on multiple lines (thus, only some options are allowed to do so), or to switch up the config file entirely and go to a more standard format like JSON.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/166#issuecomment-103241030
Usability,simpl,simple,"Obviously it is possible to implement this, but it would significantly complicate the config parsing code. Right now the parser is very simple: Go through each line, and get the name and the tokens. As far as I can see there aren't good ways to allow this aside from either having a whitelist of options that can go on multiple lines (thus, only some options are allowed to do so), or to switch up the config file entirely and go to a more standard format like JSON.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/166#issuecomment-103241030
Deployability,configurat,configuration,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749
Modifiability,config,configuration,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749
Usability,usab,usable,"Thank you for the pull request. ; Pull requests must be both to and from the ""develop"" branch (or the relevant feature branch if applicable). In order to make a pull request, please check out the develop branch, make your changes, and submit the pull request into to develop branch. . While this might be useful in some situations, and particularly the record of this pull request can be an example to other users who want to use Docker with SU2, it looks like this is specific to a version of Ubuntu, and that you have hard-coded some lines to refer to locations on your own file system. We try to make it such that SU2 will be usable in most operating systems, with appropriate changes to the configuration steps. . Since it is setting up a development environment this would be more appropriate to SU2_IDE/, rather than Quickstart/ - which is intended as the main tutorial for new users, who are not necessarily developers and who may not have heard of Docker.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/169#issuecomment-96786749
Modifiability,config,config,"Tom, I would love to address both of these. Give me some time. I feel even in the current form, it is good. Do you have plans to merge this into master, so that people can use this to setup dev environment quickly. They can also create a basic config file quickly. . I will consider both of your ideas to make user experience better. Thanks for your support. ; Krishna",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/172#issuecomment-126133647
Usability,user experience,user experience,"Tom, I would love to address both of these. Give me some time. I feel even in the current form, it is good. Do you have plans to merge this into master, so that people can use this to setup dev environment quickly. They can also create a basic config file quickly. . I will consider both of your ideas to make user experience better. Thanks for your support. ; Krishna",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/172#issuecomment-126133647
Usability,simpl,simply,If you run the code with enabled mpi support SU2_CFD will only write the restart files. You need to use SU2_SOL to convert them to .vtk. Therefore simply copy the restart_flow.dat to solution_flow.dat and run SU2_SOL. Or you could just use the parallel_computation.py script that does this automatically.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/173#issuecomment-99219314
Usability,simpl,simply,"Thank you so much. Jehan. Sent from Yahoo Mail on Android. From:""Tim Albring"" notifications@github.com; Date:Tue, May 5, 2015 at 4:56 PM; Subject:Re: [SU2] SU2 do not produce plot files such as vtk etc. (#173). If you run the code with enabled mpi support SU2_CFD will only write the restart files. You need to use SU2_SOL to convert them to .vtk. Therefore simply copy the restart_flow.dat to solution_flow.dat and run SU2_SOL. Or you could just use the parallel_computation.py script that does this automatically. —; Reply to this email directly or view it on GitHub.￼",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/173#issuecomment-99235355
Availability,error,error,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Deployability,update,updates,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Energy Efficiency,adapt,adapt,"ts in config_structure to make doxygen pretty; - Bug fixing; - Merge branch 'develop'; - EA in ft^2; - further update to config; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - Minor changes; - Updated NF BC; - More adjustments; - Small update; - Final update Nearfield BC; - added massflowrate as option for cauchy criteria, more config file comments; - Merge remote-tracking branch 'upstream/develop' into upstream_dev; - paraview output modified/added back in for current version for SU2_DEF; - Merge branch 'develop' into feature_dualoutput; - Removed deprecated options from quicstart config.; - Working version of the compressible actuator disk; - Updated fixed CL mode.; - Very minor change; - Merge branch 'develop' into feature_dualoutput; - Final push to 3.2.9; - Merge branch 'develop'; - Minor change; - Minor change; - Small change; - Minor change; - Bug fixing: unsigned short val_vertex --> unsigned long val_vertex; - CFL adapt now works for adjoint problems; - Merge branch 'develop' into feature_dualoutput; - Fixing a typo; - Fix in the Euler BC for grid movement cases; - merging and fixing conflicts bwtn feature_dealloc and develop; - dealloc; - Time spectral fix.; - Merging some recent bug fixes from master into the develop branch to keep nsync.; - Merge branch 'feature_gridvel_fix' into develop; - Merge remote-tracking branch 'upstream/develop' into feature_Deallocation; - correcting issues, adding more deallocation; - fixed uninitialized pointers in CConfig; - further deallocation; - some corrections needed to pass reg tests; - fixed some dealloc issues that caused errors in euler adj; - modifications needed to (mostly) pass reg tests; all run w/o segfault. File Changes; - D Articles/AIAA_2013-0287.pdf (0) ; - D Articles/AIAA_2014-0243.pdf (0) ; - M Common/doc/docmain.hpp (46) ; - M Common/include/config_structure.hpp (1038) ; - M Common/include/config_structure.inl (191) ; - M Common/include/dual_grid_structure.hpp (43) ; - M Common/inc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Integrability,integrat,integration,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Modifiability,config,config,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Performance,perform,perform,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Safety,predict,predicted,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Security,validat,validate,"I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working version with ParMETIS. Fixed bug in global index. Now clean up and testing...; - Cleaned version of ParMETIS routines with better console output during partitioning.; - Small bug in initial element division.; - Made arrays in ParMETIS call dynamic.; - Fixed compiler warnings and added MPI directives so that the pure serial code wor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Testability,test,tests,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Usability,guid,guidance,"Dear Heather,; I am analyzing a propeller of an UAV. I have static thrust measurements such that when I used Euler results I got 3.5 lbf thrust as compared to the measured 6 lbs. My next step was to perform an NS equation with SA turb model. I got 7 times over predicted results such that the mesh has a Y+ of less than 1. Then I thought of doing an SST but was not long enough that it gave me error with divergence. I have been setting up my SST case as per the tutorial example of NACA0012. However, I do not happen to see any entry with regards to eddy frequency etc. (usually required by SST) in the config file. Any guidance will be great.; Thanks; Jehan; From: Heather Kline notifications@github.com; To: su2code/SU2 SU2@noreply.github.com ; Sent: Tuesday, May 12, 2015 11:43 AM; Subject: [SU2] Feature deallocation (#174). Bringing this branch up to date with current develop branch. ; Various deallocation changes; Some regression tests fail but all run. (previously was not the case); You can view, comment on, or merge this pull request online at:;   https://github.com/su2code/SU2/pull/174; Commit Summary; - Updated GetEngine_Properties; - Fix to the last commit; - Small bug; - Merge branch 'develop' into feature_MPI; - merging; - SU2_SOL and SU2_CFD are working; - Preliminary, but complete, implementation of SU2_DEF; - More updates; - Working version; - Complete implementation (validate); - Working version of SU2_DEF; - Final push before moving to the develop branch; - New MPI (removing SU2_PRT); - Merged in Ben's ParMETIS integration and fixed some conflicts.; - Merge branch 'benkirk-parmetis_integration' into feature_MPI; - ParMETIS geometry routines have been copied over but are not activated yet.; - Small change to ParMETIS include.; - ParMETIS can now be activated for testing (PARMETIS=YES in config).; - Updated MG; - Updated EA subrotuine; - Small fix; - Fixing memory leak; - Fixing memory leaks; - Dev release v.3.2.6; - Increasing MAX_NUMBER_MARKER; - Working versi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/174#issuecomment-101443812
Availability,avail,available,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617
Modifiability,config,config,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617
Usability,clear,clear,"Config options and their options can be found in:; https://github.com/su2code/SU2/blob/master/config_template.cfg; As a part of the code repository, this document will remain up to date with whatever version of the code you have. I believe that this is the single document to which you refer. I apologize that its location or purpose may not have been clear - I will shortly go edit the wiki to see if I can make it clearer that this file exists. . Additionally, the file config_template_basic.cfg in the same directory is a shorter version with only the options most commonly used. . Further documentation of the config options is also available in the comments of:; https://github.com/su2code/SU2/blob/master/Common/src/config_structure.cpp. And although it has not been up to date as we moved towards the wiki and config file template rather than keeping doxygen up to date, additional documentation can be produced using the files in su2code/Documentation/Doxygen.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/183#issuecomment-111755617
Modifiability,config,config,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074
Testability,test,test,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074
Usability,clear,clearing,"No, I think we're all set. I am going to merge this in. We have two issues that we are going to be clearing up very soon: the ONERA M6 adjoint case that is failing somewhat irregularly, and a reorganization of the test cases/config files to make the regression tests more effective (in particular for pull requests). Thanks for fixing the conflicts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/186#issuecomment-127486074
Availability,avail,available,"this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067
Deployability,update,update,"-------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: 5.54565e-10. ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 1.039217 seconds on 1 core. ------------------------- Exit Success (SU2_DEF) ------------------------. [image]https://cloud.githubusercontent.com/assets/5167760/9294056/7be9439a-440f-11e5-862f-742246ef1565.png; SU2_DEF: output when deforming with all markers included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid.; No surface deformation (scaling, rotation, or translation). ----------------------- Volumetric grid deformation ---------------------; Performing a translation of the volumetric grid.; Translational displacement: (1, 0, 0). ----------------------- Write deformed grid files -----------------------; Merging grid connectivity.; Merging grid coordinates.; Writing volume mesh file.; Writing surface mesh file.; Writing .su2 file.; Adding any FFD information to the SU2 file. Completed in 0.716938 seconds on 1 core. as far as I can tell the regression test failure is the same as for the current develop branch; I'll update this pull request whenever that is resolved. —; Reply to this email directly or view it on GitHubhttps://github.com/su2code/SU2/pull/187#issuecomment-131578218.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067
Modifiability,config,config,"Thanks for adding the description, Heather. I think this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067
Testability,log,logical,"Thanks for adding the description, Heather. I think this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067
Usability,simpl,simpler,"this is a very nice contribution.. we’re working on the regressions and will pull this in once we have everything straightened out (and this branch passes). In the meantime, you got me thinking: the scale, rotate, translate options might be confusing now if a user doesn’t know whether to include the markers or not. Perhaps this is a chance for separating some of the “design” options from “mesh” options. One way I could see us do this is by moving the implementation I had just committed for the “volume” scale, rotate, and translate options over into the SU2_MSH executable, which might be a more logical home for it. However, this would require adding an extra set of config options for reading in a scale/rotate/translate options for SU2_MSH. The nice thing here is that we keep the intent separate, i.e., only design variables are listed with the other design variables while the mesh transformations are elsewhere. A different, possibly simpler way would be to just create separate names for these two types in the list of available options so that there is no ambiguity. Any thoughts?. On Aug 16, 2015, at 9:21 AM, Heather Kline <notifications@github.com<mailto:notifications@github.com>> wrote:. Some illustrative images/output in case my description was hard to understand:; [image]https://cloud.githubusercontent.com/assets/5167760/9294050/52a764b2-440f-11e5-8681-b68318da0ce7.png. SU2_DEF output when only ""airfoil"" marker included:. ------------------------- Surface grid deformation ----------------------; Performing the deformation of the surface grid. ----------------------- Volumetric grid deformation ---------------------; Performing the deformation of the volumetric grid. # FGMRES residual history. # Residual tolerance target = 4.14044e-11. # Initial residual norm = 15.8102. ```; 0 1; 50 2.17385e-06; 100 1.08998e-10; ```. # FGMRES final (true) residual:. # Iteration = 105: |res|/|res0| = 3.50764e-11. Non-linear iter.: 1/1. Linear iter.: 105. Min. area: 4.1019e-08. Error: ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132065067
Energy Efficiency,efficient,efficient,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536
Modifiability,config,config,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536
Usability,clear,clear,"Thanks Tom; I agree that we should make things easy to understand. ; My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh. . In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request). On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value. . There may be other similar areas where config file options could be clarified or compressed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-132181536
Energy Efficiency,efficient,efficient,"le (and the user will decide which one turn on of off using templet of paraview); > ; > MARKER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923
Modifiability,config,config,"KER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could be clarified or compressed.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923
Usability,clear,clear,"KER_MONITORING, MARKER_DESIGNING: The main idea is to be able to compute to different integrals over the surfaces: one for simulation and the other for design. e.g. You maybe want to include all the solid surfaces and fan faces, and charging stations in MARKER_MONITORING to compute (Drag-Thrust) but in MArKER DESIGN you are only interested on the wing surface for design.; > ; > DV_MARKER. This is an unfortunately name. At the very beginning the mesh deformation capability was developed only for shape design (DV = Design Variables). We should generalize the names of the grid deformation parameters without using DV. Thanks!; Francisco. On Aug 18, 2015, at 4:31 AM, Heather Kline notifications@github.com wrote:. > Thanks Tom; > I agree that we should make things easy to understand. ; > My thinking was that most users will want to know what parts of the mesh they are moving, but don't necessarily need to know what's happening underneath - if they specify the entire mesh the code just reverts to the more efficient method. But (from the users perspective) it may be just as easy to have a separate specification for scaling the entire mesh.; > ; > In terms of moving it to SU2_MSH; I think it may make sense to include scale/rotate/translate in SU2_MSH, but I think it would be confusing to have two options that do the same thing. I would side with separate option names (this would also eliminate a loop over markers in this pull request); > ; > On this topic, I have sometimes found MARKER_DESIGNING and DV_MARKER to be confusing; on their own they sound very similar, in the description MARKER_DESIGNING is where the objective function is evaluated - but in the code, it's not clear what MARKER_DESIGNING does - the surfaces specified by MARKER_MONITORING are what are actually used to evaluate the objective function value.; > ; > There may be other similar areas where config file options could be clarified or compressed.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/187#issuecomment-133010923
Deployability,continuous,continuously,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091
Performance,perform,performance,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091
Usability,usab,usability,"I agree with the final conclusion here... thanks for discussing this and working toward a solution. . We have found in some of our performance optimization work that continuously allocating/deallocating memory is a performance killer, and I am in favor of uniform behavior across the code for readability/usability. Let's merge this in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/200#issuecomment-149771091
Modifiability,variab,variable,"Yep, things seem to be passing just fine now, and it looks like things are coming along nicely for the turbomachinery features. Before we merge this in... I am a little concerned with the number of additions to solver_direct_mean.cpp related to the different switch statements and subroutines needed for the Riemann and non-reflecting BCs. Is there anything we can do to simplify things?. In addition, could you please clean up the spacing/style in those methods to match up with the other BCs (more comments are needed, indentation, variable declarations, etc.)? It would also be great to have a little more detail on how to use the new BCs in the descriptions in config_template.cfg. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/207#issuecomment-152406337
Usability,simpl,simplify,"Yep, things seem to be passing just fine now, and it looks like things are coming along nicely for the turbomachinery features. Before we merge this in... I am a little concerned with the number of additions to solver_direct_mean.cpp related to the different switch statements and subroutines needed for the Riemann and non-reflecting BCs. Is there anything we can do to simplify things?. In addition, could you please clean up the spacing/style in those methods to match up with the other BCs (more comments are needed, indentation, variable declarations, etc.)? It would also be great to have a little more detail on how to use the new BCs in the descriptions in config_template.cfg. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/207#issuecomment-152406337
Usability,learn,learning,Could you leave in the machine learning section a bit longer?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152095697
Availability,robust,robust,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158
Deployability,release,release,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158
Modifiability,config,config,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158
Testability,test,tests,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158
Usability,learn,learning,"No… I can’t. I’m sorry. Great to hear from you. Machine learning is a very valuable research work and I will add it as a feature branch. . Removing code from the main release is a complex task and, as in the past, I have taken tough decisions. Anyway, to maintain a clean code is critical for its growing, it is like trimming a large tree. Basic criteria to maintain forever an implementation on the develop->master branch are: - Clear benefit to the CFD community (more accurate, robust, etc.) - Existing community of users or active developers - Minimal code documentation (at least the options should be in the config file). - Easy to install and use. - The implementation style should be aligned with the SU2 style - Regressions tests. Best,; Francisco. > On Oct 28, 2015, at 11:35 PM, Brendan Tracey notifications@github.com wrote:; > ; > Could you leave in the machine learning section a bit longer?; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/208#issuecomment-152095697.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152384158
Availability,down,downloaded,"Ok. Thanks for the reply. If it's not simple to separate into a branch, don't worry. I have already downloaded the current master and can maintain a local copy. I see that there is at least one issue related to that segment (I would have responded had I seen it). Are users interested in using that segment of the code? If so, I'd be more than happy to add documentation and a usage example I the develop branch. When thus code went live we decided it was better to not add documentation since the feature is experimental. This is certainly a fixable situation on the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152404327
Usability,simpl,simple,"Ok. Thanks for the reply. If it's not simple to separate into a branch, don't worry. I have already downloaded the current master and can maintain a local copy. I see that there is at least one issue related to that segment (I would have responded had I seen it). Are users interested in using that segment of the code? If so, I'd be more than happy to add documentation and a usage example I the develop branch. When thus code went live we decided it was better to not add documentation since the feature is experimental. This is certainly a fixable situation on the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/208#issuecomment-152404327
Usability,guid,guideline,"Giulio,. Yes! It would be excellent to have the HLLC Jacobians for the ideal gas case too. Please let me know if I can assist with anything. You might also have noticed some old commented out code that you could use as a guideline. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/209#issuecomment-171112223
Availability,error,error,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818
Integrability,message,message,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818
Usability,simpl,simple,"A simple workaround would be to add an if line before the split:; Line 84 of parse_config.py; if np.size(s2) > 1:; thisval = s2.split('""')[1]; Yes, it requires also ; import numpy as np; at the beginning of the script.; Now it runs with no error message but no output produced.; Also config_gui.py is running, but it opens an empty window,; so apparently this is not good enough. best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/216#issuecomment-241208818
Testability,test,test,"Alex, Heather,. Thanks for commenting and straightening this out. Since this is a frequently asked question, I have added a new section in the documentation on how to use the test cases, which will hopefully clear things up more in the future: https://github.com/su2code/SU2/wiki/Test-Cases. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/222#issuecomment-171108493
Usability,clear,clear,"Alex, Heather,. Thanks for commenting and straightening this out. Since this is a frequently asked question, I have added a new section in the documentation on how to use the test cases, which will hopefully clear things up more in the future: https://github.com/su2code/SU2/wiki/Test-Cases. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/222#issuecomment-171108493
Availability,mask,masking,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391
Energy Efficiency,reduce,reduced,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391
Modifiability,config,config,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391
Usability,simpl,simply,"You're right about that bug with vel_i_corr. Thanks for finding it, I'll submit a correction. Yes, it's possible to modify the config file so that your implementation works. But is this simply masking the problem of reduced stability? Do you expect the direct formulation to be less stable? And do the benefits of the direct formulation make the loss of stability worthwhile? If so, then I think you should change the config file. I hope this answers your question, I'm not sure if I understood it correctly. Regards,; Daniel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/232#issuecomment-182655391
Deployability,continuous,continuous,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794
Modifiability,variab,variable,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794
Usability,usab,usable,"Thanks, Tim. Adding flexibility to the FFD is a great contribution. I was just going through the changes and I have a couple of questions:; 1. I noticed that you have added AD as an option for computing the geometric sensitivity component (change in the surface location due to a delta change in the design variable) that multiplies the adjoint sensitivity. Is there a way to make this usable for the continuous adjoint too rather than using finite differencing? This assumes that the user has built the AD version, even though they use the continuous adjoint.; 2. On a related note (I think), is the finite differencing that is currently used for computing the geometric sensitivity the only roadblock to arbitrary FFD movements for the continuous adjoint?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/239#issuecomment-183462794
Usability,clear,clear,"Heather: I know we talked about this one in person the other day, but I am still weighing things... Even though it looks like a small change, it's a really big one, and I want to make sure we keep things as clear and user-friendly as possible. . If anyone else has thoughts on this, please feel free to chime in. Maybe we can catch up about it again early this week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-184449921
Modifiability,flexible,flexible,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081
Performance,optimiz,optimization,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081
Usability,clear,clear,"I think its a good idea to separate the weight from the objective function. This makes it more clear and flexible. However, what bothers me a little bit is that the OBJECTIVE_FUNCTION option is now used for two things. Namely for the optimization and for the individual adjoint runs. Maybe it would be good to still have another option for specifying the obj. function for the adjoint run itself (with a completely different name, so that there won't be any confusions). . Maybe it's less of a problem then I think, though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/241#issuecomment-185126081
Deployability,continuous,continuous,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633
Modifiability,config,config,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633
Testability,test,tests,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633
Usability,simpl,simple,"Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?. Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191571633
Deployability,continuous,continuous,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831
Modifiability,config,config,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831
Testability,test,tests,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831
Usability,simpl,simple,"Thanks, I’ll take a look at that before the weekend,. Best,; Francisco. > On Mar 2, 2016, at 8:03 PM, Thomas D. Economon notifications@github.com wrote:; > ; > Thanks for the fixes, Francisco. The continuous adjoint tests are now failing, but I am guessing that it is something simple with the changes to the config option. Can you please take a look when you have a moment?; > ; > Couldn't agree more about keeping an eye on the Python scripts. We'll chat about it this week at the developer meeting (we need regressions for the Python scripts). More on that to come.; > ; > —; > Reply to this email directly or view it on GitHub https://github.com/su2code/SU2/pull/244#issuecomment-191571633.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/244#issuecomment-191590831
Deployability,install,installed,"As @gbaty said, it's usually easy to support both. Many times it can be done with a simple. ``` python; from __future__ import division, print_function; ```. at the top of each file, and tweaking the `print` and `import` statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default. . Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195767843
Usability,simpl,simple,"As @gbaty said, it's usually easy to support both. Many times it can be done with a simple. ``` python; from __future__ import division, print_function; ```. at the top of each file, and tweaking the `print` and `import` statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default. . Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195767843
Deployability,release,release,"This could be a very interesting contribution! Please, feel free to work on this and create a push request to the developer release. SU2 is looking forward for contributions from the open-source community. Thanks!; Francisco. Sent from my iPhone. > On Mar 12, 2016, at 8:07 AM, Pete Bachant notifications@github.com wrote:; > ; > As @gbaty said, it's usually easy to support both. Many times it can be done with a simple; > ; > from **future** import division, print_function; > at the top of each file, and tweaking the print and import statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default.; > ; > Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195781648
Usability,simpl,simple,"This could be a very interesting contribution! Please, feel free to work on this and create a push request to the developer release. SU2 is looking forward for contributions from the open-source community. Thanks!; Francisco. Sent from my iPhone. > On Mar 12, 2016, at 8:07 AM, Pete Bachant notifications@github.com wrote:; > ; > As @gbaty said, it's usually easy to support both. Many times it can be done with a simple; > ; > from **future** import division, print_function; > at the top of each file, and tweaking the print and import statements. In my experience, the Anaconda (or miniconda) Python distribution makes it very easy to setup just about any version of Python you like on a cluster, since it's installed in the user's home directory by default.; > ; > Most scientific packages (NumPy, SciPy, Matplotlib, Pandas) already support both 2.7 and 3.x within a single codebase. Python 3 is the future!; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-195781648
Performance,load,loads,"# Import issues. In Python 3, relative import behaviour changes.; In Python 2, ""import module"" loads first local module, then system module. In Python 3, it is the opposite. ## Import patterns in SU2 code. If we consider, to simplify, these generic packages:; `package1/p1m1.py`; `package1/p1m2.py`; `package1/__init__.py`. `package2/p2m1.py`; `package2/__init__.py`. In SU2 code we find these patterns:. **Pattern 1**; `package1/__init__.py`; contains. ``` python; import p1m1; import p1m2; ```. These instructions are useless as it is the common behaviour of package.; If a `__init__.py` is defined, I can do from package1 import p1m1 or import package1.p1m1. Do you know why this happens ? Is there an historical reason or other ?; For example, in [`SU2_PY/SU2/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/__init__.py) or [`SU2_PY/SU2/mesh/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/mesh/__init__.py). **Pattern 2**; `package1/__init__.py`; contains. ``` python; from p1m1 import f; ```. **Pattern 3**; `package1/p1m1.py`; contains. ``` python; from ..p1m2 import f; ```. **Pattern 4**. ``` python; import cPickle as pickle; ```. ## Solution. I suggest these solutions:. **Pattern 1**; delete imports. **Pattern 2**; replace `from p1m1 import f` with `from .p1m1 import f` . See also next solution. **Pattern 3**. This is OK. Another approach is to always use absolute imports, for example. ``` python; from ..p1m2 import f; ```. becomes. ``` python; from package1.p1m2 import f; ```. Result is the same except that it is recommended in [PEP8](https://www.python.org/dev/peps/pep-0008/#id20) but first approach is ok too.; I can do it if you want. **Pattern 4**; Py3 pickle now manage both accelerated cPickle and pure python pickle; See https://docs.python.org/3/whatsnew/3.0.html#library-changes, 4th item.; So replace it with. ``` python; if sys.version_info.major > 2:; # Py3 pickle now manage both accelerated cPickle and pure python pickle; # S",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-197397273
Usability,simpl,simplify,"# Import issues. In Python 3, relative import behaviour changes.; In Python 2, ""import module"" loads first local module, then system module. In Python 3, it is the opposite. ## Import patterns in SU2 code. If we consider, to simplify, these generic packages:; `package1/p1m1.py`; `package1/p1m2.py`; `package1/__init__.py`. `package2/p2m1.py`; `package2/__init__.py`. In SU2 code we find these patterns:. **Pattern 1**; `package1/__init__.py`; contains. ``` python; import p1m1; import p1m2; ```. These instructions are useless as it is the common behaviour of package.; If a `__init__.py` is defined, I can do from package1 import p1m1 or import package1.p1m1. Do you know why this happens ? Is there an historical reason or other ?; For example, in [`SU2_PY/SU2/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/__init__.py) or [`SU2_PY/SU2/mesh/__init__.py`](https://github.com/su2code/SU2/blob/master/SU2_PY/SU2/mesh/__init__.py). **Pattern 2**; `package1/__init__.py`; contains. ``` python; from p1m1 import f; ```. **Pattern 3**; `package1/p1m1.py`; contains. ``` python; from ..p1m2 import f; ```. **Pattern 4**. ``` python; import cPickle as pickle; ```. ## Solution. I suggest these solutions:. **Pattern 1**; delete imports. **Pattern 2**; replace `from p1m1 import f` with `from .p1m1 import f` . See also next solution. **Pattern 3**. This is OK. Another approach is to always use absolute imports, for example. ``` python; from ..p1m2 import f; ```. becomes. ``` python; from package1.p1m2 import f; ```. Result is the same except that it is recommended in [PEP8](https://www.python.org/dev/peps/pep-0008/#id20) but first approach is ok too.; I can do it if you want. **Pattern 4**; Py3 pickle now manage both accelerated cPickle and pure python pickle; See https://docs.python.org/3/whatsnew/3.0.html#library-changes, 4th item.; So replace it with. ``` python; if sys.version_info.major > 2:; # Py3 pickle now manage both accelerated cPickle and pure python pickle; # S",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-197397273
Usability,feedback,feedback,"Thank you for all your answers. @economon very good news! I am looking forward this improvement. I will rebase my branch on it. @aerialhedgehog: For first pattern, I didn't thought about this case. Thanks for feedback.; So ok to not change code matching pattern 1. In my own experience, in such cases, I prefer to create a new user friendly module that do all imports. In one hand, users have a very simple module and developers keep all real packages as clean as possible. But in other hand, it is true that there is a bit of duplication and can be confusing for whom exploring code. For pattern 4, yes, if I remember well, It happens only two times. So no need to write an helper function I think.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/246#issuecomment-201337122
Availability,error,error,"igure:4118: checking for gcc option to accept ISO C89; configure:4181: gcc -c -g -O2 conftest.c >&5; configure:4181: $? = 0; configure:4194: result: none needed; configure:4216: checking dependency style of gcc; configure:4327: result: gcc3; configure:4345: checking whether gcc and cc understand -c and -o together; configure:4376: gcc -c conftest.c -o conftest2.o >&5; configure:4380: $? = 0; configure:4386: gcc -c conftest.c -o conftest2.o >&5; configure:4390: $? = 0; configure:4401: cc -c conftest.c >&5; configure:4405: $? = 0; configure:4413: cc -c conftest.c -o conftest2.o >&5; configure:4417: $? = 0; configure:4423: cc -c conftest.c -o conftest2.o >&5; configure:4427: $? = 0; configure:4445: result: yes; configure:4513: checking for ranlib; configure:4529: found /usr/bin/ranlib; configure:4540: result: ranlib; configure:4574: checking how to run the C preprocessor; configure:4605: gcc -E conftest.c; configure:4605: $? = 0; configure:4619: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4619: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | /* end confdefs.h. */; | #include <ac_nonexistent.h>; configure:4644: result: gcc -E; configure:4664: gcc -E conftest.c; configure:4664: $? = 0; configure:4678: gcc -E conftest.c; conftest.c:11:28: error: ac_nonexistent.h: No such file or directory; configure:4678: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code"";",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Deployability,install,install,"opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Integrability,message,messages,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Modifiability,config,config,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Performance,tune,tune,"(GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux; Thread model: posix; gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ; configure:3343: $? = 0; configure:3332: g++ -V >&5; g++: '-V' option must have argument; configure:3343: $? = 1; configure:3332: g++ -qversion >&5; g++: unrecognized option '-qversion'; g++: no input files; configure:3343: $? = 1; configure:3363: checking whether the C++ compiler works; configure:3385: g++ conftest.cpp >&5; configure:3389: $? = 0; configure:3437: result: yes; configure:3440: checking for C++ compiler default output file name; configure:3442: result: a.out; configure:3448: checking for suffix of executables; configure:3455: g++ -o conftest conftest.cpp >&5; configure:3459: $? = 0; configure:3481: result: ; configure:3503: checking whether we are cross compiling; configure:3511: g++ -o conftest conftest.cpp >&5; configure:3515: $? = 0; configure:3522: ./conftest; configure:3526: $? = 0; configure:3541: result: no; configure:3546: checking for suffix of ob",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Safety,safe,safe,"opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whether build environment is sane; configure:2721: result: yes; configure:2872: checking for a thread-safe mkdir -p; configure:2911: result: /bin/mkdir -p; configure:2918: checking for gawk; configure:2934: found /bin/gawk; configure:2945: result: gawk; configure:2956: checking whether make sets $(MAKE); configure:2978: result: yes; configure:3075: checking whether make supports nested variables; configure:3092: result: yes; configure:3117: checking for style of include used by make; configure:3145: result: GNU; configure:3196: result: >>> MPI support disabled by default <<<; configure:3269: checking for g++; configure:3285: found /usr/bin/g++; configure:3296: result: g++; configure:3323: checking for C++ compiler version; configure:3332: g++ --version >&5; g++ (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4); Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. configure:3343: $? = 0; configure:3332: g++ -v >&5; Using built-in specs.; Target: x86_64-redhat-linux; Configured with: ../configure --prefix=/usr --mandir=/usr/share/man ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Testability,log,log,"Hi,. here is the contents of config.log:. ```; This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by SU2 configure 4.1.0, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ ./configure --prefix=/gshare/work/hpascalj/CodeSU2-master --with-CGNS-lib=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/lib --with-CGNS-include=/gshare/soft/code_saturne/4.0.0/prod/cgnslib_3.2.1/include. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = master; uname -m = x86_64; uname -r = 2.6.32-279.el6.x86_64; uname -s = Linux; uname -v = #1 SMP Wed Jun 13 18:24:36 EDT 2012. /usr/bin/uname -p = unknown; /bin/uname -X = unknown. /bin/arch = x86_64; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = unknown; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /gshare/soft/star-ccm+/STAR-View+9.02.007; PATH: /gshare/soft/star-ccm+/STAR-CCM+9.02.007/star/bin; PATH: /opt/xcat/bin; PATH: /opt/xcat/sbin; PATH: /usr/lib64/qt-3.3/bin; PATH: /opt/pbs/default/bin; PATH: /opt/pbs/tools/bin; PATH: /usr/lpp/mmfs/bin/; PATH: /usr/local/bin; PATH: /bin; PATH: /usr/bin; PATH: /usr/local/sbin; PATH: /usr/sbin; PATH: /sbin; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: .; PATH: /gshare/soft/init; PATH: /gshare/soft/scripts; PATH: . ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2465: checking build system type; configure:2479: result: x86_64-unknown-linux-gnu; configure:2499: checking host system type; configure:2512: result: x86_64-unknown-linux-gnu; configure:2532: checking target system type; configure:2545: result: x86_64-unknown-linux-gnu; configure:2587: checking for a BSD-compatible install; configure:2655: result: /usr/bin/install -c; configure:2666: checking whe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Usability,usab,usability,"-o conftest -g -O2 conftest.c >&5; configure:5041: $? = 0; configure:5041: ./conftest; configure:5041: $? = 0; configure:5055: result: 4; configure:5069: checking size of long int; configure:5074: gcc -o conftest -g -O2 conftest.c >&5; configure:5074: $? = 0; configure:5074: ./conftest; configure:5074: $? = 0; configure:5088: result: 8; configure:5102: checking size of float; configure:5107: gcc -o conftest -g -O2 conftest.c >&5; configure:5107: $? = 0; configure:5107: ./conftest; configure:5107: $? = 0; configure:5121: result: 4; configure:5135: checking size of double; configure:5140: gcc -o conftest -g -O2 conftest.c >&5; configure:5140: $? = 0; configure:5140: ./conftest; configure:5140: $? = 0; configure:5154: result: 8; configure:5168: checking size of void *; configure:5173: gcc -o conftest -g -O2 conftest.c >&5; configure:5173: $? = 0; configure:5173: ./conftest; configure:5173: $? = 0; configure:5187: result: 8; configure:5409: checking X11/Intrinsic.h usability; configure:5409: gcc -c -g -O2 conftest.c >&5; conftest.c:61:27: error: X11/Intrinsic.h: No such file or directory; configure:5409: $? = 1; configure: failed program was:; | /* confdefs.h */; | #define PACKAGE_NAME ""SU2""; | #define PACKAGE_TARNAME ""SU2""; | #define PACKAGE_VERSION ""4.1.0""; | #define PACKAGE_STRING ""SU2 4.1.0""; | #define PACKAGE_BUGREPORT ""su2code-dev@lists.stanford.edu""; | #define PACKAGE_URL ""https://github.com/su2code""; | #define PACKAGE ""SU2""; | #define VERSION ""4.1.0""; | #define STDC_HEADERS 1; | #define HAVE_SYS_TYPES_H 1; | #define HAVE_SYS_STAT_H 1; | #define HAVE_STDLIB_H 1; | #define HAVE_STRING_H 1; | #define HAVE_MEMORY_H 1; | #define HAVE_STRINGS_H 1; | #define HAVE_INTTYPES_H 1; | #define HAVE_STDINT_H 1; | #define HAVE_UNISTD_H 1; | #define SIZEOF_SHORT_INT 2; | #define SIZEOF_INT 4; | #define SIZEOF_UNSIGNED_INT 4; | #define SIZEOF_LONG_INT 8; | #define SIZEOF_FLOAT 4; | #define SIZEOF_DOUBLE 8; | #define SIZEOF_VOID_P 8; | /* end confdefs.h. */; | #include <stdio.h>; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/250#issuecomment-205167006
Usability,clear,clear,Also nice would be a clear separation between the blocks. Atm at ending u get Exit .....; Somethin like that:; ![unbenannt](https://cloud.githubusercontent.com/assets/11041576/15497673/13a67f62-219c-11e6-9c89-7dcc1236a706.PNG),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/257#issuecomment-221203675
Usability,resume,resume,"Ok! The workflow about this branch is now quite hard to follow. ; So to resume :; - **#424 is the branch to work on**. #424 is ""py2_and_py3_support"" merged on a recent ""develop"" branch (2017/08/11); - #260 is obsolete and replaced by previous one. That is why I close it",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/260#issuecomment-323942805
Usability,clear,clear,"We have a bit of documentation about this on the wiki here: https://github.com/su2code/SU2/wiki/Post-processing. Does this clear things up? Please let us know if this isn't adequate, and we can add more detail.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/268#issuecomment-213232801
Availability,error,error,Problem solved. Script Workshop now. Just a simple DOS/Windows-Unix fileformat error. -.-,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/279#issuecomment-222963559
Usability,simpl,simple,Problem solved. Script Workshop now. Just a simple DOS/Windows-Unix fileformat error. -.-,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/279#issuecomment-222963559
Testability,test,tests,"Thanks for bringing up this issue. It is interesting... . As Heather mentioned, is there any concern that when writing large files the lack of an endl will cause the buffer to become too large at some point (before the file gets closed and clears the stream automatically)?. Unfortunately, we do not have any regression tests that cover the output files at the moment, so it is difficult to gauge the impact of the changes, although it would be straightforward to add some tests for SU2_CFD and SU2_SOL that diff output files. Have you been able to verify that all CSV, Tecplot/ParaView files, and force breakdown files work appropriately?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/281#issuecomment-223806287
Usability,clear,clears,"Thanks for bringing up this issue. It is interesting... . As Heather mentioned, is there any concern that when writing large files the lack of an endl will cause the buffer to become too large at some point (before the file gets closed and clears the stream automatically)?. Unfortunately, we do not have any regression tests that cover the output files at the moment, so it is difficult to gauge the impact of the changes, although it would be straightforward to add some tests for SU2_CFD and SU2_SOL that diff output files. Have you been able to verify that all CSV, Tecplot/ParaView files, and force breakdown files work appropriately?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/281#issuecomment-223806287
Testability,test,tests,"I did few tests (CGNS mesh format), following are the details -; **While trying to use all 8 cores per node (Total 70 nodes, each having 24 GB RAM)-**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; ............ malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; ................; malloc failed for element data; malloc failed for element data; Loading section Connect_TETRA of element type Tetrahedron. **While trying 6 cores in each node**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data. **Finally settled with 4 cores at each node and memory usage at every node is--** . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND ; 4652 aero 30 10 872m 746m 10m R 100 3.1 43:03.38 SU2_CFD ; 4653 aero 30 10 1076m 951m 10m R 100 3.9 43:12.10 SU2_CFD ; 4654 aero 30 10 1162m 1.0g 10m R 100 4.3 43:15.15 SU2_CFD ; 4655 aero 30 10 1458m 1.3g 10m R 100 5.5 43:08.96 SU2_CFD . **With above, memory usage seems to be around 16.8 % of 24 GB RAM**. Hope I am not missing something else (some other usage etc...) and what should be the approximate memory requirement for such mesh sizes (around 60 million or is there a general guideline of memory requirement with mesh size for RANS computation with Implicit solver) ?. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/291#issuecomment-232018195
Usability,guid,guideline,"I did few tests (CGNS mesh format), following are the details -; **While trying to use all 8 cores per node (Total 70 nodes, each having 24 GB RAM)-**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; ............ malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; Error allocating I4->I8 data array...; malloc failed for element data; ................; malloc failed for element data; malloc failed for element data; Loading section Connect_TETRA of element type Tetrahedron. **While trying 6 cores in each node**. Loading section Connect_PRISM of element type Prism.; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data; malloc failed for element data. **Finally settled with 4 cores at each node and memory usage at every node is--** . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND ; 4652 aero 30 10 872m 746m 10m R 100 3.1 43:03.38 SU2_CFD ; 4653 aero 30 10 1076m 951m 10m R 100 3.9 43:12.10 SU2_CFD ; 4654 aero 30 10 1162m 1.0g 10m R 100 4.3 43:15.15 SU2_CFD ; 4655 aero 30 10 1458m 1.3g 10m R 100 5.5 43:08.96 SU2_CFD . **With above, memory usage seems to be around 16.8 % of 24 GB RAM**. Hope I am not missing something else (some other usage etc...) and what should be the approximate memory requirement for such mesh sizes (around 60 million or is there a general guideline of memory requirement with mesh size for RANS computation with Implicit solver) ?. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/291#issuecomment-232018195
Deployability,update,update,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911
Safety,avoid,avoid,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911
Usability,feedback,feedback,"Hi Ruben,. Thank you for your feedback !. It is hard to tell what to do you to avoid conflicts. Anyway, the most significant part of the changes concerns the parent CDriver class, especially the constructor and some new functions that are pieces of code coming from the main function (like Output and Monitor). So if the contributions are focused on one particular driver (single, multi, ...) and if they are more or less compatible with the main ""driver->run"" then ""driver->update"" structure, it should be straightforward to solve the potential confilcts. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237702911
Usability,feedback,feedback,"Thanks, David & Ruben. If anyone else has feedback or concerns, please let us know. We'll likely merge this in tomorrow. If folks have trouble with conflicts from the previous memory fixes, or have conflicts with these CDriver changes, We're happy to work with you directly. Just let me know.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/295#issuecomment-237737515
Usability,feedback,feedback,Ok.. thanks for the feedback. We'll go ahead with the current version (handled like the --enable-mpi option) for now.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/298#issuecomment-240882029
Usability,feedback,feedback,"I think the last commit addressed your concerns @arubino, thanks for the feedback.; @LaSerpe - that fsi bug was fixed in a separate pull request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/312#issuecomment-253286105
Integrability,interface,interface,"Hey @LaSerpe (Giulio),. I had a look at the new driver structure and it look clear to me. My only comments is on the name of the classes: I agree on having a GeneralDriver in place of the SingleZone and MultiZone Driver, as @tobadavid said we should distinguish the drivers for the different physics/applications, but the name CFluidDriver I think is a bit misleading considering the fact that is specifically for multizone fluid with sliding-mesh interface. Perhaps a SlidingMeshDriver sounds better??? Any suggestion from the others?. Regarding the fact that you still have to specify the FSI_MARKER, i would fix this before merging with the develop. . Anyway good job!!! . cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-255340813
Usability,clear,clear,"Hey @LaSerpe (Giulio),. I had a look at the new driver structure and it look clear to me. My only comments is on the name of the classes: I agree on having a GeneralDriver in place of the SingleZone and MultiZone Driver, as @tobadavid said we should distinguish the drivers for the different physics/applications, but the name CFluidDriver I think is a bit misleading considering the fact that is specifically for multizone fluid with sliding-mesh interface. Perhaps a SlidingMeshDriver sounds better??? Any suggestion from the others?. Regarding the fact that you still have to specify the FSI_MARKER, i would fix this before merging with the develop. . Anyway good job!!! . cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-255340813
Testability,test,tests,"I've (finally) managed to go over this pull request. I didn't go into too much detail as I don't want to delay this any more, but in general it all looks great to me. I have run some extra regression tests locally in my computer, and they all seem to be working fine. I also left some comments around, but they are mostly asking for some clarification, no major issues. All cleared from my side. Sorry again for taking way too long, I was so behind myself that I needed to do some merging in my own branches to be able to understand the changes in FSI context... Thanks a lot @LaSerpe for a great work!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-258872671
Usability,clear,cleared,"I've (finally) managed to go over this pull request. I didn't go into too much detail as I don't want to delay this any more, but in general it all looks great to me. I have run some extra regression tests locally in my computer, and they all seem to be working fine. I also left some comments around, but they are mostly asking for some clarification, no major issues. All cleared from my side. Sorry again for taking way too long, I was so behind myself that I needed to do some merging in my own branches to be able to understand the changes in FSI context... Thanks a lot @LaSerpe for a great work!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/322#issuecomment-258872671
Availability,error,errors,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156
Testability,test,test,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156
Usability,clear,clearly,"Yikes. Thanks, @LaSerpe, for the heads up. There is clearly something wrong with SU2_SOL for many of the cases, although the compute portion is fine. We should get a test case set up for SU2_SOL, or at least try to catch these errors too. @fpalacios, can you please take a look at this problem when you have a moment? It seems to have shown up with the merging of feature_cte_cl. Just fyi for all: the Travis CI folks have generously granted extra time for our regression tests, up to 70 minutes now. This fixes the time-out issues in the short term, but there are a few strategies we should look at for caching or further decomposing our builds to keep under the time limits in the future as we keep growing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262118156
Usability,simpl,simply,"looks like there is an array overflow in solver_structure.cpp (line 2347). ` ; while (getline (solution_file, text_line) ) {; istringstream point_line(text_line);; ; /*--- Retrieve local index. If this node from the restart file lives; on a different processor, the value of iPoint_Local will be -1, as; initialized above. Otherwise, the local index for this node on the; current processor will be returned and used to instantiate the vars. ---*/; ; iPoint_Local = Global2Local[iPoint_Global];; if (iPoint_Local >= 0) {; ; /*--- The PointID is not stored --*/; //cout << iPoint_Local << endl;; point_line >> index;; ; /*--- Store the solution (starting with node coordinates) --*/; ; for (iField = 0; iField < nVar; iField++); point_line >> Solution[iField];; ; node[iPoint_Local]->SetSolution(Solution);; ; ; }; iPoint_Global++;; }; ` . I had a brief look at it and seems the issue can be solved by simply adding the condition ""&& iPoint_Global < geometry[iZone]->GetnPointDomain()"" to the outer while loop, but I'm not completely sure this is the best way to fix the code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/325#issuecomment-262186418
Modifiability,variab,variable,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833
Security,validat,validation,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833
Testability,test,test,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833
Usability,feedback,feedback,"Dear all, ; I have added a pdf file here that includes some test case results obtained with our BC transition model. These zero pressure gradient and variable pressure gradient flat plate test cases are very popular for model validation. I have also included Eppler E387 airfoil results. I would appreciate if you have any 3-D test case and share it with me.; Looking forward to hear your feedback. ; Sincerely,; Samet. [BC_model_TestCaseResults.pdf](https://github.com/su2code/SU2/files/562425/BC_model_TestCaseResults.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/326#issuecomment-257360833
Testability,test,test,"Also works for me now! Thanks for fixing this. ~~Travis failed due to reaching the maximum time for a job. The usual time the serial test take in other PRs is like 45 min, but this one was killed after 1h 9 min. Is there something that could go wrong in the non-mpi case ?~~. ~~I just restarted the tests to see whether it occurs again.~~ . Now it has passed. If it happens again, simply restart the job in Travis ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/328#issuecomment-264239270
Usability,simpl,simply,"Also works for me now! Thanks for fixing this. ~~Travis failed due to reaching the maximum time for a job. The usual time the serial test take in other PRs is like 45 min, but this one was killed after 1h 9 min. Is there something that could go wrong in the non-mpi case ?~~. ~~I just restarted the tests to see whether it occurs again.~~ . Now it has passed. If it happens again, simply restart the job in Travis ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/328#issuecomment-264239270
Testability,test,test,"Thanks Francisco for this contribution! Although the FFD Framework is already working quite well, there is still (like always) room for improvement. In fact, I am currently working on using BSplines instead of Bezier curves. I'm going to open a pull request end of this week. But this shouldn't affect this one I hope. Do you have by any chance a simple test case I could use to check this ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/330#issuecomment-260475206
Usability,simpl,simple,"Thanks Francisco for this contribution! Although the FFD Framework is already working quite well, there is still (like always) room for improvement. In fact, I am currently working on using BSplines instead of Bezier curves. I'm going to open a pull request end of this week. But this shouldn't affect this one I hope. Do you have by any chance a simple test case I could use to check this ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/330#issuecomment-260475206
Usability,guid,guide,"Ok, sounds good. I'll go ahead and close this since it is being replaced by the other pull request. ; Since you mention formatting, [here](https://github.com/su2code/SU2/wiki/Style-Guide) is our style guide for reference. I think you are probably right that there are places where it is not strictly followed, and if you would like to spend the time to fix those things that would be welcome. Thanks again for the pull request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/331#issuecomment-261699279
Deployability,patch,patch,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218
Energy Efficiency,reduce,reduce,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218
Modifiability,refactor,refactored,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218
Usability,simpl,simply,"This is simply the way how the cmd.exe shell works on Windows - file and folder names containing spaces or special characters must be quoted into `""` to be handled correctly.; The title says it all - *to make them [executables] run*. The patch prepends one `""` and appends one `""` to the command name. This could be refactored further to reduce repetition much more by putting the different executable file names into a map and have a single place to combine quote + executable + quote.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/332#issuecomment-321264218
Availability,mainten,maintenance,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192
Testability,test,test,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192
Usability,simpl,simply,"Hi Josip,. in the current develop/master these features are still included. However, the plan is to remove these. The reason is simply because of maintenance. We have nobody that can spare time to test the current implementation. If you are willing to do this, please let use know. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/348#issuecomment-268010192
Usability,clear,clear,"Hi Tim, Heather: yes, this is an important issue to clear up before releasing v5 this week. Let's use this PR to fix the issue (even if just short term), and we'll find a better long term solution. I'm taking a look at this now too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/352#issuecomment-271199146
Modifiability,config,config,"I also agree that there should be an explicit option, and that it should; default to the current behavior, however it may be more intuitive for the; user to specify the actual step size- people who don't have Francisco's; extensive experience will not intuit that the finite difference step will; be 1/100 of the reference length, and may have difficulty figuring that out; without help. I suggest something like FD_STEP_SIZE, either way with; documentation explaining it.; -H. On Mar 6, 2017 5:26 PM, ""juanjosealonso"" <notifications@github.com> wrote:. > Agree with Francisco: the best solution is to have an input parameter that; > can be used to scale the FD step size. I would suggest FD_REFERENCE_LENGTH; > to be created (and possibly specified in the config file). If; > FD_REFERENCE_LENGTH is not specified, then it could default to; > REF_LENGTH_MOMENT.; >; > Best,; >; > Juan; >; > On Mar 5, 2017, at 6:35 PM, Francisco Palacios <notifications@github.com<; > mailto:notifications@github.com>> wrote:; >; > Hi,; >; > Yep, I changed that. I know that from the math point of view it doesn’t; > make a lot of sense but, from the practical point of view, it is useful.; >; > There are some cases, in which computing gradients using finite; > differences is the only choice. And with the shape_optimization script it; > was not possible to control the step size for the finite differences. The; > option for step size was only in finite_differences.py.; >; > The step size is scaled with the reference length because from the; > practical point of view, I have found that the size of the aircraft, wing,; > airfoil, is important to determine a meaningful step size. e.g. should we; > use the same step for an aircraft with a MAC of ~150in than for an airfoil; > with a chord of 1in.; >; > Remember that most of the times we are using FD when the adjoint is not; > converging… so we have bad convergence of the direct problem (including; > some level of unsteadiness that we want to filter with the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284314148
Usability,intuit,intuitive,"I also agree that there should be an explicit option, and that it should; default to the current behavior, however it may be more intuitive for the; user to specify the actual step size- people who don't have Francisco's; extensive experience will not intuit that the finite difference step will; be 1/100 of the reference length, and may have difficulty figuring that out; without help. I suggest something like FD_STEP_SIZE, either way with; documentation explaining it.; -H. On Mar 6, 2017 5:26 PM, ""juanjosealonso"" <notifications@github.com> wrote:. > Agree with Francisco: the best solution is to have an input parameter that; > can be used to scale the FD step size. I would suggest FD_REFERENCE_LENGTH; > to be created (and possibly specified in the config file). If; > FD_REFERENCE_LENGTH is not specified, then it could default to; > REF_LENGTH_MOMENT.; >; > Best,; >; > Juan; >; > On Mar 5, 2017, at 6:35 PM, Francisco Palacios <notifications@github.com<; > mailto:notifications@github.com>> wrote:; >; > Hi,; >; > Yep, I changed that. I know that from the math point of view it doesn’t; > make a lot of sense but, from the practical point of view, it is useful.; >; > There are some cases, in which computing gradients using finite; > differences is the only choice. And with the shape_optimization script it; > was not possible to control the step size for the finite differences. The; > option for step size was only in finite_differences.py.; >; > The step size is scaled with the reference length because from the; > practical point of view, I have found that the size of the aircraft, wing,; > airfoil, is important to determine a meaningful step size. e.g. should we; > use the same step for an aircraft with a MAC of ~150in than for an airfoil; > with a chord of 1in.; >; > Remember that most of the times we are using FD when the adjoint is not; > converging… so we have bad convergence of the direct problem (including; > some level of unsteadiness that we want to filter with the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284314148
Usability,intuit,intuitive,"I agree with Heather on that. It is only intuitive if you already have the experience. And in that case you know what an appropriate step size is, so you can also specify it directly without having it scaled by some reference length (and of course also consider the case where you don't have an aircraft, wing or airfoil).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/367#issuecomment-284349273
Usability,simpl,simple,"Any other comments here? Otherwise, this is a simple addition that we can put in right away, and folks can hack away on Doxygen whenever their heart desires.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/373#issuecomment-279838683
Usability,clear,clearly,"Hi guys,; I agree with you, we should change the name of that function including the word ""fluid"". ; In this way the purpose of the function is stated clearly against its counterparts (structural, poisson, heat, etc)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/375#issuecomment-279957104
Usability,feedback,feedback-discussions,"Please see the response on the [forum](https://www.cfd-online.com/Forums/su2/184789-poor-quality-mesh-after-deformation-su2-5-0-0-a.html#post640783).; In the future, please note that it is [recommended](https://www.cfd-online.com/Forums/site-help-feedback-discussions/175429-guide-how-ask-question-forums.html#post612025) not to double-post questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/384#issuecomment-286555388
Deployability,continuous,continuous,"@fpalacios - For the continuous adjoint it is NOT required to run multiple adjoints, you can actually combine them. Whether or not to do so is controlled by the OPT_COMBINE_OBJECTIVE option - I will try to add in some more comments as you suggest to make this clearer, along with other updates next week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-294324095
Usability,clear,clearer,"@fpalacios - For the continuous adjoint it is NOT required to run multiple adjoints, you can actually combine them. Whether or not to do so is controlled by the OPT_COMBINE_OBJECTIVE option - I will try to add in some more comments as you suggest to make this clearer, along with other updates next week.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-294324095
Deployability,continuous,continuous,"Hi Heather, I think we are getting closer. Something that is not clear for me is why we can only combine objective functions with the continuous adjoint. In principle, it is ""easier"" to combine objective functions with he discrete adjoint. Isn't it? Is there a particular reason for not combining the objective functions with he discrete adjoint? Thanks! Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296408505
Usability,clear,clear,"Hi Heather, I think we are getting closer. Something that is not clear for me is why we can only combine objective functions with the continuous adjoint. In principle, it is ""easier"" to combine objective functions with he discrete adjoint. Isn't it? Is there a particular reason for not combining the objective functions with he discrete adjoint? Thanks! Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296408505
Modifiability,config,config,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557
Testability,test,test,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557
Usability,clear,clear,"Thanks; The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver. ; An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409557
Modifiability,config,config,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876
Testability,test,test,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876
Usability,clear,clear,"Thanks for the clarification!. Best,; Francisco. > On Apr 22, 2017, at 5:01 PM, Heather Kline <notifications@github.com> wrote:; > ; > Thanks; > The discrete adjoint can also be used with combined objectives, and uses the same config specifications. It may not be clear from this pull request since this functionality was added in a previously - when multiple objectives (limited to objectives defined inside the CFD solver) are specified, they are added together (with specified weights) in the CFD solver into the 'COMBO' output to history. This variable is registered for the discrete adjoint solver.; > An example of this can be seen in the serial_regression_AD.py, test name 'discadj_multi_py'.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/385#issuecomment-296409557>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEpklrJ5WQ8CoWJNAy_FVZ0bbYN000s2ks5rypTpgaJpZM4MgM_e>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/385#issuecomment-296409876
Modifiability,config,config,"@petebachant: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327308587
Usability,simpl,simple,"@petebachant: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327308587
Modifiability,config,config,"in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327308587>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJUhyEBSuSzHV1a7BZM_Frxbtb5sks5sfbzUgaJpZM4NvG6w>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634
Performance,perform,performing,"All,. Regarding the wall function specification, if we are going to settle on a standard way that could work for both the FV and DG-FEM solvers, it might be good to think about some modifiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634
Testability,test,tested,"All,. Regarding the wall function specification, if we are going to settle on a standard way that could work for both the FV and DG-FEM solvers, it might be good to think about some modifiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634
Usability,simpl,simple,"fiers that can later allow for a generality of approaches. We can make a distinction between wall functions and wall models, but this is subject to discussion…in essence both are performing similar duties, but people should express their opinions. With that said, how about a boolean such as USE_WALL_FUNCTIONS / USE_WALL_MODEL (YES or NO) with an optional argument WALL_FUNCTION_TYPE / WALL_MODEL_TYPE that can taken one of many pre-specified values that can be added as these options are developed and tested? Certainly options like STANDARD_WALL_FUNCTION, ADAPTIVE_WALL_FUNCTION, SCALABLE_WALL_FUNCTION, compressible and incompressible versions, and even EQUILIBRIUM_WALL_MODEL and NONEQUILIBRIUM_WALL_MODEL are things that are likely to be in the code in the near future. Thoughts?. Juan. On Sep 5, 2017, at 2:27 PM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. @petebachant<https://github.com/petebachant>: the paper that I linked earlier on this thread had some fairly simple examples similar to the one you propose.. different flat plates and so on with varying y^+. You can likely reuse the grid(s) in the TestCases repo. @vdweide<https://github.com/vdweide>: it was very simple in this first implementation. It checks for a single boolean for whether or not to apply wall functions (WALL_FUNCTIONS= YES or NO, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L15339), and then assumes they should be applied to all no-slip walls (heat flux or isothermal, https://github.com/su2code/SU2/blob/43b8a4015c4b09b01d78e4243d32011c663c2b70/SU2_CFD/src/solver_direct_mean.cpp#L16653). This could of course be made more specific for individual markers using a config structure like MARKER_MONITORING to list them, or by making a dedicated BC type for it potentially. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327313634
Deployability,integrat,integration,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108
Integrability,integrat,integration,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108
Modifiability,config,config,"Edwin,. I think it is a good idea to be able to have some level of control over the application of the wall functions on a marker-by-marker basis: as you say, it would be fairly common to have a wing marker where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model ty",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108
Testability,log,logic," where integration to the wall makes sense and a fuselage marker where wall functions (or even an inviscid BC) is the right thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108
Usability,simpl,simpler,"thing to do. So let’s indeed do something like what Tom suggests (in the spirit of MARKER_MONITORING) so that one can control which markers get wall functions applied. If a list of markers is not specified in the config file, the default behavior should be that all no-slip walls get wall function BCs. If a list of markers is specified, then those and only those markers listed get wall function Bfs (with the others getting integration to the wall treatment). Now, what you point out in the second half of your message is the ultimate in flexibility: not only specifying wall functions in a subset of the no-slip wall markers, but also allowing for different kinds of wall functions to be used in those markers. I imagine that this would be a seldom used capability…but someone out there might have the need. I guess it does not seem to me that the coding of the most flexible logic is that much more complicated, so we may as well do that. If you guys think it is too complicated, the advertised options in the config file can allow some simpler behavior. My two cents,. Juan. On Sep 5, 2017, at 9:58 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Juan,. I think that having the flexibility to apply wall functions on only a subset of the viscous wall boundaries would be useful. E.g., if you are interested in a wing, you can apply integration to the wall there, but apply wall functions on the fuselage. My preference would be to have a dedicated BC type for that, i.e. Tom's second suggestion. Apart from this, we can have the different wall model types as a single input parameter, i.e. you apply the same wall model type for all viscous boundaries. Or would you like to have the flexibility to specify this as well per individual marker?. Edwin. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/399#issuecomment-327374728>, or mute the thread<https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/399#issuecomment-327377108
Safety,avoid,avoid,"@elfring: thank you very much for the suggestion, but for the time being, our philosophy is to keep the code as simple as possible to keep a low barrier to entry for new users/developers. Therefore, we try to avoid templates when possible (there are a few isolated places where they are necessary). This may change in the future, but we'll close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360053938
Usability,simpl,simple,"@elfring: thank you very much for the suggestion, but for the time being, our philosophy is to keep the code as simple as possible to keep a low barrier to entry for new users/developers. Therefore, we try to avoid templates when possible (there are a few isolated places where they are necessary). This may change in the future, but we'll close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360053938
Safety,avoid,avoid,">Therefore, we try to avoid templates when possible …. I find this view strange. I would appreciate if current C++ software techniques can be applied. How much can they help to make the source code a bit simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360055094
Usability,simpl,simpler,">Therefore, we try to avoid templates when possible …. I find this view strange. I would appreciate if current C++ software techniques can be applied. How much can they help to make the source code a bit simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360055094
Modifiability,portab,portable,"I understand, but it helps to keep the code more approachable and portable. That being said, there may be some work proposed soon using templates in the linear solver classes, and it would be great to have your feedback then. We really appreciate your interest!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360075745
Usability,feedback,feedback,"I understand, but it helps to keep the code more approachable and portable. That being said, there may be some work proposed soon using templates in the linear solver classes, and it would be great to have your feedback then. We really appreciate your interest!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/400#issuecomment-360075745
Integrability,depend,depends,"Dear @oleburghardt, . Unfortunately, your initial reply lacks of any constructive contribution. . SU2 depends on the feedback of you all. We should not discourage anybody to change/improve, show interest, ask for clarification, etc. The tone of your initial replay was unjustified and not polite.; From now on, your profile as a member of the developer team (collaborator) will be not longer active. Peace,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/405#issuecomment-313775430
Usability,feedback,feedback,"Dear @oleburghardt, . Unfortunately, your initial reply lacks of any constructive contribution. . SU2 depends on the feedback of you all. We should not discourage anybody to change/improve, show interest, ask for clarification, etc. The tone of your initial replay was unjustified and not polite.; From now on, your profile as a member of the developer team (collaborator) will be not longer active. Peace,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/405#issuecomment-313775430
Modifiability,parameteriz,parameterization,"ce_adjoint files and in contrary as what Ole expected; the compressible gives a more wavy result. However the deviation of the sens_adjoint of incompressible is huge compare to the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28306613-4425789c-6ba0-11e7-8337-41a99e15ebd2.png). So if I am understanding correctly, in order to determine the sensitivity an initial deviation of the control points has to be set to determine the (dx/dC)-term. In which 'x' indicates discrete points and 'C' control points. . ![image](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%20%3D%20%5Cfrac%7B%5Cpartial%20%5Cvec%7Bx%7D%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%5Ccdot%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7Bx%7D%7D). Tim do you mean with the current step size the step of dC ? Because the step of the discrete point is set on 0.001 (of_grad_cd.vtk). If you mean the control point step, then there should be a parameterization step in between as well in order to know the influence of dC to dx. This should give a difference in sensitivity results, however the sensitivities of the case of scale = 0.01 and of the case scale =1 are exactly the same (for the compressible and incompressible case). The values below are gradients of the file of_grad_cd.vtk from the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28307680-f01c9240-6ba3-11e7-8ada-4ddf9e4ae0a9.png). The final thing which I still have to check is the residuals of the direct and adjoint solution. As can be seen there is a difference in convergence and result, which I think is due to the difference in regime. The convergence of the direct solution is: ; ![image](https://user-images.githubusercontent.com/21182966/28309520-e967cbc6-6ba9-11e7-9233-9c9f69db126b.png). The convergence of the adjoint solution is:; ![image](https://user-images.githubusercontent.com/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103
Performance,optimiz,optimization,"nce in convergence and result, which I think is due to the difference in regime. The convergence of the direct solution is: ; ![image](https://user-images.githubusercontent.com/21182966/28309520-e967cbc6-6ba9-11e7-9233-9c9f69db126b.png). The convergence of the adjoint solution is:; ![image](https://user-images.githubusercontent.com/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103
Testability,test,tested,"Hi Tim and Ole,. First of all thanks for you great support! I noticed that the convergence of the compressible case was more difficult to obtain, compared to the incompressible case. After fixing this convergence I changed the scale factor for the incompressible and compressible case. I tested the scales 1e-6 up to 10 and 5e-6 up to 5, with a step size of 10. In this reply I posted the results of scale = 0.01, which is behaving properly for the compressible case (Scale 1 of compressible and the test cases of incompressible are not working as expected). During these tests I kept an eye on the surface_adjoint files and in contrary as what Ole expected; the compressible gives a more wavy result. However the deviation of the sens_adjoint of incompressible is huge compare to the compressible case. ![image](https://user-images.githubusercontent.com/21182966/28306613-4425789c-6ba0-11e7-8337-41a99e15ebd2.png). So if I am understanding correctly, in order to determine the sensitivity an initial deviation of the control points has to be set to determine the (dx/dC)-term. In which 'x' indicates discrete points and 'C' control points. . ![image](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%20%3D%20%5Cfrac%7B%5Cpartial%20%5Cvec%7Bx%7D%7D%7B%5Cpartial%20%5Cvec%7BC%7D%7D%5Ccdot%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cvec%7Bx%7D%7D). Tim do you mean with the current step size the step of dC ? Because the step of the discrete point is set on 0.001 (of_grad_cd.vtk). If you mean the control point step, then there should be a parameterization step in between as well in order to know the influence of dC to dx. This should give a difference in sensitivity results, however the sensitivities of the case of scale = 0.01 and of the case scale =1 are exactly the same (for the compressible and incompressible case). The values below are gradients of the file of_grad_cd.vtk from the compressible case. ![image](https://user-images.githubu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103
Usability,learn,learn,"/21182966/28308831-b937bf76-6ba7-11e7-9108-e8a2ab959b74.png). Then I noticed a difference in SENS_GEO (which is the second term of the upper equation, right?) between compressible and incompressible. . ![image](https://user-images.githubusercontent.com/21182966/28310143-bb28c42a-6bab-11e7-8c14-8409b6b12027.png). So if the scale is adjusting current step size the step of dC and SENS_GEO represents the second term, then the SENS_GEO would change when the scale is changed. But this is not the case for incompressible and compressible. . In short, the only noticeable change, due to scaling, occurs in deformation folder of DSN_002. But this is after the optimization step, which is really confusing. Scaling adjusts the current step size and because it can not find a sufficient decrease it is halving the dv_value. But then one should expect different values in the adjoint folder for different scale factors, right?. I hope you can use this information and can tell me whether it is a correct behavior of the optimizer. I should also note that I did not make use of constraints, just as in the test case. I read that the optimizer will switch from optimization procedure. I think this should not matter because of the test case. . I attached also the configure files (compressible (working, scale= 0.01) and incompressible (not working, scale =0.01)) and the mesh file, which is in both cases the same file. [compressible_cfg.txt](https://github.com/su2code/SU2/files/1155421/compressible_cfg.txt); [incompressible_cfg.txt](https://github.com/su2code/SU2/files/1155427/incompressible_cfg.txt); [mesh_300_su2.txt](https://github.com/su2code/SU2/files/1155430/mesh_300_su2.txt). I hope I provide enough information so that one can clarify the behavior of the optimizer. I also appreciate if one can tell me which variables have to be kept in mind. I really want to learn from this and if more information is needed, I really do not mind to provide it. Many thanks in advance!. Floris van der Schuur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/409#issuecomment-316018103
Modifiability,maintainab,maintainability,"Hi JSmith86,. I really appreciate your effort in cleaning up the changes. But it looks like as if there are still a lot of changes in other parts that are not related to the things you describe. Furthermore I really request you to split this up in multiple commits so that it is immediately clear what you did in each single one (this can be done quite simple with a proper diff tool like [meld](http://meldmerge.org/)). Let me emphasize that this is not to bother you in any way but rather to ease understanding and maintainability. I know from my own experience that this requires some additional work, but in the end it certainly pays off. . Thanks!; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315320576
Usability,clear,clear,"Hi JSmith86,. I really appreciate your effort in cleaning up the changes. But it looks like as if there are still a lot of changes in other parts that are not related to the things you describe. Furthermore I really request you to split this up in multiple commits so that it is immediately clear what you did in each single one (this can be done quite simple with a proper diff tool like [meld](http://meldmerge.org/)). Let me emphasize that this is not to bother you in any way but rather to ease understanding and maintainability. I know from my own experience that this requires some additional work, but in the end it certainly pays off. . Thanks!; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315320576
Usability,simpl,simplify,"Hi @talbring, I cannot agree more with you, . @JSmith36 has introduced too many changes in one pull request which has, as you pointed out, some important problems. On the other hand, @JSmith36 situation is not so strange. It is quite common to find contributors who are working on their own branch for a long time and at a certain point decide to contribute (which is very generous of them). My suggestion is the following... let's keep the pull request open (we don't want to lose this contribution) and meanwhile, @JSmith36 why don't you create pull request with the most-easy to- divide parts of your contribution. e.g. Let's start with ; ""Renaming of the keywords REF_LENGTH_MOMENT (the word MOMENT was really confusing) or RefAreaCoeff."". That is easy to reimplement and it will simplify the main pull request. For the future, please, let's all of us to keep the contributions the most simple and modular as possible. Thank you very much to each of you who contribute to this great community and great code!. Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315563582
Usability,simpl,simplify,"@fpalacios I also think it is a good idea to keep the request open. Like I said, I can also help to simplify it. In fact, splitting it up in multiple commits is probably easier then you might think @JSmith36 :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-315606418
Modifiability,config,config,"Good catch! yep! I implemented an interesting/important change: Before, WALL_DISTANCE was computed using only the surfaces that you have identified as moving surfaces... as you can imagine that only works when you have a very simple problem (maybe an airfoil) but... if you have a problem with more Navier-Stokes markers together and you are moving only one of them the method doesn't work (e.g. wing-fuselage). For that reason I reimplemented WALL_DISTANCE which now is computed from all the solid surfaces and I also created DEF_WALL_DISTANCE that computes the distance from the surfaces that we are moving (as before). Frankly, I haven't found a situation in which DEF_WALL_DISTANCE outperforms the new solid WALL_DISTANCE... And, my suggestion is to eliminate DEF_WALL_DISTANCE in the future. For the time being I have added DEFORM_STIFFNESS_TYPE= DEF_WALL_DISTANCE to the config files to see if that solves the problem. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-318673304
Usability,simpl,simple,"Good catch! yep! I implemented an interesting/important change: Before, WALL_DISTANCE was computed using only the surfaces that you have identified as moving surfaces... as you can imagine that only works when you have a very simple problem (maybe an airfoil) but... if you have a problem with more Navier-Stokes markers together and you are moving only one of them the method doesn't work (e.g. wing-fuselage). For that reason I reimplemented WALL_DISTANCE which now is computed from all the solid surfaces and I also created DEF_WALL_DISTANCE that computes the distance from the surfaces that we are moving (as before). Frankly, I haven't found a situation in which DEF_WALL_DISTANCE outperforms the new solid WALL_DISTANCE... And, my suggestion is to eliminate DEF_WALL_DISTANCE in the future. For the time being I have added DEFORM_STIFFNESS_TYPE= DEF_WALL_DISTANCE to the config files to see if that solves the problem. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/412#issuecomment-318673304
Usability,simpl,simply,"Just to clarify things, I am not against pull requests with a lot of changes, @fpalacios. For me the problem in #412 is simply the fact that everything is included in one commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/413#issuecomment-316343468
Modifiability,variab,variables,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810
Usability,clear,clearing,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810
Testability,test,test,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764
Usability,learn,learn,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764
Testability,test,tests,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631
Usability,feedback,feedback,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631
Deployability,integrat,integrated,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
Integrability,integrat,integrated,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
Usability,guid,guide,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
Deployability,integrat,integrated,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
Integrability,integrat,integrated,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
Testability,test,test,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
Usability,guid,guide,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
Integrability,rout,routine,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
Modifiability,variab,variables,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
Security,access,access,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
Testability,test,test,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
Usability,simpl,simple,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
Usability,clear,clear,"Hi, this sounds very interesting!; I'll take the chance to raise a point: we still don't have a clear strategy to manage the output of multi-zone simulations. Indeed, earlier we used to have the residuals plotted for each zone (so we used to have a line for each zone), currently we just get the residuals corresponding to ZONE_0 (this was probably changed in one of the latest pull request, I think it could be the one from @salvovitale ). We should decide if to restore the previous ""multi-residual"" output or if to sum up residuals from each zone and print out the results.; Cause right now we can't know how the residuals are behaving in the rest of the domain.; We could perhaps create an additional ""special"" output to manage multi-zone computations. cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/432#issuecomment-326204080
Usability,feedback,feedback,"Thanks for the feedback. The GitHub pages site is now the official project page, and the redirect has been put in place. Please let me know asap if any problems arise. @vdweide: yes, let's keep with our normal development process for the website, including PRs and code reviews, etc., in order to maintain quality and keep everyone informed. Lastly, if anyone is very interested in working on a website overhaul, please let us know.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/436#issuecomment-329063810
Deployability,integrat,integrate,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
Integrability,interface,interface,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
Usability,clear,clearly,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
Usability,clear,clear,"Dear @salvovitale,. I realize that it requires significant changes in the code structure and I don't have a clear answer how to do this, also because I don't know all the details of the implementation of the multi-physics simulations. . The only thing I do know is that the loop over the zones must be inside the loop over the RK stages, at least for the fluid zones. Whether this is also the case for e.g. fluid-structure problems, I don't know. As you mentioned, the opinion of the other developers is greatly appreciated on this matter. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328302068
Deployability,integrat,integration,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
Integrability,integrat,integration,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
Usability,simpl,simply,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
Deployability,integrat,integrated,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
Integrability,integrat,integrated,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
Usability,clear,clear,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developer’s meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developer’s meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
Availability,avail,available," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
Deployability,integrat,integration,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
Integrability,integrat,integration,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
Safety,predict,predictor,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
Usability,simpl,simply," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
Deployability,integrat,integration,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
Integrability,integrat,integration,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
Usability,simpl,simply,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
Deployability,integrat,integration,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
Energy Efficiency,charge,charge,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
Integrability,integrat,integration,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
Modifiability,coupling,coupling,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
Usability,simpl,simply,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
Availability,avail,available,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826
Usability,simpl,simple,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826
Availability,error,error,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
Integrability,message,messages,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
Usability,clear,clear,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
Deployability,update,updates,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805
Usability,feedback,feedback,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805
Integrability,wrap,wrapping,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
Testability,test,tests,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
Usability,simpl,simple,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
Testability,test,test,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
Usability,simpl,simply,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
Availability,avail,available,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
Integrability,rout,routines,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
Usability,simpl,simple,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
Availability,avail,available,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
Deployability,configurat,configuration,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
Integrability,rout,routines,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
Modifiability,config,configuration,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
Usability,simpl,simple,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
Testability,test,test,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237
Usability,feedback,feedback,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237
Availability,error,error,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059
Usability,simpl,simple,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059
Usability,guid,guidance,"Hi Tom,; ; I would like to work on the ALE and rotating frame implementations for incompressible solver. Under Edwin's guidance I have been looking at SU2 closely over the past few months and, as you might have heard from him, we are looking to implement a pressure based scheme. . Also, could you tell me more about what are the changes you are planning for the incompressible solver? . Thanks a lot.; Regards,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/468#issuecomment-343086793
Usability,clear,clear,I have the same problem but I don't understand the solutions you suggested. Could you explain to me a bit clear?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/469#issuecomment-707290679
Availability,error,error,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
Deployability,configurat,configuration,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
Integrability,rout,routine,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
Modifiability,config,configuration,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
Usability,simpl,simply,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
Testability,test,test,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851
Usability,simpl,simple,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851
Performance,perform,perform,"p team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
Safety,avoid,avoiding,"some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > —; > You are receiving this because you are sub",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
Security,validat,validation,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
Testability,test,test,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
Usability,simpl,simple,"Good Morning,. I'm from Chair of Thermal Engineering of Poznań University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jędrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
Modifiability,config,config,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
Safety,avoid,avoid,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
Testability,test,test,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
Usability,simpl,simply,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jędrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
Deployability,update,update,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
Testability,test,tested,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
Usability,user-friendly,user-friendly,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
Usability,clear,clear,"@talbring Thanks for getting this sorted, Tim! I also think it's the best way to maintain a clear difference between regressions and Tutorials. I do have a suggestion though. Although I think it's very nice to have the written tutorials directly in git, so people can contribute directly, I wonder if it's the best idea to have them in the main repo. As the number of tutorials grows, we will have the same problems as for the meshes, with too many files to check out (images, md files, etc). Given that there is a new ""Tutorials"" repository, would it be a good idea to incorporate them there? I think it makes sense in terms of clarity, and we could make use of github pages, which allows to create a website per repository. That way we could have a site for the tutorials - and eventually this could be incorporated seamlessly into the SU2 website. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355262713
Integrability,wrap,wrapper,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
Modifiability,config,config,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
Security,access,access,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
Testability,test,tests,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
Usability,user-friendly,user-friendly,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
Modifiability,config,config,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143
Usability,clear,clear,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143
Testability,test,test,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804
Usability,learn,learned,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804
Usability,clear,clear,"@fpalacios, you misunderstood me. What I meant was that the CrossProduct part should be uncommented in order to remove the compiler warnings, not removed. When I read this back, this was not very clear from my side. In any case there are still two compiler warnings in geometry_structure.cpp due to this issue in the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/506#issuecomment-364848312
Usability,feedback,feedback,Thanks for the feedback.. this is resolved in #600,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/515#issuecomment-459228891
Availability,failure,failures,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319
Usability,simpl,simple,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319
Deployability,update,update,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
Modifiability,config,config,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
Usability,clear,clear,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
Integrability,rout,routine,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
Modifiability,config,configure,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
Usability,simpl,simply,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
Deployability,install,installed,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
Integrability,interface,interface,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
Usability,clear,clear,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
Energy Efficiency,sustainab,sustainability,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884
Usability,feedback,feedback,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884
Modifiability,config,config,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901
Usability,feedback,feedback,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901
Testability,test,test,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905
Usability,simpl,simple,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905
Availability,error,error,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297
Usability,simpl,simply,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297
Integrability,depend,dependent,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
Testability,test,tests,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
Usability,simpl,simpler,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
Deployability,configurat,configuration,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
Modifiability,config,configuration,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
Usability,simpl,simply,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5°; 2.5°]; - twist angle = [1°; 0°; -1°] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25°; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0°. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
Energy Efficiency,reduce,reduces,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
Integrability,depend,dependent,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
Testability,test,tests,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
Usability,clear,clear,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
Security,validat,validation,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
Testability,test,test,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
Usability,simpl,simple,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
Deployability,update,updates,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
Testability,test,test,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
Usability,simpl,simple,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
Availability,redundant,redundant,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
Integrability,rout,routines,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
Safety,redund,redundant,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
Usability,feedback,feedback,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
Modifiability,inherit,inherited,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746
Usability,feedback,feedback,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746
Integrability,rout,routines,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
Modifiability,extend,extend,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
Usability,clear,clear,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
Energy Efficiency,adapt,adapting,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
Modifiability,portab,portable,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
Usability,simpl,simple,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
Energy Efficiency,allocate,allocate,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
Modifiability,config,config,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
Usability,clear,clearly,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
Modifiability,variab,variable,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029
Usability,clear,clear,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029
Energy Efficiency,allocate,allocated,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
Modifiability,variab,variables,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
Security,access,accessible,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
Usability,feedback,feedback,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
Usability,undo,undo,"Those changes in option_structure.hpp were actually done to the main branch by somebody else. I forked from main, and merged develop. I can of course undo them, if you want (or rebase my commit on develop instead of merging).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/579#issuecomment-425754699
Deployability,configurat,configuration,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Energy Efficiency,reduce,reduced," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Modifiability,config,configuration,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Performance,optimiz,optimized,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Security,validat,validating,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Testability,test,testing,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Usability,intuit,intuitive," of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
Testability,log,logical,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
Usability,clear,clear,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
Modifiability,variab,variable,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
Usability,clear,clear,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
Availability,mainten,maintenance,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349
Usability,usab,usability,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349
Deployability,install,installed,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141
Usability,simpl,simple,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141
Availability,avail,available,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
Deployability,update,update,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
Integrability,depend,dependencies,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
Modifiability,portab,portability,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
Usability,clear,clearly,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? It’s important that we don’t jump too far ahead for portability reasons (that’s why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
Usability,simpl,simply,"If you'd like me to revert the changes updating the autotools version and/or removal of auto-generated files, just let me know (you can also simply revert the last few commits for the same effect).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427689344
Usability,feedback,feedback,Thanks for the feedback. I will modify the class in a way that it is possible to specify the separator and other decoration.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/591#issuecomment-427287405
Usability,clear,clear,"@rsanfer I am attaching [some results](https://github.com/su2code/SU2/files/2612501/FFD_verification.pdf) for FFD derivatives for FSI cases (that made use of this fix) to rekindle the discussion. I am taking this directly from my early stage so apologies if not all details are clear, the conclusion is that the fix does not break the adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-441388433
Testability,test,tests,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260
Usability,simpl,simple,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260
Testability,test,test,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
Usability,simpl,simple,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
Usability,simpl,simpler,"Hi Jairo, . what is the status here ? Is it possible to provide a simpler (smaller) case ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445175541
Testability,test,tested,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093
Usability,simpl,simpler,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093
Availability,fault,faults,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
Modifiability,config,config,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
Testability,test,test,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
Usability,simpl,simpler,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
Modifiability,config,config,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder “arina2k”, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding’ its folder name, so I would have an ‘orphaned’ file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
Usability,guid,guidance,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder “arina2k”, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding’ its folder name, so I would have an ‘orphaned’ file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
Deployability,update,updated,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
Modifiability,config,config,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
Testability,test,tests,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
Usability,simpl,simple,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
Deployability,release,release,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
Energy Efficiency,adapt,adaptation,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
Integrability,message,message,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
Modifiability,adapt,adaptation,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
Usability,clear,clear,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
Usability,simpl,simple,"Yes, the GRAD_FLOW option has worked well for my simple application. I have not tried using it on other more complex problems or geometries.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-445429364
Energy Efficiency,adapt,adaptation,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
Modifiability,adapt,adaptation,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
Usability,simpl,simply,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
Integrability,depend,depend,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
Testability,test,test,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
Usability,simpl,simple,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
Integrability,rout,routine,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
Modifiability,refactor,refactoring,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
Performance,perform,perform,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
Testability,test,test,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
Usability,simpl,simply,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
Modifiability,refactor,refactoring,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
Testability,test,tested,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
Usability,simpl,simpler,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
Energy Efficiency,sensor,sensor,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
Modifiability,variab,variables,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
Usability,feedback,feedback,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
Integrability,interface,interface,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
Modifiability,variab,variables,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
Performance,perform,performance,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
Usability,clear,clear,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
Modifiability,variab,variable,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206
Usability,usab,usable,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206
Usability,feedback,feedback,Thanks again for the helpful feedback @oleburghardt. Time to get this one merged so we can keep moving.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/625#issuecomment-459996705
Integrability,depend,depends,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
Modifiability,refactor,refactoring,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
Performance,perform,performance,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
Usability,clear,clear,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
Usability,learn,learn,"Hello, @aeroamit . Thank you very much. I try for some times and find that mach number matters. When I simulate two-dimensional lid-driven cavity flow, the flow starts from static. So this case always fails. I try laminar boundary layer case with 0.1 incoming mach number. This time SU2 runs well with AUSMPLUSUP, at a very low CFL number(0.01 or lower), converging slowly. I learn that this scheme is perfect for high speed flow, but it may not be good at low mach number case. Perhaps there are some mistakes when I use it. I think I am not familiar with this scheme enough and that I know SU2 not very well. Before using it in practice, I should read more papers and codes. By the way, SU2 6.2.0 doesn't have the option 'USE_ACCURATE_FLUX_JACOBIANS'. Thanks again. Regards; Cao J. Z.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-523374440
Modifiability,variab,variables,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390
Usability,simpl,simple,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390
Testability,test,test,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027
Usability,guid,guide,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027
Usability,clear,clearer,"Hi @talbring,; thanks for this, I think it makes the output a lot clearer. ; We should merge this in soon, and open a discussion on how to improve the screen output, not only in terms of the residual convergence (I know you have been working hard on that and it's looking great) but also on the initial print-out, which is currently very chunky and not so easy to add new options to.; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/633#issuecomment-455978636
Deployability,integrat,integration,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Integrability,rout,routines,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Modifiability,refactor,refactoring,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Performance,optimiz,optimized,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Security,access,access,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Usability,simpl,simplified,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
Integrability,rout,routines,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
Performance,perform,performance,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
Security,expose,exposes,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
Testability,test,test,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
Usability,simpl,simplify,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
Performance,perform,performance,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384
Usability,learn,learning,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384
Availability,down,downloaded,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
Integrability,rout,routines,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
Performance,perform,performance,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
Testability,test,tests,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
Usability,simpl,simple,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
Performance,perform,performance,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
Testability,test,test,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
Usability,feedback,feedback,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
Usability,simpl,simply,"Hi @EduardoMolina,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460666656
Performance,perform,performance,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752
Usability,simpl,simply,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752
Deployability,release,release,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
Integrability,rout,routines,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
Testability,test,testcase,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
Usability,clear,clear,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
Usability,simpl,simpler,"Closing this for now. After talking with @oleburghardt and @talbring there are features being worked on that are much simpler to develop using Eigen, we may see a PR for that in the not too distant future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-592951260
Deployability,update,updates,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
Modifiability,evolve,evolve,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
Usability,feedback,feedback,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
Testability,log,log,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317
Usability,simpl,simply,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317
Availability,toler,tolerance," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Deployability,integrat,integration,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Integrability,interface,interface,"ETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approxima",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Modifiability,portab,portability,"n on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conser",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Performance,scalab,scalable-linear-solvers-multigrid-methods,">@bmunguia ; > @EduardoMolina and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Security,access,access,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Testability,test,test," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Usability,feedback,feedback,"dweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
Availability,error,error,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
Integrability,rout,routine,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
Security,expose,expose,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
Testability,test,testing,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
Usability,simpl,simple,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
Deployability,update,updated,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
Integrability,synchroniz,synchronized,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
Testability,test,testing,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
Usability,clear,clear,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
Usability,clear,clear,Hi @clarkpede and @economon .; Thanks for the clear explanation.; Merging now. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463729246
Usability,simpl,simpler,"@talbring that is definitely the long term goal, this was only the first step to make the templating simpler.; Thanks @rsanfer.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-475180235
Usability,clear,clear,"@pcarruscag I just had a chat with @TobiKattmann. Essentially there are two points that would, in our opinion, speak against moving the implementation to CSolver. 1. We dont know yet whether they might be some future differences in the implementations. ; 2. This defeats somehow the purpose of the class structure, as the base class should be free of specific implementations for a certain solver ... Although the intention would be to have it there only temporarily, we never know how long it actually stays there in the end. I don't mind having a little bit of code copy, if the structure is clear and easy to understand.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-472011300
Usability,learn,learn,"Yep, just an honest mistake. We'll fix it up. I know that things have been a little quiet in the repository lately, but there is a lot of motion happening behind the scenes as we prepare for the developers meeting next month (we have some exciting things in store). . Thanks for the patience, and I would also ask that, if folks in the community have some time, they please contribute to reviews. Expertise in the particular area is not required (I know it can seem intimidating, but don't be shy!), and it is a great way to learn the code and see what other folks are developing. The more input and discussion we have from various perspectives, the better.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-479973816
Modifiability,evolve,evolved,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080
Usability,responsiv,responsive,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080
Usability,clear,clear,"I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. . How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486373335
Usability,clear,clear,"Good point, Jayant. Maybe a brief tutorial and an example can be created so people know how to use this new feature? There will be a presentation by Edwin and Tom at the annual meeting that might also be helpful. Best,; Juan. On Apr 24, 2019, at 11:32 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/672#issuecomment-486373335>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRDJGI6HH6HEUDATJS3PSCRUZANCNFSM4HH7BJ7A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486418280
Usability,feedback,feedback,"Thanks for the feedback and suggestions. Nice teamwork! I am also plenty happy with this now. Last comment: it was mentioned at the meeting (maybe in the V&V working group), that it would be good to have a separate option for the user-defined solution, in the case of setting a custom initial condition or BC, that sits outside the KIND_VERIFICATION_SOLUTION option list. Doesn't have to necessarily be acted upon now, but want it on record.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-498834929
Deployability,update,update,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
Modifiability,variab,variables,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
Security,access,access,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
Usability,clear,clear,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
Usability,clear,clear,"Hi Amir,; If you create a solver object inside numerics how will this new solver know about the solver that is actually using numerics? The way the code is written does not make the relations between classes very clear as the solver and numerics containers get passed around quite freely... But the solvers are clients of the numerics (I think there are good diagrams of this in some of the papers), i.e. the solvers call methods of the numerics and not the other way around.; It is the numerics that needs a method whereby the solver can set the value of cb1, this is more or less what is done in the elasticity solver, so yes, try to follow that ""recipe"" as close as possible and it should work.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494118969
Testability,test,tested,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599
Usability,learn,learn,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599
Availability,error,error,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
Integrability,message,message,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
Usability,clear,clear,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
Usability,guid,guiding,"All above,. Can any one share the experience of the mesh quality matrix acceptable by SU2. In Pointwise, one can follow maximum included angle, centroid skewness or equiangle skew as guiding parameters. I have observed that some of the commercial Solvers can accepts and run a very high max included angle (179.99 or so) also without trouble but some others have issues with the same. . Many times due to complex geometry, one ends up with these high numbers. . Any guidelines for SU2 on mesh quality is appreciated. Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494217280
Availability,error,error,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
Integrability,message,messages,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
Usability,clear,clearly,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
Availability,error,error,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
Integrability,message,message,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
Testability,test,test,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
Usability,simpl,simple,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
Usability,guid,guidelines,"@timjim333,. Yah, those are the general guidelines you mentioned but they do not always work in practical cases.; We will probably know more details when people will share their experiences and issues faced. I have tried meshes with max include angle 175 or below, they go well. Even upto 179 also go through.; But I had trouble recently while just giving a trial for 179.8 or more case.; One thing to note is, SU2 constructs dual mesh from the primal mesh we supply but anyway properties of the primal mesh will carry forward. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494932014
Availability,robust,robust,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430
Usability,guid,guidelines,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430
Modifiability,config,config,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
Safety,detect,detected,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
Usability,simpl,simply,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
Availability,robust,robust,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
Modifiability,flexible,flexible,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
Usability,simpl,simpler,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
Usability,simpl,simple,"@clarkpede A small discussion on the pros and cons can be found here: https://mesonbuild.com/Comparisons.html. Or https://medium.com/@germandiagogomez/getting-started-with-meson-build-system-and-c-83270f444bee Of course this article is just a personal opinion, but he makes some important points. . From my experience I can really say that the syntax of meson is extremely simple and intuitive. I managed to set it up for SU2 in like half a day, without having any prior knowledge on how it works. And it seems like that a lot of projects (for example all Gnome projects) are going to or are already using meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500221287
Usability,learn,learn,"atm that still sounds like magic to me,... I really should learn this github stuff. But I was more hoping some experienced coder would pick this up instead of my messing up the code.; Also I dont yet understand the way you guys work with branches instead of regular forked code...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/688#issuecomment-495360476
Energy Efficiency,reduce,reduced,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201
Usability,clear,clear,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201
Testability,test,testing,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619
Usability,intuit,intuition,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619
Usability,clear,cleared,"Great! Sounds good, just figured id bring it up to get some of these ancient issue cleared up. :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501794908
Performance,perform,performance,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012
Usability,simpl,simpler,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012
Usability,simpl,simplifications,"@pcarruscag, Did you work out the analytical Jacobian for AUSM+-up? (holy cow). I have also worked out and implemented in my local machine for AUSM, up and up2 (with minor simplifications/assumptions, wherever seemed okay) . I was planning to consolidate things appropriately and refine it before pushing them to repo.; By the way, I am also observing the similar behavior with little time advantage for analytical part (a bit more refinement/cleaning in implementation from my side will be done) . So what should be the next plan ???. Cheers; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505621705
Usability,learn,learn,"Hi @pcarruscag and @aeroamit ,. Thanks for the discussion and for share the ideas/results. I think this is the beauty of open-source, everyone is welcome to jump in and review all the pull requests. Certainly, as you said @aeroamit, we will all learn something fruitful when we review and merge each PR. Best regards,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511209774
Availability,down,down,", 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Deployability,integrat,integrated,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Energy Efficiency,power,power,"here a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Integrability,integrat,integrated,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Modifiability,config,configure,"ls a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working corre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Security,validat,validation,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Testability,test,testing,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Usability,simpl,simpler," Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
Availability,robust,robust,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Deployability,integrat,integrated,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Energy Efficiency,power,power,"it testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Integrability,integrat,integrated,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Modifiability,config,configure," of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Security,expose,exposed,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Testability,test,tests,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Usability,simpl,simpler,"doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
Availability,toler,tolerance,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
Energy Efficiency,sensor,sensor,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
Modifiability,config,config,"github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
Testability,test,test,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
Usability,simpl,simple,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
Deployability,install,installation,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
Testability,test,tests,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
Usability,simpl,simple,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
Integrability,depend,dependency,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
Testability,test,testing,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
Usability,simpl,simplest,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
Availability,down,down,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
Deployability,release,release,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
Testability,test,tests,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
Usability,simpl,simpler,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
Integrability,depend,dependency,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
Testability,test,tests,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
Usability,simpl,simply,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
Usability,pause,paused,This issue has been paused until after v7.0.0,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-548021997
Deployability,configurat,configuration,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
Modifiability,config,config,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
Usability,clear,clearer,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
Usability,clear,clear,"Yes, I did not make that clear, the linear solver fraction of the time cannot be accelerated by this. But everything else can, from gradient/limiter computations to the Compute_Residual functions, as all those need to wait for data, it is however not very easy to measure how long that wait is compared to the rest of the computations.; In the 2015 joint work between Stanford and Intel they reported a 1.5x speed-up from this type of change for a case where the linear solver used 24% of the time. I do not know how heavy the CVariable infrastructure is now compared to then... We will see :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-506768400
Energy Efficiency,reduce,reduces,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
Integrability,interface,interface,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
Modifiability,variab,variables,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
Performance,perform,performance,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
Usability,clear,clear,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
Availability,down,downcast,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
Modifiability,variab,variables,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
Performance,optimiz,optimizations,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
Safety,safe,safe,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
Usability,simpl,simple,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
Availability,mask,mask,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Integrability,wrap,wrapper,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Performance,perform,performance,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Safety,predict,predicted,"it ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a tempor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Testability,test,test,"ed the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Usability,learn,learned,"ither. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case since the ratio of useful data to pointers and vtables is lower. After a celebratory dance I attempted to profile the code using [Perf](https://en.wikipedia.org/wiki/Perf_(Linux)) which I ""learned how to use"" from [a YouTube video](https://www.youtube.com/watch?v=nXaxk27zwlk&t=2052s).; In a nutshell compile the code as usual but with the `-fno-omit-frame-pointer` cxx flag (so perf can figure out the name of the functions, debug symbols are not required).; Run `perf record -g [command]` where command can be your usual `mpirun...` (I did not recompile my mpi with the aforementioned flag), for 2-3 minutes for hundreds of MB of record (hence the 500k mesh...).; Run `perf report -g ""fractal,0.5,caller""`, this will show % of time spent in a function relative to its caller and you can expand each function to see what are its children, grandchildren, etc. Like so:; ![image](https://user-images.githubusercontent.com/38071223/63290949-725e5080-c2ba-11e9-90aa-ffc834e726db.png); How cool is that!! Pro-tip hit ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is pr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
Availability,down,down,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
Modifiability,polymorphi,polymorphism,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
Performance,cache,cache,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
Usability,simpl,simple,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
Modifiability,polymorphi,polymorphism,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
Performance,optimiz,optimized,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
Usability,simpl,simple,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
Modifiability,coupling,coupling,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
Testability,test,tested,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
Usability,simpl,simplicity,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
Availability,error,error,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Deployability,install,installed,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Integrability,wrap,wrapper,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Modifiability,config,configure,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Safety,detect,detect,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Usability,guid,guides,"when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
Energy Efficiency,adapt,adapt,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
Modifiability,adapt,adapt,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
Testability,test,testing,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
Usability,feedback,feedback,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
Modifiability,refactor,refactoring,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
Performance,perform,performance,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
Testability,test,testing,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
Usability,simpl,simpler,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
Availability,avail,available,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
Performance,perform,performance,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
Usability,clear,clearing,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
Usability,feedback,feedback,"I understand your frustration, and the feedback is helpful. Encouraging more participation in Issues and PRs is very important for us. We are still learning and improving our processes. A good metric for us to increase in the project is the total number of *different* people submitting/participating in PRs/Issues (not the total number of comments from just a handful). The best way to scale is to have the work evenly distributed among many folks, rather than just a handful processing the PRs. This will likely take some time & training, but I expect we can accomplish it while remaining positive. Open to good ideas there on how to better achieve it. . As for the other topic - I think that our recent move toward draft PRs may help with describing design decisions. This will also take some time to be adopted, and may or may not reach the depth necessary in the descriptions, but it is a good first step so that we can see things progress in real time. Using the project boards to list tasks and post comments is also helpful (but takes more effort). Open to ideas there too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534720511
Integrability,rout,routines,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517
Usability,simpl,simple,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517
Energy Efficiency,efficient,efficiently,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
Performance,optimiz,optimization,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
Usability,clear,clear,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
Usability,feedback,feedback,"@jayantmukho : The difference is also observed when using SST.; ![rans_cp_compare-branch_roe_SST](https://user-images.githubusercontent.com/9790985/61556955-d372da00-aa17-11e9-9351-5d3505cc85a1.png). @economon and @clarkpede : Thanks for the feedback. @clarkpede , I will re-run using the commit that you pointed and I will post the results here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513330011
Availability,down,downside,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
Deployability,patch,patch,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
Modifiability,extend,extend,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
Usability,clear,clear,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
Modifiability,config,config,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331
Usability,clear,clearly,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331
Availability,error,error,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462
Usability,guid,guideline,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462
Usability,simpl,simply,Maybe also an explanation why I specifically state `single straight`:; Take a case with two symmetry planes on either side of a channel -> it could be reasonable to put both in the same Marker in the su2 mesh -> both planes are straight for themselves but as I simply loop over all nodes in a marker I then have 2 different unit normals for the same marker -> thats why the specific `single` is used,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537206528
Deployability,integrat,integrated,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
Integrability,integrat,integrated,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
Usability,guid,guidance,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
Usability,learn,learn,"Thanks for your kindly reply, Clark. It is a good habit to have a search before asking, and I should keep it. . ""feature-AdjTNE2"" seems to be a good example to learn from how to edit the kernel of governing equations. I would try to deepen the utilities of electromagnetic computation. And I have found the commit that deleting all plasma computational relevant content. 45c2a63d1a0773dd2e9ca05b5a1798ea575d47f8 Anybody willing to tell me why we delete that part? Too complicated to handle?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515276512
Usability,simpl,simpler,"@talbring Thanks! Works like a charm now! Thanks for implementing this, I think this building method is a lot simpler than the previous one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521545657
Modifiability,refactor,refactoring,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606
Usability,learn,learn,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606
Modifiability,flexible,flexible,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
Safety,avoid,avoid,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
Usability,clear,clear,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
Deployability,update,update,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
Integrability,rout,routine,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
Safety,avoid,avoid,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
Usability,simpl,simplify,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
Energy Efficiency,energy,energy,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082
Usability,feedback,feedback,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082
Availability,error,error,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
Modifiability,variab,variable,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
Security,access,access,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
Testability,test,tests,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
Usability,simpl,simply,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
Availability,avail,available,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012
Usability,learn,learning,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012
Availability,avail,available,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
Deployability,configurat,configuration,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
Modifiability,config,configuration,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
Security,expose,expose,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
Usability,guid,guiding,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
Deployability,release,released,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
Integrability,rout,routines,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
Performance,optimiz,optimization,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
Usability,intuit,intuition,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
Availability,error,errors,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Deployability,update,update,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Integrability,depend,depending,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Safety,avoid,avoid,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Security,attack,attack,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Usability,simpl,simple,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
Security,secur,secure,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018
Usability,simpl,simple,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018
Safety,risk,risk,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
Security,secur,security,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
Testability,test,tests,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
Usability,simpl,simple,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
Usability,simpl,simply,I am using the binary of SU2_CFD on Mac Os X for a single core run. There are no restart files for SU2_SOL to work with. IS there a way to simply export in CSV format? config_template.cfg is missing in the folders.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528450087
Energy Efficiency,efficient,efficiently,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
Usability,simpl,simple,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
Usability,simpl,simple,"If you _must_ use `restart_flow.dat`, then look at np.genfromtxt and the `invalid_raise` option. Here's a simple example:. ```python; import numpy as np; import matplotlib.pyplot as plt. data = np.genfromtxt(""solution_adj_combo.dat"", names=True, invalid_raise=False). plt.tricontourf(data[""x""], data[""y""], data[""Adjoint_Density""]); plt.show(); ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528493781
Availability,avail,available,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Deployability,update,update,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Energy Efficiency,efficient,efficient,"ents. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Integrability,rout,routines," would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Modifiability,variab,variables,"There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Performance,perform,performed,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Safety,avoid,avoids,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Security,access,access,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Usability,simpl,simple," silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely pe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
Availability,avail,available,"ill be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Deployability,update,update,",; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.getVec(iEdge,iDim));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from whi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Energy Efficiency,schedul,schedule,"iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Integrability,rout,routine,"{; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Modifiability,variab,variables,"setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Performance,perform,performance,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Safety,avoid,avoids,"(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volum",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Security,access,access,"_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Testability,benchmark,benchmark,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Usability,simpl,simple,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
Availability,avail,available,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Energy Efficiency,reduce,reduce,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Integrability,depend,dependence,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Modifiability,portab,portability,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Performance,perform,performance,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Safety,avoid,avoid,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Usability,simpl,simple,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
Availability,mask,masked,"ze_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Energy Efficiency,schedul,schedule,"oj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Modifiability,variab,variables,"proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = ed",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Performance,bottleneck,bottleneck,"Thanks @economon!; I don't know what is the current situation with OpenMP and CoDi but any eventual change will have to be compatible with CoDi. The worst case would be disabling OpenMP for the discrete adjoint, the parallel clause supports an ""if"" modifier so that would not be too hard. But I hope to at least be able to lower the memory footprint by fusing some loops or make pre-accumulation more effective by using point loops.; The linear solvers will indeed become the bottleneck, they already are for JST, the good thing is matrix multiplication is easier to vectorize, not sure the best strategy will be similar though. ### Limiters. Scalar (reference) version of the code:; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi(jPoint,iVar));; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi(jPoint,iVar));. phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi(iPoint,iVar));; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi(iPoint,iVar));; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double proj_i = 0.0, proj_j = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; proj_i += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }. doubl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Safety,avoid,avoids,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Security,access,access,"ive one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Usability,simpl,simplifying,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
Availability,mask,mask,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Deployability,update,update,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Energy Efficiency,schedul,schedule,"he residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Integrability,message,message,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Modifiability,variab,variables,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Performance,race condition,race conditions,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Safety,avoid,avoid,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Security,access,access,"double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorSta",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Testability,benchmark,benchmark,"ow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Usability,simpl,simple,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
Deployability,update,updates,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Energy Efficiency,schedul,schedule,"r with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Integrability,depend,depend,"connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar=0; iVar<nVar; ++iVar) {; FltVec sum = flux[iVar];; for(size_t kVar=0; kVar<nVar; ++kVar); sum += blk_j[iVar*nVar+kVar]*(phiL[kVar]-phiR[kVar])*0.5;. // residuals for iPoint and jPoint updated here. matrix.updateBlocks_v(color, iEdge, iPoint, jPoint, blk_i, blk_j);; }; ++color;; }; }; ```; The more WORKITERS we have the better the vectorized code is going to look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matri",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Modifiability,variab,variable-specific,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Safety,safe,safe,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Usability,simpl,simplest,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
Availability,down,down,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Deployability,update,update,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Energy Efficiency,reduce,reduced,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Integrability,interface,interface," for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the me",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Modifiability,polymorphi,polymorphic,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Safety,safe,safe,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Security,access,accessor,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Usability,simpl,simply,"ion, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
Energy Efficiency,adapt,adaptive,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Integrability,rout,routine,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Modifiability,adapt,adaptive,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Performance,perform,performing,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Testability,test,test,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Usability,simpl,simple,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
Availability,down,downside,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
Energy Efficiency,reduce,reduce,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
Performance,tune,tune,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
Usability,feedback,feedback,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
Availability,error,error,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
Modifiability,config,config,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
Safety,avoid,avoid,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
Security,expose,exposed,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
Usability,user-friendly,user-friendly,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
Energy Efficiency,allocate,allocated,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
Testability,test,tests,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
Usability,simpl,simple,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
Usability,clear,clear,"> @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention. Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551323531
Usability,clear,clear,"> > @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention.; > ; > Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue. If you revert my last commit, you will see the issue. It diverges right away for me, so perhaps it is just something with the initial transient that is caught by the clipping",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551351016
Energy Efficiency,energy,energy,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
Modifiability,config,configured,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
Testability,test,tested,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
Usability,simpl,simply,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
Security,access,accessible,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531
Usability,usab,usable,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531
Integrability,rout,routine,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
Security,validat,validation,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
Usability,simpl,simple,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
Usability,simpl,simply,Why not simply use clang-format and have a script to pass files/directories to have formatted? It provides more formatting options than just stripping trailing whitespaces and replacing tabs and does it in a consistent way.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-551451738
Usability,simpl,simply,"> Why not simply use clang-format and have a script to pass files/directories to have formatted? It provides more formatting options than just stripping trailing whitespaces and replacing tabs and does it in a consistent way. Tried that on a couple of files out of curiosity, it does not look very good, for example we have the habit of aligning repetitive statements across multiple lines clang-format does not keep that, we have very long lines with chained methods that look awkward when broken up.; Clang probably has a neater architecture of tiny objects where auto formatting works very well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-551551298
Availability,down,down,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130
Modifiability,enhance,enhance,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130
Usability,clear,clearing,"Hi all, . After the initial excitement of clearing all tabs and trailing whitespaces... I guess it is more reasonable to follow @pcarruscag proposal:; > What about running the solution you propose only on subfolders? i.e. on src/something/ . I now trimmed all `C*.cpp`, `C*.hpp` and `C*.inl` files in `SU2_CFD` which is equivalent to all restructured files in the Sub-folders. I added a basic script `replace-tabs-...sh ` in `externals/utils` which provides this functionality. I would enhance that script if this is the way to go.; The commit size now shrunk down to ~4k changed lines. Possible merge problems will be much smaller. . I found to have to no problem when merging the develop first -> clearing all tabs/whitespaces in the feature_branch with the provided script -> merge this develop_noWhitespaces using the `--strategy-option=ours` option. Merge conflicts will be purely due to tabs/whitespaces therefore one always wants the own code in case of conflict, as all conflicts with the develop related to other stuff were already resolved in the first merge. . Now that the commit is a lot smaller, there should be even less problems. Maybe some folks will have no problems at all. . After some back and forth in the commits I briefly chatted with @talbring to do a git rebase / squash to not have these huge commits in the history. Otherwise one could open a new & clean PR if we can agree on an approach here to keep the discussion in one place.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/808#issuecomment-553412130
Deployability,install,installed,Ok thats to be expected (as I learned) because you have probably openmpi installed. The binaries are compiled with mpich.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/813#issuecomment-557430771
Usability,learn,learned,Ok thats to be expected (as I learned) because you have probably openmpi installed. The binaries are compiled with mpich.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/813#issuecomment-557430771
Availability,avail,available,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Deployability,install,installation,"process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_B",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Integrability,depend,dependencies,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Modifiability,config,configurable,"Wonderful contribution. Thanks for doing all that. Streamlining the dev process is very helpful and cmake is definitely becoming a standard. Best,. Juan. On Nov 10, 2019, at 11:24 AM, Daumantas Kavolis <notifications@github.com> wrote:. ﻿; Proposed Changes. Added CMake build support for SU2. With this, many popular IDEs will be able to use SU2 as a project with minimal setup. CMake also enables to add dependencies more easily since most libraries have CMake support. vcpkg is great for the libraries available there. SU2 CMake has the same build options as autotools but uses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUIL",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Testability,test,tested,"SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON; * SU2_PARMETIS_CPPFLAGS: flags to pass when compiling Parmetis; * SU2_ENABLE_TECIO: ON|OFF; * SU2_TECIO_CPPFLAGS: flags to pass when compiling Tecio and TecioMPI; * SU2_TECIOMPI_CPPFLAGS: flags to pass when compiling TecioMPI, requires SU2_ENABLE_MPI. There is an additional variable that is recognized by CMake scripts - DEBUG, turning it ON enables additional STATUS messages, mainly to check that correct include directories, compile definitions and linked libraries were set up correctly. The remaining options like install location and compilers are handled by CMake. Tested this on Ubuntu with CMake 3.15.5 and everything except pySU2ad wrapper compiles. Haven't tested on earlier CMake versions so there might be bugs with them but they should be easy to resolve if any. Related Work. Resolve any issues (bug fix or feature request), note any related PRs, or mention interactions with the work of others, if any. PR Checklist. Put an X by all that apply. You can fill this out after submitting the PR. If you have any questions, don't hesitate to ask! We want to help. These are a guide for you to know what the reviewers will be looking for in your contribution. * I am submitting my contribution to the develop branch.; * My contribution generates no new compiler warnings (try with the '-Wall -Wextra -Wno-unused-parameter -Wno-empty-body' compiler flags).; * My contribution is commented and consistent with SU2 style.; * I have added a test case that demonstrates my contribution, if necessary. ________________________________; You can view, comment on, or merge this pull request online at:. https://github.com/su2code/SU2/pull/814. Commit Summary. * CMake support for SU2. File Changes. * A CMakeLists.tx",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Usability,clear,clearer,"ses CMake to find system libraries and compilers (MKL, Mutationpp, MPI and Python currently). No longer need to specify paths to compilers/libraries if they are in standard locations. In addition, compile flags can be modified from CMake. There is no need to use preconfigure.py anymore since downloading/unpacking is handled by CMake and is system-agnostic. At the moment, all library targets are static but that could be easily changed to be configurable from CMake. The installation directory is ${CMAKE_PREFIX_PATH}/bin. Similarly to autotools, some build options are disabled if built with Codi forward/reverse datatypes or without MPI. Note that SWIG fails to compile pySU2ad with Nothing known about namespace 'medi' in Common/include/mpi_structure.hpp:57 without -includeall SWIG option but then it takes forever to generate the wrapper (more than 15 minutes on my machine, stopped early). I suggest removing using namespace declarations and either importing used symbols explicitly with using or prepending namespace name, clang-tidy warns against them by default and it makes the code clearer. SU2 CMake options are:. * Build modules:; * SU2_BUILD_CFD: ON|OFF; * SU2_BUILD_DEF: ON|OFF, disabled when building with Codi; * SU2_BUILD_DOT: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_GEO: ON|OFF, disabled when building with Codi; * SU2_BUILD_MSH: ON|OFF, disabled when building with Codi; * SU2_BUILD_PY_WRAPPER: ON|OFF, disabled when building with Codi forward; * SU2_BUILD_SOL: ON|OFF, disabled when building with Codi; * Enable modules:; * SU2_ENABLE_CGNS:; * SU2_CGNS_CPPFLAGS: flags to pass when compiling CGNS; * SU2_ENABLE_CODI: no|forward|reverse; * SU2_CODI_CPPFLAGS: flags to pass to SU2 modules when compiling with Codi; * SU2_ENABLE_METIS: ON|OFF; * SU2_METIS_CPPFLAGS: flags to pass when compiling Metis; * SU2_ENABLE_MKL: ON|OFF; * SU2_ENABLE_MPI: ON|OFF; * SU2_ENABLE_MUTATIONPP: ON|OFF; * SU2_ENABLE_PARMETIS: ON|OFF, only available when SU2_ENABLE_MPI is ON",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552242380
Availability,down,down,"Dear Daumantas,. I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs. I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552360147
Usability,guid,guide,"Dear Daumantas,. I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs. I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-552360147
Availability,down,down,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450
Deployability,configurat,configuration,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450
Modifiability,config,configuration,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450
Usability,guid,guide,"> ; > ; > Dear Daumantas,; > ; > I appreciate your effort in adding support for cmake in SU2. We have recently introduced the Meson build system (https://mesonbuild.com/) (#685, #745) as a candidate to replace automake. A guide on how to use can be found [here](https://su2code.github.io/docs_v7/Build-SU2-From-Source/). The idea is that we will have this system along automake at least for the upcoming version 7 and that we get rid of automake afterwards. Considering that, I don't think that it makes sense to maintain 3 different build systems **at the moment**. I really hate turning contributions down, but this one is three months too late. However, we might reconsider adding support for another build system once we got rid of automake, or, if we feel that meson does not fit our needs.; > ; > I am all ears to hear other opinions. However, let's not start a discussion on the advantages/disadvantages of the build systems. Some benefits can be found in the Issue/PR linked above. Ok, I tried meson with MinGW but couldn't figure out how to link with MSMPI since it's not a part of MinGW. However, using CMake and with a few source code fixes, I managed to compile nearly every configuration with MSVC. Surprisingly, there were very few errors in SU2. The externals only had a few preprocessor issues. At the moment only MeDiPack fails to compile with MSVC but not with MinGW even though the MPI headers are the same so I suspect it's an issue with MSVC itself, I'm using the latest preview version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/814#issuecomment-553571450
Modifiability,config,config,"Hello Tobi,. Thanks for your quick reply! I'll address you doubts as follows. > I used this mesh <Testcases>/control_surface/mesh_ONERAM6_inv.su2 and the boundary marker names are a bit different in the mesh, compared to your provided config (WING vs LOWER_SIDE, UPPER_SIDE, TIP + SYMMETRY vs SYMMETRY_FACE). . Yeah, the mesh you are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074
Testability,test,test,"are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.0.1 as it can be seen from the Summaries: **I'm updating the issue.**. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. Didn't quite understand you here. Let me know if you need any other info regarding the topic. Looking forward to hear from you!. Best,; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074
Usability,simpl,simply,"Hello Tobi,. Thanks for your quick reply! I'll address you doubts as follows. > I used this mesh <Testcases>/control_surface/mesh_ONERAM6_inv.su2 and the boundary marker names are a bit different in the mesh, compared to your provided config (WING vs LOWER_SIDE, UPPER_SIDE, TIP + SYMMETRY vs SYMMETRY_FACE). . Yeah, the mesh you are mentioning is the same. I simply united the TIP, LOWER_SIDE and UPPER_SIDE under the marker tag WING. > The initial transient through the domain based on the initial values is unphysical to some extend and if e.g. 'steady state' results are the same for both code versions .... the problem is not that big. Although it differs quite a bit in the temporal evolution tbh; In the results (also in the mail) it looks a bit like it approaches a steady state for Cl and CD. So maybe 1000 timesteps will tell us a bit more 🤔. I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings.; [Summary_steady_6_0_1.txt](https://github.com/su2code/SU2/files/3906039/Summary_steady_6_0_1.txt); [Summary_steady_6_2_0.txt](https://github.com/su2code/SU2/files/3906010/Summary_steady_6_2_0.txt). Regarding the unsteady case, I'm aware that this test may have little physics behind (especially if comparing the first timesteps) but I wanted to investigate the reason :). Results are too different and I think these might be one of the reasons behind some discrepancies I'm encountering in my FSI framework. ; My framework for FSI features a restart from a steady solution at t=0 and an unsteady simulation with imposed boundary of the wing marker. The discrepancies in that case are huge and are clearly wrong. I went back to the root and found this weird behaviour comparing the two versions so I thought this might be one cause. > Another thing: There is no tag 6.0.2 😕 ... 6.0.1 and then 6.1.0.. Yep you are right, the version is definitely 6.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-559850074
Availability,recover,recover,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057
Modifiability,config,config-files,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057
Safety,recover,recover,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057
Testability,test,tests,"Hey Rocco,. > And both versions are/were on the develop branches -> what exactly do you refer to here: config-files, code, mesh. The code tags 6.0.1 and 6.2.0 refer to specific master-commits of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handle",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057
Usability,simpl,simply," of the code. So I want to know what is exactly of the develop branch, can't be the code if you understand the tags as I do. Maybe you refer to the develop code at the time where these tags were introduced. But maybe sth different. > I guess they converge eventually to the same values. I tried to compare the same case but steady (I attach the summary). Results in this case are fairly similar and (in my opinion) raise no warnings. That is good to hear. ; Luckily @cvencro (Thanks for that 👍 ) ran some tests and found that #740 (which rewrites Euler Wall boundaries for compressible and incompressible flows ... which was me btw) introduces the changes you see. The Euler wall for compressible is changed a bit in the way the boundary condition is enforced. Upon convergence both version should recover (close to) the same value. If the results in a steady state are the same/very-similar and if an unsteady simulation at low enough Reynolds-number converges to the same steady result (or oscillate in the same bounds) -> I would say it is simply some purely numerical effect based on the unphysical initialization and different treatment of the euler wall boundary. . 1 thing one could test additionally is to force a very high convergence in each physical timestep, i.e. usually one converges ~3 orders of magnitude in each ts -> now try converging until residual stalling in each ts. If the code versions get the same/closer results in the temporal evolution my euler wall boundary explanation would be quite reasonable.; Together with the long running unsteady simulation proposed above, I would feel more comfortable to judge. @cvencro (bringing the conversation to this place 😉 ) concerning the pitching case: the `if (dynamic_grid)` statements in the 'old' version are not necessary as that is handled by the numerics class. In the new version an appropriate 'reflected state' is constructed and the numerics container is called to compute the residual. Before, the code of one numerics ->Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-562621057
Availability,down,down,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217
Modifiability,config,config,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217
Testability,test,tests,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217
Usability,simpl,simply,"Charanya,. thanks for the detailed answer. Let me ask you some more info. Apparently, you where able to reproduce the results I had comparing the two code versions simply using different boundary conditions on the latest code version. Can you specify me how?. Tobi,. In the meanwhile, to narrow down the problem, I ran also a couple tests in 2D to seek confirmation. For the (Euler) **pitching_NACA64A010.cfg** test case in the repository I rerun the same test at AoA of 1 deg and removing the pitching (no mesh deforming). I attach config files and summaries relative to the test cases. [config_CFD_6_2_0.txt](https://github.com/su2code/SU2/files/3938858/config_CFD_6_2_0.txt); [Summary_6_2_0.txt](https://github.com/su2code/SU2/files/3938859/Summary_6_2_0.txt); [config_CFD_6_0_1.txt](https://github.com/su2code/SU2/files/3938863/config_CFD_6_0_1.txt); [Summary_6_0_1.txt](https://github.com/su2code/SU2/files/3938865/Summary_6_0_1.txt). In this case the situation is definitely better as the two solvers give the same results. It looks like it is an issue related to the 3D case. <img width=""1220"" alt=""Screenshot 2019-12-09 at 11 27 27"" src=""https://user-images.githubusercontent.com/23583209/70424365-f316a780-1a77-11ea-8f68-4fc83e188ed7.png"">. I also quote Charanya in saying that it is definitely good that convergence to same values is reached but the transient response is fundamental and holds physical/mathematical values (I think of Wagner et similia) :). I would also suggest to add a regression test in this sense. Best, ; Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563150217
Availability,recover,recovered,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Deployability,integrat,integrated,"both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one mig",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Energy Efficiency,reduce,reduced,"dy (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Integrability,integrat,integrated,"both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then we are left with this initial transient phase that differs. Of course if there is more evidence that one or the other version produces physically ""better"" results I would love to see that. Until then, both initial oscillations are equally correct/uncorrect in my opinion. [I'll add a few words about the adjoint here later]. [I'll add the idea of an FSI case of @cvencro here later where the initial phase has a major impact]; Consider an FSI computation of an airfoil where the trailing edge can exhibit flutter (periodic up-and-down-movement of the trailing edge) in certain flow regimes. Now if during the initial transient the forces on the airfoil are higher than in the converged state then the fluttering can be excited where the initial transient can be seen as an activation energy. If you were to e.g. ramp up flow speed/conditions slowly up to the same magnitude as before one mig",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Safety,recover,recovered,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Security,validat,validation,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Testability,test,test,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Usability,simpl,simply,"Hey,. @cvencro and I were discussing this issue quite a bit this morning and here an attempt of a summary:. We are looking at the following cases:; 1. 3D Onera m6, compressible euler, including euler_wall and sym_plane ; a. steady state; b. unsteady (no pitching, deforming); 2. 2D NACA64A010, compressible euler, including euler_wall; a. unsteady (no pitching/ deformation); b. pitching (with rigid and with deforming mesh -> used for the gradient validation of @cvencro 's post ). We are rather certain that the differences between the code-versions are due to the new euler_wall boundary which was introduced in #740 (by me :) ). @cvencro did a test where the old euler_wall was simply pasted into the newer function body (which currently directly calls the sym_plane boundary) -> that recovered the results obtained with the 'older' version. The steady state results (onera m6) show that both codes deliver the same results (of course with some minor differences). So far so good. Unsteady cases are a bit trickier: the latest 2D results of @RoccoBombardieri show pretty much no difference including the first timesteps. The onera m6 case in contrast converges to the same (steady-state) results for both code version eventually but their initial transient phase differs quite significantly. . A possible explanation for the different initial transient phase: In both implementations a ""reflected state"" is constructed where the normal component of the velocity is subtracted [once in the older code version & twice in the newer version]. I.e. subtracting the normal component of velocity twice means mirroring the velocity along the symmetry plane. The newer code version is a bit ""stronger"" in enforcing the boundary conditions which could lead to the reduced oscillation in CD and CL. If we agree that both code versions produce physically correct results for steady cases and unsteady cases that were integrated long enough in time to get rid of the influence of the initial condition ... then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/828#issuecomment-563314747
Performance,perform,performance,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616
Testability,benchmark,benchmark,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616
Usability,simpl,simple,"I have covered all operations used in non adjoint use, the non ideal part of the implementation I mentioned above is that the parallelization is ""local"", i.e. we get to the operation we want to make parallel and launch the threads there, for simple vector-vector operations the overhead may be significant.; Ideally we would have a parallel construct at a higher level, say CSysSolve::Solve, so that the threads are already in flight when we get to those small operations.; In principle it is not too hard to do that, but it needs to be done carefully especially when the execution gets to an MPI part of the code (which thread(s) communicate, etc.).; I will try to benchmark this to put numbers on the performance / simplicity trade-off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-560572616
Energy Efficiency,schedul,scheduling,"t the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Integrability,rout,routines,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Modifiability,variab,variable,", this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Performance,perform,performance,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Safety,safe,safe,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Security,access,access," make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call those routines in sequence since the loop sizes, and static work scheduling specifications are identical.; However, routines that access a CSysVector in a different way, should have an explicit barrier before using the vector (or risk having undefined behaviour). You will see these barriers on entry to matrix-vector product, and every `ComputeXXXPreconditioner` (if you don't, let me know xD). I think those routines are large enough to amortise the cost of this. ### Performance; Disclaimer:; - We are talking about linear solvers only, **you will not see a global improvement yet**.; - The large global improvements from ""hybridization"" will come from the multigrid behaving better on less decomposed domains, and from the ability to independently tune the number of cores used in the linear preconditioners. For now the objective is ""just"" not to loose performance while gaining flexibility.; - The performance of MPI+threads with 1 thread per rank will be worse than just MPI (no free lunches). With this [small case](https://github.com/su2code/SU2/files/3933059/small_case.zip) using 8 cores off a machine with two 2650v4 CPU, Intel MPI 2018 + GCC 8.2, the hybrid (2 ranks of 4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Testability,assert,asserting,"olvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does not seem to be a significant bottleneck.; _Worksharing_ constructs have implicit barriers at completion, for CSysVector routines I used `nowait` modifiers, it is safe to call tho",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Usability,simpl,simple,"Ok the ""simple"" version of ""going parallel"" whenever we get to a linear algebra operation did not make the cut.; On an older architecture there was a 10% slowdown of the linear solvers at ~10k nodes per core and about the same on a newer architecture but only at ~1k node per core.; Since hybrid parallel is supposed to be good for strong scaling, this was not good enough... With the new strategy it is ok (see ""performance"" below), hence this is ready for review. ### Overall Strategy; The strategy now is to start a parallel section in CSysSolve::Solve that covers building the preconditioner and solving the linear system.; Linear algebra routines called within this section have _worksharing_ constructs instead of _parallel_ ones, i.e. the work is distributed by however many threads arrive to that routine. This also makes the routines safe to call in serial.; The only ""dangerous"" things to do in parallel are to: manage memory for a shared object (multiple threads call `new` but there is only one shared pointer on which to call `delete`); writing to the same memory locations concurrently.; I tried to make the first issue debugable by asserting that the initialization routines of CSysMatrix and CSysVector are only called by the master thread.; For the second issue I made the associated classes as const-correct as possible, that should at least make someone think twice before changing a member variable of those classes. The risk is still there for input variables as an algorithm development aspect... For example `MatrixVectorProductTransposed` cannot be made thread-parallel as simply/naively as its normal counterpart. ### Communication Model; The MPI + Threads communication model is very simple, currently only the master thread calls MPI routines (including `Error`), this requires thread barriers before and after the communication to make sure the correct values are passed and _seen_ by all threads.; We can test other alternatives in the future but at the moment this does n",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/830#issuecomment-562646766
Deployability,update,updated,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823
Testability,test,testcases,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823
Usability,simpl,simply,"Of the two cases with larger residual changes:; - contadj_euler_naca0012 - No idea why they changed, neither primal nor adjoint compute limiters... the primal residuals are unchanged, and the case converges to the same values (residuals and solution) so I simply updated the residuals; - transonic_stator_restart - As shown above the case is fine, so I updated the restart file, however I do not know how to change the testcases branch anymore :) but I guess once the corresponding PR is merged this will start passing. I ran some other tests with the Venkatakrishnan-Wang limiter (which requires a global min/max) and is does not seem to be covered by the tests ATM (maybe I'll use that restart case to fix that), everything looks perfect, same results with different ranks/threads and so on, the results are tens of MB so I won't upload unless someone wants to double check.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/834#issuecomment-575310823
Deployability,integrat,integrated,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Integrability,integrat,integrated,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Modifiability,config,config,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Security,validat,validated,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Testability,test,test,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Usability,clear,clear,"> the off-PR comments can be integrated in this PR to clear that up a bit. If not that is OK as well. It's more than OK, the CHT implementation suffers a bit from being a single person's project.. you're very welcome to have a look over it! :-). > Can you add that option to the config_template.cfg together with that description, the valid inputs and the default. Actually I'm hesitating a bit adding it to the config template right now. I'd prefer to have `DIRECT_TEMPERATURE_ROBIN_HEATFLUX` as the default and ""hide"" the rest as developer's options for the moment.; The reason simply is that those different methods need to checked and validated against each other before we make them public.; E.g. I figured that for the incompressible CHT test case from the repo, there is a severe gap between the heatfluxes obtained from the ""averaged"" approach and the direct one, see below. ![heatflux_convergence](https://user-images.githubusercontent.com/22639394/72885197-bb9e4a80-3d07-11ea-9fad-a4d709dc511e.png). That needs to be cleared up first...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/839#issuecomment-577108935
Availability,error,error,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727
Integrability,message,message,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727
Modifiability,config,config,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727
Testability,test,test,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727
Usability,feedback,feedback,"Hi @themrdjj,; Thank you for the feedback, there was already a similar report in #796 (which incidentally went stale and was closed), I will try to do something about it, or if you would like to contribute code to the project I can point you to right place to add an error message. Meanwhile my best advice is to not start a config from scratch until you know SU2 very well (and even then...) look for a test case that uses similar features and go from there.; The minimal config is the one in Quickstart, the template is more of a catalog :) I don't think we'll ever have a unified minimal config, SU2 does many things, some mutually exclusive.; Convective options are reasonably well documented here: https://su2code.github.io/docs_v7/Convective-Schemes/; The output messages before ""Begin Solver"" can be helpful (although in this particular case you would need to know what to expect). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/842#issuecomment-566642727
Deployability,configurat,configuration,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Energy Efficiency,allocate,allocate,"cally equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they beco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Modifiability,config,configuration,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Performance,concurren,concurrent,"ead_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they become local and all is well, with the exception of class members, those will be shared most of the time (this is where const correctness can give some peace of mind). > Also, just an additional (hopefully constructive) comment: I find all of these developments great, and I honestly think that you are doing an amazing job on performance and overall code improvement. However, as a non-C++-master myself, I'm just a little concerned of whether some advanced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Safety,safe,safe,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Security,access,access,"cally equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could revisit the ownership relations of the numerics classes, i.e. allocate them as members of their respective solvers, which if we do, we can think of having a purpose built container that automates the per-thread creation and access. > Why are they redefined each time inside the loop?; > Is this for efficiency reasons?. Referring to variables being declared inside loops. One stylist reason is that declaring everything at the top of a function is the C way of doing things, the C++ people whose books/blogs I've read and talks I've watched, recommend keeping namespaces (the inside of the loop being one) as clean as possible.; The only reason not to do this is if you explicitly want re-use, in the case of trivial types this does not improve efficiency, and in the context of OpenMP code it can create issues. Just like we need one numerics per thread, if we declare variables outside a parallel loop the default OpenMP behaviour is to consider them shared, and concurrent writes to shared locations = gdb and many bad words xD.; **EDIT:** I should mention here that if the parallel region is started before the variable declarations they beco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Testability,test,test,"Thank you for the thorough review @rsanfer! I'll reply to your main questions and some of the smaller ones here to centralize things. > Just a request, if it's possible that you add one or two test cases so the implementation is safe onwards (and, of course, so I can play around with the new features a little bit ). The testcases are the same, no changes there other than the one optional option introduced above. When the hybrid stuff covers most of the code I would add an entire build configuration e.g. BaseMPIOMP and corresponding testcase suite. > * Should this just run ""out of the box"" with a working installation of OpenMP in any machine, or is there anything else _fancy_ needed?. I would leave it to the community to decide what the defaults should be, probably for a lot of new users that don't run on clusters just calling SU2_CFD and not having to worry about mpi would be nice (a lot of the issues on CFD online are mpi related). > * Is the previous behaviour exactly kept, or are there any modifications in the basic, non OpenMP version of code? (Not that I mind, just curious). Other than the algorithmic changes (but mathematically equivalent) introduced to limiters and gradients in #834, yes. > What's the advantage of having one numerics term per thread?. It is a requirement, we need to write data into numerics before using them, multiple threads cannot write to the same location (i.e. the internal structures of CNumerics) therefore one per thread is required. > ...Also, I think I missed the point where the numerics container is extended beyond MAX_TERMS. The allocation of space for one numerics per thread is done above in line 1995 of my 21 Dec 2019 comment: `...MAX_TERMS*omp_get_max_threads()...`.; The instantiation of one numerics per thread is then done by executing the rest of the preprocessing in parallel and instead of using `XYZ_TERM` using `XYZ_TERM+offset` where `offset = thread_id * MAX_TERMS`.; I think someone mentioned this (maybe Tim) that we could r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Usability,learn,learning,"anced programming may become an entrance barrier to new additions to the community. As I wrote in the preamble of #789:; ""But please participate even if you never heard of these topics, your opinion about readability and ""developability"" of the code is important! I think the code-style should be accessible to people starting a PhD (after they read a bit about C++...).""; I try to encapsulate and hide the tricky bits as much as possible to make the code as readable as possible, whether I am succeeding or not is for the community to decide, in all these PR's I've been pointing to the areas I think are trickier, if someone, anyone, feels they are absolutely incomprehensible please say something... either here, or trough slack, or by email (I think it shows in the commits) (I understand not everyone is keen on github exposure). > I'm aware that you have been doing very well at documenting the code and the various PRs, but I'd say we should try to find an strategy to ease the learning curve on potential new developers (maybe some developer tutorials? a collection of the comments/discussions on the PRs moved to the wiki? a list of links/useful resources?). I agree with documentation of broad design decisions, that is the intent of #789, and developer tutorials (how to implement a new X) once we are content with the restructurings, otherwise they will quickly go outdated... or actually...; We should probably first think about the answers to ""how to implement a new X"" and restructure/refactor as a function of that.; Based on previous efforts of maintaining wiki's updated while code is being developed, I much prefer this github style where you can clearly tell what version of the code the comments refer to. A collection of comments/discussions organized by topic and linked to a feature is somewhat what I had in mind when I opened a ""big PR"" (#824) with little branches such as this one, I can try to complete that with a list of links/useful resources, references as it were, goo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/843#issuecomment-577684728
Usability,simpl,simple,"Thanks for taking care of the merge with develop @pcarruscag, I am going to make some simple formatting changes to the `CFEASolver` and `CMeshSolver` so that they conform to the rest of the solver files",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/849#issuecomment-578283139
Testability,test,tests,"@economon No, this looks good to me. It is merge-ready, from my perspective. I chatted with @talbring, and in a future PR we would like to add a simple set of classes to use with unit tests. For example, I've created a ""one-point geometry"" class for use in some of my tests. But I think that we should keep the PRs as incremental as possible. PSA: If anyone else wants to review this PR, they are welcome to. It is no longer a WIP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620382001
Usability,simpl,simple,"@economon No, this looks good to me. It is merge-ready, from my perspective. I chatted with @talbring, and in a future PR we would like to add a simple set of classes to use with unit tests. For example, I've created a ""one-point geometry"" class for use in some of my tests. But I think that we should keep the PRs as incremental as possible. PSA: If anyone else wants to review this PR, they are welcome to. It is no longer a WIP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620382001
Usability,clear,clear,"Hi @clarkpede ,. Thanks for the contribution. The example of the central/upwind blending is very clear. Ready to merge. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/850#issuecomment-620948043
Availability,avail,available,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436
Deployability,install,install,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436
Usability,guid,guide,"Sure; If you want to install Su2 version 7.0.0 from scratch, you need python 3.5; atleast; The installation guide says just python 3; One of the functions used in meson.py is only available in python 3.5. On Mon, Feb 3, 2020, 12:51 AM Tim Albring <notifications@github.com> wrote:. > Thanks for opening the issue. Can you give a little bit more details on; > what you mean exactly ?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/855?email_source=notifications&email_token=AIENZ3WCJDNJV4LP655MB33RA7LI5A5CNFSM4KNO4QLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKS7V6I#issuecomment-581303033>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AIENZ3TDY7ZCOS27JO7IYXTRA7LI5ANCNFSM4KNO4QLA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/855#issuecomment-581453436
Usability,simpl,simple,"Update: This should be fixed in #2011, apologies this took so long to get round it in what is a very simple fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/857#issuecomment-1701148094
Testability,test,test,"> If anyone as an elegant solution to simply check for EXIT_SUCCES in the regression test one could add some dry_run regression tests. This can be added to the meson tests simply enough. In other words, you could add it alongside the unit tests. You can read more about meson tests [here](https://mesonbuild.com/Unit-tests.html). If you add `SU2_CFD` as a test executable with the dry run option as a command line argument, then meson will do the dry run and mark it as failing if it does not receive `EXIT_SUCCESS`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/858#issuecomment-581945210
Usability,simpl,simply,"> If anyone as an elegant solution to simply check for EXIT_SUCCES in the regression test one could add some dry_run regression tests. This can be added to the meson tests simply enough. In other words, you could add it alongside the unit tests. You can read more about meson tests [here](https://mesonbuild.com/Unit-tests.html). If you add `SU2_CFD` as a test executable with the dry run option as a command line argument, then meson will do the dry run and mark it as failing if it does not receive `EXIT_SUCCESS`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/858#issuecomment-581945210
Testability,test,test,"Hi Akshay,. Yes this is a simple fix and it could go in quickly on it's own or as part of another PR. I have this fix already modified in the draft PR #833 which is just pending the addition of a test case. I can add that and move to a PR soon if you are happy to wait?. Best wishes,; Charanya",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/860#issuecomment-582340873
Usability,simpl,simple,"Hi Akshay,. Yes this is a simple fix and it could go in quickly on it's own or as part of another PR. I have this fix already modified in the draft PR #833 which is just pending the addition of a test case. I can add that and move to a PR soon if you are happy to wait?. Best wishes,; Charanya",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/860#issuecomment-582340873
Security,access,access,"@koodlyakshay I was looking at the ADT modifications that you mention.; Do I understand correctly that the roughness height does not influence the wall distance calculation itself? But that you simply need to know what is the roughness height associated with the closest wall point? If this is the case you can probably just use the markerId returned by the wall distance function?; As for mpi aspects, each rank sees the same ADT and I recall that we do have mechanisms to access global marker information.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-595197305
Usability,simpl,simply,"@koodlyakshay I was looking at the ADT modifications that you mention.; Do I understand correctly that the roughness height does not influence the wall distance calculation itself? But that you simply need to know what is the roughness height associated with the closest wall point? If this is the case you can probably just use the markerId returned by the wall distance function?; As for mpi aspects, each rank sees the same ADT and I recall that we do have mechanisms to access global marker information.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-595197305
Availability,avail,available,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337
Integrability,rout,routines,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337
Testability,log,logic,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337
Usability,simpl,simpler,"Hi @koodlyakshay thanks for making the changes.; By default MPI barriers are ""never"" needed, the normal communication routines already do all synchronization required. Efficiency is probably not fundamental for that routine but this solution feels too complicated somehow, can you attend tomorrow's developers meeting? (I'm getting the ""there's gotta be a simpler way"" feeling, and if we pick the brains of a few people we are certain to find it). In the meantime, if you specify the roughness as a string+double list (exactly like MARKER_HEATFLUX), which is read with `addStringDoubleListOption` you could probably simplify the logic around heatflux and isothermal markers, which would make the setup more user friendly (having to stick with an order is bound to trip someone at some point).; Also the cht interface is ""just"" an isothermal boundary, any reason not to make this feature available for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630788337
Integrability,rout,routines,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158
Modifiability,config,config,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158
Safety,avoid,avoids,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158
Usability,clear,clearer,"Yes for MARKER_ROUGH, or MARKER_ROUGH_WALL to be clearer.; Or just WALL_ROUGHNESS as you have right now, since it would not really a marker, just the properties of markers (and I've seen some people on CFD online confused with similar naming e.g. MARKER_SHROUD). Regarding the MPI stuff, I had the following idea over lunch:; In CPhysicalGeometry::SetWallDistance we compute the closest distance, and in so doing we also get the mpi rank and markerID associated with the closest vertex.; So, before computing the wall distances you communicate the local marker ids and wall roughness's (via Allgather as you are doing now), with this info you can build a `unordered_map<pair<int,int>, su2double>` to map pairs of <rank,markerID> to the values of roughness.; Now when you loop over the points to compute the distances you can retrieve the roughness from this map instead of from config.; It's almost exactly the same as you have, but avoids using the config as a messenger between routines, and using a stl map should also make the code simpler. In the boundary conditions you can still get the marker roughness via the marker tag as you are doing now, and I guess the wall type (smooth / rough) can be inferred from having 0 (default) roughness (?); With the string+double list specification you also avoid having to specify 0 roughness and SMOOTH wall type for markers where you don't want to use this feature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-630861158
Usability,simpl,simplified,"I have simplified the input method now. Users need to simply add a line; ; MARKER_ROUGHWALL = (marker_name_1, k_1, marker_name_2, k_2, ..). By default all walls are smooth and only the rough walls need to be listed and the order shouldn't matter. . Edit: Just realized you asked me to use a different name. Will fix it in the next commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-642800393
Modifiability,config,config,">I found out the other day that this: unordered_map<pair<int,int>, su2double> does not work without extra tricks,. Yes, I found some examples to do it. But I was not quite understanding what are the sizes of local maps or how to communicate them over MPI. . >so if you have it out of the config in some matrix format it is probably better. In that case, I can just move the current global arrays to physical geometry class and simplify some of the function calls.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-653479936
Usability,simpl,simplify,">I found out the other day that this: unordered_map<pair<int,int>, su2double> does not work without extra tricks,. Yes, I found some examples to do it. But I was not quite understanding what are the sizes of local maps or how to communicate them over MPI. . >so if you have it out of the config in some matrix format it is probably better. In that case, I can just move the current global arrays to physical geometry class and simplify some of the function calls.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/877#issuecomment-653479936
Availability,error,error,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Deployability,update,updateHistoryMap,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Integrability,message,message,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Modifiability,config,config,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Performance,optimiz,optimization,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Usability,simpl,simply,"Hi Economon,. I encountered an issue very similar to what Auzbaig reported: the error message ""OBJECTIVE_FUNCTION: invalid option value EntropyGeneration"" during optimization with SU2. (I am using SU2 version 8.0.1 ""Harrier.""). After thoroughly examining the existing Python optimization framework, I found that one of the steps in the optimization chain is generating different config.cfg files, with a focus on DV_VALUE and OBJECTIVE_FUNCTION. DV_VALUE controls the geometry deformation;; OBJECTIVE_FUNCTION determines the type of objective/constraints.; Then the framework calls SU2_CFD and SU2_DOT to obtain performance metrics or gradient information.; As you mentioned, ""You might need to run updateHistoryMap.py to register new outputs with Python."" Initially, I thought it meant simply providing a new input for OBJECTIVE_FUNCTION in the Python optimization framework. However, it seems that this may not work at the C++ level. To verify this, I ran $ SU2_CFD your_config.cfg -d and observed all available history outputs. However, I suspect that OBJECTIVE_FUNCTION cannot use every history output, meaning that the adjoint solver might not recognize some objective functions. Does this imply that additional modifications in the C++ code are required?. Additionally, I would appreciate more information regarding CUSTOM_OBJFUNC. From TestCases/user_defined_functions/lam_flatplate.cfg, I understand that CUSTOM_OBJFUNC allows combinations of existing OBJECTIVE_FUNCTIONs and can also utilize CUSTOM_OUTPUTS. The flexibility of CUSTOM_OUTPUTS seems to enable the construction of various desired variables. However, I am unsure whether using OBJECTIVE_FUNCTION= CUSTOM_OBJFUNC along with CUSTOM_OUTPUTS can entirely replace the need for additional modifications in the C++ code. Since I’m not very proficient in C++, I would greatly appreciate your guidance. Sincerely,; Tongtong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/889#issuecomment-2324575133
Availability,down,download,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776
Performance,latency,latency,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776
Testability,log,logged,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776
Usability,simpl,simple,"These timings were all run this morning on the same cluster. . Using qperf, I'm seeing 80 microsecond latency. I'm also seeing the expected bandwidth using qperf as well. I would think that mpi would behave similarly but 100% sure. . I'm quite sure that the jobs are being launched correctly. I've checked that a bunch of times since that was my first instinct. I've both logged into all the machines and watched top and everything looked normal. And I've tried running SU2 v6 before and after v7, launching them the same way, and I keep getting the same numbers. I'm not sure how to check whether there is any reason non blocking comm would be ineffective. If you have any ideas I can certainly try something. I tried to download vampirtrace which seemingly can profile mpi, but it failed to compile against my version of mpi. When I get the chance I can try a different version of openmpi and see if I can get it running. The networking setup is pretty simple with all 4 machines plugged into the same switch and they share their own vlan as part of a bigger network. As I said, I ordered some faster networking equipment to see if it makes a difference (though I'm honestly not 100% sure that what I ordered will work with my comps but we'll see.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/894#issuecomment-593144776
Usability,simpl,simple,"Try v7.0.2. On Mon, 9 Mar 2020, 02:05 timjim333, <notifications@github.com> wrote:. > Hi,; >; > I've got an issue where on starting an SU2 6.2.0 Falcon case, the; > preprocessing steps run but then the output gets stuck at:; >; > ---------------------- Python Interface Preprocessing; > --------------------- Setting customized boundary conditions for zone 0; >; > - and remains frozen there until I kill the job.; >; > It seems to have happened for only 3 out of nearly 400 successful cases.; > They are all similar, running Euler at Mach 1.7, on 40 cores. They all have; > similar simple body, farfield, and and symmetry conditions.; >; > I'm not sure of the best way to diagnose this, so any guidance would be; > appreciated.; >; > Many thanks and kind regards,; > Tim; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/907?email_source=notifications&email_token=AJCOXN63UWSSF6UABZZXXFLRGQ6EJA5CNFSM4LD6ZHGKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4ITNPDMQ>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJCOXN6R6JOEQCAYH7FKCLTRGQ6EJANCNFSM4LD6ZHGA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/907#issuecomment-596654031
Deployability,release,releases,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600
Integrability,integrat,integration,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600
Modifiability,config,config,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600
Testability,test,test,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600
Usability,intuit,intuitive,"Hi @Eduardo-Carvalho ,. your request is now merged into the develop branch and you can test/use it if you like. It will be in one of the next releases, if no further issues occur.; Handling is intuitive: Just set your restart iteration in the config file as you would do normally and activate the restart solution option. Furthermore, place your restart file (two in the case of 2nd order time integration) in the same directory as the config file of your test case. Then you are set up and can run the scripts as normal. ; For more details, I refer to pull request #964. . Best; Steffen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/909#issuecomment-630289600
Deployability,update,updated,"That looks a bit strange, you still get Release 6.2.0 but in the aforementioned PR @jayantmukho clearly updated the version to 7.0.2, I use the old build system in an old computer and it is currently working...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/910#issuecomment-598733874
Usability,clear,clearly,"That looks a bit strange, you still get Release 6.2.0 but in the aforementioned PR @jayantmukho clearly updated the version to 7.0.2, I use the old build system in an old computer and it is currently working...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/910#issuecomment-598733874
Deployability,install,installed,"Also, this might be more of a question I guess, why does this `meson.py` script exist/why isn't the normal way of using meson (simply running `meson <builddir>`) used?. [edit] Just noticed `meson build` also works and uses the system installed `ninja` as expected. Still not really sure what the script is for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598376736
Usability,simpl,simply,"Also, this might be more of a question I guess, why does this `meson.py` script exist/why isn't the normal way of using meson (simply running `meson <builddir>`) used?. [edit] Just noticed `meson build` also works and uses the system installed `ninja` as expected. Still not really sure what the script is for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598376736
Deployability,install,installed,Hi @simonvanderveldt. Thanks for the questions. The custom meson.py script shipped with su2 also initializes the git submodules. You can of course also use an installed version of meson/ninja for building (should be also noted in the documentation on the website) by simply replacing `./meson.py` with `meson`.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598496636
Usability,simpl,simply,Hi @simonvanderveldt. Thanks for the questions. The custom meson.py script shipped with su2 also initializes the git submodules. You can of course also use an installed version of meson/ninja for building (should be also noted in the documentation on the website) by simply replacing `./meson.py` with `meson`.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598496636
Availability,down,downloads,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341
Deployability,configurat,configuration-and-compilation,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341
Integrability,depend,dependencies,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341
Modifiability,config,configuration-and-compilation,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341
Usability,simpl,simpler,"@talbring Thanks for the quick and helpful answer! I'm looking at creating an ebuild/package for gentoo, compilation is a lot simpler than OpenFoam :P which is a big plus :). Anyway, I was looking at the old docs (the main docs still point to 6.0, I missed the red text that mentioned that somehow :P), not sure why, but you're right it's indeed mentioned in the 7.0 docs here https://su2code.github.io/docs_v7/Build-SU2-Linux-MacOS/#configuration-and-compilation. The ""Automatically installed dependencies"" section left me a bit confused because it sounded like the things listed there, which includes meson and ninja, would always get installed.; Maybe merging that section into the configuration and compilation section might help to make it more clear?. If you don't mind I have some additional questions:; - I didn't initialize the git submodule at all and configuration, compilation and running worked fine. Does this mean the CoDiPack and MeDiPack dependencies are optional? Or does this mean I could have a crash at runtime somewhere?; - Would it be possible to add a source package to the GitHub releases (in addition to the binary ones) that includes the (CoDiPack and MeDiPack) submodules? Unfortunately the GitHub provided source downloads don't include submodules.; - Are MKL and OpenBLAS build-time and exclusive options or can they both be compiled in and chosen at runtime?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/911#issuecomment-598751341
Usability,simpl,simple,"Thanks @FlorianDm for putting in the fix!. Although, it sound like we still need something more general.. I think the normal neighbor concept could still work, it's just that you need to be starting from the vertex list on the axis (not the inlet or the outlet) to find it. Another simple thing to try is just setting AxiFactor = 0.0 if the y coord = 0.0, instead of 1.0. If this grid is stretched with small spacing near the wall, the contribution from the dual CV on the axis could be very small.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/927#issuecomment-611266566
Performance,race condition,race condition,"At some point the marker starts being partitioned, some of it is in one rank, some in other(s).; Your print function truncates the file when it opens it, and so you only get the output from the last rank that opened the file.; You could make the file a member of the class, so that you can guarantee it is only opened once (other ranks would need to open in append mode), but then you still have a race condition when multiple ranks try to write simultaneously to the file (the result might be mixed lines, especially when `endl` is used to terminate lines because it forces a flush, maybe with ""\n"" and some luck it would be ok, but the order of the lines is still unpredictable).; To my knowledge mpi does not have simple ways to guarantee ordered execution of certain code regions. So unless you want to get knee deep in mpi, I recommend you keep this file output as a debug feature (that works on a single core) and use the normal surface output files (paraview, tecplot, etc.) for visualization.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/944#issuecomment-616367257
Usability,simpl,simple,"At some point the marker starts being partitioned, some of it is in one rank, some in other(s).; Your print function truncates the file when it opens it, and so you only get the output from the last rank that opened the file.; You could make the file a member of the class, so that you can guarantee it is only opened once (other ranks would need to open in append mode), but then you still have a race condition when multiple ranks try to write simultaneously to the file (the result might be mixed lines, especially when `endl` is used to terminate lines because it forces a flush, maybe with ""\n"" and some luck it would be ok, but the order of the lines is still unpredictable).; To my knowledge mpi does not have simple ways to guarantee ordered execution of certain code regions. So unless you want to get knee deep in mpi, I recommend you keep this file output as a debug feature (that works on a single core) and use the normal surface output files (paraview, tecplot, etc.) for visualization.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/944#issuecomment-616367257
Availability,down,downloaded,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650
Deployability,install,install,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650
Integrability,interface,interface,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650
Modifiability,config,configure,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650
Usability,simpl,simply,"Hi @bmunguia ,; I was in the same situation as @MiracAydin1, so thanks for the hint. Nevertheless I'm having some problems. I followed your instructions to install the branch:. 1. downloaded the [feature_adapt_sst](https://github.com/su2code/SU2/tree/feature_adap_sst) branch.; 2. Used meson to configure the build; `./meson.py build -Denable-autodiff=true -Denable-directdiff=true`; 3. Added the environment variables to the .bashrc; 4. ninja build.; `./ninja -C build install`. The build didn't show any errors, only few warnings during meson ( `gcc1: warning: command line option ‘-Wno-non-virtual-dtor’ is valid for C++/ObjC++ but not for C`). When I try to run the mesh_adaption (or even run simply the solver through parallel_computation.py):. `$SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6`. It immediately shows an error (without even showing the SU2 splash screen) :; `Traceback (most recent call last):`; ` File ""/usr/local/bin/mesh_adaptation_amg.py"", line 38, in <module>`; ` import SU2`; ` File ""/usr/local/bin/SU2/__init__.py"", line 14, in <module>`; ` from SU2 import amginria`; ` File ""/usr/local/bin/SU2/amginria/__init__.py"", line 4, in <module>`; ` from .interface import *`; ` File ""/usr/local/bin/SU2/amginria/interface.py"", line 41, in <module>`; ` import _amgio as amgio`; `ImportError: No module named _amgio`. Am I missing any dependencies? ; Please note that I previously compiled SU2 master branch without issues, and have already installed mpich, numpy, scipy.; Any help would be really appreciated.; Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619332650
Deployability,install,installed,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494
Modifiability,variab,variables,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494
Usability,feedback,feedback,"The _amgio extension should be built by default. I haven't had any issues on any of the machines I've built on, so I appreciate the feedback. Just curious, are you running with python >=3.7? The shebang in all the SU2 python scripts; ```; #!/usr/bin/env python; ```; uses whatever python is set to in your environment variables, but pyamg/_amgio will only build/run with python >=3.7. Could you also check if the _amgio extension was installed in your site-packages (probably located in ~/.local/lib/python3.x/site-packages)?. If it didn't build/install, you could go into extensions/AMGIO/su2io and run; ```; python3 setup.py build_ext && python3 setup.py install; ```; If it did build/install, try the command; ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f invCyl.cfg -n 6; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619334494
Deployability,install,installed,"Thanks for the commit, I've installed it using your hints (I also changed some aliases to always point to python3), and now `parallel_computation.py` it is running properly.; `mesh_adaption_amg.py` runs, until it complains about Ncorners in the SU2 mesh.; ` ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.` ; and then mesh_adapt fails, I can't find any reference to NCORNERS in *.su2 mesh files by the way. As far as` locate Python.h` that's the output :; ```/home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/ParaView/include/paraview-5.6/vtkPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/Python/include/python3.6/Python.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/FieldPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/simpleFunctionPython.h; /home/antares/Downloads/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /home/antares/OpenFOAM/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /usr/include/python3.6m/Python.h; ```. Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619409024
Usability,simpl,simpleFunctionPython,"Thanks for the commit, I've installed it using your hints (I also changed some aliases to always point to python3), and now `parallel_computation.py` it is running properly.; `mesh_adaption_amg.py` runs, until it complains about Ncorners in the SU2 mesh.; ` ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.` ; and then mesh_adapt fails, I can't find any reference to NCORNERS in *.su2 mesh files by the way. As far as` locate Python.h` that's the output :; ```/home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/ParaView/include/paraview-5.6/vtkPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/Python/include/python3.6/Python.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/FieldPython.h; /home/antares/Downloads/SALOME-9.3.0-UB18.04-SRC/BINARIES-UB18.04/gmsh/include/simpleFunctionPython.h; /home/antares/Downloads/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /home/antares/OpenFOAM/ThirdParty-v1806/ParaView-v5.5.2/VTK/Utilities/Python/vtkPython.h; /usr/include/python3.6m/Python.h; ```. Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-619409024
Energy Efficiency,adapt,adaption,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497
Modifiability,adapt,adaption,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497
Testability,log,logs,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497
Usability,simpl,simple,"Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. ![Comparison](https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png); ![ComparisonMesh](https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621450497
Energy Efficiency,adapt,adaption,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859
Modifiability,adapt,adaption,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859
Testability,log,logs,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859
Usability,simpl,simple,"Hi @antares190,. Glad to see that things seem to be starting to work for you. We (Brian) are trying to improve this capability in the solver and any experiences / suggestions / help will be welcome. With that said, this seems like an interesting result. Would you mind submitting it (or other pictures that you like better) so the SU2 Foundation can use it to show this capability to others in the future? The link where you can do this is here<http://su2foundation.org/su2-promotional-material/?utm_source=hs_email&utm_medium=email&utm_content=76584389&_hsenc=p2ANqtz-9fEq2awKk2vd155cCcN_N4mWBCZK-rJ-TqNsZhqSJs-VWn-w7q-H6w8sdiA3LyuOTqlK4eqZhFFstKi-LQFyyGqYPdkwYc9JsNdB1yyd7pqMwTFzA&_hsmi=76584389>. Thanks a lot,. Juan. On Apr 29, 2020, at 1:38 PM, antares190 <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks Brian,; my bad, I misinterpreted the carpets / logs structure. I successfully ran a test of a very simple case. In the results there are some small artifacts, but the shocks are resolution improved consistently after mesh adaption.; Thanks for the support. [Comparison]<https://user-images.githubusercontent.com/41752169/80644172-84a7a580-8a69-11ea-9f16-58e98c808b73.png>; [ComparisonMesh]<https://user-images.githubusercontent.com/41752169/80644174-85403c00-8a69-11ea-819f-2ac00550a089.png>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/948#issuecomment-621450497>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AA5FFRCGLBHJCB3FS4JSSV3RPCF5RANCNFSM4MQACOXA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-621483859
Availability,fault,fault,"CATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280
Energy Efficiency,adapt,adaption,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280
Modifiability,adapt,adaption,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280
Testability,log,log,"2357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN INCONSISTANT TOPOLOGY . Thank you for using feflo.a . ```; Which in turn creates an invalid `amg.su2` mesh in the `adap/ite0 folder`, which triggers the fault.; I'm a bit puzzled as the domain is very simple, and the `log.out` is going well (with no complains of SU2 about any negative volume or trias with wrong normals). The mesh is only made of TRIAS and TETRAS, it should work in principle.; Am I missing something in the setup / mesh? I know you have little control on the `amg.out`, but maybe there some special hint that I'm missing. . Btw the final error in the terminal is but I think the problem arises before reaching `flo.csv` file:; ```; Traceback (most recent call last):; File ""/usr/local/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/usr/local/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/usr/local/bin/SU2/run/amg.py"", line 464, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.csv' -> 'flo_ini.csv'. ```; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280
Usability,simpl,simple,"Thanks for the hint, just uploaded a screenshot of the mesh adaption!; Now I'm trying to run a simple 3D case, but unfortunately the amg.out fails during the first try (in the adap/ini folder):; ```; ## 16739 TRIANGLE(S) DISCARDED ; fefloa_Python2Mesh : 3d mesh on input ; fefloa_Python2Mesh : msh->NbrVer 14368 ; fefloa_Python2Mesh : msh->NbrTet 58189 ; fefloa_Python2Mesh : leaving with 14368 ver. 16740 tri. 0 edg. ; -- Maximal memory ; Maximum number of Points 53800000 ; Maximun number of Bnd Points 10760000; Maximum number of Triangles 21520000 ; Maximum number of Tetrahedra 295900000 ; Allocated Memory 50.105 Gb ; Physical Memory 62.729 Gb; bounding box x: -100 200 y: -150 150 z: -150 150 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; ## WARNING: REMOVING DUPLICATED FACE 12357 12359 12358 ; 14368 Vertex ; 3 Boundary Vertices ; 58189 Tetrahedra ; 1 Triangles ; 0 Edges ; 1 Surface(s) ; % Output subdom.meshb Mesh ndimn=3, mpoin=14368, melem=58189, mface=1; Corners 0 Required 0 ; ## ERROR : TETRAHEDRON 2 BOUNDARY FACE 1 2; 9 IS MISSING ; ## ERROR : TETRAHEDRON 4 BOUNDARY FACE 3 7; 2324 IS MISSING ; ···; ## ERROR: FEFLO.A: 16740 BOUNDARY FACES ARE MISSING ; CHECK YOUR MESH . ## FATAL ERROR: FEFLOA: INITIAL OR CURRENT MESH HAS AN IN",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-623572280
Availability,down,downloaded,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Energy Efficiency,adapt,adaptation,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Modifiability,adapt,adaptation,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Performance,perform,performed,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Testability,log,log,"eature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I miss something?; If it is correct and complete, which file contains the adaptive mesh? How can I use it since there is no new .su2 file? . Thank you for the big help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Usability,clear,clear,"Hi everyone,; I was tring to use the mesh adaptation feature but the whole procedure is not clear to me.; Following the previous indications I:. 1. downloaded the `feature_adapt branch`. 2. downloaded the Adaptive 2D NACA 0012 example (https://pyamg.saclay.inria.fr/pyamgexamples.html#2dnaca): `adap_NACA0012.cfg`, `mesh_NACA0012_inv.su2`, `NACA0012_ini.dat`. 3. added the following lines to the config:; ```; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= GOAL; % Objective function used for goal-oriented adaptation; OBJECTIVE_FUNCTION= LIFT; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 4.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (30000, 60000, 120000); % Number of adaptations performed at each level; PYADAP_SUBITE= (3, 3, 3); ```. 4. run the following command: `$ python3 SU2_RUN/mesh_adaptation_amg.py -f adap_ONERAM6.cfg -n 8`. The response I have obtained is the following:; ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8; PYADAP_FLOW_ITER : (2999, 4999, 6999); PYADAP_ADJ_ITER : (2999, 4999, 6999); PYADAP_CFL : (10.0, 15.0, 20.0); PYADAP_RDG : NO. The ./adap folder was deleted. Generating GMF background surface mesh.; ## WARNING: MISSING SU2 MESH FILE KEYWORD: NCORNERS=.; Initial CFD solution is provided.; ```. As expected, a `./ADAP` folder was created, containing these docs: `amg_back_meshb`, `config_CFD.cfd`, `log.err`, `log.out` (sizes 0 byte), `mesh_NACA0012_inv.su2` (link to the mesh), `NACA0012_ini.dat` (link to the file.dat). Did I perform the procedure correctly? Or did I m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-737134105
Availability,error,error,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447
Energy Efficiency,adapt,adaptation-options,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447
Modifiability,adapt,adaptation-options,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447
Testability,log,log,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447
Usability,simpl,simple,"Ok, I went back to try varying the `.cfg` settings on the simple v7.0.3 repo `TestCases/euler/naca0012` case and managed to get `mesh_adaptation_amg.py` to run successfully. It seems that one bit of advice [from here](https://www.cfd-online.com/Forums/su2/214613-grid-adaptation-options.html) is no longer true, i.e. one needs to set:; ```; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= YES; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= YES; ```; in order for the amg mesh adaptation to function. However, for some reason, I can't get it working for my actual mesh of interest. When using the same settings, I get a different ParMETIS error (from the `adap/ini/log.out`):; ```; ------------------- Geometry Preprocessing ( Zone 0 ) -------------------; Three dimensional problem.; 4929018 grid points before partitioning.; 7406196 volume elements before partitioning.; 3 surface markers.; 18040 boundary elements in index 0 (Marker = BODY).; 50968 boundary elements in index 1 (Marker = FARFIELD).; 284054 boundary elements in index 2 (Marker = SYMMETRY).; Executing the partitioning functions.; Building the graph adjacency structure.; [ 1] ***ASSERTION failed on line 207 of file ../externals/parmetis/libparmetis/comm.c:sendind[i] >= firstvtx && sendind[i] < lastvtx; [ 1] 361316 123226 246452; [1609857970.901920] [super:1060888:0] sock.c:344 UCX ERROR recv(fd=62) failed: Connection reset by peer; ```. The only difference that I can think of is that my flow is fully supersonic and my mesh is an unstructured core with a structured collar - might this be causing the issue? Kind regards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-754686447
Energy Efficiency,sensor,sensor,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Modifiability,adapt,adaptation,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Performance,perform,performed,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Safety,avoid,avoid,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Testability,test,tests,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Usability,simpl,simple,"I was running some tests using a simple geometry but for the refinement seems to be chewing up the geometry. Has anyone who has worked on 3D geometries experienced this or figured out a way to avoid this?. I was using the following settings:; ```; % ------------- MESH ADAPTATION PARAMETER ------------%; %; % Type of sensor used for adaptation; % Options include GOAL (adjoint-based), MACH, PRES; PYADAP_SENSOR= MACH; % Maximum cell size for adaptation; PYADAP_HMAX= 500.0; % Minimum cell size for adaptation; PYADAP_HMIN= 1e-9; % Gradation factor (typically 1.2-1.8); PYADAP_HGRAD= 1.8; % Norm used for adaptation; % 1.0 or 2.0 recommended for inviscid flows; % 4.0 recommeneded for viscid; ADAP_NORM= 2.0; % Approximate mesh size (NPOI) at each level; PYADAP_COMPLEXITY= (1000000, 1300000, 1500000); % Number of adaptations performed at each level; PYADAP_SUBITE= (2, 2, 2); ```. ![refine](https://user-images.githubusercontent.com/16842258/104834786-0b94fa80-58e5-11eb-9018-687ffc5aaa9d.png). I noticed a few comments up, there is the `PYADAP_BACK` setting, which sounds like it might solve this, but how should one use this? Should the geometry alone be re-meshed to a high resolution and the whole volume exported as a SU2 block? Or should it be just a surface mesh? (It seems that Pointwise is not able to output only the surface mesh in SU2 format.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-761751741
Availability,error,error,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Deployability,install,installation,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Energy Efficiency,adapt,adaptation,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Integrability,message,message,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Modifiability,adapt,adaptation,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Testability,log,log,"Hello everyone. I am working with SU2 on the feature_adap branch and have come across an issue during the execution of the mesh adaptation script. After following the standard installation procedure and verifying the installation (the exact same steps that @chesiv presented), I encountered a problem when running the mesh_adaptation_amg.py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Usability,clear,clearly,".py script. The command used was:. ```; python3 $SU2_RUN/mesh_adaptation_amg.py -f adapt_Mesh.cfg -n 4; ```; The script initiates the mesh adaptation process as expected, with the following output:. ```; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (30000, 60000, 120000); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : GOAL; PYADAP_HMAX : 500.0; PYADAP_HMIN : 1e-9; PYADAP_HGRAD : 1.8. ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided.; ```; However, no _adap\ite0_ folder gets created. ; The log.err file in the _adap/ini_ directory provides this traceback:. ```; Traceback (most recent call last):; File "".../mesh_adaptation_amg.py"", line 111, in <module>; ...; RuntimeError: ...; Error in TokenizeString(): two or more options before an ""="" sign in the configuration file.; terminate called after throwing an instance of 'int'; ...; *** Process received signal ***; Signal: Aborted (6); Signal code: (-6); ...; ```. The critical part of this error seems to be the Error in TokenizeString() message, suggesting an issue with parsing the configuration file. This error typically indicates a syntax problem, such as having multiple options on a single line without proper separation by an equal sign (=). However, upon reviewing _adap/ini/config_CFD.cfg_, was unable to find any lines that clearly violated this syntax rule. Could this error be indicative of a more subtle issue within the configuration file, or might it be related to specific aspects of the feature_adap branch? Any insights, suggestions, or guidance on how to troubleshoot this error would be greatly appreciated. If anyone has a working adapt_mesh.cfg file for a similar setup or for the feature_adap branch, I would be very interested in seeing it. Understanding the configuration details of a working example could be highly beneficial in resolving my issue. Thank you for your help!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1847333809
Availability,error,error,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Deployability,install,install,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Energy Efficiency,adapt,adaptation,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Modifiability,adapt,adaptation,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Testability,log,log,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Usability,guid,guidance,"Hi,. Thank you for your quick answer, It indeed seems that I had some parameters that were passed that did not match su2 version 7.0.3. I am experiencing an issue while running the mesh adaptation process in SU2. The process starts but fails during the mesh generation phase, leading to a FileNotFoundError. I am looking for assistance in resolving this error.; `; SU2-AMG Anisotropic Mesh Adaptation. Mesh adaptation options:; PYADAP_COMPLEXITY : (100, 200, 300); PYADAP_SUBITE : (2, 2, 2); PYADAP_SENSOR : MACH; PYADAP_HMAX : 200; PYADAP_HMIN : 1e-8; PYADAP_HGRAD : 1.3; PYADAP_RESIDUAL_REDUCTION : (3, 3, 3); PYADAP_FLOW_ITER : (500, 500, 500). ./adap exists. Removing old mesh adaptation in 10s.; The ./adap folder was deleted. Generating GMF background surface mesh.; Initial CFD solution is provided. Starting mesh adaptation process. Iteration 0 - Mesh size coefficient 100.0; (1/2) Generating adapted mesh using AMG; AMG done: ; Running CFD; Traceback (most recent call last):; File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 111, in <module>; main(); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 72, in main; options.save_all ); File ""/path/to/SU2/install/bin/mesh_adaptation_amg.py"", line 101, in mesh_adaptation_amg; SU2.run.amg(config); File ""/path/to/SU2/install/bin/SU2/run/amg.py"", line 466, in amg; os.rename(cur_solfil, cur_solfil_ini); FileNotFoundError: [Errno 2] No such file or directory: 'flo.dat' -> 'flo_ini.dat'`. and it0 folder is created, with some log.err and log.out, but they are empty, . I would appreciate any guidance or suggestions on how to resolve this issue. Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/948#issuecomment-1855842105
Availability,failure,failure,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420
Integrability,rout,routines,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420
Modifiability,variab,variable,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420
Testability,assert,assertion,"Hello,. So, to clarify, there were two issues:. 1) With the old commit (382e82f), we were seeing the assertion failure at line 1881 of numerics_structure.cpp, but only with the very large mesh (180 million cells). 2) With the newer commit (c093a62), we were seeing the assertion failure at line 294 of C2DContainer.hpp, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420
Usability,simpl,simply,"p, which was occurring even with smaller meshes (7 million cells). The solution to (2) appears to be to change `geometry->node[iPoint]->GetnNeighbor()` to `geometry->node[iPoint]->GetnPoint()` at line 3759 of CEulerSolver.cpp, in the `CEulerSolver::SetUpwind_Ducros_Sensor()` method. I made this change locally, and attempted to run on our large mesh. Issue (2) seems to be fixed, but we still run into issue (1). I have now gone through the read restart routines, and have found a potential issue:. For reference, the restart file for our large mesh with averaging data included consists of:; 39 fields * 75,107,967 points = 2,929,210,713 variable values (which is larger than `INT_MAX`). Beginning at line 3931 of CSolver.cpp, in method `CSolver::Read_SU2_Restart_Binary(...)`, we have the following:. ```; int *blocklen = new int[geometry->GetnPointDomain()];; int *displace = new int[geometry->GetnPointDomain()];; int counter = 0;; for (iPoint_Global = 0; iPoint_Global < geometry->GetGlobal_nPointDomain(); iPoint_Global++ ) {; if (geometry->GetGlobal_to_Local_Point(iPoint_Global) > -1) {; blocklen[counter] = nFields;; displace[counter] = iPoint_Global*nFields;; counter++;; }; }; MPI_Type_indexed(geometry->GetnPointDomain(), blocklen, displace, MPI_DOUBLE, &filetype);; ```; The problem here is that for our case, where `iPoint_Global` can get up to 75,107,967 and `nFields` = 39, the value assigned to `displace[counter]` in the loop can over-run `INT_MAX`. This would result in potential garbage / incorrect displace values being passed to `MPI_Type_indexed(...)`. Unfortunately, simply changing `displace` to a `long int *` won't work, as the expected argument type for `MPI_Type_indexed(...)` is `int`. It may be that, given the limitations of MPI here, reading such large restart information requires the restart file to be read serially by one rank, and the data split and broadcast to the other ranks?. I am not an MPI expert, so there may be another way to do this. Thoughts?. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622026420
Usability,simpl,simply,"The MPI_Type_create_hindexed will indeed solve the integer overflow encountered in MPI_Type_indexed, as the former uses MPI_Aint (8 byte integers) for the the displacements and the latter regular 4 byte integers. However, as @GomerOfDoom mentioned, there may be issues for the discrete adjoint (I saw that Type_indexed is actually present in medi) if we simply replace MPI_Type_indexed by MPI_Type_create_hindexed. So @talbring, @MaxSagebaum and @economon, do you foresee any problems here? If not, then it is a very simple change of a couple of lines.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/949#issuecomment-622319245
Deployability,install,installed,"@SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621090526
Usability,simpl,simpler,"@SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621090526
Deployability,install,installed,"> @SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; > [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt). @pcarruscag Thank you very much. This works. I have installed a sequential version and a parallel version with tecio,codipack and medipack enabled. I will try the same with Intel compilers and see if it works. Regards; Suman",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621164605
Usability,simpl,simpler,"> @SumanVajjala gcc 5+ have full c++ 11 support (even more than that actually). As a last resort, if you cannot figure out what is going on with the compilers (simpler guess is that there are other versions installed and they are getting mixed up?), you can try replacing the file ""allocation_toolbox.hpp"" by this:; > [allocation_toolbox_PATCH.txt](https://github.com/su2code/SU2/files/4550786/allocation_toolbox_PATCH.txt). @pcarruscag Thank you very much. This works. I have installed a sequential version and a parallel version with tecio,codipack and medipack enabled. I will try the same with Intel compilers and see if it works. Regards; Suman",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/955#issuecomment-621164605
Usability,clear,cleared,"Sounds good. I applied Pedro's fix to my code (temporarily), and it seems to have cleared up the problem. Thanks guys! Do you want me to close this now, or wait until the PRs are applied to develop?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/956#issuecomment-620142891
Testability,test,tested,"Check out the branch [fix_inlet_file_shape_opt](https://github.com/su2code/SU2/tree/fix_inlet_file_shape_opt). There's just one commit that differs from develop (921e85b9d7d9c152c131874a84f3534caf5705c2). I tested it on a simple case, and it seemed to work. But I don't have any more complex test cases to test it on. All my ""complex"" test cases involve other features not merged with develop. You can either merge that branch or (if your branch is not up to date with develop) cherry-pick the commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-627095055
Usability,simpl,simple,"Check out the branch [fix_inlet_file_shape_opt](https://github.com/su2code/SU2/tree/fix_inlet_file_shape_opt). There's just one commit that differs from develop (921e85b9d7d9c152c131874a84f3534caf5705c2). I tested it on a simple case, and it seemed to work. But I don't have any more complex test cases to test it on. All my ""complex"" test cases involve other features not merged with develop. You can either merge that branch or (if your branch is not up to date with develop) cherry-pick the commit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-627095055
Usability,simpl,simple,"By complex, I meant more complex than my simple toy problem. So if it's working for you, then that's what I was aiming for. I'll open a PR shortly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/970#issuecomment-628681947
Deployability,update,updated,"Thank you, @economon. It turns out, that does indeed remove the issue. I updated to the latest version (7.0.5) at the same time. When checking the default behavior, the QuickStart case would run correctly the 1st time then it would fail if the restart file was not removed prior to the output stage of subsequent runs. Commenting out line 223 does appear to resolve the issues we have been encountering. Original:; Now it seems to get stuck (simply freezes for >60 sec) when writing surface_flow.vtu (from QuickStart). I don't suppose there's another flag like this in that code vicinity?. Update: This issue resolved itself. The file system was being taxed by other runs. Thank you all for your time!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/971#issuecomment-644968380
Usability,simpl,simply,"Thank you, @economon. It turns out, that does indeed remove the issue. I updated to the latest version (7.0.5) at the same time. When checking the default behavior, the QuickStart case would run correctly the 1st time then it would fail if the restart file was not removed prior to the output stage of subsequent runs. Commenting out line 223 does appear to resolve the issues we have been encountering. Original:; Now it seems to get stuck (simply freezes for >60 sec) when writing surface_flow.vtu (from QuickStart). I don't suppose there's another flag like this in that code vicinity?. Update: This issue resolved itself. The file system was being taxed by other runs. Thank you all for your time!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/971#issuecomment-644968380
Usability,simpl,simple,"Hi,; So far as I can tell from the code, no.; It would however be very simple to hack that kind of feature, I can point you to the right places if you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/973#issuecomment-626357981
Usability,simpl,simple,"Thanks a lot @pcarruscag but for the moment I decided to use [NaSt3DGP](https://ins.uni-bonn.de/media/public/u/griebel/NaSt3DGP/index.html) instead. It is a very simple code that implements 3D incompressible NS with natural convection, and it can be very easily understood because it's really a very minimal implementation (parallelized, though). I'm closing this, although if you consider this feature would be of interest for SU2, don't hesitate to open this issue again, as a feature request.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/973#issuecomment-626360321
Integrability,depend,depends,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862
Performance,perform,performing,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862
Usability,simpl,simple,"Regarding periodic boundaries: You have two options. You can hack the code to not allow grid deformation on periodic boundaries. That's a simple code edit, since the code already prevents most boundaries from being deformed. Let me know if you want to use this option, and I can point you to those lines. Second, you can use the `HOLD_GRID_FIXED` and `HOLD_GRID_FIXED_COORD` options to prevent grid deformation outside a specific box. I have found this option to be better overall, since it also makes the linear system easier to solve in `SU2_DEF`. The `DV_VALUE` and `FINDIFF_STEP` are different. I've only seen `FINDIFF_STEP` used for the finite-differencing python script, though it may have other uses I am not aware of. The `DV_VALUE` depends on the context. When using `SU2_DOT`, `DV_VALUE` is set to its default value. But when performing shape optimization using SU2's framework, the `DV_VALUE` parameters will be set based on the output of SLSQP (or whatever optimization framework you're using).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626799862
Usability,simpl,simpler,"@clarkpede I think it is simpler to lock the periodic boundaries. I can look into that if you can point me to it. I have been using BFGS but the DV_VALUE is always 0.001 in the config_DOT_AD files, even after 25 design iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-626855754
Energy Efficiency,reduce,reduce,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163
Modifiability,variab,variable,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163
Performance,optimiz,optimizer,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163
Usability,intuit,intuitive,"I am not sure about why periodic boundaries are allowed to deform. It doesn't seem to be a good idea unless there is a way to deform its periodic pair in the same way. As for @auzbaig's question about why SLSQP converges in one step: There is a huge difference in the magnitude of the objective function, O(1) and the gradient O(-11). I am guessing the optimizer doesn't think it can reduce the function value any further since the gradient with respect to the DVs is so small. . To change the relative magnitudes of the objective and gradient, you need to change the DV scaling. This isn't intuitive and is one of the things we are hoping to address in #922 . Check out the `obj_df` function in `SU2_PY/SU2/eval/design.py` (line 386 in the develop branch). There you see how the gradient is scaled: . `grad[k] = grad[k] * sign * scale * global_factor / dv_scl` . Here `scale` is the objective function scaling factor, `global_factor` is what you specify for the `OPT_GRADIENT_FACTOR`, the `dv_scl` is the design variable scaling. . So if you wanted to bring the gradient norm to O(1), you'd have to specify a DV scaling of 1e-11. Usually a gradient norm of O(-6) is what seems to work best with SLSQP.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/976#issuecomment-628724163
Deployability,update,updated,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076
Testability,log,logic,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076
Usability,simpl,simple,"Yes it definitely is confusing. Then we have to use set_ffd_design_var.py giving i,j,k which are not really 'units' in x,y,z. The website should be updated to show this. I am wondering how does SU2_DEF will determine the ""logic axis"". Won't a simple x,y,z approach have been simpler?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/977#issuecomment-626875076
Usability,simpl,simply,">Why are you defining an internal marker?. Haha. Initially, I thought by creating a dummy marker inside my domain and calling it ""INTERNAL"", I can output solution at any desired face in the solution_flow file without having to deal with post processing software. This is of course possible in Paraview or Tecplot, but I figured this may be more automatic and perhaps easier especially with curved surfaces. Now I am simply curious as to what is happening with the internal markers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/986#issuecomment-628781294
Usability,simpl,simply,"I use the connection as the additional marker. Since the connection is two sided, nodes are duplicated. This is quote from the forum post I linked earlier . >....creates unique (yet coincident) points for each ""side"" of the domain.... The quote was about Gmsh exporter and not SU2, but later on they say this is the case for all exporters except Fluent. These duplicated nodes affect the mass and momentum balance because they each carry information about the neighbors on their respective side only. . This might not be a problem if we were to apply a strong boundary condition like a wall because the dirichlet condition will simply overwrite any residuals and apply the appropriate value to both the nodes. However when used as an internal marker or any other weak boundary condition, the duplicate nodes each carry part of the residuals and if they don't communicate with each other an imbalance will occur. At the moment, it appears they do not communicate with each other.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/986#issuecomment-629182862
Availability,error,errors,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658
Deployability,install,install,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658
Usability,simpl,simply,"Hello @aditya12398 ,. No such thing as a noob question!. To use your system meson, instead of using: `./meson.py <arguments>` in your SU2 root dir, use `meson <arguments>`. This assumes your system meson is in front of your current directory in your path, of course. Likewise, to use system ninja, instead of using: `./ninja -C build install`, simply use `ninja -C build install`. I found, for some reason, that when using my system meson and ninja with the changes made in `fix_python_3.8`, I am not getting errors, but when I use SU2's included `./meson.py`, I'm still getting those errors. Not sure why this is happening, though. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/991#issuecomment-631584658
Usability,simpl,simply,"The original Spalart-Allmaras turbulence model encloses the ft2 term: https://www.researchgate.net/publication/236888804_A_One-Equation_Turbulence_Model_for_Aerodynamic_Flows or https://turbmodels.larc.nasa.gov/spalart.html#sa. After that, some modifications were introduced and the ft2 term was neglected. But accordingly, a different name is used, i.e., Spalart-Allmaras One-Equation Model without ft2 Term.; So, I would also vote for implementing the original model along with the SA-noft2 variant. Also, I would like to point out a fact about the current implementation of the Negative Spalart-Allmaras variant. From theory, https://www.iccfd.org/iccfd7/assets/pdf/papers/ICCFD7-1902_paper.pdf equation 12, the model introduces the modified vorticity S_tilde. However, in SU2 (SU2/SU2_CFD/src/numerics/turbulent/turb_sources.cpp and CSourcePieceWise_TurbSA_Neg::ComputeResidual) we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras:. Shat = S + TurbVar_i[0]*fv2*inv_k2_d2;. (Sbar is used as S_tilde). Is there any reason for that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-648883933
Usability,simpl,simply,"I can do that. I will follow the above mentioned papers to implement the original SA and SA_NEG. So we will end up with SA, SA_NEG along with SA_NOFT2 and SA_NEG_NOFT2**. SA_NEG_NOFT2**:; > we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652248694
Modifiability,config,config,"Food for thought: According to his most recent AIAA talk, Spalart himself has tried to keep the model variants ""modular."" Some of the variants are compatible with each other. For example, you can add a ""rotation-curvature correction"" and a ""compressiblity correction"". The NASA TMR catalogue reflects this design by stating ""These corrections can be applied individually or together in combination with the General Model."". A simple `SA_QCR` or `SA_COMP` naming scheme doesn't match the underlying design. On the user-facing side, separate config options might be better for some of the variations. On the code side, bit flags (Issue #770) might be a good way to gather all the model variants together into a single config option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652446915
Usability,simpl,simple,"Food for thought: According to his most recent AIAA talk, Spalart himself has tried to keep the model variants ""modular."" Some of the variants are compatible with each other. For example, you can add a ""rotation-curvature correction"" and a ""compressiblity correction"". The NASA TMR catalogue reflects this design by stating ""These corrections can be applied individually or together in combination with the General Model."". A simple `SA_QCR` or `SA_COMP` naming scheme doesn't match the underlying design. On the user-facing side, separate config options might be better for some of the variations. On the code side, bit flags (Issue #770) might be a good way to gather all the model variants together into a single config option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652446915
Usability,simpl,simply,@fpalacios: I am adding you to this discussion because I have seen you are the responsible of implementing the Negative Spalart-Allmaras variation in SU2. Maybe you can shed some light into the discussion. In particular to:; > we do not consider this modification and simply consider the modified vorticity as in the standard Spalart-Allmaras,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/992#issuecomment-652635415
Energy Efficiency,efficient,efficient,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959
Modifiability,config,config,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959
Usability,simpl,simply,"@pcarruscag I tried to restart the solution with zero mach number for config. However, for some reason, convergence takes so much longer than simply solving mach=0.1 config. Indeed, i started my simulation when you post your suggestion and it still haven't converged yet. Residual getting smaller but it is so slow. Therefore it might not be an efficient solution. Thanks for advice anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/997#issuecomment-632892959
Deployability,install,install-libiberty,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Integrability,wrap,wrapper,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Modifiability,config,configure,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Security,hash,hash-style,"@talbring Yes, I do. I can't uninstall it since it breaks other packages. @pcarruscag Yeah same for me. You can see it here:; ```; slimshady@arch-linux-hp-probook-g3-450: ~$ mpicc -v; mpicc for MPICH version 3.3.2; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/9.2.1/lto-wrapper; Target: x86_64-pc-linux-gnu; Configured with: /build/gcc/src/gcc/configure --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-pkgversion='Arch Linux 9.2.1+20200130-2' --with-bugurl=https://bugs.archlinux.org/ --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-shared --enable-threads=posix --with-system-zlib --with-isl --enable-__cxa_atexit --disable-libunwind-exceptions --enable-clocale=gnu --disable-libstdcxx-pch --disable-libssp --enable-gnu-unique-object --enable-linker-build-id --enable-lto --enable-plugin --enable-install-libiberty --with-linker-hash-style=gnu --enable-gnu-indirect-function --enable-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Testability,log,log,"ble-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output for `./ninja`](https://github.com/su2code/SU2/files/4672490/ninja_build_mpich.log). Even though the build was successful, SU2 does not seem to run properly. It displays the same thing ""NP"" (`mpirun -n NP ...`) number of times. And the console prints the output in chunks, like 57 iterations suddenly ""NP"" times, then a pause, then 57-119 ""NP"" times and so on. You can see the [logfile here](https://github.com/su2code/SU2/files/4672491/mpirun_SU2_CFD_error.log).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Usability,pause,pause,"ble-multilib --disable-werror --enable-checking=release --enable-default-pie --enable-default-ssp --enable-cet=auto gdc_include_dir=/usr/include/dlang/gdc; Thread model: posix; gcc version 9.2.1 20200130 (Arch Linux 9.2.1+20200130-2) ; ```; I did what you suggested and here is how my meson.build file looks.; ```; # If custom mpi mode is enabled, include and library pathes for MPI have to be set manually to env variables; if get_option('custom-mpi'); mpi_dep = []; mpi = true; # Otherwise they are automatically determined; else; mpi_dep = [dependency('mpich', required : get_option('with-mpi'))]; # mpi_dep = [dependency('mpi', language:'c', required : get_option('with-mpi')),; # dependency('mpi', language:'cpp', required : get_option('with-mpi'))]; #if mpi_dep[0].found() or mpi_dep[1].found(); # mpi = true; #endif; endif; ```; My SU2 build was successful but there were a couple of warnings.; Also, instead of 870 there were only 772 files in total. Is that okay?; ```; slimshady@arch-linux-hp-probook-g3-450: SU2HOME$ ./ninja -C build install; ninja: Entering directory `build'; [756/772] Generating 'SU2_PY/pySU2/_pysu2.so.p/pySU2.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [760/772] Generating 'SU2_PY/pySU2/_pysu2ad.so.p/pySU2ad.cxx'.; ../SU2_PY/pySU2/../../Common/include/mpi_structure.hpp:348: Warning 325: Nested struct not currently supported (Status ignored); [771/772] Installing files.; .; .; ```; Here is the [entire output for `./ninja`](https://github.com/su2code/SU2/files/4672490/ninja_build_mpich.log). Even though the build was successful, SU2 does not seem to run properly. It displays the same thing ""NP"" (`mpirun -n NP ...`) number of times. And the console prints the output in chunks, like 57 iterations suddenly ""NP"" times, then a pause, then 57-119 ""NP"" times and so on. You can see the [logfile here](https://github.com/su2code/SU2/files/4672491/mpirun_SU2_CFD_error.log).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-633139474
Deployability,install,installed,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410
Modifiability,variab,variables,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410
Usability,clear,clear,"Hello @aditya12398 ,. The fifth line of the file you attached shows a call to `c++`, rather than `mpicxx`, which could cause those undefined references. Basically, the linker is not seeing your mpi libraries. I believe that, in order to use the `-Dcustom-mpi=true` flag, you may need to define your compiler environment variables (such as `$CC`, `$CXX`, `$LD`, `$MPICXX`, etc). Having both OpenMPI and MPICH installed on your system is complicating things, I think. Without some manual configuration of your system's environment, it may not be clear to meson/ninja which mpi implementation should be used. You may need to do some digging around on the internet to see how to properly resolve which MPI implementation gets used for different applications. -Paul",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-634825410
Modifiability,config,configured,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008
Testability,test,test,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008
Usability,simpl,simple,"@fertinaz the problem is that the pkg_config name for MPICH is not ""mpi"" which is what meson is configured to look for...; It is ""mpich"", please see my reply from 23 of May, it is very simple to edit the meson.build script to look for ""mpich"" instead of ""mpi"".; I have used this on numerous machines and the code works fine...; Whatever you do, please do not follow the advice to use 6.2.0, we have all worked extremely hard to make v7.x much faster, fix bugs, and add nice features... Unfortunately we cannot test every combination of compiler, operating system, and libraries.; I'm sure that somewhere, someone has fixed similar problems, sadly not all fixes make it back into the code. Other alternatives, some of which folks have suggested on this thread.; - Use ""custom-mpi"" mode, you will need to set some environment variables (CC=mpicc CXX=mpicxx etc. see above); - Use the legacy build system (i.e. follow the instructions for 6.2.0 but with the 7.0.7 code) be sure to add ""-DNDEBUG"" to the CXXFLAGS environment variable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1000#issuecomment-721322008
Availability,error,error,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Energy Efficiency,adapt,adapt,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Modifiability,adapt,adapt,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Safety,avoid,avoid,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Testability,test,test,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Usability,simpl,simple,"This one is all set after a little more cleanup. I left some low-level changes to the EoS models for later. @CatarinaGarbacz @MarcoFossati : we can use a simple directory name, as you suggest. Let's just go with fluid/ since we also treat liquids with the incompressible solver. Bonus: adds a rotating frame calculation test and some extra error checks on CFL adapt params that should help avoid unreported problems with old configs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1010#issuecomment-640170715
Usability,feedback,feedback,"@pcarruscag thanks for the additional feedback. some of these comments were already in my plans, but can only do one thing at a time of course. In any case it's good to see we're thinking in the same way, confirms I'm heading in the right direction, so I definitely appreciate it. Others I had not thought about it at all, even more useful! Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-654324437
Deployability,update,updates,Lots of different updates have been done to incorporate all feedback and make improvements to this PR. It seems to be in a solid place to be merged with develop. @pcarruscag @talbring,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671
Usability,feedback,feedback,Lots of different updates have been done to incorporate all feedback and make improvements to this PR. It seems to be in a solid place to be merged with develop. @pcarruscag @talbring,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1014#issuecomment-663934671
Modifiability,variab,variables,"Hello Pedro, thanks for your quick reply! ; More than the differentiation of the mesh deformation problem I was referring to what SU2_DOT does in the specific, at least in terms of workflow.; In fact, reading your answer I realise that maybe I'm misunderstanding the process done by SU2_DOT.; I thought that, in case of Disc. Adjoint, SU2 solver was already providing the _total_ sensitivity of the objective function with respect to the boundary grid nodes displacements. This already includes the contribution of the mesh deformation. given this, I thought that SU2_DOT was simply projecting such sensitivities on the FFD box point displacements chosen as design variables. But I cannot understand then why the need to include the mesh deformation problem within SU2_DOT.; Can you let me know about that please?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772
Usability,simpl,simply,"Hello Pedro, thanks for your quick reply! ; More than the differentiation of the mesh deformation problem I was referring to what SU2_DOT does in the specific, at least in terms of workflow.; In fact, reading your answer I realise that maybe I'm misunderstanding the process done by SU2_DOT.; I thought that, in case of Disc. Adjoint, SU2 solver was already providing the _total_ sensitivity of the objective function with respect to the boundary grid nodes displacements. This already includes the contribution of the mesh deformation. given this, I thought that SU2_DOT was simply projecting such sensitivities on the FFD box point displacements chosen as design variables. But I cannot understand then why the need to include the mesh deformation problem within SU2_DOT.; Can you let me know about that please?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1017#issuecomment-640071772
Deployability,update,updated,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672
Integrability,interface,interface,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672
Performance,load,loaded,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672
Usability,simpl,simplest,"@bigfooted @economon and @pcarruscag . I created separate repo to demonstrate what I'm after in the simplest way possible: [FoamScience/AutoRegistering-Cpp-Classes](https://github.com/FoamScience/AutoRegistering-Cpp-Classes/commits/master). > If you're going to check the code, check CSolver first, then CEulerSolver ... - Commit FoamScience/AutoRegistering-Cpp-Classes@20ca601 implements the concept for a single Factory.; - (Make-believe) Standard solver classes are compiled to a library; - A (Make-beleive) Custom solver class is compiled to its own shared library; - By default, the make program knows only about CEulerSolver (from standard solvers lib); - But if you pass in a library name (eg. libCCustomSolvers.so), it gets loaded, symbols pulled and the registration map for CSolver gets updated with the new Solver automatically. - But it would bloat the code if things went this way, so commit FoamScience/AutoRegistering-Cpp-Classes@380c052 isolates self-registration code into 3 macros to:; - Declare the registration map and associated members; - Define and initialize registration-related members on the base class; - Register a class. If you only care about the interface and not how the thing is implemented, commit 380c052 is your target.; I took care to document the important parts of the code, so, please, dig in and let me know what you think. At this point, integrating this with SU2 (and at what parts, and when) is your call but If you decide to do so, l will help.; > And yes, I wrote my own build script so I can have direct control over the compiler and the linker. **One last note: I used ""dlopen"", so you will have to compile the code on Linux I suppose.**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1058#issuecomment-680962672
Integrability,depend,dependent,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807
Testability,test,testcases,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807
Usability,simpl,simplification,"Thank you for the review @economon.; I just gave the multiple constraints a try on the hybrid onera m6 mesh we have in testcases, it works, both points and edges can be balanced, but the edge cuts go up by almost 50% I guess that makes sense, more constraints less minimization.; There's another reason why I like the combined function, balancing the ""num neighbors"" metric is not exactly the same as balancing the number of edges per partition, using a small negative point weight (-1, -2) yields better results (but the ideal value will be case dependent). I think the next big improvement we can make in this area is to use a partitioner that is aware of the network topology, ParMETIS assumes that the communication cost between any two ranks is the same, this simplification can be very costly on large parallel machines that have a tree-like network topology, and in older clusters with slow interconnects (relative to intra node communication).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1059#issuecomment-671054807
Deployability,configurat,configuration,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809
Modifiability,config,configuration,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809
Usability,clear,clearly,"Hi Wally, ; I have run some axisymmetric cases earlier for pressure distribution (Cp) computation over typical payload fairing configuration (with older versions of SU2). Pressure distribution seemed to be fine with earlier runs (and also it matched well with other codes). ; Issue popped up while trying to compute heat flux for axisymmetric problems. I have seen folks and students running their cases with axisymmetric formulation. Now the issue has surfaced clearly, it need to be fixed asap.; How is solution of the case, you have been trying? . Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1063#issuecomment-699627809
Deployability,update,update,"@tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872
Usability,clear,clear,"@tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-733607872
Deployability,update,update,"> ; > ; > @tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this. I indeed tried to solve all issues that were mentioned earlier. Could you take another look to see whether I have done this well enough?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433
Usability,clear,clear,"> ; > ; > @tollennaert, can you comment on the points raised by @pcarruscag ? I think you tried to address all points in your latest update? That makes it clear to everybody that all points have been addressed. I hope you still have time for this. I indeed tried to solve all issues that were mentioned earlier. Could you take another look to see whether I have done this well enough?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1076#issuecomment-741601433
Deployability,update,updated,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999
Energy Efficiency,adapt,adapt,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999
Modifiability,adapt,adapt,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999
Usability,simpl,simple,"Those two cases are not part of the regression suite, and so they were probably not updated as some of the options were renamed.; You can have a look at the other turbomachinery examples (at least two of them are part of the regressions) it should be simple to adapt those options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1086#issuecomment-706417999
Safety,avoid,avoid,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781
Testability,test,test,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781
Usability,simpl,simple,"Hi everyone, glad this subject is of interest. I will try to make that test case. I edit my earlier comment to avoid a mess. So I changed the terms. Still not sure but the derivation is simple. source term viscous = (0, tau_xy, tau_yy - tau_thetatheta, u* tau_yx + v* tau_yy - q)/y, right?. then from Bird:. ![IMG_20201027_115003](https://user-images.githubusercontent.com/55834287/97291927-d9767e00-184a-11eb-9418-a3ace3e3a077.jpg). bulk viscosity = 0, any derivative wrt theta = 0. For the generalised inviscid part I am pretty sure it is all correct including the jacobian. You can compare with very similar terms in any generalised flux jacobian like in Glaister's paper https://www.sciencedirect.com/science/article/pii/002199918890174X",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-713564781
Testability,test,test,"I'm late to the party here, but just a note to say that the original implementation for the incompressible source terms are indeed from the text that @WallyMaier / @vdweide shared. It was added as part of the work in this paper (https://economon.github.io/docs/AIAA-2018-3111.pdf), but I did not test it much beyond a simple laminar channel case or really attempt to treat turbulence at the time. Thanks for putting in more effort on these terms!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198
Usability,simpl,simple,"I'm late to the party here, but just a note to say that the original implementation for the incompressible source terms are indeed from the text that @WallyMaier / @vdweide shared. It was added as part of the work in this paper (https://economon.github.io/docs/AIAA-2018-3111.pdf), but I did not test it much beyond a simple laminar channel case or really attempt to treat turbulence at the time. Thanks for putting in more effort on these terms!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727633198
Modifiability,variab,variables,Actually I had a look at your branch and the way it is right now is not correct I believe because I had taken the other variables v and 1/y out of the derivative using the chain rule and combined them with the other derivatives to end up with the terms as they are now so only d(mu)/dy was missing. The AxiAuxVarGrad you are using is apparently d(v*mu/y)/dy so the other terms have to be different. I will change them. Why not just simply compute the viscosity gradient? Is there any reason not to pull the other variables out?. Is there not already an AuxVar being just v*mu or something? . Anyway I guess it will work the same either way,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107
Usability,simpl,simply,Actually I had a look at your branch and the way it is right now is not correct I believe because I had taken the other variables v and 1/y out of the derivative using the chain rule and combined them with the other derivatives to end up with the terms as they are now so only d(mu)/dy was missing. The AxiAuxVarGrad you are using is apparently d(v*mu/y)/dy so the other terms have to be different. I will change them. Why not just simply compute the viscosity gradient? Is there any reason not to pull the other variables out?. Is there not already an AuxVar being just v*mu or something? . Anyway I guess it will work the same either way,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1095#issuecomment-727969107
Energy Efficiency,energy,energy,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377
Modifiability,variab,variable,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377
Usability,simpl,simply,"> @aeroamit What does temperature do? Could you compute the heat flux from the temperature in e.g. paraview? Is the root cause the computation of the energy equation or the computation of heat flux?. Hi @bigfooted, Temperature boundary condition for wall corresponds to Isothermal wall BC (cold wall condition). This condition is applied to obtain heat flux unlike adiabatic wall (no heat transfer). ; The snapshot, I posted from ParaView shows heat flux variation with x. This is obtained directly from surface_flow.vtu. You can simply go to Filters -> Data Analysis -> Plot data and select Points_X for X Array and heat flux in variable. Regarding computing heat flux from temperature field, I am not sure, but ParaView is having calculator utility as well as option to compute gradient of unstructured grid (from there you can obtain temperature gradients in 3 directions). ; Coming to last question, root cause of the problem - @WallyMaier has run the case yesterday, we will be posting some details soon.; Best ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1106#issuecomment-741947377
Usability,clear,clear,"I've changed some 'get' functions to 'compute' to be more clear. After some conversations with @pcarruscag Ive also added some 'const' to some 'get' functions. More work can be done in this regard, and that process is ongoing. I can continue doing so in this PR, or in a future one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1111#issuecomment-730849653
Performance,perform,perform,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039
Testability,test,tests,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039
Usability,feedback,feedbacks,"Thank you for the feedbacks, I am working on the modifications you suggested. I will perform a couple of tests to be sure I did not break anything. Hope to commit the new code soon!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-740209039
Integrability,wrap,wrapper,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Performance,perform,perform,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Safety,avoid,avoids,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Security,access,accessing,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Testability,test,test,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Usability,learn,learning,"I think I implemented all the modifications you suggested. I am sorry you see all the commits in between, unfortunately due to Covid I work outside of office and I actually use Github to push the modified code to the office PC. I was actually working on a separate branch but, for reason that I do not understand, all the commits have been moved in the merging process... sorry about that. I am still learning git. In particular the modifications are:. - The functions related to static mesh deformation have been removed. I only included some new lines in the python wrapper ; that overwrite the initial velocities to zero and push back the solution.; - I now use the BC_Sym_Plane of the FEA solver for the deformation at the symmetry plane. I had to add a flag that avoids ; accessing LinSysReact in case of mesh deformation, as this is not initialised in that context.; - GetnMarker_Match_Deform_Mesh is not present anymore; - The marker has been renamed from MATCH_DEFORM_MESH to DEFORM_MESH_SYM_PLANE. All the functions have also ; been renamed accordingly; - I included the SU2 header in all the new files, changing the version number to 7.0.8. I did not modify the version number of ; the files that were already present in SU2 prior to this PR. I think the merging process should take care of that, am I wrong?; - The python functions that were separated in x,y,z component now give back an array and are merged into one function only; - The descriptions for the methods have been added; - The test case has been removed. I actually prepared a tutorial and all the appropriate files will be placed in the tutorial and ; website repos. I will now perform a PR for those repos so that you can see the material. Again thank you very much and sorry for the mess with the ""internal"" commits. . Please let me know if you think I missed something",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1124#issuecomment-742471972
Modifiability,variab,variable,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412
Safety,safe,safety,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412
Usability,simpl,simple,"Maybe CNumerics is not the perfect place, but it is good enough for government work (there are much more misplaced things in there). The ""everything is class"" OO approach applied to the lowest level of abstraction is... well I think it is terrible -- and it has taken me a mighty long time to get rid of it in CPoint and CVariable and to design alternative Numerics -- because:; - Boilerplate: Set this, get that, constructor, destructor;; - Thread safety: Those classes always end up having some mutable state that renders them thread-unsafe;; - Correctness: Many of the classes we have follow this paradigm of ""pass by member variable"" - I like to know what are the inputs and outputs of something just by looking at the signature;; - Slowww: Too much virtual;; - Unnecessary complexity: A case of using a canon to kill the mosquito, good code should be as simple as possible, if a function does the job then that is the level of abstraction we should use. My introduction to C++ was also the ""everything is class"", then one day I read ""From Mathematics to Generic Programming"" and well, I started liking C++ a whole lot more.; The standard template library is incredibly successful, and it ""just"" provides some containers and generic algorithms which are functions. That is what we need in SU2, some decent containers and generic algorithms to operate on them. OO and its patterns are very good high level tools to achieve encapsulation and to isolate code, which are very important for projects with millions of lines of code, but for low level things they are overkill. Sorry for the rant, I guess I have strong feelings about tiny classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1127#issuecomment-742629412
Energy Efficiency,power,power,"Dark mode?; ""Is it possible to learn this power?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950
Usability,learn,learn,"Dark mode?; ""Is it possible to learn this power?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743123950
Energy Efficiency,power,power,"> ; > ; > Dark mode?; > ""Is it possible to learn this power?"". 🧙 Sure, if you just go to your front page (i.e. just github.com) there should be a big button directly on the right side. ; Or Settings->Appearance->Dark. Enjoy :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745
Usability,learn,learn,"> ; > ; > Dark mode?; > ""Is it possible to learn this power?"". 🧙 Sure, if you just go to your front page (i.e. just github.com) there should be a big button directly on the right side. ; Or Settings->Appearance->Dark. Enjoy :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1129#issuecomment-743130745
Usability,simpl,simple,"@lorenzob95 we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755395168
Availability,avail,available,"I suggest that you incorporate Wray-Agarwal (WA) one equation RANS model listed on NASA TMR in SU2. NASA is planning to list two equation WA-gamma transition model on NASA TMR next month. WA model is available on Github and WA model will also be posted on Github as source code. If you need any additional information or help, let me know.; Ramesh Agarwal; ________________________________; From: Pedro Gomes <notifications@github.com>; Sent: Wednesday, January 6, 2021 10:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Agarwal, Ramesh <rka@wustl.edu>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] Info on current status of LM transition model in SU2 (#1130). @lorenzob95<https://github.com/lorenzob95> we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide<https://github.com/vdweide> exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/1130#issuecomment-755395168>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ASK3WAEG3LW3AZJRUPORJPDSYSD2VANCNFSM4UVYXAAA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165
Usability,simpl,simple,"I suggest that you incorporate Wray-Agarwal (WA) one equation RANS model listed on NASA TMR in SU2. NASA is planning to list two equation WA-gamma transition model on NASA TMR next month. WA model is available on Github and WA model will also be posted on Github as source code. If you need any additional information or help, let me know.; Ramesh Agarwal; ________________________________; From: Pedro Gomes <notifications@github.com>; Sent: Wednesday, January 6, 2021 10:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Agarwal, Ramesh <rka@wustl.edu>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] Info on current status of LM transition model in SU2 (#1130). @lorenzob95<https://github.com/lorenzob95> we talked about this issue in our weekly developers meeting.; The current implementation of LM in the code is not stable enough and it has known bugs, so we will not re enable it for now.; A revised implementation by @vdweide<https://github.com/vdweide> exist in branch https://github.com/su2code/SU2/tree/feature_LM_model, but this is based on SU2 v6.2, it has been used on simple problems, convergence is not ideal on more complicated ones.; The decision is to wait for some developments that will make it easier to bring this revised implementation into version 7 (which is different in many ways from 6).; You can follow this issue to know when this gets implemented, it will probably take a few months. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/1130#issuecomment-755395168>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ASK3WAEG3LW3AZJRUPORJPDSYSD2VANCNFSM4UVYXAAA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1130#issuecomment-755440165
Energy Efficiency,adapt,adaptation,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547
Modifiability,adapt,adaptation,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547
Usability,simpl,simpler,"I could but I do not think updating that branch will fix your problem. We have not found any mesh handling bugs recently.; Creating / modifying meshes manually can get tricky (at least in my experience).; Have you tried simpler problems? Try starting with a problem that is known to work (there is a long issue with success stories, do a search for mesh adaptation here on github). Then build up from it, e.g. take the same problem and use a finer grid, change the physics to what you need, use a grid for your problem (ideally change one thing at a time).; Also keep in mind that if that branch was finished work it would probably have been merged into develop by now...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-757123547
Availability,error,error,"Hi @pcarruscag I just tried a simpler mesh and using MPI I get the UCX crash.; [err_log_SU2v7.0.3.txt](https://github.com/su2code/SU2/files/5810207/err_log_SU2v7.0.3.txt). To double check, I also used the master v7.0.8 SU2_CFD. When I run with MPI, I get the UCX error but when I run in serial, the solution appears to converge fine. I suspect that this means it's probably not the mesh that is causing the issues - what are your thoughts?; [su2_out_serial.txt](https://github.com/su2code/SU2/files/5810208/su2_out_serial.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361
Usability,simpl,simpler,"Hi @pcarruscag I just tried a simpler mesh and using MPI I get the UCX crash.; [err_log_SU2v7.0.3.txt](https://github.com/su2code/SU2/files/5810207/err_log_SU2v7.0.3.txt). To double check, I also used the master v7.0.8 SU2_CFD. When I run with MPI, I get the UCX error but when I run in serial, the solution appears to converge fine. I suspect that this means it's probably not the mesh that is causing the issues - what are your thoughts?; [su2_out_serial.txt](https://github.com/su2code/SU2/files/5810208/su2_out_serial.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1156#issuecomment-759607361
Modifiability,config,config,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555
Testability,test,tested,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555
Usability,usab,usable,"> ; > ; > @CatarinaGarbacz thanks for pushing your changes! I have left some comments and questions.; > ; > A bigger question I have is if there is a more general way to deal with SU2_INTERP, making it usable for all of develop. Just answering @WallyMaier comment, this should be possible by changing the file **fem_interpolation_structure.cpp** and change the function call:. output = COutputFactory::CreateOutput(**NEMO_NAVIER_STOKES**, input_config_container[ZONE_0],nDim);. So we have to replace **NEMO_NAVIER_STOKES** to something like **config[val_iZone]->GetKind_Solver()**.; ; I have not tested this change, but I tested changing it for NAVIER_STOKES, and it was able to interpolate the baseline SU2.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1160#issuecomment-760110555
Integrability,interface,interface,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325
Safety,predict,predicted,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325
Testability,test,test,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325
Usability,simpl,simplify,"Hi Pedro, thanks for looking into this more. I had run into inconsistencies for FSI problems with relaxation which was the reason for the domain specific calls coming into the multizone driver Update function. With the changes I introduced, the velocity at the interface was being transferred correctly with and without relaxation, so I left it there but it is a bit messy. I'll test with the modified calls for the Relaxation as you suggest. I completely agree that if we can simplify the velocity transfer by just using the velocity directly, then we should. Especially since the predicted velocity is only zero order anyway.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-774993325
Availability,avail,available,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558
Integrability,interface,interface,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558
Usability,simpl,simplifying,"@Nicola-Fonzi, you may as well want to consider importing as well the structural velocities in the interface from your external solver. That information is always available and gives a consistent definition of the displacement and velocity on both the grid motions and the interface for dynamic FSI problems -- not to mention simplifying the evaluation of the mesh adjoints.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778326558
Modifiability,config,config,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854
Performance,load,load,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854
Testability,log,logic,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854
Usability,simpl,simplification,"Hi @Nicola-Fonzi,. I'm not 100% sure of the reasons behind the GetFSI_Simulation criteria. I'd imagine that the nMarker_Fluid_Load might have been included there to make sure that a problem is treated as FSI only if there is transfer of load from the fluid to the structural domain, even if both zones existed independently in the config. But since the GetFSI_Simulation check is set up as an ""or"" rather than ""and"", as long as one of them is satisfied, the logic will be true for an FSI simulation, which might be sufficient for your application?. For the velocity transfer, I agree with Rafa that it would be better if you could also transfer the velocity from the external structural solver. If an external structural solver is used for dynamic analysis, it probably can output the structural velocities as well as the structural displacements? I left the methods for the recalculation of the grid velocity using finite differences in the code to support fluid-only problems with dynamic grid motion, I wouldn't suggest this as the method for FSI problems. For primal analysis, results from both methods agree with FSI benchmark cases but if you are interested in adjoint analysis at any point, transferring the velocity information from the structural domain directly to the fluid domain gives a significant simplification and improvement to the gradients.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-778368854
Deployability,update,updated,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242
Testability,test,tests,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242
Usability,simpl,simpler,"Yes, nothing more from me on this. Once this is merged, the comparison in PR #1260 should become simpler too. I've just updated this branch with develop, we can merge once the regression tests pass again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1174#issuecomment-827981242
Modifiability,variab,variable,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798
Testability,test,test,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798
Usability,simpl,simple,"The answer to that is very simple. Look in the data set that is present in the szplt file. The z-coordinate is not in there anymore and consequently Tecplot takes the next variable, the density in this case, as the z-coordinate. Consequently you git a picture like you showed. The same is true for the field solution. Also there the z-coordinate is not present in the szplt file and hence you get a rather funny picture when you attempt to visualize this in 3D. But 2D visualization works just fine. In contrast the z-coordinate is stored in the vtu files, because the standard requires that. Hence you can still visualize this in 3D. Could you try a truly 3D test case to see if that visualizes fine? If so, please let us know such that we can close this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1182#issuecomment-771407798
Modifiability,config,config,"Checkout the small_fixes branch please, I hope the problem is ""that"" simple as I will not debug that function any further because it has the world record for nested loops. If it does not work you will have to hope for help from the turbo folks.; ```c++; for (iMarker = 0; iMarker < nMarker; iMarker++){; for (iMarkerTP=1; iMarkerTP < config->GetnMarker_Turbomachinery()+1; iMarkerTP++){; if (config->GetMarker_All_Turbomachinery(iMarker) == iMarkerTP){; if (config->GetMarker_All_TurbomachineryFlag(iMarker) == marker_flag){; for (iVertex = 0; iVertex < nVertex[iMarker]; iVertex++) {; iPoint = vertex[iMarker][iVertex]->GetNode();; for (jMarker = 0; jMarker < nMarker; jMarker++){; if (config->GetMarker_All_KindBC(jMarker) == PERIODIC_BOUNDARY) {; PeriodicBoundary = config->GetMarker_All_PerBound(jMarker);; jVertex = nodes->GetVertex(iPoint, jMarker);; if ((jVertex != -1) && (PeriodicBoundary == (val_iZone + 1))){; coord = nodes->GetCoord(iPoint);; switch (config->GetKind_TurboMachinery(val_iZone)){; case CENTRIFUGAL; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117
Usability,simpl,simple,"Checkout the small_fixes branch please, I hope the problem is ""that"" simple as I will not debug that function any further because it has the world record for nested loops. If it does not work you will have to hope for help from the turbo folks.; ```c++; for (iMarker = 0; iMarker < nMarker; iMarker++){; for (iMarkerTP=1; iMarkerTP < config->GetnMarker_Turbomachinery()+1; iMarkerTP++){; if (config->GetMarker_All_Turbomachinery(iMarker) == iMarkerTP){; if (config->GetMarker_All_TurbomachineryFlag(iMarker) == marker_flag){; for (iVertex = 0; iVertex < nVertex[iMarker]; iVertex++) {; iPoint = vertex[iMarker][iVertex]->GetNode();; for (jMarker = 0; jMarker < nMarker; jMarker++){; if (config->GetMarker_All_KindBC(jMarker) == PERIODIC_BOUNDARY) {; PeriodicBoundary = config->GetMarker_All_PerBound(jMarker);; jVertex = nodes->GetVertex(iPoint, jMarker);; if ((jVertex != -1) && (PeriodicBoundary == (val_iZone + 1))){; coord = nodes->GetCoord(iPoint);; switch (config->GetKind_TurboMachinery(val_iZone)){; case CENTRIFUGAL; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1219#issuecomment-790064117
Modifiability,config,config,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272
Testability,test,test,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272
Usability,simpl,simple,"OK the failing regression test were due to:; 1. One simple wrong function call in Csolver; 2. Creating new output in existing groups (AERO_COEFF, FLOW_COEFF) which invalidates some regression tests; 3. pyhton code which does not test if some config variable is present or altering the python code such that it invalidates other regression tests; 4. and finally the AVG_TEMP thing above. Now all these alone were somewhat minor things. Feature_flamelet is now up-to-date with develop with all regression test working",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1223#issuecomment-898617272
Testability,test,test,"Thank you for the changes.; I would say a test case is always welcome. You can simply modify an existing one, this feature is orthogonal to everything else, and then please add the new options to the config_template (with maybe the nice explanation you have in CConfig).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781
Usability,simpl,simply,"Thank you for the changes.; I would say a test case is always welcome. You can simply modify an existing one, this feature is orthogonal to everything else, and then please add the new options to the config_template (with maybe the nice explanation you have in CConfig).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-800292781
Testability,test,tests,"Ah! Cool, sure open a new PR @maxaehle.; What adjoint stuff? file names and so on?; I think removing irrelevant options would be make the tests clearer, there are lots with Roe and JST options specified and vice versa which probably confuses new users.; I'm not so sure about removing all defaults thought... On one hand it would serve as regression for the default values set by CConfig, on the other it hides the tuning parameters of some methods... but then again those are more or less documented now.; :shrug:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589
Usability,clear,clearer,"Ah! Cool, sure open a new PR @maxaehle.; What adjoint stuff? file names and so on?; I think removing irrelevant options would be make the tests clearer, there are lots with Roe and JST options specified and vice versa which probably confuses new users.; I'm not so sure about removing all defaults thought... On one hand it would serve as regression for the default values set by CConfig, on the other it hides the tuning parameters of some methods... but then again those are more or less documented now.; :shrug:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1236#issuecomment-804035589
Usability,guid,guidelines,"> the ""modern C++"" way is to use enum class and to never rely on implicit conversions from enum to integer type. I am in. It is a little (actually quite a bit) more involved as the enum namespace has to be given now everywhere an entry is used.; I was not familiar with `enum` vs `enum class` if someone else needs an entry point [stack overflow](https://stackoverflow.com/questions/18335861/why-is-enum-class-preferred-over-plain-enum), [playin around in compiler explorer](https://gcc.godbolt.org/z/5YTd4dPoE)... oh and of course the [c++ core guidelines entry endorses the use of enum class as well](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Renum-class)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1242#issuecomment-805108781
Safety,detect,detects,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886
Testability,log,logic,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886
Usability,simpl,simple,"You could modify `CWindowedAverage::addValue` to only ""push back"" more values if it detects a change in current time iteration, otherwise it simple overwrites the last value in the history.; Then you could get rid of the entire logic in `SetUpdate_Averages` simply making it true or false (less logic is the way for less bugs).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-817952886
Deployability,update,update,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992
Testability,log,logic,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992
Usability,simpl,simpler,"Hi Pedro, thanks for the idea to update the windowing directly! I've updated addValue such that the values are added for new time only (replaces existing values if it is still the same time iteration). This is a lot simpler and very happy to remove the convoluted logic. The SetUpdate_Averages was still necessary though to pass the regression test for unsteady_cylinder_windowed_average.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1259#issuecomment-819111992
Availability,avail,available,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416
Modifiability,refactor,refactoring,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416
Performance,optimiz,optimization,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416
Usability,simpl,simply,"There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; (talking does not go very far). If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818786416
Availability,avail,available,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696
Deployability,update,updates,"e more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each operating point) have in common. There would be no need to initialise the entire `SU2_CFD` machinery for this step, or to apply the design update separately for each of the SU2 instances.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696
Modifiability,refactor,refactoring,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696
Performance,optimiz,optimization,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696
Usability,simpl,simply,"> There was a lot of talk about refactoring the shape optimization framework to be able to work completely in memory.; > I think the idea was not to have more drivers but simply to have more granularity such that you could manipulate the geometry from python (without writing it to files).; > We also wanted introspection, i.e. you could probe SU2 via python for what variables and functions are available.; > We also talked about having the projection step (DOT) included in CFD_AD so that you only need to worry about surface sensitivities, note that DEF is already part of CFD for forward mode AD.; > (talking does not go very far); > ; > If you want to lead this work, we can help you understand the inner workings. We meet every Wednesday at 4pm CET https://meet.jit.si/SU2_DevMeeting to discuss this type of issue. Thank you for the quick reply. The discussions you mention sound very promising, I would be glad to join tomorrow afternoon and learn more, so that I might contribute. One quick remark: I am aware that it is indeed possible to deform the mesh within `SU2_CFD`, I use this extensively for static aero-elastic analysis. However, I have not been able to have the deformed mesh be written to file at output (in SU2 or CGNS format). This is fine for aero-elastic updates (movement of the surface due to _structural displacements_), where it is sufficient to see the deformed mesh in the post-processing files. It becomes impractical though, for design updates (movement of the surface to due to _design displacements_, i.e. representing changes in the design variables) where the new mesh is a useful intermediate result. Even if this is just an issue in my configuration file, I think that a stand-alone driver or equivalent of `SU2_DEF` would remain useful. For each new set of updated design variables during shape optimisation, a single mesh deformation is sufficient to provide the new, updated jig geometry which all of the aerodynamic or aero-elastic analyses (one for each oper",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1262#issuecomment-818839696
Modifiability,variab,variables,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354
Performance,optimiz,optimization,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354
Usability,simpl,simple,"I am a little partial because I wrote it, but this https://github.com/su2code/FADO should do any kind of optimization you want.; Multiple operating points, manipulations of variables, running everything simultaneously... But I guess for something simple it is a little more work to setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1279#issuecomment-833754354
Deployability,update,updates,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541
Performance,perform,performing,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541
Usability,feedback,feedback,"Hello @pcarruscag @TobiKattmann and SU2 developers,. We have been busy making several code updates, performing cleanup, etc. for this PR. Can you please review and provide feedback when you get the chance? Thank you in advance!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1061224541
Availability,down,down,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827
Energy Efficiency,efficient,efficient,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827
Integrability,interface,interface,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827
Security,access,access,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827
Usability,clear,clearer,"I'll try to break down each request to make it clearer. Request: Use nomenclature consistent with the C++ interface (point instead of node, etc.); Reason: People who know the C++ interface will know how to use the python wrapper straight away, people who learn how to use the python wrapper will be able to understand the C++ implementation (without needing a translation layer in their mind all the time). Request: Return connectivity/adjacency as local indices instead of global; Reason: This is the natural way of referencing data in an MPI code, local indices correspond directly to data stored in the partition thereby making it more efficient to access (without global-to-local conversions, which are much more expensive than local-to-global). Furthermore, the local ordering strategy improves the efficiency of loops (over edges, neighboring points, etc.). Request: Do not apply unnecessary ""transformations"" to the connectivity/adjacency as part of the API; Reason: Increases the maintenance burden and makes for a less versatile API. By returning the local indices that form a marker or element, it is trivial to retrieve any other data for those indices (the ""transformation""). For example, the solution at those points, the point coordinates, whether the points are halo or domain points, the global indices, etc.; This way, by adding a **single** function to the API e.g. get the global index of a point of element, the functionality of the API grows a lot more because the user can apply the function to **any** connectivity/adjacency function. Request: Do not offer too many overloads of the same function; Reason: Increases the maintenance burden and it's returning the data in structures that are not very efficient, namely vector of vectors. It is much easier to offer domain-wide data access on the python side, as a very small function that can be part of wrapper utilities (i.e. live only in python but not c++). It may even be more efficient since you make a numpy array/matrix in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1300#issuecomment-1402197827
Availability,avail,available,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695
Integrability,wrap,wrapper,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695
Usability,resume,resume,"I haven't looked at the python wrapper in detail, we had previously tracked several properties which are not available in the conventional convergence tracker (such as Cmy) and used the stop file to obtain the data when appropriate. We have considered increasing the save frequency, but there are several files which are not created at every save point; thereby forcing each ""standard"" run to become a ""run to nearest save"" then ""resume for 1 time-step to get the actual output data"". As the decomposition and some of the file writes take a significant amount of time, it is a non-starter for commercial applications. We would switch back to v6 (which had the capability) but we need some of the other features in v7. I'll take a look at the python wrapper. Thank you for your candor.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1304#issuecomment-862344695
Usability,clear,clear,"Ok, so to be clear, if you take a fresh directory, place the restart file there and run the code, will it still have this issue?; It sounds like this does not have anything to do with writing, but reading instead... :thinking:",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1342#issuecomment-891991181
Testability,test,test,> Mpi4 is not compatible with the version of pastix we support.; > And you have to compile scotch and pastix according to the instructions in TestCases/pastix_support/ before compiling SU2. Thanks for the clarification! I use Mpi4 for most of my programs so that's why I built it that way. I followed this guide for pastix: https://solverstack.gitlabpages.inria.fr/pastix/md_docs_doxygen_chapters_Pastix_Runtime.html. So I build pastix 6.X.X. I will check the test cases directory though for the instructions. Also how does changing openmpi change c++ command line option ? . Thanks 😊,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291
Usability,guid,guide,> Mpi4 is not compatible with the version of pastix we support.; > And you have to compile scotch and pastix according to the instructions in TestCases/pastix_support/ before compiling SU2. Thanks for the clarification! I use Mpi4 for most of my programs so that's why I built it that way. I followed this guide for pastix: https://solverstack.gitlabpages.inria.fr/pastix/md_docs_doxygen_chapters_Pastix_Runtime.html. So I build pastix 6.X.X. I will check the test cases directory though for the instructions. Also how does changing openmpi change c++ command line option ? . Thanks 😊,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-894838291
Usability,simpl,simple,I'm glad you made it work. Like I said it's not needed for simple tutorials.; The general conditions in which you may find it useful are described here: https://su2code.github.io/docs_v7/Linear-Solvers-and-Preconditioners/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1349#issuecomment-895948814
Deployability,update,update,"> Thank you for updating the solution file @snow54 , there's quite a big difference in the adjoint residuals, do the final derivatives still make sense? Is the flow field noticeably different (for the better, e.g. smoother? or equivalent to not having the boundary at all?) now that nearfield is treated as an internal boundary?; > If so let's update the residuals and merge. I think we can update the residuals. Gradients between adjoint and finite difference match quite well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618
Modifiability,variab,variables,"> Thank you for updating the solution file @snow54 , there's quite a big difference in the adjoint residuals, do the final derivatives still make sense? Is the flow field noticeably different (for the better, e.g. smoother? or equivalent to not having the boundary at all?) now that nearfield is treated as an internal boundary?; > If so let's update the residuals and merge. I think we can update the residuals. Gradients between adjoint and finite difference match quite well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618
Testability,test,test,"te well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issue with VENKATAKRISHNAN_WANG limiter. It seems to be much easier for convergence than VAN_ALBADA_EDGE, so it is fairly useful. I still have a gradient un-match issue with my bigger mesh but I believe it is coming from something else. > I'm sorry that you had to spend time fixing that MPI code... But at least we found out we could clean all this obsolete code. Yeah, I noticed it had been deleted. It's OK. It was still a good opportunity for me to learn how MPI works.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618
Usability,learn,learn,"te well as shown below. I haven't finished calculating for all design variables, but I think it is enough. ![Comparison_gradient](https://user-images.githubusercontent.com/18245846/129564585-d7812108-d315-4606-83d9-e39a8c9403b3.png). In terms of flow field, the capture below is from the current develop branch. The boundary between structured grid and unstructured gird is a nearfield boundary. An object is above this capture and pressure wave propagates from there. Since this grid is inclined by Mach angle, pressure distribution on the nearfield should be fairly similar to the region above but this capture shows some strange pressure disturbance. Limiter: VAN_ALBADA_EDGE; ![NF_before](https://user-images.githubusercontent.com/18245846/129564639-030fe1b7-7e50-4bb1-9951-21f5ea27bb52.png). Limiter: VENKATAKRISHNAN_WANG; ![NF_before_VEN](https://user-images.githubusercontent.com/18245846/129568934-137681db-04db-40f1-819f-7bcc8c7e0d88.png). The capture below is from the branch with this PR. The issue I mentioned above does not exist. Limiter: VAN_ALBADA_EDGE; ![NF_after](https://user-images.githubusercontent.com/18245846/129564659-cec5a848-1b0b-4051-8298-e3d383dacc6d.png). I think the residuals for direct solver will be different like the adjoint if you run it for some hundreds more iterations (currently, the test case has only 20 iterations). However, since the nearfield boundary is a bit far from an object, it takes some iterations for pressure waves to reach the nearfield boundary. This PR also solves an issue with VENKATAKRISHNAN_WANG limiter. It seems to be much easier for convergence than VAN_ALBADA_EDGE, so it is fairly useful. I still have a gradient un-match issue with my bigger mesh but I believe it is coming from something else. > I'm sorry that you had to spend time fixing that MPI code... But at least we found out we could clean all this obsolete code. Yeah, I noticed it had been deleted. It's OK. It was still a good opportunity for me to learn how MPI works.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1351#issuecomment-899498618
Modifiability,config,config,"Let's continue this here @suargi as it should be more visible for everyone. In principle, I like what you suggest, it is clean and concise.; However, I see one big issue with backwards compatibility of the config. KIND_TURB_MODEL is in almost every config (in the world) and we cannot simply break compatibility, something with this much impact would require SU2 v8 :smile: . This is not to say you could not implement what you propose, just that you need to make it compatible with the status quo.; For example:; KIND_TURB_MODEL= SA-NEQ; QCR= YES; (I'm not even sure if that makes sense but anyway); Needs to be converted internally to:; KIND_TURB_MODEL= SA; TURB_MODEL_CORRECTIONS= SA-NEG, SA-QCR2000. And of course, if someone uses the new option TURB_MODEL_CORRECTIONS you can enforce that KIND_TURB_MODEL only contains NONE, or SA, or SST, and that corrections do not appear in the config in any other way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593
Usability,simpl,simply,"Let's continue this here @suargi as it should be more visible for everyone. In principle, I like what you suggest, it is clean and concise.; However, I see one big issue with backwards compatibility of the config. KIND_TURB_MODEL is in almost every config (in the world) and we cannot simply break compatibility, something with this much impact would require SU2 v8 :smile: . This is not to say you could not implement what you propose, just that you need to make it compatible with the status quo.; For example:; KIND_TURB_MODEL= SA-NEQ; QCR= YES; (I'm not even sure if that makes sense but anyway); Needs to be converted internally to:; KIND_TURB_MODEL= SA; TURB_MODEL_CORRECTIONS= SA-NEG, SA-QCR2000. And of course, if someone uses the new option TURB_MODEL_CORRECTIONS you can enforce that KIND_TURB_MODEL only contains NONE, or SA, or SST, and that corrections do not appear in the config in any other way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1364#issuecomment-907388593
Energy Efficiency,energy,energy,"I just ran the case and I see this as well, even after complete convergence. You clearly can see this in the energy and pressure (and density) but not in the momentum terms. The temperature field also looks smooth. So may be related to density/pressure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910
Usability,clear,clearly,"I just ran the case and I see this as well, even after complete convergence. You clearly can see this in the energy and pressure (and density) but not in the momentum terms. The temperature field also looks smooth. So may be related to density/pressure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-932510910
Usability,simpl,simple,"Just my 2¢ here. I've been struggling with a relatively simple simulation, Euler, 2D axisymmetric, supersonic, AUSM (SU2 7.5.1). I tried several meshes (and meshers) and always diverged no matter what (quality is ok, CFL as well). Conditions were ok, and were mimicking inv_wedge tutorial (which, btw was running ok even with axisymmetry ON). Long story short, I opened with a text editor the original geometry STEP file, and noticed it was carrying from the CAD some (engineering wise negligible) numerical terms (say, point 0, 0 was actually 0, 1e-6). Hence the symmetry axis was somewhat off. By correcting the STEP file, everything went fine. I wonder whether this is the expected behavior of this kind of simulation, and / or if there is any artificial diffusion parameter (such as ENTROPY_FIX_COEFF) that actually can sort things out for the EULER mode. Did any of you experienced anything similar?. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1373#issuecomment-1464335191
Usability,simpl,simpler,"Have a look at my last comment in #763, I think there is a better way of handling linear system periodicity instead of what we do, which may allow you to run at higher CFL (and with simpler periodic comms). But at the moment you are missing the PERIODIC_IMPLICIT comms after solving the linear system, see CompleteImplicitIteration_impl in CFVMFlowSolverBase.hpp.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1382#issuecomment-927138184
Usability,simpl,simpler,"Thanks @pcarruscag , I had to do a few additional things together with the PERIODIC_IMPLICIT communication to make it work, but that also brought me on the right track 👍 Now it works really nicely from my point of view. > Have a look at my last comment in #763, I think there is a better way of handling linear system periodicity instead of what we do, which may allow you to run at higher CFL (and with simpler periodic comms). I need to have a second look at this. So non of your thoughts back then are yet incorporated in this PR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1382#issuecomment-927303571
Availability,redundant,redundant,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Energy Efficiency,adapt,adapted,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Modifiability,adapt,adapted,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Safety,redund,redundant,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Security,validat,validation,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Testability,test,testcase,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Usability,simpl,simple,"Todo list:; - [x] Make sure the code can handle arbitrary many species equtions. Especially the output has to be adapted. Note the MAXNVAR of the ScalarSolver has to adapted to that need as well. Make a suitable Testcase for that.; - [x] Implement weak inlet and outlet BC. The weak approach is used in the turb and mean flow and is most likely conservative opposed to the strong one. Here a simple switch will be put in place to compare both versions.; - [x] Consolidate nVar, nSpecies, ... variable to only use 1 consistently (The choice was `nSpecies` which was already introduced for NEMO and it just makes sense to use the same container); - [x] Make the numerous reviewers happy; - [x] Check inlet profiles for Species solver (have a testcase for that) See #1427 ; - [x] Create Objective functions of Surface avg quantities (Area and Massflow? prob. And a variance-style output to capture mixing); - [x] Avoid redundant operations (pre/post processings) during solver restarts. 156d0c5. What will be done in follow-up PR's:; - Viscous contributions for BC_inlet and outlet which are currently not used (also then for Turb-solver) https://github.com/su2code/SU2/pull/1388#discussion_r752384956; - Axissymmetric source term addtion and testing; - multi-component mixing from #1332 ; - gradient validation between DA and FD",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1388#issuecomment-935901996
Modifiability,variab,variable,"Both ‘**rapidjson**’ and ‘**CoolProp**’ are licensed under the shortest and simplest permissive **MIT** license. I am not an expert but whether indicating the text of the licenses and copyright marks at the beginning of each of my files is reasonable?. Honestly, I don’t like the idea to treat **rapidjson** as a git submodule because some **rapidjson** internals are Windows specific (e.g., _/include/rapidjson/msinttypes_ subfolder content) and I don’t really confident with Meson build setup procedure. . Actually, I generated the **all_cubics_extended_JSON_binary** variable in the following way.; **CoolProp** library contains dozens of json files from which I assembled the single file for my own needs. Then, I made some modifications to the _generate_headers.py_ file (under _/dev_ subfolder of the **CoolProp** root) and run it in order to translate my large json file into the C++ header file. The generated file is not as large (~1.3 MB) as it seems but verbose a little bit. Could you clarify what **tecplot** sources do you mean?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879
Usability,simpl,simplest,"Both ‘**rapidjson**’ and ‘**CoolProp**’ are licensed under the shortest and simplest permissive **MIT** license. I am not an expert but whether indicating the text of the licenses and copyright marks at the beginning of each of my files is reasonable?. Honestly, I don’t like the idea to treat **rapidjson** as a git submodule because some **rapidjson** internals are Windows specific (e.g., _/include/rapidjson/msinttypes_ subfolder content) and I don’t really confident with Meson build setup procedure. . Actually, I generated the **all_cubics_extended_JSON_binary** variable in the following way.; **CoolProp** library contains dozens of json files from which I assembled the single file for my own needs. Then, I made some modifications to the _generate_headers.py_ file (under _/dev_ subfolder of the **CoolProp** root) and run it in order to translate my large json file into the C++ header file. The generated file is not as large (~1.3 MB) as it seems but verbose a little bit. Could you clarify what **tecplot** sources do you mean?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1402#issuecomment-942054879
Usability,simpl,simpler,"There is no automatic way of doing that. If you want a simpler code to port to GPU, the best advice I can give you is to chose something else other than SU2. In the future please open ""discussions"" instead of issues, these are not SU2 code issues.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1407#issuecomment-947489209
Availability,robust,robust,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509
Integrability,interface,interface,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509
Modifiability,coupling,coupling,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509
Security,expose,exposed,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509
Usability,simpl,simplest,"As we mentioned in the dev meeting where you exposed the problem, the implementation is not good for strongly coupled flows, and I would guess that it is worse for diffusion than convection (because diffusion is elliptic).; I suspect the main problem is that the linear system does not contain information from the other side of the interface, meaning the solution of the two domains is effectively decoupled.; You could try running the case at much lower CFL (below 1) even with an explicit method.; It is also possible that the current treatment could be improved, since it is an example of multiplicative Schwartz decomposition, maybe there is an ""optimal"" way of implementing that from a physics point of view. Just speculating here, but maybe it would help treating the interface as an outlet if flow is going out, and as an inlet if flow is coming in.; On the numerics side, you can also try hacking the MZ driver to use something more stable than block-Gauss-Seidel (e.g. some quasi-Newton thing for the interface). But those are all band-aids IMO, if you want a robust fluid-fluid interface you need the coupling to be present in the linear system. The simplest way to do that is to have an internal boundary and treat the problem as single zone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-951848509
Modifiability,coupling,coupling,"Thanks Pedro for hinting me at this coupling issue again, now I think I understand it! . **For the record**, here is what I talked about in today's developer meeting:; When I make the following changes in the `issue_simplified/multizone/multizone-i.cfg` :. 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULER_IMPLICIT. then the simplified multizone setup converges, albeit to a different solution:; ![simplified-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096529-5063dbe7-8ee8-4c53-a7c6-a2b6b3a031a1.png); than what the simplified singlezone setup (from above) converged to: ; ![simplified-singlezone-density](https://user-images.githubusercontent.com/72806890/139096586-7d096c5f-4d34-4ddb-94fa-0deab52df5e4.png). The same observation can be made analogously for `issue_complicated`:; The multizone setup with explicit Euler and CFL=0.1 (nearly) converges (actually the residual stalls at `avg[bgs][0]` approximately -13) to the following limit:; ![complicated-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096973-e9547f9f-521e-4920-aba5-2621fad79944.png); while the singlezone solution (with implicit Euler and CFL 1000) is (**EDIT**: was momentum plot, replaced by density plot); ![complicated-singlezone-density](https://user-images.githubusercontent.com/72806890/139109790-e5cae4be-041e-4c29-93a5-e086a26f72a4.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430
Usability,simpl,simplified,"Thanks Pedro for hinting me at this coupling issue again, now I think I understand it! . **For the record**, here is what I talked about in today's developer meeting:; When I make the following changes in the `issue_simplified/multizone/multizone-i.cfg` :. 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULER_IMPLICIT. then the simplified multizone setup converges, albeit to a different solution:; ![simplified-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096529-5063dbe7-8ee8-4c53-a7c6-a2b6b3a031a1.png); than what the simplified singlezone setup (from above) converged to: ; ![simplified-singlezone-density](https://user-images.githubusercontent.com/72806890/139096586-7d096c5f-4d34-4ddb-94fa-0deab52df5e4.png). The same observation can be made analogously for `issue_complicated`:; The multizone setup with explicit Euler and CFL=0.1 (nearly) converges (actually the residual stalls at `avg[bgs][0]` approximately -13) to the following limit:; ![complicated-multizone-explicit-cfl01-density](https://user-images.githubusercontent.com/72806890/139096973-e9547f9f-521e-4920-aba5-2621fad79944.png); while the singlezone solution (with implicit Euler and CFL 1000) is (**EDIT**: was momentum plot, replaced by density plot); ![complicated-singlezone-density](https://user-images.githubusercontent.com/72806890/139109790-e5cae4be-041e-4c29-93a5-e086a26f72a4.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-953043430
Integrability,interface,interface,"---------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` singlezone explicit Euler CFL=0.1; ![tke-simplified-singlezone-expliciteuler](https://user-images.githubusercontent.com/72806890/140887289-0d8725a2-e51b-4704-bdae-a51b492949bf.png); (it is ""red"" throughout the domain, except for the wall marker); - `issue_simplified` multizone explicit Euler CFL=0.1: (similar image, ""red"" everywhere except wall). **Thus, the difference in solutions observed above is due to the choice of implicit vs. explicit Euler and CFL, and not due to problems regarding the interface.**. Am I doing something wrong in the explicit Euler [cfg file](https://seafile.rlp.net/d/bb0fbb16eb414263b642/files/?p=%2Fsinglezone-simplfied-expliciteuler-cfl01.cfg&dl=1), whose diff to the [SU2/TestCases/rans/naca0012/turb_NACA0012_sst.cfg](https://github.com/su2code/SU2/blob/v7.2.0/TestCases/rans/naca0012/turb_NACA0012_sst.cfg) is as follows?. 27c27; < RESTART_SOL= NO; ---; > RESTART_SOL= YES; 45c45; < REYNOLDS_NUMBER= 1.0E6; ---; > REYNOLDS_NUMBER= 6.0E6; 70c70; < MARKER_HEATFLUX= ( circle, 0.0 ); ---; > MARKER_HEATFLUX= ( airfoil, 0.0 ); 76c76; < MARKER_PLOTTING= ( circle ); ---; > MARKER_PLOTTING= ( airfoil ); 79c79; < MARKER_MONITORING= ( circle ); ---; > MARKER_MONITORING= ( airfoil ); 88c88; < CFL_NUMBER= 0.1; ---; > CFL_NUMBER= 1000.0; 101c101; < ITER= 9999900; ---; > ITER= 99999; 162c162; < TIME_DISCRE_FLOW= EULER_EXPLICIT; ---; > TIME_DISCRE_FLOW= EULER_IMPLICIT; 177c177; < TIME_DISCRE_TURB= EULER_EXPLICIT; ---; > TIME_DISCRE_TURB= EULE",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195
Usability,simpl,simplified-singlezone-expliciteuler-density,"> I assume that your results with explicit/implicit Euler for single zone are the same?. It turns out that they are not. When I applied the above modifications (CFL: 1000 -> 0.1, TIME_DISCRE_*: EULER_IMPLICIT->EULER_EXPLICIT; additionally I had to increase ITER) to the `issue_simplified` singlezone setup (the one with AoA=10°), I obtain the following solution:. ![simplified-singlezone-expliciteuler-density](https://user-images.githubusercontent.com/72806890/140885244-abb72de1-0d2d-4dc8-bde9-e0772786e2cd.png). with the following convergence history:. +------------------------------------------------------------------------------------------+; | Inner_Iter| rms[Rho]| rms[k]| rms[w]| CL| CD| LinSolRes|; +------------------------------------------------------------------------------------------+; | 0| -3.131336| -inf| -inf| 0.000000| 2.232692| -inf|; | 1| -3.281025| -inf| -inf| 0.000000| 3.198384| -inf|; ...; | 9531740| -11.999999| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531741| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; | 9531742| -12.000000| -inf| -inf| -0.006045| 1.258662| -inf|; ; ----------------------------- Solver Exit -------------------------------; All convergence criteria satisfied.; +-----------------------------------------------------------------------+; | Convergence Field | Value | Criterion | Converged |; +-----------------------------------------------------------------------+; | rms[Rho]| -12| < -12| Yes|; +-----------------------------------------------------------------------+. The density plot is; - different from the original `issue_simplified` singlezone solution with implicit Euler and CFL=1000. ; - similar to the `issue_simplified` multizone solution with implicit Euler and CFL=0.1. . Similarly, the TKE plots:; - `issue_simplified` singlezone implicit Euler CFL=1000; ![tke-simplified-singlezone-impliciteuler](https://user-images.githubusercontent.com/72806890/140887227-fc2ed584-53cf-413d-b5ad-18d1a12f5e4a.png); - `issue_simplified` s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1414#issuecomment-963921195
Availability,error,errors,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015
Testability,test,test,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015
Usability,simpl,simpler,"@AmauryBilocq Thanks for your post. Can you please check that you are actually not running out of memory, as that can also raise such errors? Second, if Giles BC is the issue I think you will still be able to run the case with Riemann which is a bit simpler than Giles. Can you also test that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1429#issuecomment-1025177015
Usability,simpl,simple,"Hi, please attach the exact files you are using, and commands you are running, to the discussion you already opened. That will make it easier for someone to help.; The best way to get help from a developer is to make it very simple to replicate the problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1458#issuecomment-984084597
Deployability,release,released,"Sorry for the late reply! Thanks for all the help, and i am afraid i am using a 7.2.0 version and the newly released version 7.2.1 remains the same code. The problem is just lying on ""delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);"" which is also in @TobiKattmann 's code post(thanks for your kind guidance ).; In deed, this part of code should give the credit to @EduardoMolina, and the function is a part of his doctoral thesis(2018) which i just couldnot found a link or doi of. But in this paper(https://www.researchgate.net/publication/318143234; ), he gives the official definition as below without the implementation in above picture.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816
Usability,guid,guidance,"Sorry for the late reply! Thanks for all the help, and i am afraid i am using a 7.2.0 version and the newly released version 7.2.1 remains the same code. The problem is just lying on ""delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);"" which is also in @TobiKattmann 's code post(thanks for your kind guidance ).; In deed, this part of code should give the credit to @EduardoMolina, and the function is a part of his doctoral thesis(2018) which i just couldnot found a link or doi of. But in this paper(https://www.researchgate.net/publication/318143234; ), he gives the official definition as below without the implementation in above picture.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-986239816
Testability,test,test,"Thanks for the suggestion and I am preparing for a test.; As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition.; @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; ```; for (auto iDim = 0u; iDim < nDim; iDim++){; delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; }; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348
Usability,guid,guidance,"Thanks for the suggestion and I am preparing for a test.; As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition.; @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; ```; for (auto iDim = 0u; iDim < nDim; iDim++){; delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; }; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-988581348
Testability,test,test,"> Thanks for the suggestion and I am preparing for a test. As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition. @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; > ; > ```; > for (auto iDim = 0u; iDim < nDim; iDim++){; > delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; > }; > ```. Hi Shihe,. I checked the implementation and I think it is correctly done. You do need the absolute value (i.e., delta has a unit of [m] or equivalent) to keep the correct dimension of nu_t based on a Smagorinsky-type SGS model. You may find the appendix of this paper useful for your understanding of delta_omg: [https://doi.org/10.1007/s00162-011-0240-z](https://doi.org/10.1007/s00162-011-0240-z). Also note that delta_omg does not always outperforms its peers - vorticity may not be aligned to the rotation axis of a local vortex (e.g., in rotating reference frame, in attached boundary layer, to name a few), in which case the physical meaning of delta_omg becomes vague. See also my work for a brief review of DES-type methods and some applications: [https://doi.org/10.1115/1.4052019](https://doi.org/10.1115/1.4052019)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976
Usability,guid,guidance,"> Thanks for the suggestion and I am preparing for a test. As far as I understand it, I just find that to get the absolute value of r_ij ( showed in the highest equation) in this part of code is unnecessary. The cross-product operation is to find the grid vector mostly parallel to the vorticity vector and the absolute value may cause a nonphysical recognition. @EduardoMolina, I don't know if I got it wrong and wish more guidance,.; > ; > ```; > for (auto iDim = 0u; iDim < nDim; iDim++){; > delta[iDim] = fabs(coord_j[iDim] - coord_i[iDim]);; > }; > ```. Hi Shihe,. I checked the implementation and I think it is correctly done. You do need the absolute value (i.e., delta has a unit of [m] or equivalent) to keep the correct dimension of nu_t based on a Smagorinsky-type SGS model. You may find the appendix of this paper useful for your understanding of delta_omg: [https://doi.org/10.1007/s00162-011-0240-z](https://doi.org/10.1007/s00162-011-0240-z). Also note that delta_omg does not always outperforms its peers - vorticity may not be aligned to the rotation axis of a local vortex (e.g., in rotating reference frame, in attached boundary layer, to name a few), in which case the physical meaning of delta_omg becomes vague. See also my work for a brief review of DES-type methods and some applications: [https://doi.org/10.1115/1.4052019](https://doi.org/10.1115/1.4052019)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1462#issuecomment-990220976
Availability,avail,availability,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868
Modifiability,extend,extend,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868
Usability,simpl,simplest,"Simplest is to just copy the saved file again, with an iteration number appended. No keeping track of what the iteration number at the previous write was, no copying of the final saved file with manually appending the final iteration number, no lag of WRT_FREQ in the availability of the restart_xxx.dat file. It does mean that we do a copy instead of a rename. But I think this is the better (because the simplest) solution. I will extend it to the other file options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1465#issuecomment-1005529868
Availability,robust,robust,"Hi Jean,; Sorry for the delay. The hypothesis I have for the less robust behavior of periodic BC's is that the linear solver is not completely aware of the periodicity. In fact after the linear solve we have to force the matching nodes to have the same value.; This is done in CFVMFlowSolverBase.hpp::CompleteImplicitIteration_impl, in the call to InitiatePeriodicComms.; The idea is to make the linear solver aware of the periodicity, to do so would require including periodic communications in the preconditioners and the matrix-vector product.; These are all in CSysMatrix.cpp, so before each of the `/*--- MPI Parallelization ---*/` bits we would need periodic comms, for preconditioners these comms would simply make the values equal, like in CSolver::InitiatePeriodicComms(PERIODIC_IMPLICIT) whereas for the matrix-vector product we need to add the values (effectively periodicity splits a row of the matrix into two ""half rows"") and this would be similar to what is done with the linear residual in CSolver::InitiatePeriodicComms(PERIODIC_RESIDUAL).; I think @TobiKattmann was also interested in having a look into this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248
Usability,simpl,simply,"Hi Jean,; Sorry for the delay. The hypothesis I have for the less robust behavior of periodic BC's is that the linear solver is not completely aware of the periodicity. In fact after the linear solve we have to force the matching nodes to have the same value.; This is done in CFVMFlowSolverBase.hpp::CompleteImplicitIteration_impl, in the call to InitiatePeriodicComms.; The idea is to make the linear solver aware of the periodicity, to do so would require including periodic communications in the preconditioners and the matrix-vector product.; These are all in CSysMatrix.cpp, so before each of the `/*--- MPI Parallelization ---*/` bits we would need periodic comms, for preconditioners these comms would simply make the values equal, like in CSolver::InitiatePeriodicComms(PERIODIC_IMPLICIT) whereas for the matrix-vector product we need to add the values (effectively periodicity splits a row of the matrix into two ""half rows"") and this would be similar to what is done with the linear residual in CSolver::InitiatePeriodicComms(PERIODIC_RESIDUAL).; I think @TobiKattmann was also interested in having a look into this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1467#issuecomment-1017640248
Modifiability,variab,variables,"I checked and I could not find a place in the code where this option is used explicitly. Since all the drivers split between primary recording for state variables and secondary recording for geometry variables for efficiency. My own use case was for research I did, where I needed to record a tape w.r.t. to both. Since this is not ready to become a pull request any time soon, I do not really need this option. If you suggest I can create a commit to remove the enum option for simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237
Usability,simpl,simplicity,"I checked and I could not find a place in the code where this option is used explicitly. Since all the drivers split between primary recording for state variables and secondary recording for geometry variables for efficiency. My own use case was for research I did, where I needed to record a tape w.r.t. to both. Since this is not ready to become a pull request any time soon, I do not really need this option. If you suggest I can create a commit to remove the enum option for simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1492#issuecomment-1012241237
Integrability,wrap,wrap,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577
Testability,test,testcase,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577
Usability,usab,usability,"Hi Sun5k,; Thanks for tackling the Transition models. As far as I see, you are adopting the CScalarSolver-Base style just as is done for the Turbulence or SpeciesTransport solver (cf #1330 #1388 ) :+1: I think you can stay close to how things are handled in these solvers. The Turbulence solver has another class in the middle though: `CScalarSolver -> CTurbSolver -> CTurbSST/SASolver` I am not sure whether sth like this makes sense for transition models? (because I have no clue of Transition models). Otherwise the CSpeciesSolver is directly based on the CScalarSolver. Please limit this PR to 1 model only! So in this case just the LM model maybe. It is much easier for you to wrap this PR up with a limited scope instead of trying to do everything at once :) (and it is easier to review for everyone else) In case you then still want to tackle another one once LM is done :D then just open another PR :+1:; ; As unfinished Transition models (or models with a questionable state) are a bit of a companion of SU2 I would also ask you to provide a meaningful testcase with this PR that proves the usability of this feature. I personally like to think of a suitable case at the beginning of development, to adopt a bit a Test-Driven-Development approach but that is of course fully up to you. In case you did not know about the Developers meeting each Wednesday 4pm Berlin time, now you do. You are kindly invited to ask any questions, just show-and-tell to get some feedback etc. it is a very open round :). Happy coding, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1016451577
Usability,clear,clear,"I'm at the beginning, so i have no really clear my path. Anyway a soon as; possible i will follow your instructions. Sorry for this difficulty, but to; me a su2 development group is something totally new and i have to clarify; some aspects with my PhD student and with my professor. Thanks for your help; Marco. Il giorno gio 20 gen 2022 alle ore 11:47 Nijso ***@***.***>; ha scritto:. > Hi! If you want to work together over github, you can also create a; > project here:; > https://github.com/su2code/SU2/projects?type=beta and define tasks and; > divide the work. It would be good if you can sort out what the overlap is; > and what the unique parts of your research will be.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/1496#issuecomment-1017354022>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AXL7TQXSL55PQIEHSDCPT4LUW7R3TANCNFSM5MC56OYQ>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1496#issuecomment-1017587516
Usability,guid,guidance,If you share the mesh I should be able to give better guidance.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1519#issuecomment-1019359579
Modifiability,variab,variable,"> Looks quite simple to me now, what do you think?. I fully agree. The CVariable footprint is much smaller and no more nasty address handling. (Adding another variable in another solver requires a bit more code though and a little understanding of what is going on than the ""Address""-version, but on the other hand this explicit handling of each primal-solver creates a good separation :+1: )",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065
Usability,simpl,simple,"> Looks quite simple to me now, what do you think?. I fully agree. The CVariable footprint is much smaller and no more nasty address handling. (Adding another variable in another solver requires a bit more code though and a little understanding of what is going on than the ""Address""-version, but on the other hand this explicit handling of each primal-solver creates a good separation :+1: )",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1536#issuecomment-1050172065
Performance,optimiz,optimization,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095
Safety,avoid,avoid,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095
Usability,simpl,simple,"Sounds like a reasonable optimization, the only other place that handles averages is `COutput::Postprocess_HistoryData`, so this should be a very local change and thus a good first issue. Do you want to give it a go at creating a pull request for this? We can give you some pointers. But it should be simple to modify the `addValue` function to take the window type as argument and only `push_back` for non trivial windows.; Even those could be optimized by caching the sum over n-1 elements, this would avoid traversing the entire history of values when only the last entry is modified during inner iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1037249095
Usability,simpl,simply,"Unfortunately, I'm still a bit unsure of the math behind the averaging. I assumed, that the average of a new iteration calculates as follows:. avg(it) = (cumulativeWeight(it-1, it+1) * avg(it-1) + Weight(it, it+1)*Value(it)) / (cumulativeWeight(it-1,it+1)+Weight(it,it+1)). Translated into words:; At iteration `it` we define a window of width `it+1`.; The previous average is weighted with the integral of the window from 0 to it-1. The new value arriving at iteration it is weighted with the actual window weight. The weighted sum is then divided by the sum of the weights. For a rectangular window this seems to converge towards the right value, but for the hanning window it does not.; Probably the math behind it is simply wrong. Any idea what the proper weighting should look like?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1545#issuecomment-1039999787
Integrability,wrap,wrapper,"If you don't mind I'll leave this question open for now.; I'm planning to provide a simplified example setup later on, once I've had time to properly dive into the wrapper API.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958
Usability,simpl,simplified,"If you don't mind I'll leave this question open for now.; I'm planning to provide a simplified example setup later on, once I've had time to properly dive into the wrapper API.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1553#issuecomment-1071052958
Deployability,configurat,configuration,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Energy Efficiency,reduce,reduced,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Modifiability,config,config,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Security,attack,attack,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Testability,test,test,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Usability,feedback,feedback,"Thank you @TobiKattmann for your feedback. The idea behind this new regression test config file is as follows:; We should have a test case that triggers the negative part of the SA model. Depending on the flow conditions, geometry and CFD parameters it might be triggered or not. With the previous config file, it was not. ; I think there is already a regression test in SU2 that triggers the negative SA, the `turb_oneram6_nk`. However, I decided to stick to rae2822 airfoil as it is a simpler (faster) case. In order to force the negative part of the SA for the rae2822 in a reasonable amount of iterations for a regression test, I increased the angle of attack. I have removed the multigrid as it might not be stable, but I have not tested though. Anyway, with the current configuration, e.g., convective scheme, CFL number, etc, the solution is not stable and diverges after some iterations, around 15. In that sense, I reduced the number of iterations from 20 to 10. In my opinion, a diverging regression test is not a problem at all as it might not be used as a tutorial, only to verify the integrity of the commit. ""The solution should always diverge to the same results"". If the regression test should converge, let me know and I will update the config file :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067926363
Energy Efficiency,adapt,adaptions,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083
Modifiability,adapt,adaptions,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083
Testability,test,testcases,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083
Usability,clear,clear,"Thanks for the explanation @suargi . I would personally advocate for that the testcases should converge to some reasonable solution people might use it as a starting point (copy the cfg and doing mild adaptions) for their own stuff. And the Testcases show off the capabilities to some degree, to do so, convergence is beneficial. But as we have a bunch of working 2D airfoils in regression already I recon that adding a clear explanation and warning to the cfg as suggested by Pedro is fine. Otherwise you might try to bisect the AoA ... maybe there is a value that triggers negative SA and does not diverge :thinking: . Knowingly adding a diverging test without a clear warning is not good imo :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1559#issuecomment-1067977083
Deployability,update,update,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672
Security,validat,validation,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672
Usability,simpl,simply,"Guys, we cannot simply change defaults like that, update regressions, and call it a day... Even fixing #1551 is a major change that should warrant a major version update. We want SU2 users to be able to rely and trust the code we release...; That is why I suggested that this PR should be used only to change the way of specifying SST options, and introduce simple ones like the V and KL modifications. Then the validation work for SST 2003 (with and w/o modification) would be done in #1557.; But ok, let me look at this and propose a way forward that gets in develop ASAP, **please don't start updating regressions**.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1560#issuecomment-1084549672
Availability,error,errors,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722
Deployability,install,installation,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722
Integrability,message,message,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722
Safety,avoid,avoid,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722
Usability,guid,guide,"> Note that you need to checkout this branch `fix_2d_periodic_rotation` (it is not in `develop` yet). Hi Pedro,; I checked the files you sent but building SU2 from source provided some errors:. - _MinGW64_ files provided from SU2 official website are corrupted and the installation crashes; however, it is possible to install the software but the .exe file mentioned in the installation guide won't be present. ; - After building _meson.py_ , the ninja installation command was line typed and the following alert message appeared "" **ninja: fatal: chdir to 'build' - No such file or directory** "". On a different laptop (with different user, to avoid the same mistakes) the following ERROR came up after the mason.py command line:; "" **'meson.py' is not recognized as an internal or external command, operable program or batch file** "". I don't know if any other user might have experienced the same errors. ; Anyway, are the bugfix files you published already available in the pre-compiled version? ; In the meanwhile, I'll try to figure out this inconvenient. Thank you in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1562#issuecomment-1069325722
Modifiability,config,config,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565
Security,validat,validated,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565
Usability,simpl,simple,"I don't think the fix is as simple as it seems.; Indeed looking back at how we developed the CGNS reader, It was originally meant to read multiple zone in a single file. But during development, someone decided to restrict the reader to only one zone per file (and I don't know if it was validated). So now we are seating in the middle. If we replace line 169 of CGNSFVMMeshReader :; <pre>; if ( nzones > 1 ) {; SU2_MPI::Error(string(""CGNS reader currently expects only 1 zone per CGNS file."") +; string(""Multizone problems can be run with separate CGNS files for each zone.""), CURRENT_FUNCTION);; }; </pre>; by; <pre>; if ( cgnsZone > nzones) {; cgnsZone = 1;; }; </pre>. we can easily support multiple zone in one file. To support one CGNS zone per file, I guess that user should provide either the index in the cgns file of the zone we want to read or even better its name and not rely on SU2 numbering of zones. I think that supporting multiple mesh zones in the same file at the same time as one zone per mesh file should be possible as long as enough information is provided by the user. In this case, I am wondering how the option MULTIZONE_MESH and MULTIZONE option are interacting in the related issue. When MULTIZONE_MESH is set to NO do we expect one mesh file per zone ?; And in this case we can force CGNS Reader to read only the first Zone. In a more generic way something like this should be possible:; MULTIZONE=YES; CONFIG_LIST= (zone_1.cfg, zone_2.cfg, zone_3.cfg); CGNSZONENAMES = (""FluidRotor"", ""Solid"", ""FluidStator"") # To let CGNS pick the right zone in the file and if it not found the first zone can be used (current SU2 behavior). CGNSZONENAMES could also be set in each config file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1566#issuecomment-1073204565
Availability,error,error,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200
Deployability,update,update,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200
Modifiability,config,config,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200
Usability,feedback,feedback,"When I enter the ""shape_optimization.py -f unsteady_naca0012_opt.cfg"" in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 116, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 34, in main; shape_optimization( options.filename ,; File ""C:\Users\74351\Desktop\SU2\SU2\bin\test2\shape_optimization.py"", line 51, in shape_optimization; config = SU2.io.Config(filename); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\io\config.py"", line 88, in __init__; super(Config,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_bunch.py"", line 83, in __init__; super(OrderedBunch,self).__init__(*args,**kwarg); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 48, in __init__; self.__update(*args, **kwds); File ""C:\Users\74351\Desktop\SU2\SU2\bin\SU2\util\ordered_dict.py"", line 174, in update; for key, value in other:; TypeError: 'NoneType' object is not iterable; ```; When I enter the ""parallel_computation.py -f turb_naca0012.cfg -n NP in the commend the error is:; ```; Traceback (most recent call last):; File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 110, in <module>; main(); File ""C:\Users\74351\Desktop\SU2\SU2\bin\parallel_computation.py"", line 53, in main; raise Exception(""No config file provided. Use -f flag""); Exception: No config file provided. Use -f flag; ```; Any solvers related to "".py"" cannot be executed, but I can run any cases with SU2_CFD. So I wonder if this situation is a problem with the Python Wrapper? . I will be very appreciated if I could get some feedback on this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1567#issuecomment-1074910200
Availability,error,error,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956
Testability,test,test,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956
Usability,simpl,simple,"> Thanks for the fast reply! I changed the hardcoded 2 (just as a remark: the hardcoded values also appear in the calculations), added myself as an author and inserted some lines for throwing an error if the issue in #1565 occurs. I did not know exactly where to put it best.; > ; > Concerning a regression test: I strongly support the idea of introducing an axisymmetric regression test. However, I was using a testcase from @bigfooted , and I never set up such a test case on my own. There do not seem to be any axisymmetric pipe setups in the Testcases folder so far. @bigfooted , could we maybe use your mesh for the jet flow test case and, if necessary, switch to a standard flow setup?. Yes, you can use that mesh. It can be used for pipe flow setup and jets with coflows, so we can reuse it in different testcases as well if needed. But any simple rectangular mesh is fine, so a mesh from the existing testcases as @pcarruscag mentions would also work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1571#issuecomment-1075656956
Deployability,install,installing-using-pip-and-virtual-environments,The primary solution in the linked issue is to use a virtualenv. I quote:. > The easiest workaround: Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528
Usability,guid,guides,The primary solution in the linked issue is to use a virtualenv. I quote:. > The easiest workaround: Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1575#issuecomment-1076307528
Modifiability,config,configure,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534
Security,validat,validation,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534
Usability,clear,clearly,"Hi @rois1995. The LM model code under the development clearly has some problems. I've not finished yet all validation cases for commonly used. So, I can't help with the E387 profile problem. but, I think I can give some helpful comments. . Check the numerical scheme which you used. like Roe and L2Roe, AUSM and SLAU. In my case, I didn't think to use the low dissipation scheme because I thought the code was wrong. I upload the configure file for the T3A flat plate case, which I used.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1592#issuecomment-1111261534
Deployability,update,updates,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640
Testability,test,test,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640
Usability,feedback,feedback,"Thanks for the feedback. . I was not able to find any examples myself either. It looks like this is a feature that has been around for a while, but maybe has gotten lost in some updates. I will work on setting up a small test case for this and the FAN_FACE_MDOT and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1607#issuecomment-1100150640
Deployability,update,updated,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000
Testability,test,tests,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000
Usability,clear,clear,The Github Actions checks passed after making two changes:. 1) https://github.com/su2code/SU2/pull/1619/commits/efe98fe6070a0cb51f1082a9599363786e4d65ea; I needed to lower the warnlevel due to problems in `externals/cgns/hdf5`.; Maybe the HDF5 files should be updated to a newer version ?! But it is not clear to me which version has been used in https://github.com/su2code/SU2/pull/1500. ; @MicK7 Do you have an idea how to fix this ?. 2) https://github.com/su2code/SU2/pull/1619/commits/26140223e5838a6856c0b3c02163a826256306b1; A workaround recommended at https://github.com/su2code/SU2/issues/1568#issuecomment-1083104460. 3) The regression tests [fail](https://github.com/su2code/SU2/runs/6387003184?check_suite_focus=true) because the new `test-su2` Docker image is `private`. I will need someone with higher privileges than me to make it public.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1619#issuecomment-1123614000
Usability,feedback,feedback,"Hi all, thank you so much for your feedback. Are there things left for this pull request? ; Thank you so much in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1620#issuecomment-1150869650
Modifiability,extend,extend,"The fix is not as simple, using the strategy from #1631 makes it worse.; Intersection with symmetry/euler look ok, so the best is to extend the domain...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976
Usability,simpl,simple,"The fix is not as simple, using the strategy from #1631 makes it worse.; Intersection with symmetry/euler look ok, so the best is to extend the domain...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1639#issuecomment-1132302976
Integrability,message,message,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832
Testability,test,testing,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832
Usability,feedback,feedback,"I just committed a second round of changes that I would appreciate some feedback on. Compilation is successful with these changes, however, upon testing, I receive the following message: . Error in ""void CConfig::SetConfig_Parsing(std::istream&)"": ; -------------------------------------------------------------------------; Line 271 SPECIFIED_SUPERSONIC_INLET_PROFILE: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean SPECIFIED_INLET_PROFILE?; Line 274 SUPERSONIC_INLET_FILENAME: invalid option name. Check current SU2 options in config_template.cfg.; Did you mean INLET_FILENAME?. I had already adjusted CConfig.cpp to include supersonic inlet profile inputs, but apparently I am not implementing everything I need to. I'm unsure where else I would need to make changes. Any suggestions?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1652#issuecomment-1151296832
Availability,toler,tolerance,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520
Testability,test,test,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520
Usability,feedback,feedback,"> Aside from my last two comments, and the possibility I broke the code :), this looks ready. Is this missing anything, or is it ready to merge?. Thank you so much @pcarruscag for your feedback. there is one thing left, it is about the residuals of the test case (species2_primitiveVenturi_mixingmodel.cfg) that I added in the previous pull request, they have changed exceeding in some outputs the tolerance 0.00001 with respect to the values stored in the parallel_regression.py, however the test case converges very well, so could it be possible to modify the values stored in that test case in order to not have this discrepancy between values stored and computed? Thank you so much in advance!!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1690#issuecomment-1194029520
Deployability,install,install,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302
Integrability,wrap,wrap,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302
Usability,simpl,simple,"I wonder if maybe it would be a better idea to delete this (and other stuff) from externals/ and add it to subrojects/ instead. You can use `meson wrap install catch2`, and it's a simple ini file to vet instead of an 18k line file. git diffs become a lot simpler too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1726#issuecomment-1198882302
Energy Efficiency,adapt,adapt,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012
Modifiability,adapt,adapt,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012
Usability,feedback,feedback,Okay @pcarruscag I believe ; I reverted all the annoying format changes. Can you please review the code when you get the chance?. BTW I am aware about the boilerplate code in `python_wrapper_structure.cpp` and I plan to adapt `CPyWrapperMatrixView`. Would appreciate some feedback anyways,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1779150012
Availability,down,down,"Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process.; My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management.; And just to be clear I am very interested in having this feature in the code for comparison with the FP approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970
Usability,intuit,intuition,"Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process.; My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management.; And just to be clear I am very interested in having this feature in the code for comparison with the FP approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1780662970
Availability,down,down,"> Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process. My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management. And just to be clear I am very interested in having this feature in the code for comparison with the FP approach. That's exactly right. We started investigating the multizone driver a while back but we didn't get very far... It's been a while so i will need a refresher. Sure, there's broader interest in comparison with FP. Ole, Nico, and I talked about doing a detailed characterization last summer and we briefly brought it up in Varenna last week",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088
Usability,intuit,intuition,"> Sounds good, with that it will be easier to reason about when the recording types are created and used, right now someone would have to sit down and reverse-engineer the process. My intuition is that we can use some of the machinery introduced for multizone (partial tape evaluation) to simplify the recording management. And just to be clear I am very interested in having this feature in the code for comparison with the FP approach. That's exactly right. We started investigating the multizone driver a while back but we didn't get very far... It's been a while so i will need a refresher. Sure, there's broader interest in comparison with FP. Ole, Nico, and I talked about doing a detailed characterization last summer and we briefly brought it up in Varenna last week",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-1785913088
Deployability,update,updates,"Hi, are there any updates on this feature? Or maybe some simple example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036
Usability,simpl,simple,"Hi, are there any updates on this feature? Or maybe some simple example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1750#issuecomment-2337835036
Testability,test,testcase,"Mate... I graduated from the school of ""out of the scope of"" with honors ok... You and I know that is just code for ""I'll leave it for someone else"".; Just cut and past the parts of the implementation that are exactly the same as another scheme into a function instead of copying, and given that other NEMO schemes have Jacobians that is probably something you should look into re-using.; You also clicked the box for having added a testcase but I don't see anything, why don't you add the testcase for the pictures and plots you showed? That is the only way for anything in this code to continue working... It's good work, it went into a paper, make it reproducible.; These are the contribution guidelines https://su2code.github.io/docs_v7/Style-Guide/ they may not always make things easier for authors, but they make it easier for the people coming after them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765
Usability,guid,guidelines,"Mate... I graduated from the school of ""out of the scope of"" with honors ok... You and I know that is just code for ""I'll leave it for someone else"".; Just cut and past the parts of the implementation that are exactly the same as another scheme into a function instead of copying, and given that other NEMO schemes have Jacobians that is probably something you should look into re-using.; You also clicked the box for having added a testcase but I don't see anything, why don't you add the testcase for the pictures and plots you showed? That is the only way for anything in this code to continue working... It's good work, it went into a paper, make it reproducible.; These are the contribution guidelines https://su2code.github.io/docs_v7/Style-Guide/ they may not always make things easier for authors, but they make it easier for the people coming after them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1773#issuecomment-1276409765
Usability,guid,guidence,Thanks for your guidence.; I found the code snippet you metioned in version 7.4.0 hasnot shown up in my current version 7.2.0. Quite happy to see contributors have revised this.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1809#issuecomment-1308341917
Usability,simpl,simplest,"@bigfooted @EvertBunschoten Well fwiw the simplest way is to checkout a new branch from before the merge and open a new PR, there are no coments here yet, so its fine.; (If you git revert the merge it will be a pain to then merge the other PRs)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1826#issuecomment-1327961579
Usability,simpl,simplest,"> @bigfooted @EvertBunschoten Well fwiw the simplest way is to checkout a new branch from before the merge and open a new PR, there are no coments here yet, so its fine. (If you git revert the merge it will be a pain to then merge the other PRs). I did a git reset --merge ""commit-id"" to go back to my latest commit. I think this completely removed Evert's merge without any residual effects. So should we create a new PR or not? Your 'its fine' comment has ambiguous meaning :-)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1826#issuecomment-1328075694
Safety,predict,predictions,"You are proposing the exact opposite of the conclusion of the paper:. ""From the above findings, it is **recommended that all three of these terms be included** when; running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with; shock wave-induced separations."". And they clearly say this:; ""While the full inclusion of these terms does not always result in predictions that agree better; with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out; effects of other flaws in the RANS models employed."". If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562
Usability,clear,clearly,"You are proposing the exact opposite of the conclusion of the paper:. ""From the above findings, it is **recommended that all three of these terms be included** when; running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with; shock wave-induced separations."". And they clearly say this:; ""While the full inclusion of these terms does not always result in predictions that agree better; with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out; effects of other flaws in the RANS models employed."". If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1520849562
Energy Efficiency,energy,energy,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702
Safety,predict,predictions,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702
Usability,clear,clearly,"> You are proposing the exact opposite of the conclusion of the paper:; > ; > ""From the above findings, it is **recommended that all three of these terms be included** when running hypersonic, or even supersonic, turbulent flow simulations, especially for flows with shock wave-induced separations.""; > ; > And they clearly say this: ""While the full inclusion of these terms does not always result in predictions that agree better with DNS/experimental data, this is likely caused by the fact that their exclusion cancels out effects of other flaws in the RANS models employed.""; > ; > If your strategy is to get a better match with experiments by neglecting physics terms, then you should rethink your strategy. Thank you for your comment @bigfooted . The above paper is not presented to improve the current k-w SST model. . As you can see in the first post, there is a problem with the high Mach number and freestream turbulence intensity case. If high turbulence kinetic energy(TKE) and Mach number condition, the boundary condition cannot be maintained the imposed value. (I think there seems to be a bug in the temperature calculation using total energy when including the TKE). The introduction of C1 was intended to provide a 'temporary' solution at the level of first aid (simply commenting out conditional statements in code).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1521383702
Energy Efficiency,energy,energy,"Thank you for replying while busy preparing the High Lift Prediction Workshop 5. Sorry, I didn't clearly understand. From what I understand, I can suggest another energy equation calculating method instead of the current SU2 method(reading calculated TKE from inlet boundary condition and using it as an energy equation). Is that right? If not, could you please explain in more detail?. > @sun5k maybe you can try implementing the alternative I suggested of obtaining turbulence kinetic energy at inlets from the turbulence solver instead of assuming that the free stream value is imposed exactly? In the SWBLI case the SST-m versions (without divergence terms in the stress tensor) seem to underpredict the separation region https://su2code.github.io/vandv/swbli/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374
Usability,clear,clearly,"Thank you for replying while busy preparing the High Lift Prediction Workshop 5. Sorry, I didn't clearly understand. From what I understand, I can suggest another energy equation calculating method instead of the current SU2 method(reading calculated TKE from inlet boundary condition and using it as an energy equation). Is that right? If not, could you please explain in more detail?. > @sun5k maybe you can try implementing the alternative I suggested of obtaining turbulence kinetic energy at inlets from the turbulence solver instead of assuming that the free stream value is imposed exactly? In the SWBLI case the SST-m versions (without divergence terms in the stress tensor) seem to underpredict the separation region https://su2code.github.io/vandv/swbli/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-1525805374
Modifiability,variab,variables,"Hi @rois1995 . For now, I'm ignoring all TKE in Total Energy in personal research. I don't remember the details clearly. ; The problem was that the enthalpy added TKE was stored in the primitive variables. ; When I tried to fix it, the problem was when the enthalpy added TKE was stored in the primitive variables. For the Roe scheme in convective flux calculations (not sure about other flux scheme), the Roe speed of sound is calculated using enthalpy. But as I mentioned above, the stored enthalpy is higher than other simulation because of TKE. I thought it make a problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889
Usability,clear,clearly,"Hi @rois1995 . For now, I'm ignoring all TKE in Total Energy in personal research. I don't remember the details clearly. ; The problem was that the enthalpy added TKE was stored in the primitive variables. ; When I tried to fix it, the problem was when the enthalpy added TKE was stored in the primitive variables. For the Roe scheme in convective flux calculations (not sure about other flux scheme), the Roe speed of sound is calculated using enthalpy. But as I mentioned above, the stored enthalpy is higher than other simulation because of TKE. I thought it make a problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2245163889
Modifiability,config,configs,"> Thank you for your answer. If you could share the configs and meshes that you are using I can try following the approach suggested by @pcarruscag and use the TKE from the turbulence solver instead of the freestream one.; > ; > Plus, I have some doubts on the default value of the turbulent to laminar viscosity ratio which is equal to 10 in SU2, although on the NASA page suggests to be in the range of 10^-2 to 10^-5. However, I think that this is another issue. @rois1995 Hi ~ . Can you give me a link to the NASA TMR guide for setting the viscosity ratio? I'm not sure where to find it. Sorry, I found it!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355
Usability,guid,guide,"> Thank you for your answer. If you could share the configs and meshes that you are using I can try following the approach suggested by @pcarruscag and use the TKE from the turbulence solver instead of the freestream one.; > ; > Plus, I have some doubts on the default value of the turbulent to laminar viscosity ratio which is equal to 10 in SU2, although on the NASA page suggests to be in the range of 10^-2 to 10^-5. However, I think that this is another issue. @rois1995 Hi ~ . Can you give me a link to the NASA TMR guide for setting the viscosity ratio? I'm not sure where to find it. Sorry, I found it!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1851#issuecomment-2251837355
Energy Efficiency,adapt,adapted,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856
Modifiability,adapt,adapted,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856
Testability,test,test,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856
Usability,simpl,simple,"And here is a simple test case demonstrating potential use. A major benefit of the supersonic inlet is being able to model supersonic propulsion systems, such as a scramjet, where the propulsion system exit boundary is modeled as a supersonic inlet, with distinct properties from the farfield flow conditions. Here we have a two dimensional test case demonstrating the interaction of exhaust flow with free-stream flow at the exit plane of a 2D scramjet system. Flow conditions adapted from [A Design Method for Three-Dimensional Scramjet Nozzles with Shape Transition](https://arc-aiaa-org.stanford.idm.oclc.org/doi/abs/10.2514/1.B38293); Jens Kunze, Michael K. Smart, and Rowan Gollan; Journal of Propulsion and Power 2022 38:1, 3-17. <img width=""1262"" alt=""image"" src=""https://user-images.githubusercontent.com/44848904/211415971-b6122204-0d95-43ca-903b-d60fd6326c39.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1862#issuecomment-1375043856
Usability,simpl,simplifying,"You could try turning off or simplifying the contributions to the Jacobian for that type of boundary, see CNSSolver.ccp around line 550. For example, leaving only the `Jacobian_i[nDim+1][nDim+1]` or none.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1872#issuecomment-1370867223
Usability,clear,clear,"I'm still not clear on how the convection BC is supposed to work. If I understand correctly up to this point HEAT_FLUX and HEAT_TRANSFER are largely identical:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L476-L479. Essentially in both cases the heat flux is calculated and saved to `Wall_HeatFlux`. For both BCs this is taken into account via the residuals:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L491-L496. and the residual contributions is added:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L530-L532. But I'm a bit lost why HEAT_TRANSFER is treated differently here:; https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/SU2_CFD/src/solvers/CNSSolver.cpp#L538-L559. Why is this special treatment necessary if HEAT_TRANSFER essentially is just a different way to calculate `Wall_HeatFlux`? If I disable the additional Jacobian contributions, shouldn't the solution still be accurate?. Regards,; Christian",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1872#issuecomment-1643910412
Availability,robust,robustness,Here is a quick summary for the inviscid wedge case using different NEMO schemes. There is clearly work to be done in the convergence/robustness world.; [nemo_scheme_regressions.pdf](https://github.com/su2code/SU2/files/10441554/nemo_scheme_regressions.pdf),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998
Usability,clear,clearly,Here is a quick summary for the inviscid wedge case using different NEMO schemes. There is clearly work to be done in the convergence/robustness world.; [nemo_scheme_regressions.pdf](https://github.com/su2code/SU2/files/10441554/nemo_scheme_regressions.pdf),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1885#issuecomment-1386403998
Performance,perform,perform,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031
Safety,safe,safe,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031
Usability,simpl,simple,"I could create a ""safe Allgatherv"" function, e.g. in [`mpi_structure.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/parallelization/mpi_structure.hpp) or in [`ndflattener.hpp`](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp). This function should check the number of processes, perform a simple copy if it is 1, and otherwise calls the regular Allgatherv. It would then be used [here](https://github.com/su2code/SU2/blob/1b085062547ec5b066a28ddeeacf4907588f4f5a/Common/include/toolboxes/ndflattener.hpp#L235) instead of `SU2_MPI::Allgatherv`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1893#issuecomment-1397491031
Usability,simpl,simple,"Quite simple I imagine.; Since I have everything in place now to open, manipulate and export the mesh in SU2 format (c.f. #1877 ) I could easily filter points and assign their IDs to arbitrary markers or elements or simply export their ID to a different file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1894#issuecomment-1396188450
Availability,avail,available,"@pcarruscag It is ready for some external feedback.; Some things that you might want to take a look at:; - the implementation of objectives using surface_scalar_01, surface_scalar_02,... This is a simple extension to multiple scalars but could be generalized in the future.; - the implementation of axisymmetric source terms using the already available CSourceAxisymmetric_Species, this framework was present in the species implementation. It works, but this might need some more polishing in the future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654
Usability,feedback,feedback,"@pcarruscag It is ready for some external feedback.; Some things that you might want to take a look at:; - the implementation of objectives using surface_scalar_01, surface_scalar_02,... This is a simple extension to multiple scalars but could be generalized in the future.; - the implementation of axisymmetric source terms using the already available CSourceAxisymmetric_Species, this framework was present in the species implementation. It works, but this might need some more polishing in the future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1466044654
Usability,simpl,simple,"@pcarruscag I went through all your comments. There is one open discussion, maybe we can see if there is a better way to do this code sharing between flamelet and species although I think what I did now is simple and effective. ; Maybe you still see some other suboptimal implementations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1917#issuecomment-1569765685
Availability,down,download,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672
Integrability,depend,dependencies,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672
Usability,feedback,feedback,Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450323672
Availability,down,download,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338
Integrability,depend,dependencies,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338
Testability,test,tested,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338
Usability,feedback,feedback,"> Thank you for the feedback but for 99% of cases it is easier for users if we download the dependencies for them. The philosophy behind SU2 has always been to provide as much of a self contained package as possible. But this check will allow users to use external dependencies just fine, as long as they happen to use an external 0.61.1?. ... I am not entirely sure I understand the issue here. You want to make it *easier* for users by downloading the dependencies, so you make it harder if they went and got their own dependencies? If someone has gone to the effort of getting their own dependencies instead of using your documented meson.py, it would seem like that inherently means they are the 1% of use cases and you could probably just leave them to it. Is the issue rather that only Meson 0.61.1 has been tested to work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1450921338
Availability,error,error,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Deployability,release,release,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Integrability,wrap,wrapping,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Modifiability,config,configured,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Performance,cache,cached,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Testability,test,tests,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Usability,clear,clear,"```diff; $ git --no-pager diff --cached ; diff --git a/meson.build b/meson.build; index ca86992ea..b68a03c52 100644; --- a/meson.build; +++ b/meson.build; @@ -1,15 +1,12 @@; project('SU2', 'c', 'cpp',; version: '7.5.1 ""Blackbird""',; + meson_version: '0.61.1',; license: 'LGPL2',; default_options: ['buildtype=release',; 'warning_level=0',; 'c_std=c99',; 'cpp_std=c++11']); ; -if meson.version() != '0.61.1'; - error('SU2 must be configured with the extended Meson script (./meson.py) in the SU2 root directory.'); -endif; -; pymod = import('python'); python = pymod.find_installation(); ; ```. I used this patch, and then ran the following:. ```; $ meson setup builddir --wipe; The Meson build system; Version: 1.0.1; Source dir: /tmp/SU2; Build dir: /tmp/SU2/builddir; Build type: native build. meson.build:1:0: ERROR: Meson version is 1.0.1 but project requires 0.61.1; ```. Using the >= comparison, it configures fine, and downloads a git submodule for mutationpp/coolprop on demand. From a hasty look around, it seems like the other git submodules are used as externals/ directories, not meson subprojects. Another project I know uses e.g. ```; if not fs.exists('submoduledir/README.md'); error('Missing the `submoduledir` submodule! Run `git submodule update --init` to fix this.'); endif; ```. for each submodule before it gets processed by meson. This is less automatic than wrapping it in meson.py, but does provide pretty clear directions... the sticking point is if people download tarballs. You currently point people to github's autogenerated archives, which is NOT sufficient as it doesn't have submodules included. I would actually suggest using `meson dist --include-subprojects --no-tests` to produce your own tarballs and attach them as additional releases artifacts. Meson *does* include submodules (whether or not they are subprojects) automatically to the tarball it creates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/1945#issuecomment-1451057434
Deployability,update,update,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727
Integrability,depend,depends,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727
Usability,guid,guide-to-git-merge-and-git-rebase,"> How should I update my branch with upstream/develop? Should I merge upstream/develop into my branch (and push to my fork on github)? Or may I rebase my branch on top of upstream/develop (and force push to my fork on github)?. Both ways are legit, feel free to use which one is easier for you [here](https://www.freecodecamp.org/news/the-ultimate-guide-to-git-merge-and-git-rebase/) a comparison between them. It depends on the taste of the developer. . > I assume I should add myself to the _Individual Contributors_ section of AUTHORS.md, is that correct?. Yes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1466144727
Testability,test,tests,"Merge and push is simpler I think, and with that the reviewers have the option of only seeing the new commits.; Thanks for the changes, we'll merge once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800
Usability,simpl,simpler,"Merge and push is simpler I think, and with that the reviewers have the option of only seeing the new commits.; Thanks for the changes, we'll merge once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1951#issuecomment-1470769800
Usability,simpl,simply,"I tried changing line 1387 in CEulerSolver::SetReferenceValues to simply if (dynamic_grid) {...}, but that had no effect.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1463922825
Availability,avail,available,"Hi Pedro, ; I'm slightly confused right now and not sure if I'm able to do the necessary modifications. I understand that it is unlikely someone else might implement this but I think that this is beyond my abilities right now. If you don't mind, do you have some time to talk through my options in a video call? I hope that will help me to get a clearer picture. Next week, I'm generally available except for Monday, which is a public holiday here. Germany is 9 hours in advance of California, so your morning / my evening might work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492
Usability,clear,clearer,"Hi Pedro, ; I'm slightly confused right now and not sure if I'm able to do the necessary modifications. I understand that it is unlikely someone else might implement this but I think that this is beyond my abilities right now. If you don't mind, do you have some time to talk through my options in a video call? I hope that will help me to get a clearer picture. Next week, I'm generally available except for Monday, which is a public holiday here. Germany is 9 hours in advance of California, so your morning / my evening might work?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1497398492
Deployability,rolling,rolling,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240
Performance,load,load,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240
Usability,undo,undo,"Hi Pedro, ; As discussed last week, I now translate and rotate the whole aircraft in the elastic mesh in combination with a farfield onflow. Implementing and doing the coordinate transformations right took me a few hours, but now everything seems to work properly and fast :). 1. Currently, activating the gust resets/overwrites the grid velocities due to the deformed mesh, but I haven't found the place yet. Any ideas?. 2. Should I clean up / remove the split velocity approach as described in the first post or would you like to keep it?. 4. How to handle the new approach, should I close this pull request and open a new one? There are a few commits which I needed to undo. 5. Generally, I still need the rotating frame approach for steady maneuver load cases, e.g. to calculate the pitching, rolling or yawing aircraft in a steady simulation. The acceleration terms are zero in this case, but I understood that the Coriolis-Term with omega x velocity is missing. Is that correct? I guess they are probably important for objects like a propeller which spins at a couple of thousand RPMs but maybe it is justified to neglect them for slow objects?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1505397240
Testability,test,test,"@pcarruscag: I'm in the process of creating a test case for the 3D gust. To do so, I created a CFD mesh for a simple, rectangular 3m wing with a NACA0012 profile. The mesh has a size of 13.7 Mb and a restart solution is 16.3 Mb plus 5.5 Mb (.csv and .dat). Do you think that is acceptable?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126
Usability,simpl,simple,"@pcarruscag: I'm in the process of creating a test case for the 3D gust. To do so, I created a CFD mesh for a simple, rectangular 3m wing with a NACA0012 profile. The mesh has a size of 13.7 Mb and a restart solution is 16.3 Mb plus 5.5 Mb (.csv and .dat). Do you think that is acceptable?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1545475126
Testability,test,testing,"I see that the Onera M6 mesh is a half-wing with a symmetry plane and I'm not sure how the mesh deformation behaves in this case (for example, there should be zero out-of-plane movement). . Personally, I like really simple examples where I know what should happen (symmetric airfoil, subsonic flow, no sweep) and I did all my testing during the last weeks with the NACA0012 3m wing. At the same time, it is closer to how I would model a ""real"" aircraft (aircraft in the center of a spherical farfield) than the Onera M6, which is more wind-tunnel-like. The mesh and everything is there, so it's no additional work for me and I would be happy to contribute this as a new example. What's the main argument in favor of the Onear M6 wing / objection against a new example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112
Usability,simpl,simple,"I see that the Onera M6 mesh is a half-wing with a symmetry plane and I'm not sure how the mesh deformation behaves in this case (for example, there should be zero out-of-plane movement). . Personally, I like really simple examples where I know what should happen (symmetric airfoil, subsonic flow, no sweep) and I did all my testing during the last weeks with the NACA0012 3m wing. At the same time, it is closer to how I would model a ""real"" aircraft (aircraft in the center of a spherical farfield) than the Onera M6, which is more wind-tunnel-like. The mesh and everything is there, so it's no additional work for me and I would be happy to contribute this as a new example. What's the main argument in favor of the Onear M6 wing / objection against a new example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1954#issuecomment-1547295112
Energy Efficiency,monitor,monitor,"So just to be clear: In my opinion, after calling SU2Driver.Run() the iteration count should be increased immediately. Now we postpone it in the python scripts, which means we have to add +1 in monitor to get the correct iteration count.; With the current change, Monitor has the correct (imo) behavior.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540
Usability,clear,clear,"So just to be clear: In my opinion, after calling SU2Driver.Run() the iteration count should be increased immediately. Now we postpone it in the python scripts, which means we have to add +1 in monitor to get the correct iteration count.; With the current change, Monitor has the correct (imo) behavior.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464364540
Testability,test,test,"It's not required fo initialization. Ok, if it's not going to work in this way let's start a discussion about a proper way to do this. I will create a new PR for just the initialization example and put it in a regression test. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230
Usability,feedback,feedback,"It's not required fo initialization. Ok, if it's not going to work in this way let's start a discussion about a proper way to do this. I will create a new PR for just the initialization example and put it in a regression test. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1960#issuecomment-1464935230
Energy Efficiency,adapt,adapted,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978
Modifiability,adapt,adapted,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978
Testability,test,tests,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978
Usability,feedback,feedback,"Thanks for your feedback! I agree, `OMP_NUM_THREADS` is better than having the number of threads in the constructor. I adapted `disc_adj_flow` and `disc_adj_fea` for MPI and added both to parallel AD and hybrid AD tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1966#issuecomment-1472198978
Availability,avail,available,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542
Modifiability,variab,variable,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542
Safety,detect,detect,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542
Security,access,accessor,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542
Usability,clear,clear,"> Nice! By the way, did you use some scripts for going through all the files and returning 'bad' naming conventions?. No, now I am just going through it by hand probably some linters are available to at least detect them. Actually, I am a bit confused as it is not so clear in the guide. It looks like the beginning of the project was just abbreviated from the Google style guide and was not enforced. Enforcing function names in UpperCamelCase and leaving variable names to the developer seems reasonable. > Can you explain the snake/camel terminology? :). Let's say we have a variable we want to name as `number of nodes per mesh` there are 2 common choices as . ```cpp; number_of_nodes_per_mesh = 42;; numberOfNodesPerMesh = 42;; ```; The first case is called the [snake case](https://en.wikipedia.org/wiki/Snake_case) and the second one is the [camel case ](https://en.wikipedia.org/wiki/Camel_case). Snake case is generally used in Python as [PEP8](https://peps.python.org/pep-0008/) suggests. . > Please revert the python accessor changes. I merged develop many of them vanished, should I revert the remaining ones?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/1981#issuecomment-1482062542
Testability,test,tests,"Thank you @pcarruscag and @kursatyurt for your comments and suggestions! I hope that I understood and applied them as intended, if not, please let me know. This is all new to me and because I'm still learning C++, it took me a few extra commits but now all tests seem to pass :) Have a good weekend!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617
Usability,learn,learning,"Thank you @pcarruscag and @kursatyurt for your comments and suggestions! I hope that I understood and applied them as intended, if not, please let me know. This is all new to me and because I'm still learning C++, it took me a few extra commits but now all tests seem to pass :) Have a good weekend!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2024#issuecomment-1545770617
Testability,test,tests,"Hello,. I have been debugging the differences between the two versions. I found 5 differences that lead to slightly different results. Two of them have been verified to be an improvement of physical modelling. The other 3 I am still trying to figure out. Could you please run the same tests with MUSCL_FLOW=NO and see if you're still facing this issue?. I see that the MUSCL reconstruction is one of the 3 things that have been modified and not sure if could be the cause of the problem or not. I will keep working on understanding the impact of the other 2 things. When you do this - could you please save the simulation output log of both versions and send those back to me too (in this way I'll have a better feeling of what is happening to the residuals throughout the simulation)? We can just focus on the invbb case to make it simpler.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684
Usability,simpl,simpler,"Hello,. I have been debugging the differences between the two versions. I found 5 differences that lead to slightly different results. Two of them have been verified to be an improvement of physical modelling. The other 3 I am still trying to figure out. Could you please run the same tests with MUSCL_FLOW=NO and see if you're still facing this issue?. I see that the MUSCL reconstruction is one of the 3 things that have been modified and not sure if could be the cause of the problem or not. I will keep working on understanding the impact of the other 2 things. When you do this - could you please save the simulation output log of both versions and send those back to me too (in this way I'll have a better feeling of what is happening to the residuals throughout the simulation)? We can just focus on the invbb case to make it simpler.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2026#issuecomment-1562975684
Usability,clear,clear,> Can you describe the bug this is fixing a bit more. I edited the PR description. Hope it's clear now. Please let know if you need more info.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2036#issuecomment-1551960465
Modifiability,layers,layers,The dummy layer is what we used before version 7 and moved away from it for simplicity.; Two layers doesn't sound possible for unstructured meshes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415
Usability,simpl,simplicity,The dummy layer is what we used before version 7 and moved away from it for simplicity.; Two layers doesn't sound possible for unstructured meshes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2038#issuecomment-1557818415
Integrability,depend,depends,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580
Modifiability,variab,variable,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580
Usability,intuit,intuitive,"I implemented most of the reviewers suggestions. The only suggestion I left unchanged is the upper-case consistency issue raised by Wally. Since it is an optional output and it depends on the controlling variable names the user provides, I think it would be more intuitive to keep the font case consistent between the names under `CONTROLLING_VARIABLE_NAMES` and the corresponding `RMS_` outputs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2057#issuecomment-1643680580
Usability,simpl,simple,"I've also asked on OpenMPI mail-list and they said ""Can you or they provide a small, simple MPI application that replicates the issue? That would be something we could dig into and investigate.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2103#issuecomment-1673166638
Usability,simpl,simple,"Let's keep the dimensional outputs, we are already trying to have dimensional inputs to keep things simple.; In the longer term we should aim to have dimensional inputs and outputs and make the non-dimensionalization an internal detail of the solvers that users don't have to worry with.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1684078599
Usability,simpl,simply,"you are correct, there is a discussion on CFD-online about it. we impose 0 heat flux, but report an ""apparent heat flux"" most codes will simply give you back the imposed heat flux value you specify, nevertheless there will probably be a temperature gradient close to the wall",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992
Usability,simpl,simply,"Thank you so much, Tobi and Pedro. Yes, there is a temperature gradient; close to the wall. So SU2 gives me, in this case, a 'virtual heat flux'!; Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1740735437
Availability,error,error,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391
Deployability,release,releases,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391
Integrability,message,message,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391
Testability,test,tested,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391
Usability,simpl,simply,"Yet another doubt on the same subject: I just realized that SU2V7.31 (I; have not tested it on later SU2 releases) accepts imposing both adiabatic; walls plus isothermal boundary condition on some walls (when running Menter; model), but when I simply impose only isothermal conditions (leaving; commented out the adiabatic markers), I get the message: SU2 process; returned error '1'. Is there a workaround for this? Kind regards. On Thu, Sep 28, 2023 at 8:25 PM Pedro Gomes ***@***.***>; wrote:. > you are correct, there is a discussion on CFD-online about it. we impose 0; > heat flux, but report an ""apparent heat flux"" most codes will simply give; > you back the imposed heat flux value you specify, nevertheless there will; > probably be a temperature gradient close to the wall; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1740118992>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUUZNE6B63SH7XJLY2DX4YBMZANCNFSM6AAAAAA3QKLVDU>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1775968391
Usability,simpl,simple,Is there a simple example to reproduce the issue?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496
Integrability,message,message,"Unfortunately, my example involves a swirler and nozzle for the; Navier-Stokes solver with Menter model, so the dataset is relatively large.; Let me check whether some older small Euler mesh exhibits the same message!; I will let you know! Thank you very much. On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; wrote:. > Is there a simple example to reproduce the issue?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584
Usability,simpl,simple,"Unfortunately, my example involves a swirler and nozzle for the; Navier-Stokes solver with Menter model, so the dataset is relatively large.; Let me check whether some older small Euler mesh exhibits the same message!; I will let you know! Thank you very much. On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; wrote:. > Is there a simple example to reproduce the issue?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1776143584
Availability,error,error,"Hello Pedro. While searching a small sample dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035
Integrability,message,message,"Hello Pedro. While searching a small sample dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035
Usability,simpl,simple,"ple dataset, I have run some; variations on the jobs, and my findings were:; (Please note that *all* ""markers"" I have mentioned in the next items refer; to solid walls in the mesh, using the RANS solver); 1- When I impose HEATFLUX=0 *and* ISOTHERMAL=290 Kelvin, for the same; markers, there are no complaints from SU2. It shows that SU2 ignores the; imposition of HEATFLUX=0, in this case.; 2- Just setting ISOTHERMAL=290 Kelvin (using all of the same markers as in; (item 1), above), without any HEATFLUX setting, then SU2 produces the same; results as in (item1).; 3- When some markers are set with HEATFLUX=0 and the rest of them are set; with ISOTHERMAL=290 Kelvin (so that each wall marker in the mesh is; referenced), there are no complaints from SU2, and the job goes as expected.; 4-The error message mentioned earlier, appears when one or more solid wall; markers *is not marked* concerning HEATFLUX or ISOTHERMAL; .; My conclusion then is that the error message appeared when I mistakenly; have not included a wall marker (assigning it as a HEATFLUX or an; ISOTHERMAL marker!); Does it make sense?; Kind regards,. On Mon, Oct 23, 2023 at 7:48 PM Jairo Cavalcante ***@***.***>; wrote:. > Unfortunately, my example involves a swirler and nozzle for the; > Navier-Stokes solver with Menter model, so the dataset is relatively large.; > Let me check whether some older small Euler mesh exhibits the same message!; > I will let you know! Thank you very much.; >; > On Mon, Oct 23, 2023 at 6:34 PM Pedro Gomes ***@***.***>; > wrote:; >; >> Is there a simple example to reproduce the issue?; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/pull/2109#issuecomment-1776057496>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/AHGXZUV3DNRF3O55YAWT563YA3PETAVCNFSM6AAAAAA3QKLVDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZWGA2TONBZGY>; >> .; >> You are receiving this because you commented.Message ID:; >> ***@***.***>; >>; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2109#issuecomment-1777018035
Usability,simpl,simple,"Here is a simple proof-of-concept for the fluid iteration where we catch SIGTERM. If you run it and hit ctrl-c, we catch the signal and we set stopcalc to true. This will exit the for-loop and also forces a saving of the files.; I think implementing the signal handler like this is the best, because we let the solver handle all the cleanup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2110#issuecomment-1678550840
Modifiability,config,config,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397
Performance,perform,performing,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397
Security,attack,attack,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397
Usability,simpl,simple,"**SOLVED** see edit. Hello! I seem to remember that it used to be possible to get angle of attack in the history file? Is this still possible? I would like to be able to just pull the angle of attack out of the history file, along with the aero coeffs.; Context:; I have looked through the custom output document and the reference config file, and (perhaps I am secretly blind), but there does not seem to be a simple output group for it.; Reason I need it: performing analysis for fixed Cl, so angle of attack is useful information. At the moment I am getting probed data:; ```; CUSTOM_OUTPUTS='m_vel_x : Macro{VELOCITY_X};\; m_vel_y : Macro{VELOCITY_Y};\; vel_x1: Probe{$m_vel_x}[-15, -15];\; vel_y1: Probe{$m_vel_y}[-15, -15]'; ```; And just getting the tan(y/x) of the probed values for angle. This works well enough.; The other option I have is stripping the angle of attack out of the forced breakdown file, would prefer to not do, but can. EDIT:. **It can be pulled out of line 2 of flow.meta**",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2138#issuecomment-1780159397
Deployability,update,updated,@pcarruscag Based on your 2nd review we have updated the code according to your suggestions. It was not clear how to restore the accidental changes to the sha versions of submodules externals/codi/ and subprojects/CoolProp/. Please instruct us howto or override yourselves for the same if possible. Request you to please review and instruct for proceeding further.; Thank you very much.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845
Usability,clear,clear,@pcarruscag Based on your 2nd review we have updated the code according to your suggestions. It was not clear how to restore the accidental changes to the sha versions of submodules externals/codi/ and subprojects/CoolProp/. Please instruct us howto or override yourselves for the same if possible. Request you to please review and instruct for proceeding further.; Thank you very much.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2142#issuecomment-1793649845
Usability,clear,clearance,"I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2066011801
Security,validat,validation,"> I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist. Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773
Usability,clear,clearance,"> I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist. Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2071759773
Availability,down,download,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976
Security,validat,validation,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976
Usability,clear,clearance,"> > I find your work really interesting. I've been studying the internal flow field in compressors and have had good results using SU2's SA_EDDES for calculating the cantilevered stator with a tip clearance. If you need help with code verification, I'd be glad to assist.; > ; > Hi @Linnnnnn23, every help on the validation/verification is gladly accepted! Let me know if you need anything by my side.; Thank you for your response. Firstly, I would like to know what Verification and Validation (V&V) work has been conducted on the SST-based DDES (Delayed Detached Eddy Simulation) model to date. Secondly, we can provide a compressor cascade validation, with an inlet Mach number of 0.4, a Reynolds number of approximately 500,000, and a spanwise height of about 20% of the chord length, ensuring that the vortices resolved by DDES can develop in three dimensions. Thirdly, as I am a rookie to GitHub, I have not yet found out how to download your pull request code. For further communication, you can contact me via email at linnnnnn2308@gmail.com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2150#issuecomment-2072057976
Integrability,wrap,wrap,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071
Performance,perform,performance,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071
Testability,test,test,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071
Usability,simpl,simple,@EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it.; Do you have time to wrap it up and add a simple regression test?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2269672071
Integrability,wrap,wrap,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145
Performance,perform,performance,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145
Testability,test,test,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145
Usability,simpl,simple,> @EvertBunschoten even if the performance isn't great this is a pretty small change so I think we can merge it. Do you have time to wrap it up and add a simple regression test?. I just added a test case and tutorial under the TestCases and Tutorials repo under the same branch name. I'm also writing a short tutorial on the SU2 website repo.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2152#issuecomment-2271237145
Deployability,update,updated,"> Our working branch is 'develop', so you should have started from that and also merge into it. Every 6 months or so we then make the current develop into master. I changed the target branch to develop, and also updated your branch with current develop. Can you have a look at the failed check for clang-format coding style and format the changed file accordingly? https://su2code.github.io/docs_v7/Style-Guide/. Thanks a lot! It's very much appreciated. I have implemented the clang-format according to the guide and force formatting all files by using 'pre-commit run -a'. I think the new commits should be conformed to the coding style but not sure if the previous commit is also changed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110
Usability,guid,guide,"> Our working branch is 'develop', so you should have started from that and also merge into it. Every 6 months or so we then make the current develop into master. I changed the target branch to develop, and also updated your branch with current develop. Can you have a look at the failed check for clang-format coding style and format the changed file accordingly? https://su2code.github.io/docs_v7/Style-Guide/. Thanks a lot! It's very much appreciated. I have implemented the clang-format according to the guide and force formatting all files by using 'pre-commit run -a'. I think the new commits should be conformed to the coding style but not sure if the previous commit is also changed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1951941110
Energy Efficiency,efficient,efficient,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506
Integrability,interface,interface,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506
Modifiability,inherit,inherited,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506
Usability,clear,clear,"Thanks for your comments! Except for mixing plane and frozen rotor, sliding plane is also pretty common in turbomachinery simulation, it is indeed implemented in some, if not all, in-house codes. ; MRF is quite useful in turbomachinery simulation, expecially when we deal with transient simulation. Actually it is really rare to move the rotor mesh like in reality. One reason is that MRF is more efficient and accurate. Otherwise, you introduce new disturbance into the transient flow field every physical time step, which is not good. Because when you rotate the mesh, the velocity direction of each grid point inherited from last time step is not rotated. To make it more clear, you will have a flow going towards casing instead of parallel to, at the start of next physical time step. So you need more pseudo time steps to get a proper velocity variable. As a result, you get a zig-zag shape in the residual history.; I'm not actually moving the interface. The rotor mesh is not rotated, so as the interface at rotor zone. I'm just virtually rotating the rotor interface to find the new matching points between rotor and stator for each physical time step, so that the variable could be passed across the interface. In other words, only the passing variables are actually rotated. If I understand it correctly, there is no additional moving mesh restriction introduced here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2173#issuecomment-1953783506
Modifiability,rewrite,rewrite,"Hello, ; You are right, this pr cannot solve the problem but just make the solution look reasonable.; For some complicated case, it is hard to converge, not like in the simple cases.; I have read the relevant code and book, and I think maybe a good way is to rewrite the bc code and move the nonzero normal components limitation to where the flux are calculated. Or we can store the flux of the points on the sym bc, and in CFVMFlowSolverBase<V, R>::BC_Sym_Plane we just use the stored flux without recalculation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319
Usability,simpl,simple,"Hello, ; You are right, this pr cannot solve the problem but just make the solution look reasonable.; For some complicated case, it is hard to converge, not like in the simple cases.; I have read the relevant code and book, and I think maybe a good way is to rewrite the bc code and move the nonzero normal components limitation to where the flux are calculated. Or we can store the flux of the points on the sym bc, and in CFVMFlowSolverBase<V, R>::BC_Sym_Plane we just use the stored flux without recalculation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2174#issuecomment-1868453319
Deployability,update,updated,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956
Integrability,wrap,wrapper,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956
Modifiability,config,config,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956
Usability,clear,clear,"@bigfooted Has there ever been any discussion regarding implementation of a `START_TIME=` capability into the config file? After going through the code a bit, it looks like doing this would be a good starting point for implementing ability to adjust deltaT mid-runs, as in general the code presumes `TimeIter*deltaT` as being the current time. This would be problematic for unsteady restarts that have a varying timestep. Plus, this would allow one to, without using the Python wrapper, use a different timestep in the config file for an unsteady restart. It also may clear up some confusion to have an explicit option for this, as in #2071. It can maybe look something like:. % Start time for restarting unsteady simulations; % = -1 for default calculation (START_TIME=RESTART_ITER*TIME_STEP); START_TIME=-1. Then `CConfig::GetPhysicalTime` could be appropriately updated and used in-place of all locations in the code where a physical time is manually calculated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2190#issuecomment-1870730956
Modifiability,variab,variable,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505
Testability,test,test,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505
Usability,simpl,simple,"> I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?. That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements:; https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development. The domain is just a rectangle so pretty simple to set up. You could also use the V&V test that we have, but it is a variable density jet:; https://su2code.github.io/vandv/SANDIA_jet/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1889612505
Modifiability,variab,variable,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092
Testability,test,test,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092
Usability,simpl,simple,"> > I'm thinking about reusing the SST test case ([axisymmetric_rans/air_nozzle](https://github.com/su2code/SU2/tree/master/TestCases/axisymmetric_rans/air_nozzle)) so that the same mesh can be used. Would that be fine ?; > ; > That's a quite specific testcase. How did you test the implementation? Do you have some simple results for the turbulent axisymmetric jet? We know that the results for round jets are not super good for standard SA, but at least we know what the result should look like, here on p.32 - 35 they test SA for the round jet and compare to the Wygnanski & Fiedler measurements: https://www.researchgate.net/publication/24296213_Turbulence_Modeling_Validation_Testing_and_Development; > ; > The domain is just a rectangle so pretty simple to set up.; > ; > You could also use the V&V test that we have, but it is a variable density jet: https://su2code.github.io/vandv/SANDIA_jet/. I did some tests on a supersonic jet, since I already had the files, but it's a quite complex case so it's not that good to verify the implementation. I will look into the simpler cases you mentioned !",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2197#issuecomment-1891046092
Energy Efficiency,reduce,reduced,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226
Integrability,interface,interface,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226
Modifiability,variab,variables,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226
Performance,perform,performance,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226
Usability,clear,clear,"> You may want to remove the string based interface since it's known to be inneficient. When replacing the string-based with index-based look-up methods, the performance improves substantially. The figure below shows the average measured evaluation time (measured with chrono library) vs the number of output variables. It's clear that using index-based look-up methods results in reduced query time, as well as improved scaling. ![scaling_nVars](https://github.com/su2code/SU2/assets/38651601/31252439-ac6e-4f1b-82d4-e13a55d54c98)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2214#issuecomment-1952521226
Integrability,wrap,wrapper,"The source term is pretty simple but the feature as a whole is very intrusive on the code, even the mesh deformation is getting involved in this.; Would it be viable to use the python wrapper to provide the source term?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850
Usability,simpl,simple,"The source term is pretty simple but the feature as a whole is very intrusive on the code, even the mesh deformation is getting involved in this.; Would it be viable to use the python wrapper to provide the source term?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2273#issuecomment-2098573850
Testability,test,tests,"Hi,; I went through this work but it is a bit hard to me to completely follow and continue you guys' idea. If you could help finish this issue, I am really willing to do some tests and give feedbacks ASAP. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280
Usability,feedback,feedbacks,"Hi,; I went through this work but it is a bit hard to me to completely follow and continue you guys' idea. If you could help finish this issue, I am really willing to do some tests and give feedbacks ASAP. Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2275#issuecomment-2098689280
Availability,error,error," the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation; ![image](https://github.com/su2code/SU2/assets/79575547/27f2a79b-824d-4a32-a626-73cd87750c0c). # Residuals:; ![image](https://github.com/su2code/SU2/assets/79575547/3f0800fe-478e-433d-8495-cd4964d0f8ee). # Mesh:; ![image](https://github.com/su2code/SU2/assets/79575547/0ebaf86b-fbf9-40b1-aeb9-8764a90a1440)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449
Testability,test,test,"To add some data I'll put a test where you can see the issue:. This is an inviscid Euler simulation using the Span-Wagner EoS (CoolProp) of a non-ideal MDM nozzle, see https://su2code.github.io/tutorials/NICFD_nozzle using ```GREEN_GAUSS``` for the gradient computation. Convergence can still be achieved but the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449
Usability,simpl,simply," the solution at the inlet corner is completely wrong, while the outlet is ok most likely because characteristics are outgoing as it is supersonic. The artifacts disappear if we disable MUSCL everywhere (1st order solution) or disable it only on boundaries (not ideal solution, but disabling only on corners would still be good enough for now I believe). Using ```WEIGHTED_LEAST_SQUARES``` seems to not present the same issue, in this test case at least, as the stencil ""does not care"" about the boundary states. The boundary conditions are:; - ```MARKER_SYMMETRY``` at centerline; - ```MARKER_EULER``` at wall; - ```MARKER_RIEMANN= (INLET, TOTAL_CONDITIONS_PT, 904388, 542.13, 1.0, 0.0, 0.0)``` at inlet; - ```MARKER_RIEMANN= (OUTLET, STATIC_PRESSURE, 200000.0, 0.0, 0.0, 0.0, 0.0)``` at outlet. I tried both with and without a slope limiter as there are no discontinuities, but it makes no difference on the artifacts:. ```; SLOPE_LIMITER_FLOW= VENKATAKRISHNAN_WANG; VENKAT_LIMITER_COEFF= 0.1; ```. # Complete test case ZIP; [mdm_coolprop_nozzle.zip](https://github.com/su2code/SU2/files/15403732/mdm_coolprop_nozzle.zip). # Inlet pressure zoom; ![Screenshot from 2024-05-22 15-06-36](https://github.com/su2code/SU2/assets/79575547/9ba71127-cb12-4c5f-8e49-3ea9e839b1f4). # Notation: ; - ""1st order"" no MUSCL; - ""2nd order"" MUSCL as implemented in SU2; - ""2nd order (BC 1st order)"" I simply disabled MUSCL on ALL physical boundaries in the upwind residual computations, see code snippet below. # Proof of concept code modification for ""2nd order (BC 1st order)"":; To show that the error lies in MUSCL/gradients at boundaries I added these two lines of code in the upwind gradient computation; ![image](https://github.com/su2code/SU2/assets/79575547/27f2a79b-824d-4a32-a626-73cd87750c0c). # Residuals:; ![image](https://github.com/su2code/SU2/assets/79575547/3f0800fe-478e-433d-8495-cd4964d0f8ee). # Mesh:; ![image](https://github.com/su2code/SU2/assets/79575547/0ebaf86b-fbf9-40b1-aeb9-8764a90a1440)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/2285#issuecomment-2124781449
Availability,robust,robustness,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152
Testability,test,test,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152
Usability,guid,guidelines,"We are wondering what the status with the merge request is. Am I supposed to do something more? is it just waiting for an additional review? . Additionally, we have many more proposed modifications, we have worked on, adding robustness to the existing turbulence models. It is expected, many of these changes will effect the test cases behaviour, are there any guidelines how to compile the code to run the full set of tests locally, or should I just open pull requests, and base upon the github test results? ; ; I am sorry if I may be asking the obvious, but I am new to contributing to open code..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2295#issuecomment-2219624152
Usability,clear,clear,"Hi rois1995,. First of all, enjoy your time in Las Vegas. Any paper that you are presenting?. As for our discussion about the cross-diffusion term, I've emailed the ""source"" (Menter). I believe he will make it clear.; It may be that he will be able to answer only in a while ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2252939132
Availability,avail,available,"I totally agree. On real meshes, Omega usually drops to extremely low values. In cases where the cross-diffusion term is negative (allowed to be negative), it behaves as a sink term, further amplifying the drop of Omega. A simple addition of this term to the implicit diagonal is insufficient (I tried this). Other more rigorous methods are required (some available in the open literature). . My main argument is that the factor (1-F1) guarantees only the k-epsilon branch outside the boundary layer, in which the cross-diffusion term is already positive. It may not be so because of numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698
Usability,simpl,simple,"I totally agree. On real meshes, Omega usually drops to extremely low values. In cases where the cross-diffusion term is negative (allowed to be negative), it behaves as a sink term, further amplifying the drop of Omega. A simple addition of this term to the implicit diagonal is insufficient (I tried this). Other more rigorous methods are required (some available in the open literature). . My main argument is that the factor (1-F1) guarantees only the k-epsilon branch outside the boundary layer, in which the cross-diffusion term is already positive. It may not be so because of numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2253297698
Usability,simpl,simple,"Hi All,. We are lucky, Florian Menter just replied to me. He agreed that the factor (1-F1) should activate the CD term only at the ""k-epsilon"" branch, where the CD term is already positive.; Therefore, clipping with zero is in terms of the model and is not incorrect. Me: A simple boundary layer simulation will reveal that the CD term switch sign is inside the boundary layer and that the F1 function switches from 1 to zero outside the boundary layer. Namely, the CD term should be positive. Florian is unaware of the occasions when it may be negative (even though the model was designed so that this term will be activated when it is positive). . Best wishes,; Yair",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2256154395
Safety,avoid,avoid,"I expect that epsilon to be a simple measure to avoid division by 0, if that lower bound had physical meaning it would have to be multiplied by some reference factors to make its dimensions appropriate, otherwise SST would not give the same results for the same Reynolds obtained with different rho and mu.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205
Usability,simpl,simple,"I expect that epsilon to be a simple measure to avoid division by 0, if that lower bound had physical meaning it would have to be multiplied by some reference factors to make its dimensions appropriate, otherwise SST would not give the same results for the same Reynolds obtained with different rho and mu.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2284506205
Usability,intuit,intuitive,"Hi, . I'm not sure what ""new boundary conditions"" means. Is someone replacing the present far-field BC of the TKE and Omega? ; I recognize these ""new"" BCs as the ones given on the TMR (proposed in the original paper). I find the present setting in SU2 very comfortable and more ""intuitive"" than that given on the TMR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2307448209
Usability,clear,clearly,"I think the problem is in the fix for the symmetry boundary in PR #2194. I tried with the develop at the last commit (LC), at the commit before the implementation of the correction (BC) and at the commit of the implementation (AC). It is clearly visible that something is happening with the symmetry BC correction. I will look further into it. ![CommitsComparison_RMSRho](https://github.com/user-attachments/assets/7db41c0e-2885-4e66-bd1c-d01b038430bc). Also the profiles of the Mach number and nu_tilde are the same between LC and AC. With the BC instead the Mach number and nu_tilde are correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2370888175
Deployability,update,updates,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Energy Efficiency,energy,energy,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Modifiability,variab,variables,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Safety,predict,prediction,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Testability,test,test,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Usability,simpl,simply,"I have a few updates. I found out that most of my FGMRES problems in this branch where related to the fact that I was using single precision for the linear system. You can see it in this graphs for the residuals of Rho. ![RMSRho_Mesh_3](https://github.com/user-attachments/assets/185b8195-e415-4dff-9332-cff573c069cc). The first two curves are in mixed-precision and they stop long before reaching the minimum residual required due to divergence of the linear solver. Moreover, it seems that the 2003 model here implemented (which, simply put, considers the full reynolds stress tensor for the computation of the production of k and always considers k in the stress tensor and in the thermodynamic variables) has faster convergence and increases the recirculating zone (maybe due to the reduction of turbulence kinetic energy) which is a feature that has also been seen in [DOI:10.1017/aer.2020.93]. . ![SFC_Mesh_3](https://github.com/user-attachments/assets/81a50021-6b58-4a84-9057-a18b5bab023c). There are some differences between the use of the TMR boundary conditions and the ones used before. The results improve with respect to the develop in the prediction of the SFC distribution, which has results completely off from the V&V page of SU2. ![SFC_Mesh_3_Old](https://github.com/user-attachments/assets/0f4d634b-df31-4f86-a324-d9f67947f1ff). ![RMSRho_Mesh_3_Old](https://github.com/user-attachments/assets/24d5c2f5-93fe-432f-82d9-c050a90f7339). I may keep on checking if the implementation of the v2003 model is correct or not by searching for other test cases (probably coming from DOI:10.1017/aer.2020.93).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2329#issuecomment-2393433487
Deployability,update,updated,"@kursatyurt Hello, thank you so much for the lead. Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay. Again, thank you for the lead!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761
Usability,simpl,simple,"@kursatyurt Hello, thank you so much for the lead. Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay. Again, thank you for the lead!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397639761
Availability,avail,available,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
Deployability,update,updated,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
Integrability,depend,dependency,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
Performance,perform,performant,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
Testability,test,test,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
Usability,simpl,simple,"> @kursatyurt Hello, thank you so much for the lead.; > ; > Our initial scope mostly involved writing our own kernels and I did explore some libraries at the start - I was planning on using CUSP as well but my main concern was its lack of being updated to the newly compatible versions of the toolkit. cuSolver and cuBLAS do exist, but I chose to go ahead with a ""simple"" kernel implementation to have more control. I also felt that if I could keep the block size of the grid in optimal territory then they could be just as fast as those options (please do correct me if my reading of the literature or the situation was incorrect). To learn the basics, it's a good idea, but for large-scale projects, I prefer using existing libraries if possible.; Those libraries generally exploit state-of-the-art solution like mixed-precision computing. A gaming GPU is not way faster than a good CPU in double precision, but way faster in single precision, most of them have 64:1 ratio, however server class GPU have 2:1 ratio. Also when available they use vendor libraries like cuBLAS or hipBLAS. It is always nice to have you only care about connection and somebody else handle the solver as performant as possible. In future probably they will provide more and more solvers and it will be automagically works. It is kind of light-weight too, not a huge dependency like Trilinos or PETSc. ; > ; > I was not aware of Ginkgo and I will surely give it a go and try to produce some comparative results. I am currently super busy for this month and will get to working on the code with some delay.; > ; > Again, thank you for the lead!. I can test on various GPUs (P100/V100/A100 and 4070Mobile) on single node multi-gpu etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/2346#issuecomment-2397803409
