id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:5150,Modifiability,variab,variable,5150," cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; global variable declaration to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:5907,Modifiability,variab,variable,5907,"mmandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie, not ``-filename.c``). To support this style of; argument, the CommandLine library allows for `positional`_ arguments to be; specified for the program. These positional argumen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:8549,Modifiability,extend,extended,8549,"). Command line; options default to being optional, so if we would like to require that the user; always specify an input filename, we would add the `cl::Required`_ flag, and we; could eliminate the `cl::init`_ modifier, like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::Required);. Again, the CommandLine library does not require the options to be specified in; any particular order, so the above declaration is equivalent to:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::Required, cl::desc(""<input file>""));. By simply adding the `cl::Required`_ flag, the CommandLine library will; automatically issue an error if the argument is not specified, which shifts all; of the command line option verification code out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:9491,Modifiability,variab,variables,9491,"ns above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevents it from being shown by the standard ""``-help``"" output (note; that it is still shown in the ""``-help-hidden``"" output). The CommandLine library uses a `different parser`_ for different data types.; For example, in the string case, the argument passed to the option is copied; literally into the content of the string variable... we obviously cannot do that; in the boolean case, however, so we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the following inputs:. ::. compiler -f # No value, 'Force' == true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value spec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:9991,Modifiability,variab,variable,9991,"gs: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevents it from being shown by the standard ""``-help``"" output (note; that it is still shown in the ""``-help-hidden``"" output). The CommandLine library uses a `different parser`_ for different data types.; For example, in the string case, the argument passed to the option is copied; literally into the content of the string variable... we obviously cannot do that; in the boolean case, however, so we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the following inputs:. ::. compiler -f # No value, 'Force' == true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:10204,Modifiability,variab,variable,10204,"e (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevents it from being shown by the standard ""``-help``"" output (note; that it is still shown in the ""``-help-hidden``"" output). The CommandLine library uses a `different parser`_ for different data types.; For example, in the string case, the argument passed to the option is copied; literally into the content of the string variable... we obviously cannot do that; in the boolean case, however, so we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the following inputs:. ::. compiler -f # No value, 'Force' == true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. U",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:12577,Modifiability,variab,variable,12577,"alar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:12753,Modifiability,variab,variable,12753,"iases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal str",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:13157,Modifiability,variab,variable,13157,"q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14296,Modifiability,variab,variables,14296," ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15070,Modifiability,variab,variable,15070,"ld specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15142,Modifiability,variab,variable,15142,"The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:17881,Modifiability,variab,variable,17881,"ther useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option name. For this case,; the code looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically change",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19820,Modifiability,variab,variable,19820,"vel declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes severa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:20148,Modifiability,variab,variable,20148,"types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21032,Modifiability,variab,variable,21032," ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:29374,Modifiability,variab,variables,29374,"'``--``' marker. When the user specifies '``--``' on the; command line, it is telling the program that all options after the '``--``'; should be treated as positional arguments, not options. Thus, we can use it; like this:. ::. $ spiffygrep -- -foo test.txt; ...output... Determining absolute position with getPosition(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes an option can affect or modify the meaning of another option. For; example, consider ``gcc``'s ``-x LANG`` option. This tells ``gcc`` to ignore the; suffix of subsequent positional arguments and force the file to be interpreted; as if it contained source code in language ``LANG``. In order to handle this; properly, you need to know the absolute position of each argument, especially; those in lists, so their interaction(s) can be applied correctly. This is also; useful for options like ``-llibname`` which is actually a positional argument; that starts with a dash. So, generally, the problem is that you have two ``cl::list`` variables that; interact in some way. To ensure the correct interaction, you can use the; ``cl::list::getPosition(optnum)`` method. This method returns the absolute; position (as found on the command line) of the ``optnum`` item in the; ``cl::list``. The idiom for usage is like this:. .. code-block:: c++. static cl::list<std::string> Files(cl::Positional, cl::OneOrMore);; static cl::list<std::string> Libraries(""l"");. int main(int argc, char**argv) {; // ...; std::vector<std::string>::iterator fileIt = Files.begin();; std::vector<std::string>::iterator libIt = Libraries.begin();; unsigned libPos = 0, filePos = 0;; while ( 1 ) {; if ( libIt != Libraries.end() ); libPos = Libraries.getPosition( libIt - Libraries.begin() );; else; libPos = 0;; if ( fileIt != Files.end() ); filePos = Files.getPosition( fileIt - Files.begin() );; else; filePos = 0;. if ( filePos != 0 && (libPos == 0 || filePos < libPos) ) {; // Source File Is next; ++fileIt;; }; else if ( libPos != 0 && (filePos ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:32325,Modifiability,variab,variable,32325,"in/sh``). To run ``/bin/sh``, first you specify options; to the shell itself (like ``-x`` which turns on trace output), then you specify; the name of the script to run, then you specify arguments to the script. These; arguments to the script are parsed by the Bourne shell command line option; processor, but are not interpreted as options to the shell itself. Using the; CommandLine library, we would specify this as:. .. code-block:: c++. cl::opt<string> Script(cl::Positional, cl::desc(""<input script>""), cl::init(""-""));; cl::list<string> Argv(cl::ConsumeAfter, cl::desc(""<program arguments>...""));; cl::opt<bool> Trace(""x"", cl::desc(""Enable trace output""));. which automatically provides the help output:. ::. USAGE: spiffysh [options] <input script> <program arguments>... OPTIONS:; -help - display available options (-help-hidden for more); -x - Enable trace output. At runtime, if we run our new shell replacement as ```spiffysh -x test.sh -a -x; -y bar``', the ``Trace`` variable will be set to true, the ``Script`` variable; will be set to ""``test.sh``"", and the ``Argv`` list will contain ``[""-a"", ""-x"",; ""-y"", ""bar""]``, because they were specified after the last positional argument; (which is the script name). There are several limitations to when ``cl::ConsumeAfter`` options can be; specified. For example, only one ``cl::ConsumeAfter`` can be specified per; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:32370,Modifiability,variab,variable,32370,"in/sh``). To run ``/bin/sh``, first you specify options; to the shell itself (like ``-x`` which turns on trace output), then you specify; the name of the script to run, then you specify arguments to the script. These; arguments to the script are parsed by the Bourne shell command line option; processor, but are not interpreted as options to the shell itself. Using the; CommandLine library, we would specify this as:. .. code-block:: c++. cl::opt<string> Script(cl::Positional, cl::desc(""<input script>""), cl::init(""-""));; cl::list<string> Argv(cl::ConsumeAfter, cl::desc(""<program arguments>...""));; cl::opt<bool> Trace(""x"", cl::desc(""Enable trace output""));. which automatically provides the help output:. ::. USAGE: spiffysh [options] <input script> <program arguments>... OPTIONS:; -help - display available options (-help-hidden for more); -x - Enable trace output. At runtime, if we run our new shell replacement as ```spiffysh -x test.sh -a -x; -y bar``', the ``Trace`` variable will be set to true, the ``Script`` variable; will be set to ""``test.sh``"", and the ``Argv`` list will contain ``[""-a"", ""-x"",; ""-y"", ""bar""]``, because they were specified after the last positional argument; (which is the script name). There are several limitations to when ``cl::ConsumeAfter`` options can be; specified. For example, only one ``cl::ConsumeAfter`` can be specified per; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:44777,Modifiability,extend,extending,44777,"quired`_ modifier. .. _cl::ValueRequired:. * The **cl::ValueRequired** modifier (which is the default for all other types; except for `unnamed alternatives using the generic parser`_) specifies that a; value must be provided. This mode informs the command line library that if an; option is not provides with an equal sign, that the next argument provided; must be the value. This allows things like '``-o a.out``' to work. .. _cl::ValueDisallowed:. * The **cl::ValueDisallowed** modifier (which is the default for `unnamed; alternatives using the generic parser`_) indicates that it is a runtime error; for the user to specify a value. This can be provided to disallow users from; providing options to boolean options (like '``-foo=true``'). In general, the default values for this option group work just like you would; want them to. As mentioned above, you can specify the `cl::ValueDisallowed`_; modifier to a boolean argument to restrict your command line parser. These; options are mostly useful when `extending the library`_. .. _formatting option:. Controlling other formatting options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The formatting option group is used to specify that the command line option has; special abilities and is otherwise different from other command line arguments.; As usual, you can only specify one of these arguments at most. .. _cl::NormalFormatting:. * The **cl::NormalFormatting** modifier (which is the default all options); specifies that this option is ""normal"". .. _cl::Positional:. * The **cl::Positional** modifier specifies that this is a positional argument; that does not have a command line option associated with it. See the; `Positional Arguments`_ section for more information. * The **cl::ConsumeAfter** modifier specifies that this option is used to; capture ""interpreter style"" arguments. See `this section for more; information`_. .. _prefix:; .. _cl::Prefix:. * The **cl::Prefix** modifier specifies that this option prefixes its value.; With 'Pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:53203,Modifiability,variab,variables,53203,"tions"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is designed to be called directly from; ``main`` and *before* ``cl::ParseCommandLineOptions``. Its use is optional. It; simply arranges for a function to be called in response to the ``--version``; option instead of having the ``CommandLine`` library print out the usual version; string for LLVM. This is useful for programs that are not part of LLVM but wish; to use the ``CommandLine`` facilities. Such programs should just define a small; function that takes no arguments and returns ``void`` and that prints out; whatever version information i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:59187,Modifiability,extend,extended,59187,"to the constructor as ``const char*``. Note that declaring an option category and associating it with an option before; parsing options (e.g. statically) will change the output of ``-help`` from; uncategorized to categorized. If an option category is declared but not; associated with an option then it will be hidden from the output of ``-help``. .. _different parser:; .. _discussed previously:. Builtin parsers; ---------------. Parsers control how the string value taken from the command line is translated; into a typed value, suitable for use in a C++ program. By default, the; CommandLine library uses an instance of ``parser<type>`` if the command line; option specifies that it uses values of type '``type``'. Because of this,; custom option processing is specified with specializations of the '``parser``'; class. The CommandLine library provides the following builtin parser specializations,; which are sufficient for most applications. It can, however, also be extended to; work with new data types and new ways of interpreting the same data. See the; `Writing a Custom Parser`_ for more details on this type of library extension. .. _enums:; .. _cl::parser:. * The generic ``parser<t>`` parser can be used to map strings values to any data; type, through the use of the `cl::values`_ property, which specifies the; mapping information. The most common use of this parser is for parsing enum; values, which allows you to use the CommandLine library for all of the error; checking to make sure that only valid enum values are specified (as opposed to; accepting arbitrary strings). Despite this, however, the generic parser class; can be used for any data type. .. _boolean flags:; .. _bool parser:. * The **parser<bool> specialization** is used to convert boolean strings to a; boolean value. Currently accepted strings are ""``true``"", ""``TRUE``"",; ""``True``"", ""``1``"", ""``false``"", ""``FALSE``"", ""``False``"", and ""``0``"". * The **parser<boolOrDefault> specialization** is used for cases wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:63590,Modifiability,inherit,inherits,63590,"rks well in situations where you would line to parse an; option using special syntax for a not-very-special data-type. The drawback; of this approach is that users of your parser have to be aware that they are; using your parser instead of the builtin ones. To guide the discussion, we will discuss a custom parser that accepts file; sizes, specified with an optional unit after the numeric size. For example, we; would like to parse ""102kb"", ""41M"", ""1G"" into the appropriate integer value. In; this case, the underlying data type we want to parse into is '``unsigned``'. We; choose approach #2 above because we don't want to make this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leavin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:63922,Modifiability,variab,variables,63922,"e discussion, we will discuss a custom parser that accepts file; sizes, specified with an optional unit after the numeric size. For example, we; would like to parse ""102kb"", ""41M"", ""1G"" into the appropriate integer value. In; this case, the underlying data type we want to parse into is '``unsigned``'. We; choose approach #2 above because we don't want to make this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1186,Performance,perform,performance,1186,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2022,Performance,load,loaded,2022,"ditionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:13847,Performance,optimiz,optimization,13847,"again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:13874,Performance,optimiz,optimizer,13874,"again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14728,Performance,optimiz,optimization,14728," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14783,Performance,optimiz,optimizations,14783," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14849,Performance,optimiz,optimizations,14849," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14897,Performance,optimiz,optimizations,14897," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14947,Performance,optimiz,optimizations,14947," we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15571,Performance,optimiz,optimization,15571," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15600,Performance,optimiz,optimizations,15600," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15654,Performance,optimiz,optimizations,15654," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15690,Performance,optimiz,optimizations,15690," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15728,Performance,optimiz,optimizations,15728," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16280,Performance,optimiz,optimization,16280,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16344,Performance,optimiz,optimizations,16344,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16411,Performance,optimiz,optimizations,16411,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16460,Performance,optimiz,optimizations,16460,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16511,Performance,optimiz,optimizations,16511,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:17319,Performance,optimiz,optimization,17319,"alN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option name. For this case,; the code looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18153,Performance,optimiz,optimization,18153,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18182,Performance,optimiz,optimizations,18182,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18236,Performance,optimiz,optimizations,18236,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18272,Performance,optimiz,optimizations,18272,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18310,Performance,optimiz,optimizations,18310,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18757,Performance,optimiz,optimization,18757," debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your """,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19259,Performance,optimiz,optimizer,19259," -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19294,Performance,optimiz,optimizations,19294," -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19311,Performance,perform,perform,19311," -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19614,Performance,optimiz,optimizations,19614,"ut filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One es",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19651,Performance,perform,perform,19651,"ut filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One es",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:25948,Performance,tune,tune,25948,"`-help`` will become categorized if an option category is; declared. The output looks something like ::. OVERVIEW: This is a small program to demo the LLVM CommandLine API; USAGE: Sample [options]. OPTIONS:. General options:. -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more). Stage Selection Options:; These control which stages are run. -E - Run preprocessor stage.; -c - Run all stages except linking. In addition to the behaviour of ``-help`` changing when an option category is; declared, the command line option ``-help-list`` becomes visible which will; print the command line options as uncategorized list. Note that Options that are not explicitly categorized will be placed in the; ``cl::getGeneralCategory()`` category. .. _Reference Guide:. Reference Guide; ===============. Now that you know the basics of how to use the CommandLine library, this section; will give you the detailed information you need to tune how command line options; work, as well as information on more ""advanced"" command line option processing; capabilities. .. _positional:; .. _positional argument:; .. _Positional Arguments:; .. _Positional arguments section:; .. _positional options:. Positional Arguments; --------------------. Positional arguments are those arguments that are not named, and are not; specified with a hyphen. Positional arguments should be used when an option is; specified by its position alone. For example, the standard Unix ``grep`` tool; takes a regular expression argument, and an optional filename to search through; (which defaults to standard input if a filename is not specified). Using the; CommandLine library, this would be specified as:. .. code-block:: c++. cl::opt<string> Regex (cl::Positional, cl::desc(""<regular expression>""), cl::Required);; cl::opt<string> Filename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. Given these two option declarations, the ``-help`` output fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:36141,Performance,tune,tune,36141,"Enable debug output""), cl::Hidden, cl::location(DebugFlag));. In the above example, we specify ""``true``"" as the second argument to the; `cl::opt`_ template, indicating that the template should not maintain a copy of; the value itself. In addition to this, we specify the `cl::location`_; attribute, so that ``DebugFlag`` is automatically set. Option Attributes; -----------------. This section describes the basic attributes that you can specify on options. * The option name attribute (which is required for all options, except; `positional options`_) specifies what the option name is. This option is; specified in simple double quotes:. .. code-block:: c++. cl::opt<bool> Quiet(""quiet"");. .. _cl::desc(...):. * The **cl::desc** attribute specifies a description for the option to be; shown in the ``-help`` output for the program. This attribute supports; multi-line descriptions with lines separated by '\n'. .. _cl::value_desc:. * The **cl::value_desc** attribute specifies a string that can be used to; fine tune the ``-help`` output for a command line option. Look `here`_ for an; example. .. _cl::init:. * The **cl::init** attribute specifies an initial value for a `scalar`_; option. If this attribute is not specified then the command line option value; defaults to the value created by the default constructor for the; type. .. warning::. If you specify both **cl::init** and **cl::location** for an option, you; must specify **cl::location** first, so that when the command-line parser; sees **cl::init**, it knows where to put the initial value. (You will get an; error at runtime if you don't put them in the right order.). .. _cl::location:. * The **cl::location** attribute where to store the value for a parsed command; line option if using external storage. See the section on `Internal vs; External Storage`_ for more information. .. _cl::aliasopt:. * The **cl::aliasopt** attribute specifies which option a `cl::alias`_ option is; an alias for. .. _cl::values:. * The **cl::values",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:60613,Performance,perform,performed,60613,"ser is for parsing enum; values, which allows you to use the CommandLine library for all of the error; checking to make sure that only valid enum values are specified (as opposed to; accepting arbitrary strings). Despite this, however, the generic parser class; can be used for any data type. .. _boolean flags:; .. _bool parser:. * The **parser<bool> specialization** is used to convert boolean strings to a; boolean value. Currently accepted strings are ""``true``"", ""``TRUE``"",; ""``True``"", ""``1``"", ""``false``"", ""``FALSE``"", ""``False``"", and ""``0``"". * The **parser<boolOrDefault> specialization** is used for cases where the value; is boolean, but we also need to know whether the option was specified at all.; boolOrDefault is an enum with 3 values, BOU_UNSET, BOU_TRUE and BOU_FALSE.; This parser accepts the same strings as **``parser<bool>``**. .. _strings:. * The **parser<string> specialization** simply stores the parsed string into the; string value specified. No conversion or modification of the data is; performed. .. _integers:; .. _int:. * The **parser<int> specialization** uses the C ``strtol`` function to parse the; string input. As such, it will accept a decimal number (with an optional '+'; or '-' prefix) which must start with a non-zero digit. It accepts octal; numbers, which are identified with a '``0``' prefix digit, and hexadecimal; numbers with a prefix of '``0x``' or '``0X``'. .. _doubles:; .. _float:; .. _double:. * The **parser<double>** and **parser<float> specializations** use the standard; C ``strtod`` function to convert floating point strings into floating point; values. As such, a broad range of string formats is supported, including; exponential notation (ex: ``1.7e15``) and properly supports locales. .. _Extension Guide:; .. _extending the library:. Extension Guide; ===============. Although the CommandLine library has a lot of functionality built into it; already (as discussed previously), one of its true strengths lie in its; extensibility. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:67136,Performance,load,loaded,67136,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:22001,Safety,redund,redundant,22001,":desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. To test to see if ``instsimplify`` was specified, we can use the ``cl:bits::isSet``; function:. .. code-block:: c++. if (OptimizationBits.isSet(instsimplify)) {; ...; }. It's also possible to get the raw bit vector using the ``cl::bits::getBits``; function:. .. code-block:: c++. unsigned bits = OptimizationBits.getBits();. Finally, if external storage is used, then the location specified must be of; **type** ``unsigned``. In all other ways a `cl::bits`_ option is equivalent to a; `cl::list`_ option. .. _additional extra text:. Adding f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1133,Security,access,accessed,1133,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1747,Security,access,accessible,1747,"#. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. La",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2156,Security,secur,security,2156," which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18007,Security,expose,exposed,18007,"that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option name. For this case,; the code looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most approp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:20235,Security,access,access,20235,"e want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21097,Security,access,accessing,21097,"rip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:33681,Security,access,accessible,33681,"; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however, it is nice to separate the command line option processing; code from the storage of the value parsed. For example, lets say that we have a; '``-debug``' option that we would like to use to enable debug information across; the entire body of our program. In this case, the boolean value controlling the; debug code should be globally accessible (in a header file, for example) yet the; command line option processing code should not be exposed to all of these; clients (requiring lots of .cpp files to ``#include CommandLine.h``). To do this, set up your .h file with your option, like this for example:. .. code-block:: c++. // DebugFlag.h - Get access to the '-debug' command line option; //. // DebugFlag - This boolean is set to true if the '-debug' command line option; // is specified. This should probably not be referenced directly, instead, use; // the DEBUG macro below.; //; extern bool DebugFlag;. // DEBUG macro - This macro should be used by code to emit debug information.; // In the '-debug' option is specified on the command line, and if this is a; // debug build, then the code specified as the option to the macro will be; // executed. Otherwise it will not be.; #ifdef NDEBUG; #define LLVM_DEBUG(X); #else; #define LLVM_DEBUG(X) do { if (DebugFlag) { X; } } while (0); #endif. This allows clients to blissfully use the ``LLVM_DEBUG()`` macro, or the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:33783,Security,expose,exposed,33783,"; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however, it is nice to separate the command line option processing; code from the storage of the value parsed. For example, lets say that we have a; '``-debug``' option that we would like to use to enable debug information across; the entire body of our program. In this case, the boolean value controlling the; debug code should be globally accessible (in a header file, for example) yet the; command line option processing code should not be exposed to all of these; clients (requiring lots of .cpp files to ``#include CommandLine.h``). To do this, set up your .h file with your option, like this for example:. .. code-block:: c++. // DebugFlag.h - Get access to the '-debug' command line option; //. // DebugFlag - This boolean is set to true if the '-debug' command line option; // is specified. This should probably not be referenced directly, instead, use; // the DEBUG macro below.; //; extern bool DebugFlag;. // DEBUG macro - This macro should be used by code to emit debug information.; // In the '-debug' option is specified on the command line, and if this is a; // debug build, then the code specified as the option to the macro will be; // executed. Otherwise it will not be.; #ifdef NDEBUG; #define LLVM_DEBUG(X); #else; #define LLVM_DEBUG(X) do { if (DebugFlag) { X; } } while (0); #endif. This allows clients to blissfully use the ``LLVM_DEBUG()`` macro, or the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:33994,Security,access,access,33994,"-----------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however, it is nice to separate the command line option processing; code from the storage of the value parsed. For example, lets say that we have a; '``-debug``' option that we would like to use to enable debug information across; the entire body of our program. In this case, the boolean value controlling the; debug code should be globally accessible (in a header file, for example) yet the; command line option processing code should not be exposed to all of these; clients (requiring lots of .cpp files to ``#include CommandLine.h``). To do this, set up your .h file with your option, like this for example:. .. code-block:: c++. // DebugFlag.h - Get access to the '-debug' command line option; //. // DebugFlag - This boolean is set to true if the '-debug' command line option; // is specified. This should probably not be referenced directly, instead, use; // the DEBUG macro below.; //; extern bool DebugFlag;. // DEBUG macro - This macro should be used by code to emit debug information.; // In the '-debug' option is specified on the command line, and if this is a; // debug build, then the code specified as the option to the macro will be; // executed. Otherwise it will not be.; #ifdef NDEBUG; #define LLVM_DEBUG(X); #else; #define LLVM_DEBUG(X) do { if (DebugFlag) { X; } } while (0); #endif. This allows clients to blissfully use the ``LLVM_DEBUG()`` macro, or the; ``DebugFlag`` explicitly if they want to. Now we just need to be able to set; the ``DebugFlag`` boolean when the option is set. To do this, we pass an; additional argument to our command line argument processor, and we specify where; to fill in with the `cl::location`_ attribute:. .. code-block",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:39085,Security,validat,validate,39085,"i_val:. * The **cl::multi_val** attribute specifies that this option takes has multiple; values (example: ``-sectalign segname sectname sectvalue``). This attribute; takes one unsigned argument - the number of values for the option. This; attribute is valid only on ``cl::list`` options (and will fail with compile; error if you try to use it with other option types). It is allowed to use all; of the usual modifiers on multi-valued options (besides; ``cl::ValueDisallowed``, obviously). .. _cl::cat:. * The **cl::cat** attribute specifies the option category that the option; belongs to. The category should be a `cl::OptionCategory`_ object. .. _cl::callback:. * The **cl::callback** attribute specifies a callback function that is; called when an option is seen, and can be used to set other options,; as in option B implies option A. If the option is a `cl::list`_,; and `cl::CommaSeparated`_ is also specified, the callback will fire; once for each value. This could be used to validate combinations or; selectively set other options. .. code-block:: c++. cl::opt<bool> OptA(""a"", cl::desc(""option a""));; cl::opt<bool> OptB(; ""b"", cl::desc(""option b -- This option turns on option a""),; cl::callback([&](const bool &) { OptA = true; }));; cl::list<std::string, cl::list<std::string>> List(; ""list"",; cl::desc(""option list -- This option turns on options a when ""; ""'foo' is included in list""),; cl::CommaSeparated,; cl::callback([&](const std::string &Str) {; if (Str == ""foo""); OptA = true;; }));. Option Modifiers; ----------------. Option modifiers are the flags and expressions that you pass into the; constructors for `cl::opt`_ and `cl::list`_. These modifiers give you the; ability to tweak how options are parsed and how ``-help`` output is generated to; fit your application well. These options fall into five main categories:. #. Hiding an option from ``-help`` output. #. Controlling the number of occurrences required and allowed. #. Controlling whether or not a value must be specifi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:51369,Security,access,access,51369,"^^^^^. Some systems, such as certain variants of Microsoft Windows and some older; Unices have a relatively low limit on command-line length. It is therefore; customary to use the so-called 'response files' to circumvent this; restriction. These files are mentioned on the command-line (using the ""@file""); syntax. The program reads these files and inserts the contents into argv,; thereby working around the command-line length limits. Top-Level Classes and Functions; -------------------------------. Despite all of the built-in flexibility, the CommandLine option library really; only consists of one function `cl::ParseCommandLineOptions`_ and three main; classes: `cl::opt`_, `cl::list`_, and `cl::alias`_. This section describes; these three classes in detail. .. _cl::getRegisteredOptions:. The ``cl::getRegisteredOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::getRegisteredOptions`` function is designed to give a programmer; access to declared non-positional command line options so that how they appear; in ``-help`` can be modified prior to calling `cl::ParseCommandLineOptions`_.; Note this method should not be called during any static initialisation because; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:51753,Security,access,access,51753,"to argv,; thereby working around the command-line length limits. Top-Level Classes and Functions; -------------------------------. Despite all of the built-in flexibility, the CommandLine option library really; only consists of one function `cl::ParseCommandLineOptions`_ and three main; classes: `cl::opt`_, `cl::list`_, and `cl::alias`_. This section describes; these three classes in detail. .. _cl::getRegisteredOptions:. The ``cl::getRegisteredOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::getRegisteredOptions`` function is designed to give a programmer; access to declared non-positional command line options so that how they appear; in ``-help`` can be modified prior to calling `cl::ParseCommandLineOptions`_.; Note this method should not be called during any static initialisation because; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescrip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:51835,Security,access,access,51835,"to argv,; thereby working around the command-line length limits. Top-Level Classes and Functions; -------------------------------. Despite all of the built-in flexibility, the CommandLine option library really; only consists of one function `cl::ParseCommandLineOptions`_ and three main; classes: `cl::opt`_, `cl::list`_, and `cl::alias`_. This section describes; these three classes in detail. .. _cl::getRegisteredOptions:. The ``cl::getRegisteredOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::getRegisteredOptions`` function is designed to give a programmer; access to declared non-positional command line options so that how they appear; in ``-help`` can be modified prior to calling `cl::ParseCommandLineOptions`_.; Note this method should not be called during any static initialisation because; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescrip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:62081,Security,validat,validating,62081,". _float:; .. _double:. * The **parser<double>** and **parser<float> specializations** use the standard; C ``strtod`` function to convert floating point strings into floating point; values. As such, a broad range of string formats is supported, including; exponential notation (ex: ``1.7e15``) and properly supports locales. .. _Extension Guide:; .. _extending the library:. Extension Guide; ===============. Although the CommandLine library has a lot of functionality built into it; already (as discussed previously), one of its true strengths lie in its; extensibility. This section discusses how the CommandLine library works under; the covers and illustrates how to do some simple, common, extensions. .. _Custom parsers:; .. _custom parser:; .. _Writing a Custom Parser:. Writing a custom parser; -----------------------. One of the simplest and most common extensions is the use of a custom parser.; As `discussed previously`_, parsers are the portion of the CommandLine library; that turns string input from the user into a particular parsed data type,; validating the input in the process. There are two ways to use a new parser:. #. Specialize the `cl::parser`_ template for your custom data type. This approach has the advantage that users of your custom data type will; automatically use your custom parser whenever they define an option with a; value type of your data type. The disadvantage of this approach is that it; doesn't work if your fundamental data type is something that is already; supported. #. Write an independent class, using it explicitly from options that need it. This approach works well in situations where you would line to parse an; option using special syntax for a not-very-special data-type. The drawback; of this approach is that users of your parser have to be aware that they are; using your parser instead of the builtin ones. To guide the discussion, we will discuss a custom parser that accepts file; sizes, specified with an optional unit after the numeric",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66853,Security,access,accessible,66853,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:14279,Testability,test,test,14279," ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; could easily implement this with boolean options like above, but there are; several problems with this strategy:. #. A user could specify more than one of the options at a time, for example,; ""``compiler -O3 -O2``"". The CommandLine library would not be able to catch; this erroneous input for us. #. We would have to test 4 different variables to see which ones are set. #. This doesn't map to the numeric levels that we want... so we cannot easily; see if some level >= ""``-O1``"" is enabled. To cope with these problems, we can use an enum value, and have the CommandLine; library fill it in with the appropriate level directly, which is used like this:. .. code-block:: c++. enum OptLevel {; g, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:22445,Testability,test,test,22445," of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. To test to see if ``instsimplify`` was specified, we can use the ``cl:bits::isSet``; function:. .. code-block:: c++. if (OptimizationBits.isSet(instsimplify)) {; ...; }. It's also possible to get the raw bit vector using the ``cl::bits::getBits``; function:. .. code-block:: c++. unsigned bits = OptimizationBits.getBits();. Finally, if external storage is used, then the location specified must be of; **type** ``unsigned``. In all other ways a `cl::bits`_ option is equivalent to a; `cl::list`_ option. .. _additional extra text:. Adding freeform text to help output; -----------------------------------. As our program grows and becomes more mature, we may decide to put summary; information about what it does into the help output. The help output is styled; to look similar to a Unix ``man`` page, providing concise information about a; program. Unix ``man`` pages, however often have a description about what the; program does. To add this to your CommandLine program, simply pass a third; argument to the `cl::ParseCommandLineOptions`_ call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:28048,Testability,test,test,28048,"n> <input file>. OPTIONS:; -help - display available options (-help-hidden for more). ... and the resultant program could be used just like the standard ``grep``; tool. Positional arguments are sorted by their order of construction. This means that; command line options will be ordered according to how they are listed in a .cpp; file, but will not have an ordering defined if the positional arguments are; defined in multiple .cpp files. The fix for this problem is simply to define; all of your positional arguments in one .cpp file. Specifying positional options with hyphens; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may want to specify a value to your positional argument that; starts with a hyphen (for example, searching for '``-foo``' in a file). At; first, you will have trouble doing this, because it will try to find an argument; named '``-foo``', and will fail (and single quotes will not save you). Note; that the system ``grep`` has the same problem:. ::. $ spiffygrep '-foo' test.txt; Unknown command line argument '-foo'. Try: spiffygrep -help'. $ grep '-foo' test.txt; grep: illegal option -- f; grep: illegal option -- o; grep: illegal option -- o; Usage: grep -hblcnsviw pattern file . . . The solution for this problem is the same for both your tool and the system; version: use the '``--``' marker. When the user specifies '``--``' on the; command line, it is telling the program that all options after the '``--``'; should be treated as positional arguments, not options. Thus, we can use it; like this:. ::. $ spiffygrep -- -foo test.txt; ...output... Determining absolute position with getPosition(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes an option can affect or modify the meaning of another option. For; example, consider ``gcc``'s ``-x LANG`` option. This tells ``gcc`` to ignore the; suffix of subsequent positional arguments and force the file to be interpreted; as if it contained source code in language ``LANG``. In order to han",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:28134,Testability,test,test,28134," and the resultant program could be used just like the standard ``grep``; tool. Positional arguments are sorted by their order of construction. This means that; command line options will be ordered according to how they are listed in a .cpp; file, but will not have an ordering defined if the positional arguments are; defined in multiple .cpp files. The fix for this problem is simply to define; all of your positional arguments in one .cpp file. Specifying positional options with hyphens; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may want to specify a value to your positional argument that; starts with a hyphen (for example, searching for '``-foo``' in a file). At; first, you will have trouble doing this, because it will try to find an argument; named '``-foo``', and will fail (and single quotes will not save you). Note; that the system ``grep`` has the same problem:. ::. $ spiffygrep '-foo' test.txt; Unknown command line argument '-foo'. Try: spiffygrep -help'. $ grep '-foo' test.txt; grep: illegal option -- f; grep: illegal option -- o; grep: illegal option -- o; Usage: grep -hblcnsviw pattern file . . . The solution for this problem is the same for both your tool and the system; version: use the '``--``' marker. When the user specifies '``--``' on the; command line, it is telling the program that all options after the '``--``'; should be treated as positional arguments, not options. Thus, we can use it; like this:. ::. $ spiffygrep -- -foo test.txt; ...output... Determining absolute position with getPosition(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes an option can affect or modify the meaning of another option. For; example, consider ``gcc``'s ``-x LANG`` option. This tells ``gcc`` to ignore the; suffix of subsequent positional arguments and force the file to be interpreted; as if it contained source code in language ``LANG``. In order to handle this; properly, you need to know the absolute position of each argument, especially; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:28610,Testability,test,test,28610,"tions with hyphens; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may want to specify a value to your positional argument that; starts with a hyphen (for example, searching for '``-foo``' in a file). At; first, you will have trouble doing this, because it will try to find an argument; named '``-foo``', and will fail (and single quotes will not save you). Note; that the system ``grep`` has the same problem:. ::. $ spiffygrep '-foo' test.txt; Unknown command line argument '-foo'. Try: spiffygrep -help'. $ grep '-foo' test.txt; grep: illegal option -- f; grep: illegal option -- o; grep: illegal option -- o; Usage: grep -hblcnsviw pattern file . . . The solution for this problem is the same for both your tool and the system; version: use the '``--``' marker. When the user specifies '``--``' on the; command line, it is telling the program that all options after the '``--``'; should be treated as positional arguments, not options. Thus, we can use it; like this:. ::. $ spiffygrep -- -foo test.txt; ...output... Determining absolute position with getPosition(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes an option can affect or modify the meaning of another option. For; example, consider ``gcc``'s ``-x LANG`` option. This tells ``gcc`` to ignore the; suffix of subsequent positional arguments and force the file to be interpreted; as if it contained source code in language ``LANG``. In order to handle this; properly, you need to know the absolute position of each argument, especially; those in lists, so their interaction(s) can be applied correctly. This is also; useful for options like ``-llibname`` which is actually a positional argument; that starts with a dash. So, generally, the problem is that you have two ``cl::list`` variables that; interact in some way. To ensure the correct interaction, you can use the; ``cl::list::getPosition(optnum)`` method. This method returns the absolute; position (as found on the command line) of the ``optnum`` item",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:32285,Testability,test,test,32285," example, lets say we are developing a replacement for the standard; Unix Bourne shell (``/bin/sh``). To run ``/bin/sh``, first you specify options; to the shell itself (like ``-x`` which turns on trace output), then you specify; the name of the script to run, then you specify arguments to the script. These; arguments to the script are parsed by the Bourne shell command line option; processor, but are not interpreted as options to the shell itself. Using the; CommandLine library, we would specify this as:. .. code-block:: c++. cl::opt<string> Script(cl::Positional, cl::desc(""<input script>""), cl::init(""-""));; cl::list<string> Argv(cl::ConsumeAfter, cl::desc(""<program arguments>...""));; cl::opt<bool> Trace(""x"", cl::desc(""Enable trace output""));. which automatically provides the help output:. ::. USAGE: spiffysh [options] <input script> <program arguments>... OPTIONS:; -help - display available options (-help-hidden for more); -x - Enable trace output. At runtime, if we run our new shell replacement as ```spiffysh -x test.sh -a -x; -y bar``', the ``Trace`` variable will be set to true, the ``Script`` variable; will be set to ""``test.sh``"", and the ``Argv`` list will contain ``[""-a"", ""-x"",; ""-y"", ""bar""]``, because they were specified after the last positional argument; (which is the script name). There are several limitations to when ``cl::ConsumeAfter`` options can be; specified. For example, only one ``cl::ConsumeAfter`` can be specified per; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:32398,Testability,test,test,32398,"in/sh``). To run ``/bin/sh``, first you specify options; to the shell itself (like ``-x`` which turns on trace output), then you specify; the name of the script to run, then you specify arguments to the script. These; arguments to the script are parsed by the Bourne shell command line option; processor, but are not interpreted as options to the shell itself. Using the; CommandLine library, we would specify this as:. .. code-block:: c++. cl::opt<string> Script(cl::Positional, cl::desc(""<input script>""), cl::init(""-""));; cl::list<string> Argv(cl::ConsumeAfter, cl::desc(""<program arguments>...""));; cl::opt<bool> Trace(""x"", cl::desc(""Enable trace output""));. which automatically provides the help output:. ::. USAGE: spiffysh [options] <input script> <program arguments>... OPTIONS:; -help - display available options (-help-hidden for more); -x - Enable trace output. At runtime, if we run our new shell replacement as ```spiffysh -x test.sh -a -x; -y bar``', the ``Trace`` variable will be set to true, the ``Script`` variable; will be set to ""``test.sh``"", and the ``Argv`` list will contain ``[""-a"", ""-x"",; ""-y"", ""bar""]``, because they were specified after the last positional argument; (which is the script name). There are several limitations to when ``cl::ConsumeAfter`` options can be; specified. For example, only one ``cl::ConsumeAfter`` can be specified per; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the common case,; especially when combined with the ability to define command line options in the; files that use them. This is called the internal storage model. Sometimes, however,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:52274,Testability,assert,assert,52274," ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::getRegisteredOptions`` function is designed to give a programmer; access to declared non-positional command line options so that how they appear; in ``-help`` can be modified prior to calling `cl::ParseCommandLineOptions`_.; Note this method should not be called during any static initialisation because; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are availa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:52472,Testability,assert,assert,52472,"lp`` can be modified prior to calling `cl::ParseCommandLineOptions`_.; Note this method should not be called during any static initialisation because; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:52619,Testability,assert,assert,52619,"e; it cannot be guaranteed that all options will have been initialised. Hence it; should be called from ``main``. This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is des",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:52727,Testability,assert,assert,52727,". This function can be used to gain access to options declared in libraries that; the tool writer may not have direct access to. The function retrieves a :ref:`StringMap <dss_stringmap>` that maps the option; string (e.g. ``-help``) to an ``Option*``. Here is an example of how the function could be used:. .. code-block:: c++. using namespace llvm;; int main(int argc, char **argv) {; cl::OptionCategory AnotherCategory(""Some options"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is designed to be called directly from; ``main`` and *before* ``cl::ParseCommandLineOptions``. Its use is optional. It;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65946,Testability,test,test,65946," 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65991,Testability,test,test,65991," 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66065,Testability,test,test,66065,"recognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66083,Testability,test,test,66083,"error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66130,Testability,test,test,66130,"ze argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66175,Testability,test,test,66175,"er for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2424,Usability,simpl,simple,2424,"cts, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2618,Usability,simpl,simple,2618,"apture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff wo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:3580,Usability,simpl,simple,3580,". Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine header file into your program:. .. code-block:: c++. #include ""llvm/Support/CommandLine.h"". Additionally, you need to add this as the first line of your main program:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:3716,Usability,simpl,simple,3716,"he command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine header file into your program:. .. code-block:: c++. #include ""llvm/Support/CommandLine.h"". Additionally, you need to add this as the first line of your main program:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; glob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:5286,Usability,simpl,simple,5286,"ine arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; global variable declaration to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:5942,Usability,usab,usable,5942,"mmandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie, not ``-filename.c``). To support this style of; argument, the CommandLine library allows for `positional`_ arguments to be; specified for the program. These positional argumen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:8115,Usability,simpl,simply,8115,"me. Here we use the `cl::init`_ option to specify an initial; value for the command line option, which is used if the option is not specified; (if you do not specify a `cl::init`_ modifier for an option, then the default; constructor for the data type is used to initialize the value). Command line; options default to being optional, so if we would like to require that the user; always specify an input filename, we would add the `cl::Required`_ flag, and we; could eliminate the `cl::init`_ modifier, like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::Required);. Again, the CommandLine library does not require the options to be specified in; any particular order, so the above declaration is equivalent to:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::Required, cl::desc(""<input file>""));. By simply adding the `cl::Required`_ flag, the CommandLine library will; automatically issue an error if the argument is not specified, which shifts all; of the command line option verification code out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11550,Usability,simpl,simple,11550,".. you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11603,Usability,simpl,simple,11603," Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Becaus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:12973,Usability,simpl,simply,12973,"ormationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer is that it uses a table-driven generic parser (unless you specify; your own parser, as described in the `Extension Guide`_). This parser maps; literal strings to whatever type is required, and requires you to tell it what; this mapping should be. Let's say that we would like to add four optimization levels to our optimizer,; using the standard flags ""``-g``"", ""``-O0``"", ""``-O1``"", and ""``-O2``"". We; co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21120,Usability,simpl,simple,21120,"rip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:23417,Usability,simpl,simply,23417,")));. To test to see if ``instsimplify`` was specified, we can use the ``cl:bits::isSet``; function:. .. code-block:: c++. if (OptimizationBits.isSet(instsimplify)) {; ...; }. It's also possible to get the raw bit vector using the ``cl::bits::getBits``; function:. .. code-block:: c++. unsigned bits = OptimizationBits.getBits();. Finally, if external storage is used, then the location specified must be of; **type** ``unsigned``. In all other ways a `cl::bits`_ option is equivalent to a; `cl::list`_ option. .. _additional extra text:. Adding freeform text to help output; -----------------------------------. As our program grows and becomes more mature, we may decide to put summary; information about what it does into the help output. The help output is styled; to look similar to a Unix ``man`` page, providing concise information about a; program. Unix ``man`` pages, however often have a description about what the; program does. To add this to your CommandLine program, simply pass a third; argument to the `cl::ParseCommandLineOptions`_ call in main. This additional; argument is then printed as the overview information for your program, allowing; you to include any additional information that you want. For example:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv, "" CommandLine compiler example\n\n""; "" This program blah blah blah...\n"");; ...; }. would yield the help output:. ::. **OVERVIEW: CommandLine compiler example. This program blah blah blah...**. USAGE: compiler [options] <input file>. OPTIONS:; ...; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. .. _grouping options into categories:. Grouping options into categories; --------------------------------. If our program has a large number of options it may become difficult for users; of our tool to navigate the output of ``-help``. To alleviate this problem we; can put our options into categories. This can be done by d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:27508,Usability,simpl,simply,27508," optional filename to search through; (which defaults to standard input if a filename is not specified). Using the; CommandLine library, this would be specified as:. .. code-block:: c++. cl::opt<string> Regex (cl::Positional, cl::desc(""<regular expression>""), cl::Required);; cl::opt<string> Filename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. Given these two option declarations, the ``-help`` output for our grep; replacement would look like this:. ::. USAGE: spiffygrep [options] <regular expression> <input file>. OPTIONS:; -help - display available options (-help-hidden for more). ... and the resultant program could be used just like the standard ``grep``; tool. Positional arguments are sorted by their order of construction. This means that; command line options will be ordered according to how they are listed in a .cpp; file, but will not have an ordering defined if the positional arguments are; defined in multiple .cpp files. The fix for this problem is simply to define; all of your positional arguments in one .cpp file. Specifying positional options with hyphens; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may want to specify a value to your positional argument that; starts with a hyphen (for example, searching for '``-foo``' in a file). At; first, you will have trouble doing this, because it will try to find an argument; named '``-foo``', and will fail (and single quotes will not save you). Note; that the system ``grep`` has the same problem:. ::. $ spiffygrep '-foo' test.txt; Unknown command line argument '-foo'. Try: spiffygrep -help'. $ grep '-foo' test.txt; grep: illegal option -- f; grep: illegal option -- o; grep: illegal option -- o; Usage: grep -hblcnsviw pattern file . . . The solution for this problem is the same for both your tool and the system; version: use the '``--``' marker. When the user specifies '``--``' on the; command line, it is telling the program that all options after the '``--``'; should be treated as positi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:35744,Usability,simpl,simple,35744,"tly if they want to. Now we just need to be able to set; the ``DebugFlag`` boolean when the option is set. To do this, we pass an; additional argument to our command line argument processor, and we specify where; to fill in with the `cl::location`_ attribute:. .. code-block:: c++. bool DebugFlag; // the actual value; static cl::opt<bool, true> // The parser; Debug(""debug"", cl::desc(""Enable debug output""), cl::Hidden, cl::location(DebugFlag));. In the above example, we specify ""``true``"" as the second argument to the; `cl::opt`_ template, indicating that the template should not maintain a copy of; the value itself. In addition to this, we specify the `cl::location`_; attribute, so that ``DebugFlag`` is automatically set. Option Attributes; -----------------. This section describes the basic attributes that you can specify on options. * The option name attribute (which is required for all options, except; `positional options`_) specifies what the option name is. This option is; specified in simple double quotes:. .. code-block:: c++. cl::opt<bool> Quiet(""quiet"");. .. _cl::desc(...):. * The **cl::desc** attribute specifies a description for the option to be; shown in the ``-help`` output for the program. This attribute supports; multi-line descriptions with lines separated by '\n'. .. _cl::value_desc:. * The **cl::value_desc** attribute specifies a string that can be used to; fine tune the ``-help`` output for a command line option. Look `here`_ for an; example. .. _cl::init:. * The **cl::init** attribute specifies an initial value for a `scalar`_; option. If this attribute is not specified then the command line option value; defaults to the value created by the default constructor for the; type. .. warning::. If you specify both **cl::init** and **cl::location** for an option, you; must specify **cl::location** first, so that when the command-line parser; sees **cl::init**, it knows where to put the initial value. (You will get an; error at runtime if you don't put th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:37525,Usability,simpl,simple,37525,"on** for an option, you; must specify **cl::location** first, so that when the command-line parser; sees **cl::init**, it knows where to put the initial value. (You will get an; error at runtime if you don't put them in the right order.). .. _cl::location:. * The **cl::location** attribute where to store the value for a parsed command; line option if using external storage. See the section on `Internal vs; External Storage`_ for more information. .. _cl::aliasopt:. * The **cl::aliasopt** attribute specifies which option a `cl::alias`_ option is; an alias for. .. _cl::values:. * The **cl::values** attribute specifies the string-to-value mapping to be used; by the generic parser. It takes a list of (option, value, description); triplets that specify the option name, the value mapped to, and the; description shown in the ``-help`` for the tool. Because the generic parser; is used most frequently with enum values, two macros are often useful:. #. The **clEnumVal** macro is used as a nice simple way to specify a triplet; for an enum. This macro automatically makes the option name be the same as; the enum name. The first option to the macro is the enum, the second is; the description for the command line option. #. The **clEnumValN** macro is used to specify macro options where the option; name doesn't equal the enum name. For this macro, the first argument is; the enum value, the second is the flag name, and the second is the; description. You will get a compile time error if you try to use cl::values with a parser; that does not support it. .. _cl::multi_val:. * The **cl::multi_val** attribute specifies that this option takes has multiple; values (example: ``-sectalign segname sectname sectvalue``). This attribute; takes one unsigned argument - the number of values for the option. This; attribute is valid only on ``cl::list`` options (and will fail with compile; error if you try to use it with other option types). It is allowed to use all; of the usual modifiers on mult",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:53719,Usability,simpl,simply,53719,"l::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is designed to be called directly from; ``main`` and *before* ``cl::ParseCommandLineOptions``. Its use is optional. It; simply arranges for a function to be called in response to the ``--version``; option instead of having the ``CommandLine`` library print out the usual version; string for LLVM. This is useful for programs that are not part of LLVM but wish; to use the ``CommandLine`` facilities. Such programs should just define a small; function that takes no arguments and returns ``void`` and that prints out; whatever version information is appropriate for the program. Pass the address of; that function to ``cl::SetVersionPrinter`` to arrange for it to be called when; the ``--version`` option is given by the user. .. _cl::opt:; .. _scalar:. The ``cl::opt`` class; ^^^^^^^^^^^^^^^^^^^^^. The ``cl::opt`` class is the class used to represent scalar command line; options, and is the one used most of the time. It is a templated class which; can take up to three arguments (all except for the first have default values; though):. .. code-block:: c++. namespace cl {; template <class DataType, bool ExternalStorage = false,; class ParserClass = parser<DataType> >; class opt;; }. The first template",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:57408,Usability,simpl,simply,57408,"late <class DataType, class Storage = bool,; class ParserClass = parser<DataType> >; class bits;; }. This class works the exact same as the `cl::list`_ class, except that the second; argument must be of **type** ``unsigned`` if external storage is used. .. _cl::alias:. The ``cl::alias`` class; ^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::alias`` class is a nontemplated class that is used to form aliases for; other arguments. .. code-block:: c++. namespace cl {; class alias;; }. The `cl::aliasopt`_ attribute should be used to specify which option this is an; alias for. Alias arguments default to being `cl::Hidden`_, and use the aliased; options parser to do the conversion from string to data. .. _cl::extrahelp:. The ``cl::extrahelp`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::extrahelp`` class is a nontemplated class that allows extra help text; to be printed out for the ``-help`` option. .. code-block:: c++. namespace cl {; struct extrahelp;; }. To use the extrahelp, simply construct one with a ``const char*`` parameter to; the constructor. The text passed to the constructor will be printed at the; bottom of the help message, verbatim. Note that multiple ``cl::extrahelp``; **can** be used, but this practice is discouraged. If your tool needs to print; additional help information, put all that help into a single ``cl::extrahelp``; instance. For example:. .. code-block:: c++. cl::extrahelp(""\nADDITIONAL HELP:\n\n This is the extra help\n"");. .. _cl::OptionCategory:. The ``cl::OptionCategory`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::OptionCategory`` class is a simple class for declaring; option categories. .. code-block:: c++. namespace cl {; class OptionCategory;; }. An option category must have a name and optionally a description which are; passed to the constructor as ``const char*``. Note that declaring an option category and associating it with an option before; parsing options (e.g. statically) will change the output of ``-help`` from; uncategorized to categor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:58021,Usability,simpl,simple,58021," being `cl::Hidden`_, and use the aliased; options parser to do the conversion from string to data. .. _cl::extrahelp:. The ``cl::extrahelp`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::extrahelp`` class is a nontemplated class that allows extra help text; to be printed out for the ``-help`` option. .. code-block:: c++. namespace cl {; struct extrahelp;; }. To use the extrahelp, simply construct one with a ``const char*`` parameter to; the constructor. The text passed to the constructor will be printed at the; bottom of the help message, verbatim. Note that multiple ``cl::extrahelp``; **can** be used, but this practice is discouraged. If your tool needs to print; additional help information, put all that help into a single ``cl::extrahelp``; instance. For example:. .. code-block:: c++. cl::extrahelp(""\nADDITIONAL HELP:\n\n This is the extra help\n"");. .. _cl::OptionCategory:. The ``cl::OptionCategory`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::OptionCategory`` class is a simple class for declaring; option categories. .. code-block:: c++. namespace cl {; class OptionCategory;; }. An option category must have a name and optionally a description which are; passed to the constructor as ``const char*``. Note that declaring an option category and associating it with an option before; parsing options (e.g. statically) will change the output of ``-help`` from; uncategorized to categorized. If an option category is declared but not; associated with an option then it will be hidden from the output of ``-help``. .. _different parser:; .. _discussed previously:. Builtin parsers; ---------------. Parsers control how the string value taken from the command line is translated; into a typed value, suitable for use in a C++ program. By default, the; CommandLine library uses an instance of ``parser<type>`` if the command line; option specifies that it uses values of type '``type``'. Because of this,; custom option processing is specified with specializations of the '``parse",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:60501,Usability,simpl,simply,60501,"operty, which specifies the; mapping information. The most common use of this parser is for parsing enum; values, which allows you to use the CommandLine library for all of the error; checking to make sure that only valid enum values are specified (as opposed to; accepting arbitrary strings). Despite this, however, the generic parser class; can be used for any data type. .. _boolean flags:; .. _bool parser:. * The **parser<bool> specialization** is used to convert boolean strings to a; boolean value. Currently accepted strings are ""``true``"", ""``TRUE``"",; ""``True``"", ""``1``"", ""``false``"", ""``FALSE``"", ""``False``"", and ""``0``"". * The **parser<boolOrDefault> specialization** is used for cases where the value; is boolean, but we also need to know whether the option was specified at all.; boolOrDefault is an enum with 3 values, BOU_UNSET, BOU_TRUE and BOU_FALSE.; This parser accepts the same strings as **``parser<bool>``**. .. _strings:. * The **parser<string> specialization** simply stores the parsed string into the; string value specified. No conversion or modification of the data is; performed. .. _integers:; .. _int:. * The **parser<int> specialization** uses the C ``strtol`` function to parse the; string input. As such, it will accept a decimal number (with an optional '+'; or '-' prefix) which must start with a non-zero digit. It accepts octal; numbers, which are identified with a '``0``' prefix digit, and hexadecimal; numbers with a prefix of '``0x``' or '``0X``'. .. _doubles:; .. _float:; .. _double:. * The **parser<double>** and **parser<float> specializations** use the standard; C ``strtod`` function to convert floating point strings into floating point; values. As such, a broad range of string formats is supported, including; exponential notation (ex: ``1.7e15``) and properly supports locales. .. _Extension Guide:; .. _extending the library:. Extension Guide; ===============. Although the CommandLine library has a lot of functionality built into it; already (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:61698,Usability,simpl,simple,61698,"arser<int> specialization** uses the C ``strtol`` function to parse the; string input. As such, it will accept a decimal number (with an optional '+'; or '-' prefix) which must start with a non-zero digit. It accepts octal; numbers, which are identified with a '``0``' prefix digit, and hexadecimal; numbers with a prefix of '``0x``' or '``0X``'. .. _doubles:; .. _float:; .. _double:. * The **parser<double>** and **parser<float> specializations** use the standard; C ``strtod`` function to convert floating point strings into floating point; values. As such, a broad range of string formats is supported, including; exponential notation (ex: ``1.7e15``) and properly supports locales. .. _Extension Guide:; .. _extending the library:. Extension Guide; ===============. Although the CommandLine library has a lot of functionality built into it; already (as discussed previously), one of its true strengths lie in its; extensibility. This section discusses how the CommandLine library works under; the covers and illustrates how to do some simple, common, extensions. .. _Custom parsers:; .. _custom parser:; .. _Writing a Custom Parser:. Writing a custom parser; -----------------------. One of the simplest and most common extensions is the use of a custom parser.; As `discussed previously`_, parsers are the portion of the CommandLine library; that turns string input from the user into a particular parsed data type,; validating the input in the process. There are two ways to use a new parser:. #. Specialize the `cl::parser`_ template for your custom data type. This approach has the advantage that users of your custom data type will; automatically use your custom parser whenever they define an option with a; value type of your data type. The disadvantage of this approach is that it; doesn't work if your fundamental data type is something that is already; supported. #. Write an independent class, using it explicitly from options that need it. This approach works well in situations wher",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:61858,Usability,simpl,simplest,61858,"bers, which are identified with a '``0``' prefix digit, and hexadecimal; numbers with a prefix of '``0x``' or '``0X``'. .. _doubles:; .. _float:; .. _double:. * The **parser<double>** and **parser<float> specializations** use the standard; C ``strtod`` function to convert floating point strings into floating point; values. As such, a broad range of string formats is supported, including; exponential notation (ex: ``1.7e15``) and properly supports locales. .. _Extension Guide:; .. _extending the library:. Extension Guide; ===============. Although the CommandLine library has a lot of functionality built into it; already (as discussed previously), one of its true strengths lie in its; extensibility. This section discusses how the CommandLine library works under; the covers and illustrates how to do some simple, common, extensions. .. _Custom parsers:; .. _custom parser:; .. _Writing a Custom Parser:. Writing a custom parser; -----------------------. One of the simplest and most common extensions is the use of a custom parser.; As `discussed previously`_, parsers are the portion of the CommandLine library; that turns string input from the user into a particular parsed data type,; validating the input in the process. There are two ways to use a new parser:. #. Specialize the `cl::parser`_ template for your custom data type. This approach has the advantage that users of your custom data type will; automatically use your custom parser whenever they define an option with a; value type of your data type. The disadvantage of this approach is that it; doesn't work if your fundamental data type is something that is already; supported. #. Write an independent class, using it explicitly from options that need it. This approach works well in situations where you would line to parse an; option using special syntax for a not-very-special data-type. The drawback; of this approach is that users of your parser have to be aware that they are; using your parser instead of the builtin on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:62892,Usability,guid,guide,62892,"sers are the portion of the CommandLine library; that turns string input from the user into a particular parsed data type,; validating the input in the process. There are two ways to use a new parser:. #. Specialize the `cl::parser`_ template for your custom data type. This approach has the advantage that users of your custom data type will; automatically use your custom parser whenever they define an option with a; value type of your data type. The disadvantage of this approach is that it; doesn't work if your fundamental data type is something that is already; supported. #. Write an independent class, using it explicitly from options that need it. This approach works well in situations where you would line to parse an; option using special syntax for a not-very-special data-type. The drawback; of this approach is that users of your parser have to be aware that they are; using your parser instead of the builtin ones. To guide the discussion, we will discuss a custom parser that accepts file; sizes, specified with an optional unit after the numeric size. For example, we; would like to parse ""102kb"", ""41M"", ""1G"" into the appropriate integer value. In; this case, the underlying data type we want to parse into is '``unsigned``'. We; choose approach #2 above because we don't want to make this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65209,Usability,simpl,simple,65209,"o parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1240,Availability,reliab,reliable,1240,"ails about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2416,Availability,error,errors,2416,"on via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently su",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:5815,Availability,avail,available,5815,"lents, but because the intermediate result in an fma is not rounded,; this flag can affect numerical code. * ``-fcuda-flush-denormals-to-zero`` (default: off) When this is enabled,; floating point operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6079,Availability,avail,available,6079,"dia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6160,Availability,avail,available,6160,"; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6268,Availability,avail,available,6268,"; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6466,Availability,error,error,6466,"ag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6510,Availability,avail,available,6510,"ag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6724,Availability,error,error,6724,"th`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; proces",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:11462,Availability,robust,robust,11462," this step is a ``ptx`` file ``P_arch``. * Invoke ``ptxas`` to generate a SASS file, ``S_arch``. Note that, unlike; nvcc, clang always generates SASS code. * Invoke ``fatbin`` to combine all ``P_arch`` and ``S_arch`` files into a; single fat binary file, ``F``. * Compile ``H`` using clang. ``__device__`` code is parsed and must be; semantically correct, even though we're not generating code for the device; at this time. ``F`` is passed to this compilation, and clang includes it in a special ELF; section, where it can be found by tools like ``cuobjdump``. (You may ask at this point, why does clang need to parse the input file; multiple times? Why not parse it just once, and then use the AST to generate; code for the host and each device architecture?. Unfortunately this can't work because we have to define different macros during; host compilation and during device compilation for each GPU architecture.). clang's approach allows it to be highly robust to C++ edge cases, as it doesn't; need to decide at an early stage which declarations to keep and which to throw; away. But it has some consequences you should be aware of. Overloading Based on ``__host__`` and ``__device__`` Attributes; ---------------------------------------------------------------. Let ""H"", ""D"", and ""HD"" stand for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12075,Availability,error,error,12075,"se the input file; multiple times? Why not parse it just once, and then use the AST to generate; code for the host and each device architecture?. Unfortunately this can't work because we have to define different macros during; host compilation and during device compilation for each GPU architecture.). clang's approach allows it to be highly robust to C++ edge cases, as it doesn't; need to decide at an early stage which declarations to keep and which to throw; away. But it has some consequences you should be aware of. Overloading Based on ``__host__`` and ``__device__`` Attributes; ---------------------------------------------------------------. Let ""H"", ""D"", and ""HD"" stand for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12293,Availability,error,error,12293,"fine different macros during; host compilation and during device compilation for each GPU architecture.). clang's approach allows it to be highly robust to C++ edge cases, as it doesn't; need to decide at an early stage which declarations to keep and which to throw; away. But it has some consequences you should be aware of. Overloading Based on ``__host__`` and ``__device__`` Attributes; ---------------------------------------------------------------. Let ""H"", ""D"", and ""HD"" stand for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12564,Availability,error,error,12564,"ay. But it has some consequences you should be aware of. Overloading Based on ``__host__`` and ``__device__`` Attributes; ---------------------------------------------------------------. Let ""H"", ""D"", and ""HD"" stand for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer to call other Ds. HDs are given lower priority. * Similarly, H functions prefer to call other Hs, or ``__global__`` functions; (with equal priority). HDs are given lower priority. * HD functions prefer to call other HDs. When compiling for device, HDs will call Ds wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12731,Availability,error,error,12731,"for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer to call other Ds. HDs are given lower priority. * Similarly, H functions prefer to call other Hs, or ``__global__`` functions; (with equal priority). HDs are given lower priority. * HD functions prefer to call other HDs. When compiling for device, HDs will call Ds with lower priority than HD, and; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example bel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12790,Availability,error,error,12790,"for ""``__host__`` functions"", ""``__device__``; functions"", and ""``__host__ __device__`` functions"", respectively. Functions; with no attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer to call other Ds. HDs are given lower priority. * Similarly, H functions prefer to call other Hs, or ``__global__`` functions; (with equal priority). HDs are given lower priority. * HD functions prefer to call other HDs. When compiling for device, HDs will call Ds with lower priority than HD, and; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example bel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12894,Availability,error,error,12894,"o attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer to call other Ds. HDs are given lower priority. * Similarly, H functions prefer to call other Hs, or ``__global__`` functions; (with equal priority). HDs are given lower priority. * HD functions prefer to call other HDs. When compiling for device, HDs will call Ds with lower priority than HD, and; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:12914,Availability,error,error,12914,"o attributes behave the same as H. nvcc does not allow you to create H and D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; __host__ void foo() {}; __device__ void foo() {}. However, nvcc allows you to ""overload"" H and D functions with different; signatures:. .. code-block:: c++. // nvcc: no error; __host__ void foo(int) {}; __device__ void foo() {}. In clang, the ``__host__`` and ``__device__`` attributes are part of a; function's signature, and so it's legal to have H and D functions with; (otherwise) the same signature:. .. code-block:: c++. // clang: no error; __host__ void foo() {}; __device__ void foo() {}. HD functions cannot be overloaded by H or D functions with the same signature:. .. code-block:: c++. // nvcc: error - function ""foo"" has already been defined; // clang: error - redefinition of 'foo'; __host__ __device__ void foo() {}; __device__ void foo() {}. // nvcc: no error; // clang: no error; __host__ __device__ void bar(int) {}; __device__ void bar() {}. When resolving an overloaded function, clang considers the host/device; attributes of the caller and callee. These are used as a tiebreaker during; overload resolution. See `IdentifyCUDAPreference; <https://clang.llvm.org/doxygen/SemaCUDA_8cpp.html>`_ for the full set of rules,; but at a high level they are:. * D functions prefer to call other Ds. HDs are given lower priority. * Similarly, H functions prefer to call other Hs, or ``__global__`` functions; (with equal priority). HDs are given lower priority. * HD functions prefer to call other HDs. When compiling for device, HDs will call Ds with lower priority than HD, and; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:14570,Availability,error,error,14570,"Ds. When compiling for device, HDs will call Ds with lower priority than HD, and; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void foo();. __host__ void bar();; __host__ __device__ void bar();. __host__ void test_host() {; foo(); // calls H overload; bar(); // calls H overload; }. __device__ void test_device() {; foo(); // calls D overload; bar(); // calls HD overload; }. __host__ __device__ void test_hd() {; foo(); // calls H overload when compiling for host, otherwise D overload; bar(); // always calls HD overload; }. Wrong-side rule example:. .. code-block:: c++. __host__ void host_only();. // We don't codegen inline functions unless they're referenced by a; // non-inline function. inline_hd1() is called only from the host side, so; // does not generate an error. inline_hd2() is called from the device side,; // so it generates an error.; inline __host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:14645,Availability,error,error,14645,"d; will call Hs with still lower priority. If it's forced to call an H, the; program is malformed if we emit code for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void foo();. __host__ void bar();; __host__ __device__ void bar();. __host__ void test_host() {; foo(); // calls H overload; bar(); // calls H overload; }. __device__ void test_device() {; foo(); // calls D overload; bar(); // calls HD overload; }. __host__ __device__ void test_hd() {; foo(); // calls H overload when compiling for host, otherwise D overload; bar(); // always calls HD overload; }. Wrong-side rule example:. .. code-block:: c++. __host__ void host_only();. // We don't codegen inline functions unless they're referenced by a; // non-inline function. inline_hd1() is called only from the host side, so; // does not generate an error. inline_hd2() is called from the device side,; // so it generates an error.; inline __host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_only`` entirely, or it may try to generate code for; ``host_only`` on the device.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:14721,Availability,error,error,14721,"e for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void foo();. __host__ void bar();; __host__ __device__ void bar();. __host__ void test_host() {; foo(); // calls H overload; bar(); // calls H overload; }. __device__ void test_device() {; foo(); // calls D overload; bar(); // calls HD overload; }. __host__ __device__ void test_hd() {; foo(); // calls H overload when compiling for host, otherwise D overload; bar(); // always calls HD overload; }. Wrong-side rule example:. .. code-block:: c++. __host__ void host_only();. // We don't codegen inline functions unless they're referenced by a; // non-inline function. inline_hd1() is called only from the host side, so; // does not generate an error. inline_hd2() is called from the device side,; // so it generates an error.; inline __host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_only`` entirely, or it may try to generate code for; ``host_only`` on the device. What you get seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:14793,Availability,error,error,14793,"e for this HD function. We call this the; ""wrong-side rule"", see example below. The rules are symmetrical when compiling for host. Some examples:. .. code-block:: c++. __host__ void foo();; __device__ void foo();. __host__ void bar();; __host__ __device__ void bar();. __host__ void test_host() {; foo(); // calls H overload; bar(); // calls H overload; }. __device__ void test_device() {; foo(); // calls D overload; bar(); // calls HD overload; }. __host__ __device__ void test_hd() {; foo(); // calls H overload when compiling for host, otherwise D overload; bar(); // always calls HD overload; }. Wrong-side rule example:. .. code-block:: c++. __host__ void host_only();. // We don't codegen inline functions unless they're referenced by a; // non-inline function. inline_hd1() is called only from the host side, so; // does not generate an error. inline_hd2() is called from the device side,; // so it generates an error.; inline __host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_only`` entirely, or it may try to generate code for; ``host_only`` on the device. What you get seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:15012,Availability,error,error,15012,"_ void test_host() {; foo(); // calls H overload; bar(); // calls H overload; }. __device__ void test_device() {; foo(); // calls D overload; bar(); // calls HD overload; }. __host__ __device__ void test_hd() {; foo(); // calls H overload when compiling for host, otherwise D overload; bar(); // always calls HD overload; }. Wrong-side rule example:. .. code-block:: c++. __host__ void host_only();. // We don't codegen inline functions unless they're referenced by a; // non-inline function. inline_hd1() is called only from the host side, so; // does not generate an error. inline_hd2() is called from the device side,; // so it generates an error.; inline __host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_only`` entirely, or it may try to generate code for; ``host_only`` on the device. What you get seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions, including constructors, may be overloaded using H and D; attributes. However, destructors cannot be overloaded. Using a Different Class on Host/Device; --------------------------------------. Occasionally you may want to have a class with different host/device versions. If ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:16600,Availability,error,error,16600,"t seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions, including constructors, may be overloaded using H and D; attributes. However, destructors cannot be overloaded. Using a Different Class on Host/Device; --------------------------------------. Occasionally you may want to have a class with different host/device versions. If all of the class's members are the same on the host and device, you can just; provide overloads for the class's member functions. However, if you want your class to have different members on host/device, you; won't be able to provide working H and D overloads in both classes. In this; case, clang is likely to be unhappy with you. .. code-block:: c++. #ifdef __CUDA_ARCH__; struct S {; __device__ void foo() { /* use device_only */ }; int device_only;; };; #else; struct S {; __host__ void foo() { /* use host_only */ }; double host_only;; };. __device__ void test() {; S s;; // clang generates an error here, because during host compilation, we; // have ifdef'ed away the __device__ overload of S::foo(). The __device__; // overload must be present *even during host compilation*.; S.foo();; }; #endif. We posit that you don't really want to have classes with different members on H; and D. For example, if you were to pass one of these as a parameter to a; kernel, it would have a different layout on H and D, so would not work; properly. To make code like this compatible with clang, we recommend you separate it out; into two classes. If you need to write code that works on both host and; device, consider writing an overloaded wrapper function that returns different; types on host and device. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload base",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:804,Deployability,install,installed,804,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:848,Deployability,install,installation,848,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:903,Deployability,install,installation-guide-linux,903,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1057,Deployability,install,installed,1057,"===================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1158,Deployability,install,installation,1158,"ails about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1275,Deployability,install,install,1275,"ails about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2158,Deployability,install,install,2158,"n on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2461,Deployability,install,install,2461,"work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2504,Deployability,install,installed,2504,"work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2983,Deployability,release,release-notes,2983,"n the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would be; forwards-compatible with e.g. ``sm_35`` GPUs. You can pass ``--cuda-gpu-arch`` multiple times to compile for multiple archs. The `-L` and `-l` flags only need to be passed when linking. When compiling,; you may also need to pass ``--cuda-path=/path/to/cuda`` if you didn't install; the CUDA SDK into ``/usr/local/cuda`` or ``/usr/local/cuda-X.Y``. Flags that control numerical code; ---------------------------------. If you're using GPUs, you probably care about making numerical code run ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:3765,Deployability,install,install,3765," you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would be; forwards-compatible with e.g. ``sm_35`` GPUs. You can pass ``--cuda-gpu-arch`` multiple times to compile for multiple archs. The `-L` and `-l` flags only need to be passed when linking. When compiling,; you may also need to pass ``--cuda-path=/path/to/cuda`` if you didn't install; the CUDA SDK into ``/usr/local/cuda`` or ``/usr/local/cuda-X.Y``. Flags that control numerical code; ---------------------------------. If you're using GPUs, you probably care about making numerical code run fast.; GPU hardware allows for more control over numerical operations than most CPUs,; but this results in more compiler options for you to juggle. Flags you may wish to tweak include:. * ``-ffp-contract={on,off,fast}`` (defaults to ``fast`` on host and device when; compiling CUDA) Controls whether the compiler emits fused multiply-add; operations. * ``off``: never emit fma operations, and prevent ptxas from fusing multiply; and add instructions.; * ``on``: fuse multiplies and adds within a single statement, but never; across statements (C11 semantics). Prevent ptxas from fusing other; multiplies and adds.; * ``fast``: fuse multiplies and adds wherever profitable, even across; statements. Doesn't prevent ptxas from fusing additional multiplies and; adds. Fused mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6001,Energy Efficiency,adapt,adapted,6001,"oint operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18487,Energy Efficiency,reduce,reduce,18487," code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:4177,Integrability,contract,contract,4177,"_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would be; forwards-compatible with e.g. ``sm_35`` GPUs. You can pass ``--cuda-gpu-arch`` multiple times to compile for multiple archs. The `-L` and `-l` flags only need to be passed when linking. When compiling,; you may also need to pass ``--cuda-path=/path/to/cuda`` if you didn't install; the CUDA SDK into ``/usr/local/cuda`` or ``/usr/local/cuda-X.Y``. Flags that control numerical code; ---------------------------------. If you're using GPUs, you probably care about making numerical code run fast.; GPU hardware allows for more control over numerical operations than most CPUs,; but this results in more compiler options for you to juggle. Flags you may wish to tweak include:. * ``-ffp-contract={on,off,fast}`` (defaults to ``fast`` on host and device when; compiling CUDA) Controls whether the compiler emits fused multiply-add; operations. * ``off``: never emit fma operations, and prevent ptxas from fusing multiply; and add instructions.; * ``on``: fuse multiplies and adds within a single statement, but never; across statements (C11 semantics). Prevent ptxas from fusing other; multiplies and adds.; * ``fast``: fuse multiplies and adds wherever profitable, even across; statements. Doesn't prevent ptxas from fusing additional multiplies and; adds. Fused multiply-add instructions can be much faster than the unfused; equivalents, but because the intermediate result in an fma is not rounded,; this flag can affect numerical code. * ``-fcuda-flush-denormals-to-zero`` (default: off) When this is enabled,; floating point operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-tran",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:15637,Integrability,depend,depend,15637,"_host__ __device__ void inline_hd1() { host_only(); } // no error; inline __host__ __device__ void inline_hd2() { host_only(); } // error. __host__ void host_fn() { inline_hd1(); }; __device__ void device_fn() { inline_hd2(); }. // This function is not inline, so it's always codegen'ed on both the host; // and the device. Therefore, it generates an error.; __host__ __device__ void not_inline_hd() { host_only(); }. For the purposes of the wrong-side rule, templated functions also behave like; ``inline`` functions: They aren't codegen'ed unless they're instantiated; (usually as part of the process of invoking them). clang's behavior with respect to the wrong-side rule matches nvcc's, except; nvcc only emits a warning for ``not_inline_hd``; device code is allowed to call; ``not_inline_hd``. In its generated code, nvcc may omit ``not_inline_hd``'s; call to ``host_only`` entirely, or it may try to generate code for; ``host_only`` on the device. What you get seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions, including constructors, may be overloaded using H and D; attributes. However, destructors cannot be overloaded. Using a Different Class on Host/Device; --------------------------------------. Occasionally you may want to have a class with different host/device versions. If all of the class's members are the same on the host and device, you can just; provide overloads for the class's member functions. However, if you want your class to have different members on host/device, you; won't be able to provide working H and D overloads in both classes. In this; case, clang is likely to be unhappy with you. .. code-block:: c++. #ifdef __CUDA_ARCH__; struct S {; __device__ void foo() { /* use device_only */ }; int device_only;; };; #else; struct S {; __host__ void foo() { /* use host_only */ }; double host_only;; };. __device__ void test() {; S s;; // clang generates an error here, because during host compilation, we; // have ifde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:17235,Integrability,wrap,wrapper,17235,"ble to provide working H and D overloads in both classes. In this; case, clang is likely to be unhappy with you. .. code-block:: c++. #ifdef __CUDA_ARCH__; struct S {; __device__ void foo() { /* use device_only */ }; int device_only;; };; #else; struct S {; __host__ void foo() { /* use host_only */ }; double host_only;; };. __device__ void test() {; S s;; // clang generates an error here, because during host compilation, we; // have ifdef'ed away the __device__ overload of S::foo(). The __device__; // overload must be present *even during host compilation*.; S.foo();; }; #endif. We posit that you don't really want to have classes with different members on H; and D. For example, if you were to pass one of these as a parameter to a; kernel, it would have a different layout on H and D, so would not work; properly. To make code like this compatible with clang, we recommend you separate it out; into two classes. If you need to write code that works on both host and; device, consider writing an overloaded wrapper function that returns different; types on host and device. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are archi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6001,Modifiability,adapt,adapted,6001,"oint operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:7079,Performance,optimiz,optimizations,7079,"u>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18437,Performance,optimiz,optimizations,18437," MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18700,Performance,optimiz,optimizations,18700,". .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unroll",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19389,Performance,optimiz,optimization,19389,"e changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19624,Performance,optimiz,optimization,19624," This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacque",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19938,Performance,optimiz,optimizations,19938,"l, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacques Pienaar, Bjarke Roune, Rob Springer, Xuetian Weng, Robert Hundt; | *Proceedings of the 2016 International Symposium on Code Generation and Optimization (CGO 2016)*; |; | `Slides from the CGO talk <http://wujingyue.github.io/docs/gpucc-talk.pdf>`_; |; | `Tutorial given at CGO <http://wujingyue.github.io/do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:20337,Performance,optimiz,optimizations,20337,"pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacques Pienaar, Bjarke Roune, Rob Springer, Xuetian Weng, Robert Hundt; | *Proceedings of the 2016 International Symposium on Code Generation and Optimization (CGO 2016)*; |; | `Slides from the CGO talk <http://wujingyue.github.io/docs/gpucc-talk.pdf>`_; |; | `Tutorial given at CGO <http://wujingyue.github.io/docs/gpucc-tutorial.pdf>`_. Obtaining Help; ==============. To obtain help on LLVM in general and its CUDA support, see `the LLVM; community <https://llvm.org/docs/#mailing-lists>`_.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:631,Safety,detect,detects,631,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:710,Safety,detect,detected,710,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:1827,Safety,detect,detects,1827,"e; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:7659,Safety,detect,detect,7659,"`; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather than being used as a; subtool of NVCC's -- it defines the ``__CUDA__`` macro. ``__CUDA_ARCH__`` is; defined only in device mode (but will be defined if NVCC is using clang as a; preprocessor). So you can use the following incantations to detect clang CUDA; compilation, in host and device modes:. .. code-block:: c++. #if defined(__clang__) && defined(__CUDA__) && !defined(__CUDA_ARCH__); // clang compiling CUDA code, host mode.; #endif. #if defined(__clang__) && defined(__CUDA__) && defined(__CUDA_ARCH__); // clang compiling CUDA code, device mode.; #endif. Both clang and nvcc define ``__CUDACC__`` during CUDA compilation. You can; detect ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:8235,Safety,detect,detect,8235,"th libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather than being used as a; subtool of NVCC's -- it defines the ``__CUDA__`` macro. ``__CUDA_ARCH__`` is; defined only in device mode (but will be defined if NVCC is using clang as a; preprocessor). So you can use the following incantations to detect clang CUDA; compilation, in host and device modes:. .. code-block:: c++. #if defined(__clang__) && defined(__CUDA__) && !defined(__CUDA_ARCH__); // clang compiling CUDA code, host mode.; #endif. #if defined(__clang__) && defined(__CUDA__) && defined(__CUDA_ARCH__); // clang compiling CUDA code, device mode.; #endif. Both clang and nvcc define ``__CUDACC__`` during CUDA compilation. You can; detect NVCC specifically by looking for ``__NVCC__``. Dialect Differences Between clang and nvcc; ==========================================. There is no formal CUDA spec, and clang and nvcc speak slightly different; dialects of the language. Below, we describe some of the differences. This section is painful; hopefully you can skip this section and live your life; blissfully unaware. Compilation Models; ------------------. Most of the differences between clang and nvcc stem from the different; compilation models used by clang and nvcc. nvcc uses *split compilation*,; which works roughly as follows",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:8636,Safety,detect,detect,8636,"o detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather than being used as a; subtool of NVCC's -- it defines the ``__CUDA__`` macro. ``__CUDA_ARCH__`` is; defined only in device mode (but will be defined if NVCC is using clang as a; preprocessor). So you can use the following incantations to detect clang CUDA; compilation, in host and device modes:. .. code-block:: c++. #if defined(__clang__) && defined(__CUDA__) && !defined(__CUDA_ARCH__); // clang compiling CUDA code, host mode.; #endif. #if defined(__clang__) && defined(__CUDA__) && defined(__CUDA_ARCH__); // clang compiling CUDA code, device mode.; #endif. Both clang and nvcc define ``__CUDACC__`` during CUDA compilation. You can; detect NVCC specifically by looking for ``__NVCC__``. Dialect Differences Between clang and nvcc; ==========================================. There is no formal CUDA spec, and clang and nvcc speak slightly different; dialects of the language. Below, we describe some of the differences. This section is painful; hopefully you can skip this section and live your life; blissfully unaware. Compilation Models; ------------------. Most of the differences between clang and nvcc stem from the different; compilation models used by clang and nvcc. nvcc uses *split compilation*,; which works roughly as follows:. * Run a preprocessor over the input ``.cu`` file to split it into two source; files: ``H``, containing source code for the host, and ``D``, containing; source code for the device. * For each GPU architecture ``arch`` that we're compiling for, do:. * Compile ``D`` using nvcc proper. The result of this is a ``ptx`` file for; ``P_arch``. * Optionally, invoke ``ptxas``, the PTX assembler, to generate a file,; ``S_a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18494,Safety,redund,redundancy,18494," code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:5866,Testability,test,test-suite,5866,"t rounded,; this flag can affect numerical code. * ``-fcuda-flush-denormals-to-zero`` (default: off) When this is enabled,; floating point operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:5916,Testability,test,tests,5916,"code. * ``-fcuda-flush-denormals-to-zero`` (default: off) When this is enabled,; floating point operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard fr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:5953,Testability,test,test-suite,5953,"(default: off) When this is enabled,; floating point operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6023,Testability,test,test,6023,"oint operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6405,Testability,test,test,6405,"ng the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) bec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:7174,Testability,test,tested,7174,"he standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to an ``std::complex`` function,; especially when compiling without optimizations. As of 2016-11-16, clang supports ``std::complex`` without these caveats. It is; tested with libstdc++ 4.8.5 and newer, but is known to work only with libc++; newer than 2016-11-16. ``<algorithm>``; ---------------. In C++14, many useful functions from ``<algorithm>`` (notably, ``std::min`` and; ``std::max``) become constexpr. You can therefore use these in device code,; when compiling with clang. Detecting clang vs NVCC from code; =================================. Although clang's CUDA implementation is largely compatible with NVCC's, you may; still want to detect when you're compiling CUDA code specifically with clang. This is tricky, because NVCC may invoke clang as part of its own compilation; process! For example, NVCC uses the host compiler's preprocessor when; compiling for device code, and that host compiler may in fact be clang. When clang is actually compiling CUDA code -- rather than being used as a; subtool of NVCC's -- it defines the ``__CUDA__`` macro. ``__CUDA_ARCH__`` is; defined only in device mode (but will be defined if NVCC is using clang as a; preproc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:16562,Testability,test,test,16562,"t seems to depend on whether or not; the compiler chooses to inline ``host_only``. Member functions, including constructors, may be overloaded using H and D; attributes. However, destructors cannot be overloaded. Using a Different Class on Host/Device; --------------------------------------. Occasionally you may want to have a class with different host/device versions. If all of the class's members are the same on the host and device, you can just; provide overloads for the class's member functions. However, if you want your class to have different members on host/device, you; won't be able to provide working H and D overloads in both classes. In this; case, clang is likely to be unhappy with you. .. code-block:: c++. #ifdef __CUDA_ARCH__; struct S {; __device__ void foo() { /* use device_only */ }; int device_only;; };; #else; struct S {; __host__ void foo() { /* use host_only */ }; double host_only;; };. __device__ void test() {; S s;; // clang generates an error here, because during host compilation, we; // have ifdef'ed away the __device__ overload of S::foo(). The __device__; // overload must be present *even during host compilation*.; S.foo();; }; #endif. We posit that you don't really want to have classes with different members on H; and D. For example, if you were to pass one of these as a parameter to a; kernel, it would have a different layout on H and D, so would not work; properly. To make code like this compatible with clang, we recommend you separate it out; into two classes. If you need to write code that works on both host and; device, consider writing an overloaded wrapper function that returns different; types on host and device. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload base",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19546,Testability,benchmark,benchmarks,19546,"ion; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:391,Usability,guid,guide,391,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:446,Usability,guid,guide,446,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:861,Usability,guid,guide,861,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:916,Usability,guid,guide-linux,916,"=========================; Compiling CUDA with clang; =========================. .. contents::; :local:. Introduction; ============. This document describes how to compile CUDA code with clang, and gives some; details about LLVM and clang's CUDA implementations. This document assumes a basic familiarity with CUDA. Information about CUDA; programming can be found in the; `CUDA programming guide; <http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html>`_. Compiling CUDA Code; ===================. Prerequisites; -------------. CUDA is supported since llvm 3.9. Clang currently supports CUDA 7.0 through; 12.1. If clang detects a newer CUDA version, it will issue a warning and will; attempt to use detected CUDA SDK it as if it were CUDA 12.1. Before you build CUDA code, you'll need to have installed the CUDA SDK. See; `NVIDIA's CUDA installation guide; <https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html>`_ for; details. Note that clang `maynot support; <https://bugs.llvm.org/show_bug.cgi?id=26966>`_ the CUDA toolkit as installed by; some Linux package managers. Clang does attempt to deal with specific details of; CUDA installation on a handful of common Linux distributions, but in general the; most reliable way to make it work is to install CUDA in a single directory from; NVIDIA's `.run` package and specify its location via `--cuda-path=...` argument. CUDA compilation is supported on Linux. Compilation on MacOS and Windows may or; may not work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:6439,Availability,down,download,6439,"eration (registration required, free sign-up) <http://www-01.ibm.com/support/docview.wss?uid=isg2b9de5f05a9d57819852571c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-Extensions-to-gABI>`_; * `64-Bit ELF V2 ABI Specification: Power Architecture <https://openpowerfoundation.org/?",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:6547,Availability,down,download,6547,"1c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-Extensions-to-gABI>`_; * `64-Bit ELF V2 ABI Specification: Power Architecture <https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture>`_. * `OpenPOWER ELFv2 Errata: ELFv2 ABI Version 1.4 <h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:6683,Availability,down,download,6683," * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-Extensions-to-gABI>`_; * `64-Bit ELF V2 ABI Specification: Power Architecture <https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture>`_. * `OpenPOWER ELFv2 Errata: ELFv2 ABI Version 1.4 <https://openpowerfoundation.org/?resource_lib=openpower-elfv2-errata-elfv2-abi-version-1-4>`_; * `PowerPC 64-bit ELF ABI Supp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:4342,Deployability,patch,patches,4342,"s://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents, collections, notes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `PowerPC Compiler Writer's Guide <http://www.ibm.com/chips/techlib/techlib.nsf/techdocs/852569B20050FF7785256996007558C6>`_; * `Intro to PowerPC Architecture <http://www.ibm.com/developerworks/linux/library/l-powarch/>`_; * `Various IBM specifications and white papers <https://www.power.org/documentation/?document_company=105&document_category=all&publish_year=all&grid_order=DESC&grid_sort=title>`_; * `PowerPC ABI documents <http://penguinppc.org/dev/#library>`_; * `PowerPC64 alignment of long doubles (from GCC) <http://gcc.gnu.org/ml/gcc-patches/2003-09/msg00997.html>`_; * `Long branch stubs for powerpc64-linux (from binutils) <http://sources.redhat.com/ml/binutils/2002-04/msg00573.html>`_. AMDGPU; ------. Refer to :doc:`AMDGPUUsage` for additional documentation. RISC-V; ------; * `RISC-V User-Level ISA Specification <https://riscv.org/specifications/>`_. C-SKY; ------; * `C-SKY Architecture User Guide <https://github.com/c-sky/csky-doc/blob/master/CSKY%20Architecture%20user_guide.pdf>`_; * `C-SKY V2 ABI <https://github.com/c-sky/csky-doc/blob/master/C-SKY_V2_CPU_Applications_Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1-EN.html>`_; * `LoongArch ELF ABI specification <https://loongson.github.io/LoongArch-Documentation/LoongArch-ELF-ABI-EN.html>`_. SPARC; -----. * `SPARC standards <http://sparc.org/standards>`_; * `SPARC V9 ABI <http://sparc.org/standards/64.psabi.1.35.ps.Z>`_; * `SP",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2203,Energy Efficiency,power,power-isa-version-,2203,"rata <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0045d/IHI0045D_ABI_addenda.pdf>`_. * `Cortex-A57 Software Optimization Guide <http://infocenter.arm.com/help/topic/com.arm.doc.uan0015b/Cortex_A57_Software_Optimization_Guide_external.pdf>`_. * `Run-time ABI for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0043d/IHI0043D_rtabi.pdf>`_ This documents the __aeabi_* helper functions. Itanium (ia64); --------------. * `Itanium documentation <http://developer.intel.com/design/itanium2/documentation.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <htt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2448,Energy Efficiency,power,power-isa-version-,2448,">`_. * `Run-time ABI for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0043d/IHI0043D_rtabi.pdf>`_ This documents the __aeabi_* helper functions. Itanium (ia64); --------------. * `Itanium documentation <http://developer.intel.com/design/itanium2/documentation.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2733,Energy Efficiency,power,power,2733,"ion.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:4079,Energy Efficiency,power,power,4079,"erPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents, collections, notes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `PowerPC Compiler Writer's Guide <http://www.ibm.com/chips/techlib/techlib.nsf/techdocs/852569B20050FF7785256996007558C6>`_; * `Intro to PowerPC Architecture <http://www.ibm.com/developerworks/linux/library/l-powarch/>`_; * `Various IBM specifications and white papers <https://www.power.org/documentation/?document_company=105&document_category=all&publish_year=all&grid_order=DESC&grid_sort=title>`_; * `PowerPC ABI documents <http://penguinppc.org/dev/#library>`_; * `PowerPC64 alignment of long doubles (from GCC) <http://gcc.gnu.org/ml/gcc-patches/2003-09/msg00997.html>`_; * `Long branch stubs for powerpc64-linux (from binutils) <http://sources.redhat.com/ml/binutils/2002-04/msg00573.html>`_. AMDGPU; ------. Refer to :doc:`AMDGPUUsage` for additional documentation. RISC-V; ------; * `RISC-V User-Level ISA Specification <https://riscv.org/specifications/>`_. C-SKY; ------; * `C-SKY Architecture User Guide <https://github.com/c-sky/csky-doc/blob/master/CSKY%20Architecture%20user_guide.pdf>`_; * `C-SKY V2 ABI <https://github.com/c-sky/csky-doc/blob/master/C-SKY_V2_CPU_Applications_Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:7502,Energy Efficiency,power,power-architecture,7502,"_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-Extensions-to-gABI>`_; * `64-Bit ELF V2 ABI Specification: Power Architecture <https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture>`_. * `OpenPOWER ELFv2 Errata: ELFv2 ABI Version 1.4 <https://openpowerfoundation.org/?resource_lib=openpower-elfv2-errata-elfv2-abi-version-1-4>`_; * `PowerPC 64-bit ELF ABI Supplement <http://www.linuxbase.org/spec/ELF/ppc64/>`_; * `Procedure Call Standard for the AArch64 Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055a/IHI0055A_aapcs64.pdf>`_; * `Procedure Call Standard for the ARM Architecture <https://developer.arm.com/docs/ihi0042/latest>`_; * `ELF for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0044e/IHI0044E_aaelf.pdf>`_; * `ELF for the ARM 64-bit Architecture (AArch64) <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0056a/IHI0056A_aaelf64.pdf>`_; * `System z ELF ABI Supplement <http://legacy.redhat.com/pub/redhat/linux/7.1/es/os/s390x/doc/lzsabi0.pdf>`_. macOS; -----. * `Mach-O Runtime Architecture <http://developer.apple.com/documentation/Darwin/RuntimeArchitecture-date.html>`_; * `Note",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:6332,Performance,optimiz,optimize,6332,"* `SPARC V8 ABI <http://sparc.org/standards/psABI3rd.pdf>`_. SystemZ; -------. * `z/Architecture Principles of Operation (registration required, free sign-up) <http://www-01.ibm.com/support/docview.wss?uid=isg2b9de5f05a9d57819852571c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:4391,Testability,stub,stubs,4391,"df>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents, collections, notes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `PowerPC Compiler Writer's Guide <http://www.ibm.com/chips/techlib/techlib.nsf/techdocs/852569B20050FF7785256996007558C6>`_; * `Intro to PowerPC Architecture <http://www.ibm.com/developerworks/linux/library/l-powarch/>`_; * `Various IBM specifications and white papers <https://www.power.org/documentation/?document_company=105&document_category=all&publish_year=all&grid_order=DESC&grid_sort=title>`_; * `PowerPC ABI documents <http://penguinppc.org/dev/#library>`_; * `PowerPC64 alignment of long doubles (from GCC) <http://gcc.gnu.org/ml/gcc-patches/2003-09/msg00997.html>`_; * `Long branch stubs for powerpc64-linux (from binutils) <http://sources.redhat.com/ml/binutils/2002-04/msg00573.html>`_. AMDGPU; ------. Refer to :doc:`AMDGPUUsage` for additional documentation. RISC-V; ------; * `RISC-V User-Level ISA Specification <https://riscv.org/specifications/>`_. C-SKY; ------; * `C-SKY Architecture User Guide <https://github.com/c-sky/csky-doc/blob/master/CSKY%20Architecture%20user_guide.pdf>`_; * `C-SKY V2 ABI <https://github.com/c-sky/csky-doc/blob/master/C-SKY_V2_CPU_Applications_Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1-EN.html>`_; * `LoongArch ELF ABI specification <https://loongson.github.io/LoongArch-Documentation/LoongArch-ELF-ABI-EN.html>`_. SPARC; -----. * `SPARC standards <http://sparc.org/standards>`_; * `SPARC V9 ABI <http://sparc.org/standards/64.psabi.1.35.ps.Z>`_; * `SPARC V8 ABI <http://sparc.org/standards/psABI3rd.pdf>`_. Sys",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:3237,Usability,guid,guide,3237,"R9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents, collections, notes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `PowerPC Compiler Writer's Guide <http://www.ibm.com/chips/techlib/techlib.nsf/techdocs/852569B20050FF7785256996007558C6>`_; * `Intro to PowerPC Architecture <http://www.ibm.com/developerworks/linux/library/l-powarch/>`_; * `Various IBM specifications and white papers <https://www.power.org/documentation/?document_company=105&document_category=all&publish_year=all&grid_order=DESC&grid_sort=title>`_; * `PowerPC ABI documents <http://pen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:5665,Usability,guid,guide,5665," ------; * `C-SKY Architecture User Guide <https://github.com/c-sky/csky-doc/blob/master/CSKY%20Architecture%20user_guide.pdf>`_; * `C-SKY V2 ABI <https://github.com/c-sky/csky-doc/blob/master/C-SKY_V2_CPU_Applications_Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1-EN.html>`_; * `LoongArch ELF ABI specification <https://loongson.github.io/LoongArch-Documentation/LoongArch-ELF-ABI-EN.html>`_. SPARC; -----. * `SPARC standards <http://sparc.org/standards>`_; * `SPARC V9 ABI <http://sparc.org/standards/64.psabi.1.35.ps.Z>`_; * `SPARC V8 ABI <http://sparc.org/standards/psABI3rd.pdf>`_. SystemZ; -------. * `z/Architecture Principles of Operation (registration required, free sign-up) <http://www-01.ibm.com/support/docview.wss?uid=isg2b9de5f05a9d57819852571c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:5872,Usability,guid,guides-manuals,5872,"Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1-EN.html>`_; * `LoongArch ELF ABI specification <https://loongson.github.io/LoongArch-Documentation/LoongArch-ELF-ABI-EN.html>`_. SPARC; -----. * `SPARC standards <http://sparc.org/standards>`_; * `SPARC V9 ABI <http://sparc.org/standards/64.psabi.1.35.ps.Z>`_; * `SPARC V8 ABI <http://sparc.org/standards/psABI3rd.pdf>`_. SystemZ; -------. * `z/Architecture Principles of Operation (registration required, free sign-up) <http://www-01.ibm.com/support/docview.wss?uid=isg2b9de5f05a9d57819852571c500428f9a>`_. VE; --. * `NEC SX-Aurora TSUBASA ISA Guide <https://www.hpc.nec/documents/guide/pdfs/Aurora_ISA_guide.pdf>`_; * `NEC SX-Aurora TSUBASA manuals and documentation <https://www.hpc.nec/documentation>`_. X86; ---. * `AMD processor manuals <http://developer.amd.com/resources/developer-guides-manuals/>`_; * `Intel 64 and IA-32 manuals <http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html>`_; * `Intel Itanium documentation <http://www.intel.com/design/itanium/documentation.htm?iid=ipp_srvr_proc_itanium2+techdocs>`_; * `X86 and X86-64 SysV psABI <https://github.com/hjl-tools/x86-psABI/wiki/X86-psABI>`_; * `Calling conventions for different C++ compilers and operating systems <http://www.agner.org/optimize/calling_conventions.pdf>`_. XCore; -----. * `The XMOS XS1 Architecture (ISA) <https://www.xmos.ai/download/The-XMOS-XS1-Architecture%281.0%29.pdf>`_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1238,Availability,failure,failure,1238,"e appreciate all contributions. In case you have questions,; you can either use the `Forum`_ or, for a more interactive chat, go to our; `Discord server`_ or the IRC #llvm channel on `irc.oftc.net`_. If you want to contribute code, please familiarize yourself with the :doc:`DeveloperPolicy`. .. contents::; :local:. Ways to Contribute; ==================. Bug Reports; -----------; If you are working with LLVM and run into a bug, we definitely want to know; about it. Please let us know and follow the instructions in; :doc:`HowToSubmitABug` to create a bug report. Bug Fixes; ---------; If you are interested in contributing code to LLVM, bugs labeled with the; `good first issue`_ keyword in the `bug tracker`_ are a good way to get familiar with; the code base. If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format yo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5044,Availability,ping,ping,5044,"le doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5101,Availability,ping,ping,5101,"ers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1971,Deployability,patch,patch,1971," If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2013,Deployability,patch,patch,2013," to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2196,Deployability,patch,patch,2196,"doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pendin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2327,Deployability,patch,patches,2327," build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2520,Deployability,patch,patches,2520,"see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We sti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2547,Deployability,patch,patch,2547,"rk; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-revi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2666,Deployability,integrat,integration,2666,"st of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, plea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2756,Deployability,install,installed,2756,"nterested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2773,Deployability,install,installable,2773,"nterested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3134,Deployability,update,update,3134,"-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3261,Deployability,install,installed,3261,"tted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of pot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3360,Deployability,integrat,integration,3360,"tted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of pot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3847,Deployability,patch,patch,3847,"ormat only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3909,Deployability,patch,patch,3909,"ormat only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4048,Deployability,patch,patch,4048,"commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4610,Deployability,update,updated,4610,"ion of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4634,Deployability,patch,patch,4634,"ion of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4742,Deployability,patch,patch,4742,"e workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4996,Deployability,patch,patch,4996,"le doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5417,Deployability,patch,patch,5417,"rtain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at once.; You can set it up (on Unix systems) by running from the repository root:. .. code-block:: console. % ln -sf ../../llvm/utils/git/pre-push.py .git/hooks/pre-push. Helpful Information About LLVM; ==============================; :doc:`LLVM's documentation <index>` provides a wealth of information about LLVM's internals as; well as various user guides",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2666,Integrability,integrat,integration,2666,"st of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, plea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3360,Integrability,integrat,integration,3360,"tted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of pot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5500,Integrability,interface,interface,5500,"rtain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at once.; You can set it up (on Unix systems) by running from the repository root:. .. code-block:: console. % ln -sf ../../llvm/utils/git/pre-push.py .git/hooks/pre-push. Helpful Information About LLVM; ==============================; :doc:`LLVM's documentation <index>` provides a wealth of information about LLVM's internals as; well as various user guides",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5710,Modifiability,config,configured,5710," the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at once.; You can set it up (on Unix systems) by running from the repository root:. .. code-block:: console. % ln -sf ../../llvm/utils/git/pre-push.py .git/hooks/pre-push. Helpful Information About LLVM; ==============================; :doc:`LLVM's documentation <index>` provides a wealth of information about LLVM's internals as; well as various user guides. The pages listed below should provide a good overview; of LLVM's high-level design, as well as its internals:. :doc:`GettingStarted`; Discusses how to get up and running quickly with the LLVM infrastructure.; Everything from unpacking and compilation of the distribution to ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:5997,Safety,sanity check,sanity checks,5997,"st a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at once.; You can set it up (on Unix systems) by running from the repository root:. .. code-block:: console. % ln -sf ../../llvm/utils/git/pre-push.py .git/hooks/pre-push. Helpful Information About LLVM; ==============================; :doc:`LLVM's documentation <index>` provides a wealth of information about LLVM's internals as; well as various user guides. The pages listed below should provide a good overview; of LLVM's high-level design, as well as its internals:. :doc:`GettingStarted`; Discusses how to get up and running quickly with the LLVM infrastructure.; Everything from unpacking and compilation of the distribution to execution; of some tools. :doc:`LangRef`; Defines the LLVM intermediate representation. :doc:`ProgrammersManual`; Introduction to the general layout of the LLVM sourcebase, important classes; and APIs, and some tips & tricks. `LLVM for Grad Students`__; This is an introduction to the LLVM i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1497,Security,secur,security-related,1497,"l:. Ways to Contribute; ==================. Bug Reports; -----------; If you are working with LLVM and run into a bug, we definitely want to know; about it. Please let us know and follow the instructions in; :doc:`HowToSubmitABug` to create a bug report. Bug Fixes; ---------; If you are interested in contributing code to LLVM, bugs labeled with the; `good first issue`_ keyword in the `bug tracker`_ are a good way to get familiar with; the code base. If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1537,Security,secur,security-issue,1537,"l:. Ways to Contribute; ==================. Bug Reports; -----------; If you are working with LLVM and run into a bug, we definitely want to know; about it. Please let us know and follow the instructions in; :doc:`HowToSubmitABug` to create a bug report. Bug Fixes; ---------; If you are interested in contributing code to LLVM, bugs labeled with the; `good first issue`_ keyword in the `bug tracker`_ are a good way to get familiar with; the code base. If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4860,Security,access,access,4860,"dd them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:1332,Testability,assert,assertions,1332,"ord server`_ or the IRC #llvm channel on `irc.oftc.net`_. If you want to contribute code, please familiarize yourself with the :doc:`DeveloperPolicy`. .. contents::; :local:. Ways to Contribute; ==================. Bug Reports; -----------; If you are working with LLVM and run into a bug, we definitely want to know; about it. Please let us know and follow the instructions in; :doc:`HowToSubmitABug` to create a bug report. Bug Fixes; ---------; If you are interested in contributing code to LLVM, bugs labeled with the; `good first issue`_ keyword in the `bug tracker`_ are a good way to get familiar with; the code base. If you are interested in fixing a bug please comment on it to; let people know you are working on it. Then try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2051,Testability,test,test,2051,"hen try to reproduce and fix the bug with upstream LLVM. Start by building; LLVM from source as described in :doc:`GettingStarted` and; use the built binaries to reproduce the failure described in the bug. Use; a debug build (`-DCMAKE_BUILD_TYPE=Debug`) or a build with assertions; (`-DLLVM_ENABLE_ASSERTIONS=On`, enabled for Debug builds). Reporting a Security Issue; --------------------------. There is a separate process to submit security-related bugs, see :ref:`report-security-issue`. Bigger Pieces of Work; ---------------------; In case you are interested in taking on a bigger piece of work, a list of; interesting projects is maintained at the `LLVM's Open Projects page`_. In case; you are interested in working on any of these projects, please post on the; `Forum`_, so that we know the project is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4483,Testability,test,test,4483,"ll Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" butt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:2827,Usability,simpl,simply,2827,"is being worked on. .. _submit_patch:. How to Submit a Patch; =====================; Once you have a patch ready, it is time to submit it. The patch should:. * include a small unit test; * conform to the :doc:`CodingStandards`. You can use the `clang-format-diff.py`_ or `git-clang-format`_ tools to automatically format your patch properly.; * not contain any unrelated changes; * be an isolated change. Independent changes should be submitted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select su",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4538,Usability,guid,guidance,4538,"ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:4585,Usability,feedback,feedback,4585,"ion of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of potential reviewers by CC'ing them in a comment -- just; @name them. A reviewer may request changes or ask questions during the review. If you are; uncertain on how to provide test cases, documentation, etc., feel free to ask; for guidance during the review. Please address the feedback and re-post an; updated version of your patch. This cycle continues until all requests and comments; have been addressed and a reviewer accepts the patch with a `Looks good to me` or `LGTM`.; Once that is done the change can be committed. If you do not have commit; access, please let people know during the review and someone should commit it; on your behalf. If you have received no comments on your patch for a week, you can request a; review by 'ping'ing the GitHub PR with ""Ping"". The common courtesy 'ping' rate; is once a week. Please remember that you are asking for valuable time from other; professional developers. For more information on LLVM's code-review process, please see :doc:`CodeReview`. .. _commit_from_git:. For developers to commit changes from Git; -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:6454,Usability,guid,guides,6454," -----------------------------------------. Once a patch is reviewed, you can select the ""Squash and merge"" button in the; GitHub web interface. You might need to rebase your change before pushing; it to the repo. LLVM currently has a linear-history policy, which means that merge commits are; not allowed. The `llvm-project` repo on github is configured to reject pushes; that include merges, so the `git rebase` step above is required. Please ask for help if you're having trouble with your particular git workflow. .. _git_pre_push_hook:. Git pre-push hook; ^^^^^^^^^^^^^^^^^. We include an optional pre-push hook that run some sanity checks on the revisions; you are about to push and ask confirmation if you push multiple commits at once.; You can set it up (on Unix systems) by running from the repository root:. .. code-block:: console. % ln -sf ../../llvm/utils/git/pre-push.py .git/hooks/pre-push. Helpful Information About LLVM; ==============================; :doc:`LLVM's documentation <index>` provides a wealth of information about LLVM's internals as; well as various user guides. The pages listed below should provide a good overview; of LLVM's high-level design, as well as its internals:. :doc:`GettingStarted`; Discusses how to get up and running quickly with the LLVM infrastructure.; Everything from unpacking and compilation of the distribution to execution; of some tools. :doc:`LangRef`; Defines the LLVM intermediate representation. :doc:`ProgrammersManual`; Introduction to the general layout of the LLVM sourcebase, important classes; and APIs, and some tips & tricks. `LLVM for Grad Students`__; This is an introduction to the LLVM infrastructure by Adrian Sampson. While it; has been written for grad students, it provides a good, compact overview of; LLVM's architecture, LLVM's IR and how to write a new pass. .. __: http://www.cs.cornell.edu/~asampson/blog/llvm.html. `Intro to LLVM`__; Book chapter providing a compiler hacker's introduction to LLVM. .. __: http://www",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Contributing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:11614,Availability,down,down,11614,"; convergence-before ``L3``. .. _convergence-cycle-headers:. Dependence on Cycles Headers; ----------------------------. Contradictions in *convergence-before* are possible only between two; nodes that are inside some cycle. The dynamic instances of such nodes; may be interleaved in the same thread, and this interleaving may be; different for different threads. When a thread executes a node ``X`` once and then executes it again,; it must have followed a closed path in the CFG that includes ``X``.; Such a path must pass through the header of at least one cycle --- the; smallest cycle that includes the entire closed path. In a given; thread, two dynamic instances of ``X`` are either separated by the; execution of at least one cycle header, or ``X`` itself is a cycle; header. In reducible cycles (natural loops), each execution of the header is; equivalent to the start of a new iteration of the cycle. But this; analogy breaks down in the presence of explicit constraints on the; converged-with relation, such as those described in :ref:`future; work<convergence-note-convergence>`. Instead, cycle headers should be; treated as implicit *points of convergence* in a maximal; converged-with relation. Consider a sequence of nested cycles ``C1``, ``C2``, ..., ``Ck`` such; that ``C1`` is the outermost cycle and ``Ck`` is the innermost cycle,; with headers ``H1``, ``H2``, ..., ``Hk`` respectively. When a thread; enters the cycle ``Ck``, any of the following is possible:. 1. The thread directly entered cycle ``Ck`` without having executed; any of the headers ``H1`` to ``Hk``. 2. The thread executed some or all of the nested headers one or more; times. The maximal converged-with relation captures the following intuition; about cycles:. 1. When two threads enter a top-level cycle ``C1``, they execute; converged dynamic instances of every node that is a :ref:`child; <cycle-parent-block>` of ``C1``. 2. When two threads enter a nested cycle ``Ck``, they execute; converged dynamic instanc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:738,Integrability,depend,depends,738,".. _convergence-and-uniformity:. ==========================; Convergence And Uniformity; ==========================. .. contents::; :local:. Introduction; ============. Some parallel environments execute threads in groups that allow; communication within the group using special primitives called; *convergent* operations. The outcome of a convergent operation is; sensitive to the set of threads that executes it ""together"", i.e.,; convergently. A value is said to be *uniform* across a set of threads if it is the; same across those threads, and *divergent* otherwise. Correspondingly,; a branch is said to be a uniform branch if its condition is uniform,; and it is a divergent branch otherwise. Whether threads are *converged* or not depends on the paths they take; through the control flow graph. Threads take different outgoing edges; at a *divergent branch*. Divergent branches constrain; program transforms such as changing the CFG or moving a convergent; operation to a different point of the CFG. Performing these; transformations across a divergent branch can change the sets of; threads that execute convergent operations convergently. While these; constraints are out of scope for this document, the described; *uniformity analysis* allows these transformations to identify; uniform branches where these constraints do not hold. Convergence and; uniformity are inter-dependent: When threads diverge at a divergent; branch, they may later *reconverge* at a common program point.; Subsequent operations are performed convergently, but the inputs may; be non-uniform, thus producing divergent outputs. Uniformity is also useful by itself on targets that execute threads in; groups with shared execution resources (e.g. waves, warps, or; subgroups):. - Uniform outputs can potentially be computed or stored on shared; resources.; - These targets must ""linearize"" a divergent branch to ensure that; each side of the branch is followed by the corresponding threads in; the same group. But linea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:1380,Integrability,depend,dependent,1380,"together"", i.e.,; convergently. A value is said to be *uniform* across a set of threads if it is the; same across those threads, and *divergent* otherwise. Correspondingly,; a branch is said to be a uniform branch if its condition is uniform,; and it is a divergent branch otherwise. Whether threads are *converged* or not depends on the paths they take; through the control flow graph. Threads take different outgoing edges; at a *divergent branch*. Divergent branches constrain; program transforms such as changing the CFG or moving a convergent; operation to a different point of the CFG. Performing these; transformations across a divergent branch can change the sets of; threads that execute convergent operations convergently. While these; constraints are out of scope for this document, the described; *uniformity analysis* allows these transformations to identify; uniform branches where these constraints do not hold. Convergence and; uniformity are inter-dependent: When threads diverge at a divergent; branch, they may later *reconverge* at a common program point.; Subsequent operations are performed convergently, but the inputs may; be non-uniform, thus producing divergent outputs. Uniformity is also useful by itself on targets that execute threads in; groups with shared execution resources (e.g. waves, warps, or; subgroups):. - Uniform outputs can potentially be computed or stored on shared; resources.; - These targets must ""linearize"" a divergent branch to ensure that; each side of the branch is followed by the corresponding threads in; the same group. But linearization is unnecessary at uniform; branches, since the whole group of threads follows either one side; of the branch or the other. This document presents a definition of convergence that is reasonable; for real targets and is compatible with the currently implicit; semantics of convergent operations in LLVM IR. This is accompanied by; a *uniformity analysis* that extends previous work on divergence analysis; [D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:17796,Integrability,depend,depending,17796," for all threads in ``S``. Divergent Cycle Exits; ---------------------. When a divergent branch occurs inside a cycle, it is possible that a; diverged path continues to an exit of the cycle. This is called a; divergent cycle exit. If the cycle is irreducible, the diverged path; may re-enter and eventually reach a join within the cycle. Such a join; should be examined for the :ref:`diverged entry; <convergence-diverged-entry>` criterion. Nodes along the diverged path that lie outside the cycle experience; *temporal divergence*, when two threads executing convergently inside; the cycle produce uniform values, but exit the cycle along the same; divergent path after executing the header a different number of times; (informally, on different iterations of the cycle). For a node ``N``; inside the cycle the outputs may be uniform for the two threads, but; any use ``U`` outside the cycle receives a value from non-converged; dynamic instances of ``N``. An output of ``U`` may be divergent,; depending on the semantics of the instruction. .. _uniformity-analysis:. Static Uniformity Analysis; ==========================. Irreducible control flow results in different cycle hierarchies; depending on the choice of headers during depth-first traversal. As a; result, a static analysis cannot always determine the convergence of; nodes in irreducible cycles, and any uniformity analysis is limited to; those static instances whose convergence is independent of the cycle; hierarchy:. .. _convergence-m-converged:. **m-converged static instances:**. A static instance ``X`` is *m-converged* for a given CFG if and only; if the maximal converged-with relation for its dynamic instances is; the same in every cycle hierarchy that can be constructed for that CFG. .. note::. In other words, two dynamic instances ``X1`` and ``X2`` of an; m-converged static instance ``X`` are converged in some cycle; hierarchy if and only if they are also converged in every other; cycle hierarchy for the same CFG. As ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:17990,Integrability,depend,depending,17990,". This is called a; divergent cycle exit. If the cycle is irreducible, the diverged path; may re-enter and eventually reach a join within the cycle. Such a join; should be examined for the :ref:`diverged entry; <convergence-diverged-entry>` criterion. Nodes along the diverged path that lie outside the cycle experience; *temporal divergence*, when two threads executing convergently inside; the cycle produce uniform values, but exit the cycle along the same; divergent path after executing the header a different number of times; (informally, on different iterations of the cycle). For a node ``N``; inside the cycle the outputs may be uniform for the two threads, but; any use ``U`` outside the cycle receives a value from non-converged; dynamic instances of ``N``. An output of ``U`` may be divergent,; depending on the semantics of the instruction. .. _uniformity-analysis:. Static Uniformity Analysis; ==========================. Irreducible control flow results in different cycle hierarchies; depending on the choice of headers during depth-first traversal. As a; result, a static analysis cannot always determine the convergence of; nodes in irreducible cycles, and any uniformity analysis is limited to; those static instances whose convergence is independent of the cycle; hierarchy:. .. _convergence-m-converged:. **m-converged static instances:**. A static instance ``X`` is *m-converged* for a given CFG if and only; if the maximal converged-with relation for its dynamic instances is; the same in every cycle hierarchy that can be constructed for that CFG. .. note::. In other words, two dynamic instances ``X1`` and ``X2`` of an; m-converged static instance ``X`` are converged in some cycle; hierarchy if and only if they are also converged in every other; cycle hierarchy for the same CFG. As noted earlier, for brevity, we restrict the term *converged* to; mean ""related under the maximal converged-with relation for a given; cycle hierarchy"". Each node ``X`` in a given CFG is rep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:21202,Integrability,depend,depends,21202,"me other cycle hierarchy ``T'``. This property allows compiler transforms to use the uniformity; analysis without being affected by DFS choices made in the underlying; cycle analysis. When two transforms use different instances of the; uniformity analysis for the same CFG, a ""divergent value"" result in; one analysis instance cannot contradict a ""uniform value"" result in; the other. Generic transforms such as SimplifyCFG, CSE, and loop transforms; commonly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region. When two threads diverge at ``Q``, the convergence of; dynamic instances within the cyclic region depends on the cycle; hierarchy chosen:. 1. In an implementation that detects a single cycle ``C`` with header; ``P``, convergence inside the cycle is determined by ``P``. 2. In an implementation that detects two nested cycles with headers; ``R`` and ``S``, convergence inside those cycles is determined by; their respective headers. .. _convergence-diverged-entry:. A conservative approach would be to simply report all nodes inside; irreducible cycles as having divergent outputs. But it is desirable to; recognize m-converged nodes in the CFG in order to maximize; uniformity. This section describes one such pattern of nodes derived; from *closed paths*, which are a property of the CFG and do not depend; on the cycle hierarchy. **Diverged Entry Criterion:**. The dynamic instances of all the nodes in a closed path ``P`` are; m-converged only if for every divergent branch ``B`` and its; join node ``J`` that lie on ``P``, there is no entry to ``P`` which; lies on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:21904,Integrability,depend,depend,21904,"ransforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region. When two threads diverge at ``Q``, the convergence of; dynamic instances within the cyclic region depends on the cycle; hierarchy chosen:. 1. In an implementation that detects a single cycle ``C`` with header; ``P``, convergence inside the cycle is determined by ``P``. 2. In an implementation that detects two nested cycles with headers; ``R`` and ``S``, convergence inside those cycles is determined by; their respective headers. .. _convergence-diverged-entry:. A conservative approach would be to simply report all nodes inside; irreducible cycles as having divergent outputs. But it is desirable to; recognize m-converged nodes in the CFG in order to maximize; uniformity. This section describes one such pattern of nodes derived; from *closed paths*, which are a property of the CFG and do not depend; on the cycle hierarchy. **Diverged Entry Criterion:**. The dynamic instances of all the nodes in a closed path ``P`` are; m-converged only if for every divergent branch ``B`` and its; join node ``J`` that lie on ``P``, there is no entry to ``P`` which; lies on a diverged path from ``B`` to ``J``. .. figure:: convergence-closed-path.png; :name: convergence-closed-path. Consider the closed path ``P -> Q -> R -> S`` in the above figure.; ``P`` and ``R`` are :ref:`entries to the closed; path<cycle-closed-path>`. ``Q`` is a divergent branch and ``S`` is a; join for that branch, with diverged paths ``Q -> R -> S`` and ``Q ->; S``. - If a diverged entry ``R`` exists, then in some cycle hierarchy,; ``R`` is the header of the smallest cycle ``C`` containing the; closed path and a :ref:`child cycle<cycle-definition>` ``C'``; exists in the set ``C - R``, containing both branch ``Q`` and join; ``S``. When threads diverge at ``Q``, one subset ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:26757,Integrability,depend,depends,26757,"s passing through the header of; an outer cycle that contains ``C``. Thus, the diverged entry criterion can be conservatively simplified; as follows:. For a divergent branch ``B`` and its join node ``J``, the nodes in a; cycle ``C`` that contains both ``B`` and ``J`` are m-converged only; if:. - ``B`` strictly dominates ``J``, or,; - The header ``H`` of ``C`` strictly dominates ``J``, or,; - Recursively, there is cycle ``C'`` inside ``C`` that satisfies the; same condition. When ``J`` is the same as ``H`` or ``B``, the trivial dominance is; insufficient to make any statement about entries to diverged paths. .. _convergence-diverged-outside:. Diverged Paths reaching a Cycle; -------------------------------. .. figure:: convergence-divergent-outside.png; :name: convergence-divergent-outside. The figure shows two cycle hierarchies with a divergent branch in; ``Entry`` instead of ``Q``. For two threads that enter the closed path; ``P -> Q -> R -> S`` at ``P`` and ``R`` respectively, the convergence; of dynamic instances generated along the path depends on whether ``P``; or ``R`` is the header. - Convergence when ``P`` is the header. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | | | | P1 | Q1 | R1 | S1 | P3 | Q3 | | S3 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | | R2 | S2 | P2 | Q2 | | S2 | P4 | Q4 | R3 | S4 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+. |. - Convergence when ``R`` is the header. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |; +---------+-------+-----+-----",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:2368,Modifiability,extend,extends,2368," When threads diverge at a divergent; branch, they may later *reconverge* at a common program point.; Subsequent operations are performed convergently, but the inputs may; be non-uniform, thus producing divergent outputs. Uniformity is also useful by itself on targets that execute threads in; groups with shared execution resources (e.g. waves, warps, or; subgroups):. - Uniform outputs can potentially be computed or stored on shared; resources.; - These targets must ""linearize"" a divergent branch to ensure that; each side of the branch is followed by the corresponding threads in; the same group. But linearization is unnecessary at uniform; branches, since the whole group of threads follows either one side; of the branch or the other. This document presents a definition of convergence that is reasonable; for real targets and is compatible with the currently implicit; semantics of convergent operations in LLVM IR. This is accompanied by; a *uniformity analysis* that extends previous work on divergence analysis; [DivergenceSPMD]_ to cover irreducible control-flow. .. [DivergenceSPMD] Julian Rosemann, Simon Moll, and Sebastian; Hack. 2021. An Abstract Interpretation for SPMD Divergence on; Reducible Control Flow Graphs. Proc. ACM Program. Lang. 5, POPL,; Article 31 (January 2021), 35 pages.; https://doi.org/10.1145/3434312. Terminology; ===========. Cycles; Described in :ref:`cycle-terminology`. Closed path; Described in :ref:`cycle-closed-path`. Disjoint paths; Two paths in a CFG are said to be disjoint if the only nodes common; to both are the start node or the end node, or both. Join node; A join node of a branch is a node reachable along disjoint paths; starting from that branch. Diverged path; A diverged path is a path that starts from a divergent branch and; either reaches a join node of the branch or reaches the end of the; function without passing through any join node of the branch. .. _convergence-dynamic-instances:. Threads and Dynamic Instances; =============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:1518,Performance,perform,performed,1518,"ivergent* otherwise. Correspondingly,; a branch is said to be a uniform branch if its condition is uniform,; and it is a divergent branch otherwise. Whether threads are *converged* or not depends on the paths they take; through the control flow graph. Threads take different outgoing edges; at a *divergent branch*. Divergent branches constrain; program transforms such as changing the CFG or moving a convergent; operation to a different point of the CFG. Performing these; transformations across a divergent branch can change the sets of; threads that execute convergent operations convergently. While these; constraints are out of scope for this document, the described; *uniformity analysis* allows these transformations to identify; uniform branches where these constraints do not hold. Convergence and; uniformity are inter-dependent: When threads diverge at a divergent; branch, they may later *reconverge* at a common program point.; Subsequent operations are performed convergently, but the inputs may; be non-uniform, thus producing divergent outputs. Uniformity is also useful by itself on targets that execute threads in; groups with shared execution resources (e.g. waves, warps, or; subgroups):. - Uniform outputs can potentially be computed or stored on shared; resources.; - These targets must ""linearize"" a divergent branch to ensure that; each side of the branch is followed by the corresponding threads in; the same group. But linearization is unnecessary at uniform; branches, since the whole group of threads follows either one side; of the branch or the other. This document presents a definition of convergence that is reasonable; for real targets and is compatible with the currently implicit; semantics of convergent operations in LLVM IR. This is accompanied by; a *uniformity analysis* that extends previous work on divergence analysis; [DivergenceSPMD]_ to cover irreducible control-flow. .. [DivergenceSPMD] Julian Rosemann, Simon Moll, and Sebastian; Hack. 2021. An Abstr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:19925,Safety,safe,safe,19925,"le hierarchy"". Each node ``X`` in a given CFG is reported to be m-converged if and; only if every cycle that contains ``X`` satisfies the following necessary; conditions:. 1. Every divergent branch inside the cycle satisfies the; :ref:`diverged entry criterion<convergence-diverged-entry>`, and,; 2. There are no :ref:`diverged paths reaching the; cycle<convergence-diverged-outside>` from a divergent branch; outside it. .. note::. A reducible cycle :ref:`trivially satisfies; <convergence-reducible-cycle>` the above conditions. In particular,; if the whole CFG is reducible, then all nodes in the CFG are; m-converged. The uniformity of each output of a static instance; is determined using the criteria; :ref:`described earlier <convergence-uniformity>`. The discovery of; divergent outputs may cause their uses (including branches) to also; become divergent. The analysis propagates this divergence until a; fixed point is reached. The convergence inferred using these criteria is a safe subset of the; maximal converged-with relation for any cycle hierarchy. In; particular, it is sufficient to determine if a static instance is; m-converged for a given cycle hierarchy ``T``, even if that fact is; not detected when examining some other cycle hierarchy ``T'``. This property allows compiler transforms to use the uniformity; analysis without being affected by DFS choices made in the underlying; cycle analysis. When two transforms use different instances of the; uniformity analysis for the same CFG, a ""divergent value"" result in; one analysis instance cannot contradict a ""uniform value"" result in; the other. Generic transforms such as SimplifyCFG, CSE, and loop transforms; commonly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:20146,Safety,detect,detected,20146,"ions:. 1. Every divergent branch inside the cycle satisfies the; :ref:`diverged entry criterion<convergence-diverged-entry>`, and,; 2. There are no :ref:`diverged paths reaching the; cycle<convergence-diverged-outside>` from a divergent branch; outside it. .. note::. A reducible cycle :ref:`trivially satisfies; <convergence-reducible-cycle>` the above conditions. In particular,; if the whole CFG is reducible, then all nodes in the CFG are; m-converged. The uniformity of each output of a static instance; is determined using the criteria; :ref:`described earlier <convergence-uniformity>`. The discovery of; divergent outputs may cause their uses (including branches) to also; become divergent. The analysis propagates this divergence until a; fixed point is reached. The convergence inferred using these criteria is a safe subset of the; maximal converged-with relation for any cycle hierarchy. In; particular, it is sufficient to determine if a static instance is; m-converged for a given cycle hierarchy ``T``, even if that fact is; not detected when examining some other cycle hierarchy ``T'``. This property allows compiler transforms to use the uniformity; analysis without being affected by DFS choices made in the underlying; cycle analysis. When two transforms use different instances of the; uniformity analysis for the same CFG, a ""divergent value"" result in; one analysis instance cannot contradict a ""uniform value"" result in; the other. Generic transforms such as SimplifyCFG, CSE, and loop transforms; commonly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:21272,Safety,detect,detects,21272,"hoices made in the underlying; cycle analysis. When two transforms use different instances of the; uniformity analysis for the same CFG, a ""divergent value"" result in; one analysis instance cannot contradict a ""uniform value"" result in; the other. Generic transforms such as SimplifyCFG, CSE, and loop transforms; commonly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region. When two threads diverge at ``Q``, the convergence of; dynamic instances within the cyclic region depends on the cycle; hierarchy chosen:. 1. In an implementation that detects a single cycle ``C`` with header; ``P``, convergence inside the cycle is determined by ``P``. 2. In an implementation that detects two nested cycles with headers; ``R`` and ``S``, convergence inside those cycles is determined by; their respective headers. .. _convergence-diverged-entry:. A conservative approach would be to simply report all nodes inside; irreducible cycles as having divergent outputs. But it is desirable to; recognize m-converged nodes in the CFG in order to maximize; uniformity. This section describes one such pattern of nodes derived; from *closed paths*, which are a property of the CFG and do not depend; on the cycle hierarchy. **Diverged Entry Criterion:**. The dynamic instances of all the nodes in a closed path ``P`` are; m-converged only if for every divergent branch ``B`` and its; join node ``J`` that lie on ``P``, there is no entry to ``P`` which; lies on a diverged path from ``B`` to ``J``. .. figure:: convergence-closed-path.png; :name: convergence-closed-path. Consider the closed path `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:21403,Safety,detect,detects,21403,"ent value"" result in; one analysis instance cannot contradict a ""uniform value"" result in; the other. Generic transforms such as SimplifyCFG, CSE, and loop transforms; commonly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region. When two threads diverge at ``Q``, the convergence of; dynamic instances within the cyclic region depends on the cycle; hierarchy chosen:. 1. In an implementation that detects a single cycle ``C`` with header; ``P``, convergence inside the cycle is determined by ``P``. 2. In an implementation that detects two nested cycles with headers; ``R`` and ``S``, convergence inside those cycles is determined by; their respective headers. .. _convergence-diverged-entry:. A conservative approach would be to simply report all nodes inside; irreducible cycles as having divergent outputs. But it is desirable to; recognize m-converged nodes in the CFG in order to maximize; uniformity. This section describes one such pattern of nodes derived; from *closed paths*, which are a property of the CFG and do not depend; on the cycle hierarchy. **Diverged Entry Criterion:**. The dynamic instances of all the nodes in a closed path ``P`` are; m-converged only if for every divergent branch ``B`` and its; join node ``J`` that lie on ``P``, there is no entry to ``P`` which; lies on a diverged path from ``B`` to ``J``. .. figure:: convergence-closed-path.png; :name: convergence-closed-path. Consider the closed path ``P -> Q -> R -> S`` in the above figure.; ``P`` and ``R`` are :ref:`entries to the closed; path<cycle-closed-path>`. ``Q`` is a divergent branch an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:23993,Safety,detect,detected,23993,"; reaches ``R``. Dynamic instances of ``S`` executed by threads in set; ``M`` are not converged with those executed in set ``N`` due to the; presence of ``R``. Informally, threads that diverge at ``Q``; reconverge in the same iteration of the outer cycle ``C``, but they; may have executed the inner cycle ``C'`` differently. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | P1 | Q1 | | | | R1 | S1 | P3 | ... | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | P2 | Q2 | S2 | P4 | Q4 | R2 | S4 | | | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+. In the table above, ``S2`` is not converged with ``S1`` due to ``R1``. |. - If ``R`` does not exist, or if any node other than ``R`` is the; header of ``C``, then no such child cycle ``C'`` is detected.; Threads that diverge at ``Q`` execute converged dynamic instances of; ``S`` since they do not encounter the cycle header on any path from; ``Q`` to ``S``. Informally, threads that diverge at ``Q``; reconverge at ``S`` in the same iteration of ``C``. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | P1 | Q1 | R1 | S1 | P3 | Q3 | R3 | S3 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | P2 | Q2 | | S2 | P4 | Q4 | R2 | S4 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+. |. .. note::. In general, the cycle ``C`` in the above statements is not; expected to be the same cycle for different headers. Cycles and; their headers are tightly coupled; f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:25006,Safety,detect,detected,25006,"en no such child cycle ``C'`` is detected.; Threads that diverge at ``Q`` execute converged dynamic instances of; ``S`` since they do not encounter the cycle header on any path from; ``Q`` to ``S``. Informally, threads that diverge at ``Q``; reconverge at ``S`` in the same iteration of ``C``. .. table::; :align: left. +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread1 | Entry | P1 | Q1 | R1 | S1 | P3 | Q3 | R3 | S3 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | P2 | Q2 | | S2 | P4 | Q4 | R2 | S4 | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+------+. |. .. note::. In general, the cycle ``C`` in the above statements is not; expected to be the same cycle for different headers. Cycles and; their headers are tightly coupled; for different headers in the; same outermost cycle, the child cycles detected may be different.; The property relevant to the above examples is that for every; closed path, there is a cycle ``C`` that contains the path and; whose header is on that path. The diverged entry criterion must be checked for every closed path; passing through a divergent branch ``B`` and its join ``J``. Since; :ref:`every closed path passes through the header of some; cycle<cycle-closed-path-header>`, this amounts to checking every cycle; ``C`` that contains ``B`` and ``J``. When the header of ``C``; dominates the join ``J``, there can be no entry to any path from the; header to ``J``, which includes any diverged path from ``B`` to ``J``.; This is also true for any closed paths passing through the header of; an outer cycle that contains ``C``. Thus, the diverged entry criterion can be conservatively simplified; as follows:. For a divergent branch ``B`` and its join node ``J``, the nodes in a; cycle ``C`` that contains both ``B`` and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:28960,Safety,detect,detected,28960,"| Q3 | S3 | | | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+; | Thread2 | Entry | | | | R2 | S2 | P2 | Q2 | S2 | P4 | ... | Exit |; +---------+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+. |. Thus, when diverged paths reach different entries of an irreducible; cycle from outside the cycle, the static analysis conservatively; reports every node in the cycle as not m-converged. .. _convergence-reducible-cycle:. Reducible Cycle; ---------------. If ``C`` is a reducible cycle with header ``H``, then in any DFS,; ``H`` :ref:`must be the header of some cycle<cycle-reducible-headers>`; ``C'`` that contains ``C``. Independent of the DFS, there is no entry; to the subgraph ``C`` other than ``H`` itself. Thus, we have the; following:. 1. The diverged entry criterion is trivially satisfied for a divergent; branch and its join, where both are inside subgraph ``C``.; 2. When diverged paths reach the subgraph ``C`` from outside, their; convergence is always determined by the same header ``H``. Clearly, this can be determined only in a cycle hierarchy ``T`` where; ``C`` is detected as a reducible cycle. No such conclusion can be made; in a different cycle hierarchy ``T'`` where ``C`` is part of a larger; cycle ``C'`` with the same header, but this does not contradict the; conclusion in ``T``. Controlled Convergence; ======================. :ref:`Convergence control tokens <dynamic_instances_and_convergence_tokens>`; provide an explicit semantics for determining which threads are converged at a; given point in the program. The impact of this is incorporated in a; :ref:`controlled maximal converged-with <controlled_maximal_converged_with>`; relation over dynamic instances and a :ref:`controlled m-converged; <controlled_m_converged>` property of static instances. The :ref:`uniformity; analysis <uniformity-analysis>` implemented in LLVM includes this for targets; that support convergence control tokens.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:12401,Usability,intuit,intuition,12401,"e; execution of at least one cycle header, or ``X`` itself is a cycle; header. In reducible cycles (natural loops), each execution of the header is; equivalent to the start of a new iteration of the cycle. But this; analogy breaks down in the presence of explicit constraints on the; converged-with relation, such as those described in :ref:`future; work<convergence-note-convergence>`. Instead, cycle headers should be; treated as implicit *points of convergence* in a maximal; converged-with relation. Consider a sequence of nested cycles ``C1``, ``C2``, ..., ``Ck`` such; that ``C1`` is the outermost cycle and ``Ck`` is the innermost cycle,; with headers ``H1``, ``H2``, ..., ``Hk`` respectively. When a thread; enters the cycle ``Ck``, any of the following is possible:. 1. The thread directly entered cycle ``Ck`` without having executed; any of the headers ``H1`` to ``Hk``. 2. The thread executed some or all of the nested headers one or more; times. The maximal converged-with relation captures the following intuition; about cycles:. 1. When two threads enter a top-level cycle ``C1``, they execute; converged dynamic instances of every node that is a :ref:`child; <cycle-parent-block>` of ``C1``. 2. When two threads enter a nested cycle ``Ck``, they execute; converged dynamic instances of every node that is a child of; ``Ck``, until either thread exits ``Ck``, if and only if they; executed converged dynamic instances of the last nested header that; either thread encountered. Note that when a thread exits a nested cycle ``Ck``, it must follow; a closed path outside ``Ck`` to reenter it. This requires executing; the header of some outer cycle, as described earlier. Consider two dynamic instances ``X1`` and ``X2`` produced by threads ``T1``; and ``T2`` for a node ``X`` that is a child of nested cycle ``Ck``.; Maximal convergence relates ``X1`` and ``X2`` as follows:. 1. If neither thread executed any header from ``H1`` to ``Hk``, then; ``X1`` and ``X2`` are converged. 2. Otherw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:21605,Usability,simpl,simply,21605,"monly change the program in ways that change the maximal; converged-with relations. This also means that a value that was; previously uniform can become divergent after such a transform.; Uniformity has to be recomputed after such transforms. Divergent Branch inside a Cycle; -------------------------------. .. figure:: convergence-divergent-inside.png; :name: convergence-divergent-inside. The above figure shows a divergent branch ``Q`` inside an irreducible; cyclic region. When two threads diverge at ``Q``, the convergence of; dynamic instances within the cyclic region depends on the cycle; hierarchy chosen:. 1. In an implementation that detects a single cycle ``C`` with header; ``P``, convergence inside the cycle is determined by ``P``. 2. In an implementation that detects two nested cycles with headers; ``R`` and ``S``, convergence inside those cycles is determined by; their respective headers. .. _convergence-diverged-entry:. A conservative approach would be to simply report all nodes inside; irreducible cycles as having divergent outputs. But it is desirable to; recognize m-converged nodes in the CFG in order to maximize; uniformity. This section describes one such pattern of nodes derived; from *closed paths*, which are a property of the CFG and do not depend; on the cycle hierarchy. **Diverged Entry Criterion:**. The dynamic instances of all the nodes in a closed path ``P`` are; m-converged only if for every divergent branch ``B`` and its; join node ``J`` that lie on ``P``, there is no entry to ``P`` which; lies on a diverged path from ``B`` to ``J``. .. figure:: convergence-closed-path.png; :name: convergence-closed-path. Consider the closed path ``P -> Q -> R -> S`` in the above figure.; ``P`` and ``R`` are :ref:`entries to the closed; path<cycle-closed-path>`. ``Q`` is a divergent branch and ``S`` is a; join for that branch, with diverged paths ``Q -> R -> S`` and ``Q ->; S``. - If a diverged entry ``R`` exists, then in some cycle hierarchy,; ``R`` is the h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:25826,Usability,simpl,simplified,25826,"he above statements is not; expected to be the same cycle for different headers. Cycles and; their headers are tightly coupled; for different headers in the; same outermost cycle, the child cycles detected may be different.; The property relevant to the above examples is that for every; closed path, there is a cycle ``C`` that contains the path and; whose header is on that path. The diverged entry criterion must be checked for every closed path; passing through a divergent branch ``B`` and its join ``J``. Since; :ref:`every closed path passes through the header of some; cycle<cycle-closed-path-header>`, this amounts to checking every cycle; ``C`` that contains ``B`` and ``J``. When the header of ``C``; dominates the join ``J``, there can be no entry to any path from the; header to ``J``, which includes any diverged path from ``B`` to ``J``.; This is also true for any closed paths passing through the header of; an outer cycle that contains ``C``. Thus, the diverged entry criterion can be conservatively simplified; as follows:. For a divergent branch ``B`` and its join node ``J``, the nodes in a; cycle ``C`` that contains both ``B`` and ``J`` are m-converged only; if:. - ``B`` strictly dominates ``J``, or,; - The header ``H`` of ``C`` strictly dominates ``J``, or,; - Recursively, there is cycle ``C'`` inside ``C`` that satisfies the; same condition. When ``J`` is the same as ``H`` or ``B``, the trivial dominance is; insufficient to make any statement about entries to diverged paths. .. _convergence-diverged-outside:. Diverged Paths reaching a Cycle; -------------------------------. .. figure:: convergence-divergent-outside.png; :name: convergence-divergent-outside. The figure shows two cycle hierarchies with a divergent branch in; ``Entry`` instead of ``Q``. For two threads that enter the closed path; ``P -> Q -> R -> S`` at ``P`` and ``R`` respectively, the convergence; of dynamic instances generated along the path depends on whether ``P``; or ``R`` is the header. - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:622,Availability,avail,available,622,"==============================; Convergent Operation Semantics; ==============================. .. contents::; :local:; :depth: 4. Overview; ========. Some parallel execution environments execute threads in groups that allow; efficient communication within the group using special primitives called; *convergent* operations. The outcome of a convergent operation is sensitive to; the set of threads that executes it ""together"", i.e., convergently. When control; flow :ref:`diverges <convergence-and-uniformity>`, i.e. threads of the same; group follow different; paths through the CFG, not all threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:1624,Availability,down,down,1624,"l threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness of generic program transforms and; convergence-related analyses such as :ref:`uniformity analysis; <convergence-and-uniformity>`. .. _convergent_operations:. Convergent Operations; =====================. In LLVM IR, the only way to communicate between threads as described; above is by calling target-defined convergent intrinsics. Hence, only; a call-site in LLVM IR (a :ref:`call <i_call>`, :ref:`invoke; <i_invoke>`, or :ref:`callbr <i_callbr>` instruction) can result in a; convergent operation. A function in LLVM IR is said to be *convergent* if it has the; :ref:`convergent <attr_con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13429,Availability,mask,mask,13429," This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13474,Availability,mask,mask,13474,"ead to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13490,Availability,mask,mask,13490,"ead to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13502,Availability,mask,maskedBallot,13502,"following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set of threads as the; final ``@subgroupBroadcastFir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13535,Availability,mask,mask,13535,"following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set of threads as the; final ``@subgroupBroadcastFir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:13594,Availability,mask,maskedBallot,13594,"ngle atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %maskedBallot); %relativeThreadIdx = trunc i64 %relativeThreadIdx.p to i32. %isFirstThread = icmp eq i32 %relativeThreadIdx, 0; br i1 %isFirstThread, label %then, label %end. then:; %baseOffset.1 = atomicrmw add ptr @bufferAllocationCount, i32 %numThreads monotonic; br label %end. end:; %baseOffset.2 = phi i32 [ undef, %entry ], [ %baseOffset.1, %then ]; %baseOffset = call i32 @subgroupBroadcastFirst(i32 %baseOffset.2) [ ""convergencectrl""(token %anchor) ]; %offset = add i32 %baseOffset, %relativeThreadIdx; ret i32 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set of threads as the; final ``@subgroupBroadcastFirst``. Nothing else is required for correctness as; far as convergence is concerned. The func",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:21472,Availability,robust,robust,21472,"he; token value in both threads was returned by converged dynamic; instances of ``D``. .. note::. The text defines convergence token values as representing dynamic instances.; But if we were to assume that converged dynamic instances produce the same; token value, then we could almost think of the token value as representing a; set of threads instead -- specifically, the set ``S`` of threads that; executed converged dynamic instances of the defining instruction ``D``. In this intuitive picture, when a convergence token value ``T`` is used by a; ``convergencectrl`` bundle on an instruction ``I``, then the set of threads that; communicates in ``I`` is a subset of the set ``S`` represented by the token value.; Specifically, it is the subset of threads that ends up executing ``I`` while; using the token value. This by itself wouldn't quite work as a definition: what if ``I`` is executed; multiple times by the same threads? Which execution of ``I`` in thread 1; communicates with which execution of ``I`` in thread 2? Leaning on the notion; of dynamic instances gives a robust answer to this question as long as ``D``; and ``I`` are at the same loop (or cycle) nesting level. The case where ``D`` and ``I`` are at different loop nesting levels is; forbidden by the :ref:`static rules <convergence_static_rules>` -- handling; that case is the purpose of :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>`. .. _convergence_control_intrinsics:. Convergence Control Intrinsics; ==============================. This section describes target-independent intrinsics that can be used to; produce convergence tokens. Behaviour is undefined if a convergence control intrinsic is called; indirectly. .. _llvm.experimental.convergence.entry:. ``llvm.experimental.convergence.entry``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.entry() convergent readnone. This intrinsic is used to tie the dynamic instances inside of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:23537,Availability,error,error,23537,"t-defined. For example:. a. In an OpenCL *kernel launch*, the maximal set of threads that; can communicate outside the memory model is a *workgroup*.; Hence, a suitable choice is to specify that all the threads from; a single workgroup in OpenCL execute converged dynamic instances; of this intrinsic.; b. In a C/C++ program, threads are launched independently and they can; communicate only through the memory model. Hence the dynamic instances of; this intrinsic in a C/C++ program are never converged.; 2. If the function is called from a call-site in LLVM IR, then two; threads execute converged dynamic instances of this intrinsic if and; only if both threads entered the function by executing converged; dynamic instances of the call-site. This intrinsic can occur at most once in a function, and only in the entry; block of the function. If this intrinsic occurs in a basic block, then it must; precede any other convergent operation in the same basic block. It is an error if this intrinsic appears in a non-convergent function. It is an error to specify a ``convergencectrl`` operand bundle at a; call to this intrinsic. Function inlining substitutes this intrinsic with the token from the operand; bundle. For example:. .. code-block:: c++. // Before inlining:. void callee() convergent {; %tok = call token @llvm.experimental.convergence.entry(); convergent_operation(...) [ ""convergencectrl""(token %tok) ]; }. void main() {; %outer = call token @llvm.experimental.convergence.anchor(); for (...) {; %inner = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; callee() [ ""convergencectrl""(token %inner) ]; }; }. // After inlining:. void main() {; %outer = call token @llvm.experimental.convergence.anchor(); for (...) {; %inner = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; convergent_operation(...) [ ""convergencectrl""(token %inner) ]; }; }. .. _llvm.experimental.convergence.loop:. ``llvm.experimental.convergen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:23608,Availability,error,error,23608,"ds that; can communicate outside the memory model is a *workgroup*.; Hence, a suitable choice is to specify that all the threads from; a single workgroup in OpenCL execute converged dynamic instances; of this intrinsic.; b. In a C/C++ program, threads are launched independently and they can; communicate only through the memory model. Hence the dynamic instances of; this intrinsic in a C/C++ program are never converged.; 2. If the function is called from a call-site in LLVM IR, then two; threads execute converged dynamic instances of this intrinsic if and; only if both threads entered the function by executing converged; dynamic instances of the call-site. This intrinsic can occur at most once in a function, and only in the entry; block of the function. If this intrinsic occurs in a basic block, then it must; precede any other convergent operation in the same basic block. It is an error if this intrinsic appears in a non-convergent function. It is an error to specify a ``convergencectrl`` operand bundle at a; call to this intrinsic. Function inlining substitutes this intrinsic with the token from the operand; bundle. For example:. .. code-block:: c++. // Before inlining:. void callee() convergent {; %tok = call token @llvm.experimental.convergence.entry(); convergent_operation(...) [ ""convergencectrl""(token %tok) ]; }. void main() {; %outer = call token @llvm.experimental.convergence.anchor(); for (...) {; %inner = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; callee() [ ""convergencectrl""(token %inner) ]; }; }. // After inlining:. void main() {; %outer = call token @llvm.experimental.convergence.anchor(); for (...) {; %inner = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; convergent_operation(...) [ ""convergencectrl""(token %inner) ]; }; }. .. _llvm.experimental.convergence.loop:. ``llvm.experimental.convergence.loop``; --------------------------------------. .. code-block:: llvm. token @ll",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:25310,Availability,error,error,25310,"en @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; convergent_operation(...) [ ""convergencectrl""(token %inner) ]; }; }. .. _llvm.experimental.convergence.loop:. ``llvm.experimental.convergence.loop``; --------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token) ] convergent readnone. This intrinsic represents the place where an imaginary counter is incremented; for determining convergence inside a control flow cycle. Let ``U`` be a call to this intrinsic and ``D`` be the convergent operation that; defines the token value used as the ``convergencectrl`` operand to ``U``. Two; threads execute converged dynamic instances of ``U`` if and only if:. 1. The token value in both threads was returned by converged dynamic; instances of ``D``, and,; 2. There is an integer *n* such that both threads execute ``U`` for the *n*'th time; with that token value. It is an error to omit the ``convergencectrl`` operand bundle on a; call to this intrinsic. If this intrinsic occurs in a basic block, then it must precede any other; convergent operation in the same basic block. .. _convergence_cycle_heart:. **Heart of a Cycle:**. If a :ref:`cycle <cycle-terminology>` ``C`` contains an occurrence ``H`` of; this intrinsic whose token operand is defined outside ``C``, then ``H`` is; called the heart of ``C``. .. note::. The static rules for cycles imply that a heart can occur only in the header; of a natural loop. This ensures that the heart closely represents the; intuitive notion of a loop iteration. If this restriction is relaxed, the; resulting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.exp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:26760,Availability,error,error,26760,"t a heart can occur only in the header; of a natural loop. This ensures that the heart closely represents the; intuitive notion of a loop iteration. If this restriction is relaxed, the; resulting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.experimental.convergence.anchor:. ``llvm.experimental.convergence.anchor``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.anchor() convergent readnone. This intrinsic produces an initial convergence token that is independent from; any ""outer scope"". The set of threads executing converged dynamic instances of; this intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a group that ""happen to be active; at the same time"" will execute converged dynamic instances, so that programs; can detect the maximal set of threads that can communicate efficiently within; some local region of the program. .. _convergence_uncontrolled:. Uncontrolled Convergent Operations; ==================================. Convergent operations with an explicit ``convergencectrl`` operand bundle are; called *controlled convergent operations*. All other convergent operations are; said to be *uncontrolled*. An uncontrolled convergent operation is said to have *implicit convergence; control* determined by the ``convergent`` attribute alone. The semantics of the; ``convergent`` attribute as implemented in LLVM differs from the documented; semantics. The implementation tries to follow common intuition about convergent; operations, which remains under-specified. As such, it is not possible",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:226,Energy Efficiency,efficient,efficient,226,"==============================; Convergent Operation Semantics; ==============================. .. contents::; :local:; :depth: 4. Overview; ========. Some parallel execution environments execute threads in groups that allow; efficient communication within the group using special primitives called; *convergent* operations. The outcome of a convergent operation is sensitive to; the set of threads that executes it ""together"", i.e., convergently. When control; flow :ref:`diverges <convergence-and-uniformity>`, i.e. threads of the same; group follow different; paths through the CFG, not all threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:27067,Energy Efficiency,efficient,efficiently,27067,"lting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.experimental.convergence.anchor:. ``llvm.experimental.convergence.anchor``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.anchor() convergent readnone. This intrinsic produces an initial convergence token that is independent from; any ""outer scope"". The set of threads executing converged dynamic instances of; this intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a group that ""happen to be active; at the same time"" will execute converged dynamic instances, so that programs; can detect the maximal set of threads that can communicate efficiently within; some local region of the program. .. _convergence_uncontrolled:. Uncontrolled Convergent Operations; ==================================. Convergent operations with an explicit ``convergencectrl`` operand bundle are; called *controlled convergent operations*. All other convergent operations are; said to be *uncontrolled*. An uncontrolled convergent operation is said to have *implicit convergence; control* determined by the ``convergent`` attribute alone. The semantics of the; ``convergent`` attribute as implemented in LLVM differs from the documented; semantics. The implementation tries to follow common intuition about convergent; operations, which remains under-specified. As such, it is not possible to fully; translate implicit convergence control into explicit convergence control tokens,; and these two modes cannot be mixed in the same function. If a function contains a controlled conv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:851,Integrability,synchroniz,synchronization,851,"==============================; Convergent Operation Semantics; ==============================. .. contents::; :local:; :depth: 4. Overview; ========. Some parallel execution environments execute threads in groups that allow; efficient communication within the group using special primitives called; *convergent* operations. The outcome of a convergent operation is sensitive to; the set of threads that executes it ""together"", i.e., convergently. When control; flow :ref:`diverges <convergence-and-uniformity>`, i.e. threads of the same; group follow different; paths through the CFG, not all threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:3259,Integrability,depend,depend,3259,"threads as described; above is by calling target-defined convergent intrinsics. Hence, only; a call-site in LLVM IR (a :ref:`call <i_call>`, :ref:`invoke; <i_invoke>`, or :ref:`callbr <i_callbr>` instruction) can result in a; convergent operation. A function in LLVM IR is said to be *convergent* if it has the; :ref:`convergent <attr_convergent>` attribute. A call-site in LLVM IR is said to be *convergent* if it is a direct; call to a convergent function or it has the :ref:`convergent; <attr_convergent>` attribute or a :ref:`convergencectrl operand bundle; <convergencectrl>`. Informational notes:. A function may have to be treated as convergent if that function, or; transitively, any function called from it, contains a convergent call-site. A; frontend generating the ``convergent`` attribute should take this into account; when emitting functions and function calls. But this is not always the case:. A non-convergent function may contain convergent operations; such operations; do not directly depend on the set of threads that enter the function as a; single communicating group. Instead, these operations depend on an; implementation-defined subset of threads within the body of the function, as; shown in :ref:`opportunistic_convergence`. Examples of Convergent Operations; ========================================. (This section is informative.). Texture sampling in a pixel shader; ----------------------------------. The following stylized pixel shader samples a texture at a given set of; coordinates, using the builtin function `textureSample`. Texture sampling; requires screen-space derivatives of the coordinates to determine the level of; detail (mipmap level) of the sample. They are commonly approximated by taking; the difference between neighboring pixels, which are computed by different; threads in the same group:. .. code-block:: c++. void example_shader() {; ...; color = textureSample(texture, coordinates);; if (condition) {; use(color);; }; ...; }. From a purely sin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:3372,Integrability,depend,depend,3372,":ref:`callbr <i_callbr>` instruction) can result in a; convergent operation. A function in LLVM IR is said to be *convergent* if it has the; :ref:`convergent <attr_convergent>` attribute. A call-site in LLVM IR is said to be *convergent* if it is a direct; call to a convergent function or it has the :ref:`convergent; <attr_convergent>` attribute or a :ref:`convergencectrl operand bundle; <convergencectrl>`. Informational notes:. A function may have to be treated as convergent if that function, or; transitively, any function called from it, contains a convergent call-site. A; frontend generating the ``convergent`` attribute should take this into account; when emitting functions and function calls. But this is not always the case:. A non-convergent function may contain convergent operations; such operations; do not directly depend on the set of threads that enter the function as a; single communicating group. Instead, these operations depend on an; implementation-defined subset of threads within the body of the function, as; shown in :ref:`opportunistic_convergence`. Examples of Convergent Operations; ========================================. (This section is informative.). Texture sampling in a pixel shader; ----------------------------------. The following stylized pixel shader samples a texture at a given set of; coordinates, using the builtin function `textureSample`. Texture sampling; requires screen-space derivatives of the coordinates to determine the level of; detail (mipmap level) of the sample. They are commonly approximated by taking; the difference between neighboring pixels, which are computed by different; threads in the same group:. .. code-block:: c++. void example_shader() {; ...; color = textureSample(texture, coordinates);; if (condition) {; use(color);; }; ...; }. From a purely single-threaded perspective, sinking the `textureSample` into; the if-statement appears legal. However, if the condition is false for some; neighboring pixels, then their cor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:4797,Integrability,depend,depends,4797,"e builtin function `textureSample`. Texture sampling; requires screen-space derivatives of the coordinates to determine the level of; detail (mipmap level) of the sample. They are commonly approximated by taking; the difference between neighboring pixels, which are computed by different; threads in the same group:. .. code-block:: c++. void example_shader() {; ...; color = textureSample(texture, coordinates);; if (condition) {; use(color);; }; ...; }. From a purely single-threaded perspective, sinking the `textureSample` into; the if-statement appears legal. However, if the condition is false for some; neighboring pixels, then their corresponding threads will not execute together; in the group, making it impossible to take the difference of coordinates as an; approximation of the screen-space derivative. In practice, the outcome will be; an undefined value. That is, the `textureSample` operation fits our definition of a convergent; operation:. 1. It communicates with a set of threads that implicitly depends on control; flow.; 2. Correctness depends on this set of threads. The compiler frontend can emit IR that expresses the convergence constraints as; follows:. .. code-block:: llvm. define void @example_shader() convergent {; %entry = call token @llvm.experimental.convergence.entry(); ...; %color = call T @textureSample(U %texture, V %coordinates) [ ""convergencectrl""(token %entry) ]; br i1 %condition, label %then, label %end. then:; call void @use(T %color); br label %end. end:; ret void; }. The :ref:`llvm.experimental.convergence.entry <llvm.experimental.convergence.entry>`; intrinsic is itself ``convergent``, and we expect it to communicate at least; among all threads of the same ""quad"" -- a group of 2x2 pixels that are; evaluated together for the purpose of approximating screen-space derivatives.; This fact is not part of the generic LLVM IR semantics; it would have to be; defined somewhere else, for example as part of target-specific ABI definitions; and/or in r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:4839,Integrability,depend,depends,4839,"een-space derivatives of the coordinates to determine the level of; detail (mipmap level) of the sample. They are commonly approximated by taking; the difference between neighboring pixels, which are computed by different; threads in the same group:. .. code-block:: c++. void example_shader() {; ...; color = textureSample(texture, coordinates);; if (condition) {; use(color);; }; ...; }. From a purely single-threaded perspective, sinking the `textureSample` into; the if-statement appears legal. However, if the condition is false for some; neighboring pixels, then their corresponding threads will not execute together; in the group, making it impossible to take the difference of coordinates as an; approximation of the screen-space derivative. In practice, the outcome will be; an undefined value. That is, the `textureSample` operation fits our definition of a convergent; operation:. 1. It communicates with a set of threads that implicitly depends on control; flow.; 2. Correctness depends on this set of threads. The compiler frontend can emit IR that expresses the convergence constraints as; follows:. .. code-block:: llvm. define void @example_shader() convergent {; %entry = call token @llvm.experimental.convergence.entry(); ...; %color = call T @textureSample(U %texture, V %coordinates) [ ""convergencectrl""(token %entry) ]; br i1 %condition, label %then, label %end. then:; call void @use(T %color); br label %end. end:; ret void; }. The :ref:`llvm.experimental.convergence.entry <llvm.experimental.convergence.entry>`; intrinsic is itself ``convergent``, and we expect it to communicate at least; among all threads of the same ""quad"" -- a group of 2x2 pixels that are; evaluated together for the purpose of approximating screen-space derivatives.; This fact is not part of the generic LLVM IR semantics; it would have to be; defined somewhere else, for example as part of target-specific ABI definitions; and/or in reference to some relevant API specs. Since the ``@textureSample`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:5972,Integrability,depend,dependencies,5972,"vergence constraints as; follows:. .. code-block:: llvm. define void @example_shader() convergent {; %entry = call token @llvm.experimental.convergence.entry(); ...; %color = call T @textureSample(U %texture, V %coordinates) [ ""convergencectrl""(token %entry) ]; br i1 %condition, label %then, label %end. then:; call void @use(T %color); br label %end. end:; ret void; }. The :ref:`llvm.experimental.convergence.entry <llvm.experimental.convergence.entry>`; intrinsic is itself ``convergent``, and we expect it to communicate at least; among all threads of the same ""quad"" -- a group of 2x2 pixels that are; evaluated together for the purpose of approximating screen-space derivatives.; This fact is not part of the generic LLVM IR semantics; it would have to be; defined somewhere else, for example as part of target-specific ABI definitions; and/or in reference to some relevant API specs. Since the ``@textureSample`` call then uses the token produced by the entry; intrinsic in its ``convergencectrl`` bundle, and has no additional control; dependencies, it must communicate among the same set of threads. This indicates; to generic program transforms that sinking the ``@textureSample`` call is; forbidden. (A program transform can still sink the call if it can prove somehow,; e.g. by leaning on target-specific callbacks that can analyze the program with; additional knowledge, that ``%condition`` is always uniform across the threads; referenced by the *convergence token* ``%entry``.). .. _convergence_example_reductions:. Reductions inside divergent control flow; ----------------------------------------. The following example shows that merging common code of branches can be; incorrect in the face of convergent operations:. .. code-block:: c++. void example_kernel() {; delta = ...; if (delta > 0) {; total_gains = subgroupAdd(delta);; ...; } else {; total_losses = subgroupAdd(delta);; ...; }; }. The ``subgroupAdd`` computing the ``total_gains`` will be executed by the; subset of thr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:8193,Integrability,depend,dependency,8193,"d merge the ``subgroupAdd`` above the if-statement, it; would sum up the ``delta`` across *all* threads instead. The compiler frontend can emit IR that expresses the convergence constraints; as follows:. .. code-block:: llvm. define void @example_kernel() convergent {; %entry = call token @llvm.experimental.convergence.entry(); %delta = ...; %cc = icmp sgt i32 %delta, 0; br i1 %cc, label %then, label %else. then:; %total_gains = call i32 @subgroupAdd(i32 %delta) [ ""convergencectrl""(token %entry) ]; ...; br label %end. else:; %total_losses = call i32 @subgroupAdd(i32 %delta) [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; ...; }. The entry intrinsic behaves like in the previous example: assuming that; ``@example_kernel`` is an OpenCL kernel (as hinted at by the ""subgroup""; terminology), we expect it to communicate among all threads within the; ""subgroup"". This typically maps to a SIMD vector on GPU hardware. The calls to ``@subgroupAdd`` use the token produced by the entry intrinsic,; but they also have an additional control dependency. According to the rules; defined in this document, they only communicate among the subset of threads; that actually end up executing the respective (static) call site. Hoisting them would remove the control dependency and cause them to communicate; among the full set of threads that the entry intrinsic communicated with.; Again, hoisting is allowed if it can be proven that ``%cc`` is always uniform; among the relevant set of threads: in that case, the ``@subgroupAdd`` already; communicates among the full set of threads in the original program. Motivating Examples of Convergence Control; ==========================================. (This section is informative.). Unstructured control flow; -------------------------. Consider an example of how jump threading removes structure in a way that can; make semantics non-obvious without the convergence intrinsics described in this; document:. .. code-block:: llvm. void example_origi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:8411,Integrability,depend,dependency,8411,"onvergence.entry(); %delta = ...; %cc = icmp sgt i32 %delta, 0; br i1 %cc, label %then, label %else. then:; %total_gains = call i32 @subgroupAdd(i32 %delta) [ ""convergencectrl""(token %entry) ]; ...; br label %end. else:; %total_losses = call i32 @subgroupAdd(i32 %delta) [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; ...; }. The entry intrinsic behaves like in the previous example: assuming that; ``@example_kernel`` is an OpenCL kernel (as hinted at by the ""subgroup""; terminology), we expect it to communicate among all threads within the; ""subgroup"". This typically maps to a SIMD vector on GPU hardware. The calls to ``@subgroupAdd`` use the token produced by the entry intrinsic,; but they also have an additional control dependency. According to the rules; defined in this document, they only communicate among the subset of threads; that actually end up executing the respective (static) call site. Hoisting them would remove the control dependency and cause them to communicate; among the full set of threads that the entry intrinsic communicated with.; Again, hoisting is allowed if it can be proven that ``%cc`` is always uniform; among the relevant set of threads: in that case, the ``@subgroupAdd`` already; communicates among the full set of threads in the original program. Motivating Examples of Convergence Control; ==========================================. (This section is informative.). Unstructured control flow; -------------------------. Consider an example of how jump threading removes structure in a way that can; make semantics non-obvious without the convergence intrinsics described in this; document:. .. code-block:: llvm. void example_original() {; entry:; ...; br i1 %cond1, label %then1, label %mid. then1:; ...; %cond2 = ...; br label %mid. mid:; %flag = phi i1 [ true, %entry ], [ %cond2, %then1 ]; br i1 %flag, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier(); ...; br label %end. end:; }. void example_jumpthreaded() {",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:9689,Integrability,synchroniz,synchronize,9689," program. Motivating Examples of Convergence Control; ==========================================. (This section is informative.). Unstructured control flow; -------------------------. Consider an example of how jump threading removes structure in a way that can; make semantics non-obvious without the convergence intrinsics described in this; document:. .. code-block:: llvm. void example_original() {; entry:; ...; br i1 %cond1, label %then1, label %mid. then1:; ...; %cond2 = ...; br label %mid. mid:; %flag = phi i1 [ true, %entry ], [ %cond2, %then1 ]; br i1 %flag, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier(); ...; br label %end. end:; }. void example_jumpthreaded() {; entry:; ...; br i1 %cond1, label %then1, label %then2. then1:; ...; %cond2 = ...; br i1 %cond2, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier(); ...; br label %end. end:; }. Is the control barrier guaranteed to synchronize among the same set of threads; in both cases? Different implementations in the literature may give different; answers to this question:. * In an implementation that reconverges at post-dominators, threads reconverge; at ``mid`` in the first version, so that all threads (within a subgroup/wave); that execute the control barrier do so together. In the second version,; threads that reach the control barrier via different paths synchronize; separately: the first (and only) post-dominator is ``end``, so threads do not; reconverge before then. * An implementation that sorts basic blocks topologically and ensures maximal; reconvergence for each basic block would behave the same way in both; versions. We generally take the stance that reconvergence in acyclic control flow must; be maximal. The compiler frontend could augment the original code as follows:. .. code-block:: llvm. define void @example_original() convergent {; entry:; %entry = call token @llvm.experimental.convergence.entry(); ...; br i1 %cond1, label %then1, label %mid. th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:10129,Integrability,synchroniz,synchronize,10129," {; entry:; ...; br i1 %cond1, label %then1, label %mid. then1:; ...; %cond2 = ...; br label %mid. mid:; %flag = phi i1 [ true, %entry ], [ %cond2, %then1 ]; br i1 %flag, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier(); ...; br label %end. end:; }. void example_jumpthreaded() {; entry:; ...; br i1 %cond1, label %then1, label %then2. then1:; ...; %cond2 = ...; br i1 %cond2, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier(); ...; br label %end. end:; }. Is the control barrier guaranteed to synchronize among the same set of threads; in both cases? Different implementations in the literature may give different; answers to this question:. * In an implementation that reconverges at post-dominators, threads reconverge; at ``mid`` in the first version, so that all threads (within a subgroup/wave); that execute the control barrier do so together. In the second version,; threads that reach the control barrier via different paths synchronize; separately: the first (and only) post-dominator is ``end``, so threads do not; reconverge before then. * An implementation that sorts basic blocks topologically and ensures maximal; reconvergence for each basic block would behave the same way in both; versions. We generally take the stance that reconvergence in acyclic control flow must; be maximal. The compiler frontend could augment the original code as follows:. .. code-block:: llvm. define void @example_original() convergent {; entry:; %entry = call token @llvm.experimental.convergence.entry(); ...; br i1 %cond1, label %then1, label %mid. then1:; ...; %cond2 = ...; br label %mid. mid:; %flag = phi i1 [ true, %entry ], [ %cond2, %then1 ]; br i1 %flag, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier() [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; }. If S is the set of threads that the entry intrinsic communicated with, then; the ``@subgroupControlBarrier`` call communicates with the subset of S ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:11772,Integrability,depend,dependencies,11772,"en1:; ...; %cond2 = ...; br label %mid. mid:; %flag = phi i1 [ true, %entry ], [ %cond2, %then1 ]; br i1 %flag, label %then2, label %end. then2:; ...; call void @subgroupControlBarrier() [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; }. If S is the set of threads that the entry intrinsic communicated with, then; the ``@subgroupControlBarrier`` call communicates with the subset of S that; actually reaches the call site. This set of threads doesn't change after; jump-threading, so the answer to the question posed above remains the same. .. _opportunistic_convergence:. Opportunistic convergent operations; -----------------------------------. Some programs have local regions of code that contain a sequence of convergent; operations where the code does not care about the exact set of threads with; which it is executed, but only that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:11938,Integrability,depend,dependencies,11938,"then2:; ...; call void @subgroupControlBarrier() [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; }. If S is the set of threads that the entry intrinsic communicated with, then; the ``@subgroupControlBarrier`` call communicates with the subset of S that; actually reaches the call site. This set of threads doesn't change after; jump-threading, so the answer to the question posed above remains the same. .. _opportunistic_convergence:. Opportunistic convergent operations; -----------------------------------. Some programs have local regions of code that contain a sequence of convergent; operations where the code does not care about the exact set of threads with; which it is executed, but only that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:15042,Integrability,contract,contract,15042,"2 %offset; }. The key here is that the function really doesn't care which set of threads it; is being called with. It takes whatever set of threads it can get. What the; implementation of the function cares about is that the initial; ``@subgroupBallot`` -- which is used to retrieve the bitmask of threads that; executed the anchor together -- executes with the same set of threads as the; final ``@subgroupBroadcastFirst``. Nothing else is required for correctness as; far as convergence is concerned. The function ``@reserveSpaceInBuffer`` itself is _not_ ``convergent``: callers; are free to move call sites of the function as they see fit. This can change; the behavior in practice, by changing the sets of threads that are grouped; together for the atomic operation. This can be visible in the output of the; program, since the order in which outputs appear in the buffer is changed.; However, this does not break the overall contract that ``@reserveSpaceInBuffer``; has with its caller -- which makes sense: the order of outputs is; non-deterministic anyway because of the atomic operation that is involved. If the function is inlined, the use of the anchor intrinsic similarly indicates; that certain transforms which are usually forbidden by the presence of; convergent operations are in fact allowed, as long as they don't break up the; region of code that is controlled by the anchor. .. _convergence_high-level_break:. Extended Cycles: Divergent Exit from a Loop; -------------------------------------------. High-level languages typically provide a ``break`` statement that transfers; control out of a loop statement. In most cases, the loop is structured and hence; there is no ambiguity about convergence inside the loop. But an ambiguity arises; when a ``break`` is control dependent on a divergent condition inside the loop.; Consider the following example:. .. code-block:: c++. void example() {; // A; ...; for (...) {; // B; if (condition) { // divergent condition; // C; convergent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:15900,Integrability,depend,dependent,15900,"ible in the output of the; program, since the order in which outputs appear in the buffer is changed.; However, this does not break the overall contract that ``@reserveSpaceInBuffer``; has with its caller -- which makes sense: the order of outputs is; non-deterministic anyway because of the atomic operation that is involved. If the function is inlined, the use of the anchor intrinsic similarly indicates; that certain transforms which are usually forbidden by the presence of; convergent operations are in fact allowed, as long as they don't break up the; region of code that is controlled by the anchor. .. _convergence_high-level_break:. Extended Cycles: Divergent Exit from a Loop; -------------------------------------------. High-level languages typically provide a ``break`` statement that transfers; control out of a loop statement. In most cases, the loop is structured and hence; there is no ambiguity about convergence inside the loop. But an ambiguity arises; when a ``break`` is control dependent on a divergent condition inside the loop.; Consider the following example:. .. code-block:: c++. void example() {; // A; ...; for (...) {; // B; if (condition) { // divergent condition; // C; convergent_op();; break;; }; // D; ...; }; // E; }. In this program, the call to convergent_op() is lexically ""inside"" the ``for``; loop. But when translated to LLVM IR, the basic block B is an exiting block; ending in a divergent branch, and the basic block C is an exit of the loop.; Thus, the call to convergent_op() is outside the loop. This causes a mismatch; between the programmer's expectation and the compiled program. The call should; be executed convergently on every iteration of the loop, by threads that; together take the branch to exit the loop. But when compiled, all threads that; take the divergent exit on different iterations first converge at the beginning; of basic block C and then together execute the call to convergent_op(). In this case, :ref:`llvm.experimental.converg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:34558,Integrability,synchroniz,synchronizing,34558,"nt`` attribute on a; call-site or a function and any explicit ``convergencectrl`` operand; bundle at a call-site. An optimizer may remove the ``convergent`` attribute and any explicit; ``convergencectrl`` operand bundle from a call-site if it can prove; that the execution of this call-site always results in a call to a; non-convergent function. An optimizer may remove the ``convergent`` attribute on a function if it can; prove that the function does not contain a call to; :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>`, or any uncontrolled convergent; operations. Memory Model Non-Interaction; ============================. The fact that an operation is convergent has no effect on how it is treated for; memory model purposes. In particular, an operation that is ``convergent`` and; ``readnone`` does not introduce additional ordering constraints as far as the; memory model is concerned. There is no implied barrier, neither in the memory; barrier sense nor in the control barrier sense of synchronizing the execution; of threads. Informational note: Threads that execute converged dynamic instances do not; necessarily do so at the same time. Other Interactions; ==================. A function can be both ``convergent`` and; ``speculatable``, indicating that the function does not have undefined; behavior and has no effects besides calculating its result, but is still; affected by the set of threads executing this function. This typically; prevents speculation of calls to the function unless the constraint imposed; by ``convergent`` is further relaxed by some other means. Controlled Maximal Convergence; ==============================. The :ref:`converged-with relation <convergence-definition>` over dynamic; instances of each controlled convergent operation is completely defined by the; semantics of convergence tokens. But the implementation-defined convergence at a; call to :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.converge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:35545,Integrability,depend,depends,35545,"ecution; of threads. Informational note: Threads that execute converged dynamic instances do not; necessarily do so at the same time. Other Interactions; ==================. A function can be both ``convergent`` and; ``speculatable``, indicating that the function does not have undefined; behavior and has no effects besides calculating its result, but is still; affected by the set of threads executing this function. This typically; prevents speculation of calls to the function unless the constraint imposed; by ``convergent`` is further relaxed by some other means. Controlled Maximal Convergence; ==============================. The :ref:`converged-with relation <convergence-definition>` over dynamic; instances of each controlled convergent operation is completely defined by the; semantics of convergence tokens. But the implementation-defined convergence at a; call to :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` also depends on the cycle hierarchy; chosen if it occurs inside an irreducible cycle. When the token defined by a convergent operation ``D`` is used at another; convergent operation ``U``, the implementation must ensure that the threads that; converge at ``U`` are all the threads that reached ``U`` after converging at; ``D``. On most implementations, it is reasonable to assume that only these; threads are converged at every node they reach on any path from ``D`` to ``U``.; In other words, the converged-with relation at ``D`` produces groups of threads; that can converge only within each group, while inside the convergence region of; ``D``. All this affects the :ref:`maximal converged-with relation; <convergence-maximal>` over dynamic instances and in turn the :ref:`m-converged; property <uniformity-analysis>` of static instances in the convergence region of; ``D``. .. _controlled_maximal_converged_with:. **Controlled Maximal converged-with Relation**. 1. Dynamic instances of a *convergent operation* are related in the cont",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:46391,Integrability,depend,dependencies,46391,"thread ``i`` (each thread executes it only once), and; let ``@op.k(i)`` be as before. Then:. 1. ``%loop(1) == %loop(2)`` because of the dynamic rule about loop heart; intrinsics. 2. ``@op.1(1) == @op.1(2)`` because ``@op.1(i)`` uses the value of ``%loop``; referring to ``%loop(i)``, and ``%loop(1) == %loop(2)``. 3. Whether ``@op.2(1) == @op.2(2)`` is implementation-defined because of the; use of the ``%free`` anchor intrinsic. In practice, they almost certainly have to be non-converged dynamic; instances. Consider that if an implementation strictly follows the order of; instructions given in the program, the executions of the threads can be; ""aligned"" as follows:. .. code-block:: text. Thread 1: A B C D F B D E F G; Thread 2: A B D E F B C D F G. So then ``@op.2(1)`` physically executes later than ``@op.2(2)`` and there; can be no communication between the threads, which means they execute; non-converged dynamic instances. That said, it is conceivable that there aren't actually any data or other; dependencies that would enforce this execution order. In that case, a highly; out-of-order implementation could potentially allow communication. That's; why the rules defined in this document are silent about whether; ``@op.2(1) == @op.2(2)`` or not. This type of convergence control seems relatively unlikely to appear in real; programs. Its possibility is simply a logical consequence of the model. An equivalent issue arises if the convergent operations are replaced by nested; loops with loop heart intrinsics that directly refer to ``%anchor``, hence; the variants of the static rules about cycles that apply to them:. .. code-block:: llvm. ; WARNING: Example of incorrect convergence control!. %anchor = call token @llvm.experimental.convergence.anchor(); for (;;) {; if (condition1) {; for (;;) {; %loop1 = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; }; }; if (condition2) {; for (;;) {; %loop2 = call token @llvm.experimental.convergence.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:56301,Integrability,depend,depending,56301,"ecute converged dynamic instances of the operation. By; definition, this changes the set of threads that participate in the; communication of the convergent operation, which will typically change its; result. There are a number of exceptions, though most of them require additional; knowledge. For example, hoisting and sinking across *uniform* conditional branches -- i.e.,; conditional branches where within every possible relevant set of threads, all; threads will always take the same direction -- is generally allowed. See the end; of the :ref:`example of reductions inside control flow; <convergence_example_reductions>` for a brief discussion. Some convergent operations can be hoisted but not sunk, or vice versa. A simple; example is the ``subgroupShuffle(data, id)`` operation. It returns the ``data``; operand of the thread identified by ``id``, where thread IDs are fixed and; assigned to each thread at launch. The result is undefined (or perhaps there is; UB, depending on the language and environment) if thread ``id`` is not in the; communicating set of threads. So hoisting is allowed in the following; pseudo-code example:. .. code-block:: llvm. define void @example(...) convergent {; %entry = call token @llvm.experimental.convergence.entry(); %data = ...; %id = ...; if (condition) {; %shuffled = call i32 @subgroupShuffle(i32 %data, i32 %id) [ ""convergencectrl""(token %entry) ]; ...; } else {; %shuffled = call i32 @subgroupShuffle(i32 %data, i32 %id) [ ""convergencectrl""(token %entry) ]; ...; }; }. After hoisting the calls to ``@subgroupShuffle``, the communicating set of; threads is the union of the two sets of threads in the original program, so; ``%id`` can only go ""out of range"" after hoisting if it did so in the original; program. However, speculative execution of ``@subgroupShuffle`` in the following program; may be forbidden:. .. code-block:: llvm. define void @example(...) convergent {; %entry = call token @llvm.experimental.convergence.entry(); %data = ...; %i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:18462,Modifiability,extend,extended,18462,"r label %for. for:; %inner = call token @llvm.experimental.convergence.loop() [""convergencectrl""(token %entry)]; %for.cond = i1 ...; br i1 %for.cond, label %B, label %E. B:; ...; %condition = i1 ...; br i1 %condition, label %C, label %D. C:; call void @convergent_op() [""convergencectrl""(token %inner)]; br label %E. D:; ...; br label %for. E:; ...; ret void; }. The LLVM IR version of the same program shows a cycle consisting of the basic; blocks ``%for``, ``%B`` and ``%D``, while ``%C`` is an exit reached by the; divergent branch at the end of the exiting block ``%B``. But the use of; convergence control tokens makes it clear that block ``%C`` must be executed; convergently only by those threads that convergently take the exit edge from %B; to ``%C``. In other words, the convergent execution of ``%C`` is governed by the; call to the :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>` intrinsic inside the cycle. The cycle is; effectively extended to include all uses of this token that lie outside the; cycle. .. _dynamic_instances_and_convergence_tokens:. Dynamic Instances and Convergence Tokens; ========================================. Every execution of an LLVM IR instruction occurs in a :ref:`dynamic instance; <convergence-dynamic-instances>` of the instruction. Dynamic instances are the; formal objects by which we talk about communicating threads in convergent; operations. Dynamic instances are defined for *all* operations in an LLVM; program, whether convergent or not. Convergence control is primarily about the; dynamic instances of convergent operations since they affect execution of the; program through inter-thread communication. The dynamic instances for; non-convergent operations are relevant for determining :ref:`uniformity; <convergence-and-uniformity>` of values. Dynamic instances produced by the execution of the same *convergent operation*; by different threads may be :ref:`converged <convergence-definition>`. When; executing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:38338,Modifiability,extend,extends,38338,"`X2`` in the; respective thread is convergence-before ``X1``,; - without assuming that ``X1`` is converged with ``X2``. .. _controlled_m_converged:. **Controlled m-converged Static Instances**. A node ``X`` in a given CFG is reported to be m-converged if and only if:. 1. For any token definition ``D`` such that ``X`` is inside the convergence region; of ``D``, ``D`` itself is m-converged, and,; 2. Every cycle that contains ``X`` satisfies the following necessary; conditions:. a. Every divergent branch inside the cycle satisfies the :ref:`diverged; entry criterion<convergence-diverged-entry>`, and,; b. There are no :ref:`diverged paths reaching the; cycle<convergence-diverged-outside>` from a divergent branch outside it. Temporal Divergence at Cycle Exit; ---------------------------------. When a cycle has a divergent exit, maximal convergence assumes that all threads; converge at the exit block. But if a controlled convergent operation outside the; cycle uses a token defined by an operation ``D`` inside the cycle, the; convergence region of ``D`` now extends outside the cycle. If two threads; executed converged dynamic instances of ``D`` before exiting the cycle, then; they continue to execute converged dynamic instances of nodes in the convergence; region of ``D`` outside the cycle. Thus, for a value ``V`` defined inside the; cycle, any use ``U`` of ``V`` within the convergence region of ``T`` uses the; output of converged dynamic instances of ``V``. If ``V`` is uniform, then its; use at such a ``U`` is also uniform. In other words, temporal divergence applies; only to a use of ``V`` that is outside the convergence region of ``D``. Rationales for Static rules about cycles; ========================================. (This section is informative.). .. note::. For convenience, we use the operator ``==`` to represent the relation; ``converged-with`` and the operator ``!=`` to represent its negation. Consider a loop with (incorrect!) convergence control as in the followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:12567,Performance,perform,performant,12567,"that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThreadIdx.ext; %mask = sub i64 %mask.p, 1. %maskedBallot = and i64 %ballot, %mask; %relativeThreadIdx.p = call i64 @llvm.ctpop.i64(i64 %ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:17262,Performance,perform,performed,17262,"he basic block B is an exiting block; ending in a divergent branch, and the basic block C is an exit of the loop.; Thus, the call to convergent_op() is outside the loop. This causes a mismatch; between the programmer's expectation and the compiled program. The call should; be executed convergently on every iteration of the loop, by threads that; together take the branch to exit the loop. But when compiled, all threads that; take the divergent exit on different iterations first converge at the beginning; of basic block C and then together execute the call to convergent_op(). In this case, :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>` can be used to express the desired; semantics. A call to this intrinsic is placed in the loop header, which tracks; each iteration of the loop. The token produced by this is used as a; ``convergencectrl`` operand to the convergent call. The semantics of the; ``loop`` intrinsic ensures that the convergent call is performed convergently; only by those threads that convergently exited the loop in a given iteration. .. code-block:: llvm. define void @example() convergent {; %entry = call token @llvm.experimental.convergence.entry(); br label %for. for:; %inner = call token @llvm.experimental.convergence.loop() [""convergencectrl""(token %entry)]; %for.cond = i1 ...; br i1 %for.cond, label %B, label %E. B:; ...; %condition = i1 ...; br i1 %condition, label %C, label %D. C:; call void @convergent_op() [""convergencectrl""(token %inner)]; br label %E. D:; ...; br label %for. E:; ...; ret void; }. The LLVM IR version of the same program shows a cycle consisting of the basic; blocks ``%for``, ``%B`` and ``%D``, while ``%C`` is an exit reached by the; divergent branch at the end of the exiting block ``%B``. But the use of; convergence control tokens makes it clear that block ``%C`` must be executed; convergently only by those threads that convergently take the exit edge from %B; to ``%C``. In other words, the convergen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:33472,Performance,optimiz,optimizer,33472,"ce_region:. Convergence Regions; -------------------. The *convergence region* of a convergence token T is the minimal region in; which T is live and used, i.e., the set of program points dominated by the; definition D of T from which a use of T can be reached. The following static rule about convergence regions must be satisfied by; valid programs:. If a convergence region R for a token T1 contains a use of a convergence; token T2, then R must also contain the definition of T2. (In other words,; convergence regions must be reasonably nested.). .. note::. For brevity, this document uses the term ""convergence region of a token; definition ``D``"" to actually refer to the convergence region of the token; ``T`` defined by ``D``. .. _inferring_noconvergent:. Inferring non-convergence; =========================. When the target or the environment guarantees that threads do not; communicate using convergent operations or that threads never diverge,; the dynamic instances in the program are irrelevant and an optimizer; may remove any occurrence of the ``convergent`` attribute on a; call-site or a function and any explicit ``convergencectrl`` operand; bundle at a call-site. An optimizer may remove the ``convergent`` attribute and any explicit; ``convergencectrl`` operand bundle from a call-site if it can prove; that the execution of this call-site always results in a call to a; non-convergent function. An optimizer may remove the ``convergent`` attribute on a function if it can; prove that the function does not contain a call to; :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>`, or any uncontrolled convergent; operations. Memory Model Non-Interaction; ============================. The fact that an operation is convergent has no effect on how it is treated for; memory model purposes. In particular, an operation that is ``convergent`` and; ``readnone`` does not introduce additional ordering constraints as far as the; memory model is concerned. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:33643,Performance,optimiz,optimizer,33643,"rgence regions must be satisfied by; valid programs:. If a convergence region R for a token T1 contains a use of a convergence; token T2, then R must also contain the definition of T2. (In other words,; convergence regions must be reasonably nested.). .. note::. For brevity, this document uses the term ""convergence region of a token; definition ``D``"" to actually refer to the convergence region of the token; ``T`` defined by ``D``. .. _inferring_noconvergent:. Inferring non-convergence; =========================. When the target or the environment guarantees that threads do not; communicate using convergent operations or that threads never diverge,; the dynamic instances in the program are irrelevant and an optimizer; may remove any occurrence of the ``convergent`` attribute on a; call-site or a function and any explicit ``convergencectrl`` operand; bundle at a call-site. An optimizer may remove the ``convergent`` attribute and any explicit; ``convergencectrl`` operand bundle from a call-site if it can prove; that the execution of this call-site always results in a call to a; non-convergent function. An optimizer may remove the ``convergent`` attribute on a function if it can; prove that the function does not contain a call to; :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>`, or any uncontrolled convergent; operations. Memory Model Non-Interaction; ============================. The fact that an operation is convergent has no effect on how it is treated for; memory model purposes. In particular, an operation that is ``convergent`` and; ``readnone`` does not introduce additional ordering constraints as far as the; memory model is concerned. There is no implied barrier, neither in the memory; barrier sense nor in the control barrier sense of synchronizing the execution; of threads. Informational note: Threads that execute converged dynamic instances do not; necessarily do so at the same time. Other Interactions; ==================. A fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:33876,Performance,optimiz,optimizer,33876," other words,; convergence regions must be reasonably nested.). .. note::. For brevity, this document uses the term ""convergence region of a token; definition ``D``"" to actually refer to the convergence region of the token; ``T`` defined by ``D``. .. _inferring_noconvergent:. Inferring non-convergence; =========================. When the target or the environment guarantees that threads do not; communicate using convergent operations or that threads never diverge,; the dynamic instances in the program are irrelevant and an optimizer; may remove any occurrence of the ``convergent`` attribute on a; call-site or a function and any explicit ``convergencectrl`` operand; bundle at a call-site. An optimizer may remove the ``convergent`` attribute and any explicit; ``convergencectrl`` operand bundle from a call-site if it can prove; that the execution of this call-site always results in a call to a; non-convergent function. An optimizer may remove the ``convergent`` attribute on a function if it can; prove that the function does not contain a call to; :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>`, or any uncontrolled convergent; operations. Memory Model Non-Interaction; ============================. The fact that an operation is convergent has no effect on how it is treated for; memory model purposes. In particular, an operation that is ``convergent`` and; ``readnone`` does not introduce additional ordering constraints as far as the; memory model is concerned. There is no implied barrier, neither in the memory; barrier sense nor in the control barrier sense of synchronizing the execution; of threads. Informational note: Threads that execute converged dynamic instances do not; necessarily do so at the same time. Other Interactions; ==================. A function can be both ``convergent`` and; ``speculatable``, indicating that the function does not have undefined; behavior and has no effects besides calculating its result, but is still; af",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:27012,Safety,detect,detect,27012,"lting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.experimental.convergence.anchor:. ``llvm.experimental.convergence.anchor``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.anchor() convergent readnone. This intrinsic produces an initial convergence token that is independent from; any ""outer scope"". The set of threads executing converged dynamic instances of; this intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a group that ""happen to be active; at the same time"" will execute converged dynamic instances, so that programs; can detect the maximal set of threads that can communicate efficiently within; some local region of the program. .. _convergence_uncontrolled:. Uncontrolled Convergent Operations; ==================================. Convergent operations with an explicit ``convergencectrl`` operand bundle are; called *controlled convergent operations*. All other convergent operations are; said to be *uncontrolled*. An uncontrolled convergent operation is said to have *implicit convergence; control* determined by the ``convergent`` attribute alone. The semantics of the; ``convergent`` attribute as implemented in LLVM differs from the documented; semantics. The implementation tries to follow common intuition about convergent; operations, which remains under-specified. As such, it is not possible to fully; translate implicit convergence control into explicit convergence control tokens,; and these two modes cannot be mixed in the same function. If a function contains a controlled conv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:11880,Testability,log,logically,11880,"then2:; ...; call void @subgroupControlBarrier() [ ""convergencectrl""(token %entry) ]; ...; br label %end. end:; }. If S is the set of threads that the entry intrinsic communicated with, then; the ``@subgroupControlBarrier`` call communicates with the subset of S that; actually reaches the call site. This set of threads doesn't change after; jump-threading, so the answer to the question posed above remains the same. .. _opportunistic_convergence:. Opportunistic convergent operations; -----------------------------------. Some programs have local regions of code that contain a sequence of convergent; operations where the code does not care about the exact set of threads with; which it is executed, but only that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:39754,Testability,log,logical,39754,"orm, then its; use at such a ``U`` is also uniform. In other words, temporal divergence applies; only to a use of ``V`` that is outside the convergence region of ``D``. Rationales for Static rules about cycles; ========================================. (This section is informative.). .. note::. For convenience, we use the operator ``==`` to represent the relation; ``converged-with`` and the operator ``!=`` to represent its negation. Consider a loop with (incorrect!) convergence control as in the following; pseudocode:. .. code-block:: llvm. ; WARNING: Example of incorrect convergence control!. %anchor = call token @llvm.experimental.convergence.anchor(); for (;;) {; ...; call void @convergent.op() [ ""convergencectrl""(token %anchor) ]; ...; }. This code is forbidden by the first static rule about cycles. A first formal argument why we have to do this is that the dynamic rule for; deciding whether two threads execute converged dynamic instances of; ``@convergent.op`` leads to a logical contradiction in this code.; Assume two threads execute converged dynamic instances of the anchor; followed by two iterations of the loop. Thread 1 executes dynamic instances; I1 and I2 of ``@convergent.op``, thread 2 executes dynamic instances J1 and J2.; Using all the rules, we can deduce:. 1. ``I1 != I2`` and ``J1 != J2`` by the basic rules of dynamic instances. 2. ``I1 == J1`` by the first dynamic rule about controlled convergent; operations: both threads execute the same static instruction while using; a convergence token value produced by converged dynamic instances of an; instruction (the anchor). 3. ``I1 == J2`` by the same argument. Also, ``I2 == J1`` and ``I2 == J2``. The fact that one may be *intuitively* tempted to think of ``I1`` and ``J2``; as being executed in different loop iterations is completely irrelevant for; the *formal* argument. There is no mechanism in LLVM IR semantics for; forming associations between loop iterations in different threads, *except*; for the rule",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:46758,Testability,log,logical,46758,"se of the; use of the ``%free`` anchor intrinsic. In practice, they almost certainly have to be non-converged dynamic; instances. Consider that if an implementation strictly follows the order of; instructions given in the program, the executions of the threads can be; ""aligned"" as follows:. .. code-block:: text. Thread 1: A B C D F B D E F G; Thread 2: A B D E F B C D F G. So then ``@op.2(1)`` physically executes later than ``@op.2(2)`` and there; can be no communication between the threads, which means they execute; non-converged dynamic instances. That said, it is conceivable that there aren't actually any data or other; dependencies that would enforce this execution order. In that case, a highly; out-of-order implementation could potentially allow communication. That's; why the rules defined in this document are silent about whether; ``@op.2(1) == @op.2(2)`` or not. This type of convergence control seems relatively unlikely to appear in real; programs. Its possibility is simply a logical consequence of the model. An equivalent issue arises if the convergent operations are replaced by nested; loops with loop heart intrinsics that directly refer to ``%anchor``, hence; the variants of the static rules about cycles that apply to them:. .. code-block:: llvm. ; WARNING: Example of incorrect convergence control!. %anchor = call token @llvm.experimental.convergence.anchor(); for (;;) {; if (condition1) {; for (;;) {; %loop1 = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; }; }; if (condition2) {; for (;;) {; %loop2 = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; }; }; }. There is a cycle (closed walk in the CFG) that goes through both loop heart; intrinsics using ``%anchor`` but not through the definition of ``%anchor``,; so this code is invalid. Examples for the Correctness of Program Transforms; ==================================================. (This section is informative.). As implied ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:1426,Usability,intuit,intuitive,1426,"tly. When control; flow :ref:`diverges <convergence-and-uniformity>`, i.e. threads of the same; group follow different; paths through the CFG, not all threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness of generic program transforms and; convergence-related analyses such as :ref:`uniformity analysis; <convergence-and-uniformity>`. .. _convergent_operations:. Convergent Operations; =====================. In LLVM IR, the only way to communicate between threads as described; above is by calling target-defined convergent intrinsics. Hence, only; a call-site in LLVM IR (a :ref:`call <i_call>`, :ref:`invoke; <i_invoke>`, or :ref:`callbr <i_cal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:1607,Usability,intuit,intuition,1607,"l threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness of generic program transforms and; convergence-related analyses such as :ref:`uniformity analysis; <convergence-and-uniformity>`. .. _convergent_operations:. Convergent Operations; =====================. In LLVM IR, the only way to communicate between threads as described; above is by calling target-defined convergent intrinsics. Hence, only; a call-site in LLVM IR (a :ref:`call <i_call>`, :ref:`invoke; <i_invoke>`, or :ref:`callbr <i_callbr>` instruction) can result in a; convergent operation. A function in LLVM IR is said to be *convergent* if it has the; :ref:`convergent <attr_con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:12445,Usability,simpl,simple,12445,"sequence of convergent; operations where the code does not care about the exact set of threads with; which it is executed, but only that the set of threads is the same for all the; operations within the sequence. (If a subset of the convergent operations in the; sequence have additional, non-uniform control dependencies, then this is not; possible. However, the code may still require that the sets of threads are; logically consistent with the conditions of those control dependencies.) In this; case, :ref:`llvm.experimental.convergence.anchor; <llvm.experimental.convergence.anchor>` can be used to express the desired; semantics. The following example function could be part of a hypothetical ""append buffer""; implementation, where threads conditionally write fixed-sized records; contiguously into a global buffer. The function ``@reserveSpaceInBuffer``; returns the index into the buffer at which the calling thread should store its; data. This could be achieved by using a simple atomic operation in every thread to; bump an allocation counter. However, the following implementation can be more performant on some hardware,; because it uses only a single atomic operation for an entire group of threads.; To do this, it first determines the total size of the group, which will be the; operand to the atomic operation, and then later broadcasts the result of the; atomic operation to all threads of the group, so that each thread can compute; its individual position in the buffer:. .. code-block:: llvm. define i32 @reserveSpaceInBuffer() { ; NOTE: _not_ a convergent function!; entry:; %anchor = call token @llvm.experimental.convergence.anchor(). %ballot = call i64 @subgroupBallot(i1 true) [ ""convergencectrl""(token %anchor) ]; %numThreads.p = call i64 @llvm.ctpop.i64(i64 %ballot); %numThreads = trunc i64 %numThreads.p to i32. %absoluteThreadIdx = call i32 @getSubgroupLocalInvocationId(); %absoluteThreadIdx.ext = zext i32 %absoluteThreadIdx to i64; %mask.p = shl i64 1, %absoluteThrea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:18111,Usability,clear,clear,18111,"` operand to the convergent call. The semantics of the; ``loop`` intrinsic ensures that the convergent call is performed convergently; only by those threads that convergently exited the loop in a given iteration. .. code-block:: llvm. define void @example() convergent {; %entry = call token @llvm.experimental.convergence.entry(); br label %for. for:; %inner = call token @llvm.experimental.convergence.loop() [""convergencectrl""(token %entry)]; %for.cond = i1 ...; br i1 %for.cond, label %B, label %E. B:; ...; %condition = i1 ...; br i1 %condition, label %C, label %D. C:; call void @convergent_op() [""convergencectrl""(token %inner)]; br label %E. D:; ...; br label %for. E:; ...; ret void; }. The LLVM IR version of the same program shows a cycle consisting of the basic; blocks ``%for``, ``%B`` and ``%D``, while ``%C`` is an exit reached by the; divergent branch at the end of the exiting block ``%B``. But the use of; convergence control tokens makes it clear that block ``%C`` must be executed; convergently only by those threads that convergently take the exit edge from %B; to ``%C``. In other words, the convergent execution of ``%C`` is governed by the; call to the :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>` intrinsic inside the cycle. The cycle is; effectively extended to include all uses of this token that lie outside the; cycle. .. _dynamic_instances_and_convergence_tokens:. Dynamic Instances and Convergence Tokens; ========================================. Every execution of an LLVM IR instruction occurs in a :ref:`dynamic instance; <convergence-dynamic-instances>` of the instruction. Dynamic instances are the; formal objects by which we talk about communicating threads in convergent; operations. Dynamic instances are defined for *all* operations in an LLVM; program, whether convergent or not. Convergence control is primarily about the; dynamic instances of convergent operations since they affect execution of the; program through int",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:20874,Usability,intuit,intuitive,20874,"; a convergence token operand to define the set of communicating threads relative; to the operation that defined the token. Let ``U`` be a convergent operation other than a call to a convergence; control intrinsic, and ``D`` be the convergent operation that defines; the token value used as the ``convergencectrl`` operand to ``U``. Two; threads execute converged dynamic instances of ``U`` if and only if the; token value in both threads was returned by converged dynamic; instances of ``D``. .. note::. The text defines convergence token values as representing dynamic instances.; But if we were to assume that converged dynamic instances produce the same; token value, then we could almost think of the token value as representing a; set of threads instead -- specifically, the set ``S`` of threads that; executed converged dynamic instances of the defining instruction ``D``. In this intuitive picture, when a convergence token value ``T`` is used by a; ``convergencectrl`` bundle on an instruction ``I``, then the set of threads that; communicates in ``I`` is a subset of the set ``S`` represented by the token value.; Specifically, it is the subset of threads that ends up executing ``I`` while; using the token value. This by itself wouldn't quite work as a definition: what if ``I`` is executed; multiple times by the same threads? Which execution of ``I`` in thread 1; communicates with which execution of ``I`` in thread 2? Leaning on the notion; of dynamic instances gives a robust answer to this question as long as ``D``; and ``I`` are at the same loop (or cycle) nesting level. The case where ``D`` and ``I`` are at different loop nesting levels is; forbidden by the :ref:`static rules <convergence_static_rules>` -- handling; that case is the purpose of :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>`. .. _convergence_control_intrinsics:. Convergence Control Intrinsics; ==============================. This section describes target-independent intrinsi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:25906,Usability,intuit,intuitive,25906,"insic and ``D`` be the convergent operation that; defines the token value used as the ``convergencectrl`` operand to ``U``. Two; threads execute converged dynamic instances of ``U`` if and only if:. 1. The token value in both threads was returned by converged dynamic; instances of ``D``, and,; 2. There is an integer *n* such that both threads execute ``U`` for the *n*'th time; with that token value. It is an error to omit the ``convergencectrl`` operand bundle on a; call to this intrinsic. If this intrinsic occurs in a basic block, then it must precede any other; convergent operation in the same basic block. .. _convergence_cycle_heart:. **Heart of a Cycle:**. If a :ref:`cycle <cycle-terminology>` ``C`` contains an occurrence ``H`` of; this intrinsic whose token operand is defined outside ``C``, then ``H`` is; called the heart of ``C``. .. note::. The static rules for cycles imply that a heart can occur only in the header; of a natural loop. This ensures that the heart closely represents the; intuitive notion of a loop iteration. If this restriction is relaxed, the; resulting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.experimental.convergence.anchor:. ``llvm.experimental.convergence.anchor``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.anchor() convergent readnone. This intrinsic produces an initial convergence token that is independent from; any ""outer scope"". The set of threads executing converged dynamic instances of; this intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:27697,Usability,intuit,intuition,27697,"his intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a group that ""happen to be active; at the same time"" will execute converged dynamic instances, so that programs; can detect the maximal set of threads that can communicate efficiently within; some local region of the program. .. _convergence_uncontrolled:. Uncontrolled Convergent Operations; ==================================. Convergent operations with an explicit ``convergencectrl`` operand bundle are; called *controlled convergent operations*. All other convergent operations are; said to be *uncontrolled*. An uncontrolled convergent operation is said to have *implicit convergence; control* determined by the ``convergent`` attribute alone. The semantics of the; ``convergent`` attribute as implemented in LLVM differs from the documented; semantics. The implementation tries to follow common intuition about convergent; operations, which remains under-specified. As such, it is not possible to fully; translate implicit convergence control into explicit convergence control tokens,; and these two modes cannot be mixed in the same function. If a function contains a controlled convergent operation, then all convergent; operations in that function must either be controlled operations or calls to; the convergence control intrinsics. Inferring Tokens; ----------------. (This section is informational). Sometimes, it may be necessary to reinterpret the implicit convergence control; in terms of explicit convergence control tokens. For example, this may happen; when a function call is inlined, and either the caller or the callee contains; uncontrolled convergent operations. Some uses of uncontrolled convergent operations may need to satisfy the; following property:. For an environment-defined group of threads (such as an OpenCL workgroup or; subgroup), if one thread in the group executes a convergen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:40475,Usability,intuit,intuitively,40475,"n by the first static rule about cycles. A first formal argument why we have to do this is that the dynamic rule for; deciding whether two threads execute converged dynamic instances of; ``@convergent.op`` leads to a logical contradiction in this code.; Assume two threads execute converged dynamic instances of the anchor; followed by two iterations of the loop. Thread 1 executes dynamic instances; I1 and I2 of ``@convergent.op``, thread 2 executes dynamic instances J1 and J2.; Using all the rules, we can deduce:. 1. ``I1 != I2`` and ``J1 != J2`` by the basic rules of dynamic instances. 2. ``I1 == J1`` by the first dynamic rule about controlled convergent; operations: both threads execute the same static instruction while using; a convergence token value produced by converged dynamic instances of an; instruction (the anchor). 3. ``I1 == J2`` by the same argument. Also, ``I2 == J1`` and ``I2 == J2``. The fact that one may be *intuitively* tempted to think of ``I1`` and ``J2``; as being executed in different loop iterations is completely irrelevant for; the *formal* argument. There is no mechanism in LLVM IR semantics for; forming associations between loop iterations in different threads, *except*; for the rules defined in this document -- and the rules in this document; require a loop heart intrinsic for talking about loop iterations. 4. By transitivity, we have ``I1 == I2`` and ``J1 == J2``. That is a; contradiction. This problem goes away by inserting a loop heart intrinsic as follows, which; establishes a relationship between loop iterations across threads. .. code-block:: llvm. %anchor = call token @llvm.experimental.convergence.anchor(); for (;;) {; %loop = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; ...; call void @convergent.op() [ ""convergencectrl""(token %loop) ]; ...; }. In the same scenario of two threads executing converged dynamic instances of the; anchor and then two iterations of the loop, the dynamic rule about",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:46749,Usability,simpl,simply,46749,"se of the; use of the ``%free`` anchor intrinsic. In practice, they almost certainly have to be non-converged dynamic; instances. Consider that if an implementation strictly follows the order of; instructions given in the program, the executions of the threads can be; ""aligned"" as follows:. .. code-block:: text. Thread 1: A B C D F B D E F G; Thread 2: A B D E F B C D F G. So then ``@op.2(1)`` physically executes later than ``@op.2(2)`` and there; can be no communication between the threads, which means they execute; non-converged dynamic instances. That said, it is conceivable that there aren't actually any data or other; dependencies that would enforce this execution order. In that case, a highly; out-of-order implementation could potentially allow communication. That's; why the rules defined in this document are silent about whether; ``@op.2(1) == @op.2(2)`` or not. This type of convergence control seems relatively unlikely to appear in real; programs. Its possibility is simply a logical consequence of the model. An equivalent issue arises if the convergent operations are replaced by nested; loops with loop heart intrinsics that directly refer to ``%anchor``, hence; the variants of the static rules about cycles that apply to them:. .. code-block:: llvm. ; WARNING: Example of incorrect convergence control!. %anchor = call token @llvm.experimental.convergence.anchor(); for (;;) {; if (condition1) {; for (;;) {; %loop1 = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; }; }; if (condition2) {; for (;;) {; %loop2 = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %anchor) ]; }; }; }. There is a cycle (closed walk in the CFG) that goes through both loop heart; intrinsics using ``%anchor`` but not through the definition of ``%anchor``,; so this code is invalid. Examples for the Correctness of Program Transforms; ==================================================. (This section is informative.). As implied ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:53224,Usability,simpl,simply,53224,"ental.convergence.loop() [ ""convergencectrl""(token %outer) ]; ; (B); call void @convergent.operation() [ ""convergencectrl""(token %inner) ]; call void @convergent.operation() [ ""convergencectrl""(token %inner) ]; counter -= 2;; }; ; (C); if (counter > 0) {; %remainder = call token @llvm.experimental.convergence.loop() [ ""convergencectrl""(token %outer) ]; ; (D); call void @convergent.operation() [ ""convergencectrl""(token %remainder) ]; }; ; (E). First of all, note some interesting problems surrounding the loop intrinsic:. 1. It is *not* duplicated inside the unrolled loop. This is to comply with; the :ref:`convergence_static_rules`. 2. It is unclear whether the loop intrinsic ought to be duplicated in the; remainder, or whether the final ``@convergent.operation`` in D should just; refer to either ``%inner`` (which is possible in SSA form) or directly to; ``%outer``. The decision made here is arbitrary and doesn't change the; argument that follows. Ultimately, it simply doesn't matter because the; transform is incorrect either way. The threads now execute the following sequences of blocks:. .. code-block:: text. Thread 1: A B C D E; Thread 2: A B B C D E. Analogous to the argument above, they execute converged dynamic instances of the; ``%inner`` intrinsic and the ``@convergent.operation`` in the first iteration; of the unrolled loop, which corresponds to the first 2 iterations of the; original loop. However, they execute different static calls to ``@convergent.operation`` for; the 3rd iteration of the original loop. In thread 1, that iteration corresponds; to the call in the remainder, while in thread 2 it corresponds to the first; call to ``@convergent.operation`` in the unrolled loop. Therefore, they execute; non-converged dynamic instances, which means that the set of communicating threads; for the 3rd iteration of the original loop is different. This is why the; unrolling is incorrect. On the other hand, unrolling without ""tail"" is allowed. For example, assuming; th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:56051,Usability,simpl,simple,56051,"eral, hoisting and sinking of convergent operations is forbidden. This is; because moving the operation to a different point in control flow generally; changes the set of threads that reach the operation and therefore, the set of; threads that execute converged dynamic instances of the operation. By; definition, this changes the set of threads that participate in the; communication of the convergent operation, which will typically change its; result. There are a number of exceptions, though most of them require additional; knowledge. For example, hoisting and sinking across *uniform* conditional branches -- i.e.,; conditional branches where within every possible relevant set of threads, all; threads will always take the same direction -- is generally allowed. See the end; of the :ref:`example of reductions inside control flow; <convergence_example_reductions>` for a brief discussion. Some convergent operations can be hoisted but not sunk, or vice versa. A simple; example is the ``subgroupShuffle(data, id)`` operation. It returns the ``data``; operand of the thread identified by ``id``, where thread IDs are fixed and; assigned to each thread at launch. The result is undefined (or perhaps there is; UB, depending on the language and environment) if thread ``id`` is not in the; communicating set of threads. So hoisting is allowed in the following; pseudo-code example:. .. code-block:: llvm. define void @example(...) convergent {; %entry = call token @llvm.experimental.convergence.entry(); %data = ...; %id = ...; if (condition) {; %shuffled = call i32 @subgroupShuffle(i32 %data, i32 %id) [ ""convergencectrl""(token %entry) ]; ...; } else {; %shuffled = call i32 @subgroupShuffle(i32 %data, i32 %id) [ ""convergencectrl""(token %entry) ]; ...; }; }. After hoisting the calls to ``@subgroupShuffle``, the communicating set of; threads is the union of the two sets of threads in the original program, so; ``%id`` can only go ""out of range"" after hoisting if it did so in the original;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8282,Availability,avail,available,8282,"ing whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:13920,Availability,alive,alive,13920,"ne frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:173,Deployability,release,releases,173,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:7638,Deployability,pipeline,pipeline,7638," values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buffer that is; passed to the `coro.id` intrinsic, which guarantees a certain size; and alignment statically. The same buffer must be passed to the; continuation function(s). The coroutine will allocate memory if the; buffer is insufficient, in which case it will need to store at; least that pointer in the buffer; therefore the buffer must always; be at least pointer-sized. How the coroutine uses the buffer may; vary between suspend points. In addition to the buffer pointer, continuation functions take an; argument indicating whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume fun",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:9650,Deployability,update,update,9650," function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20315,Deployability,update,updated,20315,"dex = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:39196,Deployability,update,update,39196,"the coroutine. .. _coro.id.async:. 'llvm.coro.id.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.async(i32 <context size>, i32 <align>,; ptr <context arg>,; ptr <async function pointer>). Overview:; """""""""""""""""". The '``llvm.coro.id.async``' intrinsic returns a token identifying an async coroutine. Arguments:; """""""""""""""""""". The first argument provides the initial size of the `async context` as required; from the frontend. Lowering will add to this size the size required by the frame; storage and store that value to the `async function pointer`. The second argument, is the alignment guarantee of the memory of the; `async context`. The frontend guarantees that the memory will be aligned by this; value. The third argument is the `async context` argument in the current coroutine. The fourth argument is the address of the `async function pointer` struct.; Lowering will update the context size requirement in this struct by adding the; coroutine frame size requirement to the initial size requirement as specified by; the first argument of this intrinsic. Semantics:; """""""""""""""""""". A frontend should emit exactly one `coro.id.async` intrinsic per coroutine. A frontend should emit function attribute `presplitcoroutine` for the coroutine. .. _coro.id.retcon:. 'llvm.coro.id.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.retcon(i32 <size>, i32 <align>, ptr <buffer>,; ptr <continuation prototype>,; ptr <alloc>, ptr <dealloc>). Overview:; """""""""""""""""". The '``llvm.coro.id.retcon``' intrinsic returns a token identifying a; multiple-suspend returned-continuation coroutine. The 'result-type sequence' of the coroutine is defined as follows:. - if the return type of the coroutine function is ``void``, it is the; empty sequence;. - if the return type of the coroutine function is a ``struct``, it is the; element types of that ``struct`` in order;. - otherwise, it is just the return type of the coroutine function",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51866,Deployability,update,update,51866,""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Whatever coroutine state changes are required to enable resumption of; the coroutine from the corresponding suspend point should be done at the point; of `coro.save` intrinsic. Example:; """""""""""""""". Separate save and suspend points are necessary when a coroutine is used to; represent an asynchronous control flow driven by callbacks representing; completions of asynchronous operations. In such a case, a coroutine should be ready for resumption prior to a call to; `async_op` function that may trigger resumption of a coroutine from the same or; a different thread possibly prior to `async_op` cal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:6925,Energy Efficiency,allocate,allocate,6925," normal returned-continuation lowering, the coroutine may suspend; itself multiple times. This means that a continuation function; itself returns another continuation pointer, as well as a list of; yielded values. The coroutine indicates that it has run to completion by returning; a null continuation pointer. Any yielded values will be `undef`; should be ignored. - In yield-once returned-continuation lowering, the coroutine must; suspend itself exactly once (or throw an exception). The ramp; function returns a continuation function pointer and yielded; values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buffer that is; passed to the `coro.id` intrinsic, which guarantees a certain size; and alignment statically. The same buffer must be passed to the; continuation function(s). The coroutine will allocate memory if the; buffer is insufficient, in which case it will need to store at; least that pointer in the buffer; therefore the buffer must always; be at least pointer-sized. How the coroutine uses the buffer may; vary between suspend points. In addition to the buffer pointer, continuation functions take an; argument indicating whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:12666,Energy Efficiency,allocate,allocated,12666,"oken @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @malloc(i32 %size); %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); br label %loop; loop:; %n.val = phi i32 [ %n, %entry ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; call void @print(i32 %n.val); %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:13056,Energy Efficiency,allocate,allocated,13056,"end(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14251,Energy Efficiency,allocate,allocated,14251,"letion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, pt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:32782,Energy Efficiency,allocate,allocated,32782,".size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". The '``llvm.coro.align``' intrinsic returns the alignment of a `coroutine frame`_.; This is only supported for switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.align` intrinsic is lowered to a constant representing the alignment of; the coroutine frame. .. _coro.begin:. 'llvm.coro.begin' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.begin(token <id>, ptr <mem>). Overview:; """""""""""""""""". The '``llvm.coro.begin``' intrinsic returns an address of the coroutine frame. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; instructions that express relative access to data can be more compactly encoded; with small positive and negative offsets). A frontend should emit exactly one `coro.begin` intrinsic per coroutine. .. _coro.free:. 'llvm.coro.free' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.free(token %id, ptr <frame>). Overview:; """""""""""""""""". The '``llvm.coro.free``' intrinsic returns a pointer to a block of memory where; coroutine frame is stored or `null` if this instance of a coroutine did not use; dynamically allocated memory for its coroutine frame. This intrinsic is not; supported for re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:33661,Energy Efficiency,allocate,allocated,33661," a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; instructions that express relative access to data can be more compactly encoded; with small positive and negative offsets). A frontend should emit exactly one `coro.begin` intrinsic per coroutine. .. _coro.free:. 'llvm.coro.free' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.free(token %id, ptr <frame>). Overview:; """""""""""""""""". The '``llvm.coro.free``' intrinsic returns a pointer to a block of memory where; coroutine frame is stored or `null` if this instance of a coroutine did not use; dynamically allocated memory for its coroutine frame. This intrinsic is not; supported for returned-continuation coroutines. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to the coroutine frame. This should be the same; pointer that was returned by prior `coro.begin` call. Example (custom deallocation function):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %frame); %mem_not_null = icmp ne ptr %mem, null; br i1 %mem_not_null, label %if.then, label %if.end; if.then:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ret void. Example (standard deallocation functions):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %frame); call void @free(ptr %mem); ret void. .. _coro.alloc:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:41230,Energy Efficiency,allocate,allocate,41230,"struct`` in order;. - otherwise, it is just the return type of the coroutine function. The first element of the result-type sequence must be a pointer type;; continuation functions will be coerced to this type. The rest of; the sequence are the 'yield types', and any suspends in the coroutine; must take arguments of these types. Arguments:; """""""""""""""""""". The first and second arguments are the expected size and alignment of; the buffer provided as the third argument. They must be constant. The fourth argument must be a reference to a global function, called; the 'continuation prototype function'. The type, calling convention,; and attributes of any continuation functions will be taken from this; declaration. The return type of the prototype function must match the; return type of the current function. The first parameter type must be; a pointer type. The second parameter type must be an integer type;; it will be used only as a boolean flag. The fifth argument must be a reference to a global function that will; be used to allocate memory. It may not fail, either by returning null; or throwing an exception. It must take an integer and return a pointer. The sixth argument must be a reference to a global function that will; be used to deallocate memory. It must take a pointer and return ``void``. Semantics:; """""""""""""""""""". A frontend should emit function attribute `presplitcoroutine` for the coroutine. 'llvm.coro.id.retcon.once' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.retcon.once(i32 <size>, i32 <align>, ptr <buffer>,; ptr <prototype>,; ptr <alloc>, ptr <dealloc>). Overview:; """""""""""""""""". The '``llvm.coro.id.retcon.once``' intrinsic returns a token identifying a; unique-suspend returned-continuation coroutine. Arguments:; """""""""""""""""""". As for ``llvm.core.id.retcon``, except that the return type of the; continuation prototype must represent the normal return type of the continuation; (instead of matching the coroutine's return type). Sem",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:48047,Energy Efficiency,allocate,allocate,48047,"e done |; +------------+-------------+------------------------+---------------------------------+. .. _coro.end.results:. 'llvm.coro.end.results' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.end.results(...). Overview:; """""""""""""""""". The '``llvm.coro.end.results``' intrinsic captures values to be returned from; unique-suspend returned-continuation coroutines. Arguments:; """""""""""""""""""". The number of arguments must match the return type of the continuation function:. - if the return type of the continuation function is ``void`` there must be no; arguments. - if the return type of the continuation function is a ``struct``, the arguments; will be of element types of that ``struct`` in order;. - otherwise, it is just the return value of the continuation function. .. code-block:: llvm. define {ptr, ptr} @g(ptr %buffer, ptr %ptr, i8 %val) presplitcoroutine {; entry:; %id = call token @llvm.coro.id.retcon.once(i32 8, i32 8, ptr %buffer,; ptr @prototype,; ptr @allocate, ptr @deallocate); %hdl = call ptr @llvm.coro.begin(token %id, ptr null). ... cleanup:; %tok = call token (...) @llvm.coro.end.results(i8 %val); call i1 @llvm.coro.end(ptr %hdl, i1 0, token %tok); unreachable. ... declare i8 @prototype(ptr, i1 zeroext); . 'llvm.coro.end.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end.async(ptr <handle>, i1 <unwind>, ...). Overview:; """""""""""""""""". The '``llvm.coro.end.async``' marks the point where execution of the resume part; of the coroutine should end and control should return to the caller. As part of; its variable tail arguments this instruction allows to specify a function and; the function's arguments that are to be tail called as the last action before; returning. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4794,Integrability,protocol,protocol,4794,"ol can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4955,Integrability,protocol,protocol,4955," 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the ramp function and then an arbitrary number of; these continuation functions, one for each suspend point. LLVM actually supports two closely-related returned-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25790,Integrability,inject,injected,25790," a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this sectio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26073,Integrability,inject,inject,26073,"n idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26277,Integrability,inject,injected,26277," function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26458,Integrability,inject,injected,26458," function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44560,Integrability,depend,depending,44560,"continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bund",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:48650,Modifiability,variab,variable,48650," will be of element types of that ``struct`` in order;. - otherwise, it is just the return value of the continuation function. .. code-block:: llvm. define {ptr, ptr} @g(ptr %buffer, ptr %ptr, i8 %val) presplitcoroutine {; entry:; %id = call token @llvm.coro.id.retcon.once(i32 8, i32 8, ptr %buffer,; ptr @prototype,; ptr @allocate, ptr @deallocate); %hdl = call ptr @llvm.coro.begin(token %id, ptr null). ... cleanup:; %tok = call token (...) @llvm.coro.end.results(i8 %val); call i1 @llvm.coro.end(ptr %hdl, i1 0, token %tok); unreachable. ... declare i8 @prototype(ptr, i1 zeroext); . 'llvm.coro.end.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end.async(ptr <handle>, i1 <unwind>, ...). Overview:; """""""""""""""""". The '``llvm.coro.end.async``' marks the point where execution of the resume part; of the coroutine should end and control should return to the caller. As part of; its variable tail arguments this instruction allows to specify a function and; the function's arguments that are to be tail called as the last action before; returning. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. The third argument if present should specify a function to be called. If the third argument is present, the remaining arguments are the arguments to; the function call. .. code-block:: llvm. call i1 (ptr, i1, ...) @llvm.coro.end.async(; ptr %hdl, i1 0,; ptr @must_tail_call_return,; ptr %ctxt, ptr %task, ptr %actor); unreachable. .. _coro.suspend:; .. _suspend points:. 'llvm.coro.suspend' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i8 @",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:12812,Performance,optimiz,optimization,12812,"n %id, ptr %alloc); br label %loop; loop:; %n.val = phi i32 [ %n, %entry ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; call void @print(i32 %n.val); %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15745,Performance,load,load,15745,"he; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` if dynamic allocation is; el",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:16479,Performance,optimiz,optimization,16479,"0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` if dynamic allocation is; elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:17783,Performance,optimiz,optimization,17783," elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping the deallocation code:. .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); %need.dyn.free = icmp ne ptr %mem, null; br i1 %need.dyn.free, label %dyn.free, label %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19274,Performance,load,load,19274,"he same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19418,Performance,load,load,19418,"@print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20406,Performance,optimiz,optimizer,20406,"n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:23890,Performance,load,load,23890,"c, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @malloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final susp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:23995,Performance,load,load,23995,"loc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is dest",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:24100,Performance,load,load,24100,"]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25179,Performance,optimiz,optimization,25179,"r example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <des",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:30953,Performance,load,load,30953,"ntrinsics return a pointer to a promise; from a coroutine handle. This argument only accepts constants. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a coroutine promise; leads to undefined behavior. It is possible to read and modify coroutine; promise of the coroutine which is currently executing. The coroutine author and; a coroutine user are responsible to makes sure there is no data races. Example:; """""""""""""""". .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %promise = alloca i32; ; the second argument to coro.id points to the coroutine promise.; %id = call token @llvm.coro.id(i32 0, ptr %promise, ptr null, ptr null); ...; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); ...; store i32 42, ptr %promise ; store something into the promise; ...; ret ptr %hdl; }. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4) ; starts the coroutine and returns its handle; %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val = load i32, ptr %promise.addr ; load a value from the promise; call void @print(i32 %val); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine intrinsics:. Coroutine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.cor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:30983,Performance,load,load,30983,"ument only accepts constants. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a coroutine promise; leads to undefined behavior. It is possible to read and modify coroutine; promise of the coroutine which is currently executing. The coroutine author and; a coroutine user are responsible to makes sure there is no data races. Example:; """""""""""""""". .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %promise = alloca i32; ; the second argument to coro.id points to the coroutine promise.; %id = call token @llvm.coro.id(i32 0, ptr %promise, ptr null, ptr null); ...; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); ...; store i32 42, ptr %promise ; store something into the promise; ...; ret ptr %hdl; }. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4) ; starts the coroutine and returns its handle; %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val = load i32, ptr %promise.addr ; load a value from the promise; call void @print(i32 %val); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine intrinsics:. Coroutine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:38028,Performance,optimiz,optimization,38028,"en identifying a; switched-resume coroutine. Arguments:; """""""""""""""""""". The first argument provides information on the alignment of the memory returned; by the allocation function and given to `coro.begin` by the first argument. If; this argument is 0, the memory is assumed to be aligned to 2 * sizeof(ptr).; This argument only accepts constants. The second argument, if not `null`, designates a particular alloca instruction; to be a `coroutine promise`_. The third argument is `null` coming out of the frontend. The CoroEarly pass sets; this argument to point to the function this coro.id belongs to. The fourth argument is `null` before coroutine is split, and later is replaced; to point to a private global constant array containing function pointers to; outlined resume and destroy parts of the coroutine. Semantics:; """""""""""""""""""". The purpose of this intrinsic is to tie together `coro.id`, `coro.alloc` and; `coro.begin` belonging to the same coroutine to prevent optimization passes from; duplicating any of these instructions unless entire body of the coroutine is; duplicated. A frontend should emit exactly one `coro.id` intrinsic per coroutine. A frontend should emit function attribute `presplitcoroutine` for the coroutine. .. _coro.id.async:. 'llvm.coro.id.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.async(i32 <context size>, i32 <align>,; ptr <context arg>,; ptr <async function pointer>). Overview:; """""""""""""""""". The '``llvm.coro.id.async``' intrinsic returns a token identifying an async coroutine. Arguments:; """""""""""""""""""". The first argument provides the initial size of the `async context` as required; from the frontend. Lowering will add to this size the size required by the frame; storage and store that value to the `async function pointer`. The second argument, is the alignment guarantee of the memory of the; `async context`. The frontend guarantees that the memory will be aligned by this; value. The third argument is the `async",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44973,Performance,load,load,44973," ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` befor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:45014,Performance,load,load,45014,"eached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` before; the `coro.end`_ intrinsic and will rem",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51583,Performance,perform,perform,51583,"final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Whatever coroutine state changes are required to enable resumption of; the coroutine from the corresponding suspend point should be done at the point; of `coro.save` intrinsic. Example:; """""""""""""""". Separate save and suspend points are necessary when a coroutine is us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51591,Performance,optimiz,optimizations,51591,"final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Whatever coroutine state changes are required to enable resumption of; the coroutine from the corresponding suspend point should be done at the point; of `coro.save` intrinsic. Example:; """""""""""""""". Separate save and suspend points are necessary when a coroutine is us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:56839,Performance,optimiz,optimization,56839,"he next continuation function. Semantics:; """""""""""""""""""". The result of the intrinsic indicates whether the coroutine should resume; abnormally (non-zero). In a normal coroutine, it is undefined behavior if the coroutine executes; a call to ``llvm.coro.suspend.retcon`` after resuming abnormally. In a yield-once coroutine, it is undefined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:58929,Performance,optimiz,optimization,58929,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:59205,Performance,optimiz,optimization,59205,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:59439,Performance,optimiz,optimizations,59439,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:16498,Safety,avoid,avoid,16498,"0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` if dynamic allocation is; elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:23700,Security,access,access,23700,"ry:; %promise = alloca i32; %id = call token @llvm.coro.id(i32 0, ptr %promise, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @malloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25790,Security,inject,injected,25790," a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this sectio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26073,Security,inject,inject,26073,"n idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26277,Security,inject,injected,26277," function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26458,Security,inject,injected,26458," function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:33159,Security,access,access,33159,""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.align` intrinsic is lowered to a constant representing the alignment of; the coroutine frame. .. _coro.begin:. 'llvm.coro.begin' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.begin(token <id>, ptr <mem>). Overview:; """""""""""""""""". The '``llvm.coro.begin``' intrinsic returns an address of the coroutine frame. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; instructions that express relative access to data can be more compactly encoded; with small positive and negative offsets). A frontend should emit exactly one `coro.begin` intrinsic per coroutine. .. _coro.free:. 'llvm.coro.free' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.free(token %id, ptr <frame>). Overview:; """""""""""""""""". The '``llvm.coro.free``' intrinsic returns a pointer to a block of memory where; coroutine frame is stored or `null` if this instance of a coroutine did not use; dynamically allocated memory for its coroutine frame. This intrinsic is not; supported for returned-continuation coroutines. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to the coroutine frame. This should be the same; pointer that was returned by prior `coro.begin` call. Example (custom deallocation function):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:55467,Security,access,accessible,55467," this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used to block inlining of the; async coroutine until after coroutine splitting. Arguments:; """""""""""""""""""". The first argument should be an async coroutine of type `void (ptr, ptr, ptr)`.; Lowering will replace this intrinsic with its coroutine function argument. .. _coro.suspend.retcon:. 'llvm.coro.suspend.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.suspend.retcon(...). Overview:; """""""""""""""""". The '``llvm.coro.suspend.retcon``' intrinsic marks the point where; execution of a returned-continuation coroutine is suspended and control; is returned back to the caller. `llvm.coro.suspend.retcon`` does not support separate save points;; they are not useful when the continuation function is not locally; accessible. That would be a more appropriate feature for a ``passcon``; lowering that is not yet implemented. Arguments:; """""""""""""""""""". The types of the arguments must exactly match the yielded-types sequence; of the coroutine. They will be turned into return values from the ramp; and continuation functions, along with the next continuation function. Semantics:; """""""""""""""""""". The result of the intrinsic indicates whether the coroutine should resume; abnormally (non-zero). In a normal coroutine, it is undefined behavior if the coroutine executes; a call to ``llvm.coro.suspend.retcon`` after resuming abnormally. In a yield-once coroutine, it is undefined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the corouti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:58419,Security,access,access,58419,"--------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20347,Testability,test,testing,20347,"n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:43897,Testability,log,logic,43897,"riate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. Non-trivial (non-none) token argument can only be specified for unique-suspend; returned-continuation coroutines where it must be a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:59477,Testability,test,tests,59477,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:59489,Testability,test,tests,59489,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:59501,Testability,test,tests,59501,"en_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled LICM for loops that have coro.suspend, but the general problem still; exists and requires a general solution. #. Take advantage of the lifetime intrinsics for the data that goes into the; coroutine frame. Leave lifetime intrinsics as is for the data that stays in; allocas. #. The CoroElide optimization pass relies on coroutine ramp function to be; inlined. It would be beneficial to split the ramp function further to; increase the chance that it will get inlined into its caller. #. Design a convention that would make it possible to apply coroutine heap; elision optimization across ABI boundaries. #. Cannot handle coroutines with `inalloca` parameters (used in x86 on Windows). #. Alignment is ignored by coro.begin and coro.free intrinsics. #. Make required changes to make sure that coroutine optimizations work with; LTO. #. More tests, more tests, more tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:473,Usability,resume,resumed,473,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:746,Usability,resume,resume,746,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:896,Usability,resume,resume,896,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:935,Usability,resume,resume,935,"=====================================; Coroutines in LLVM; =====================================. .. contents::; :local:; :depth: 3. .. warning::; Compatibility across LLVM releases is not guaranteed. Introduction; ============. .. _coroutine handle:. LLVM coroutines are functions that have one or more `suspend points`_.; When a suspend point is reached, the execution of a coroutine is suspended and; control is returned back to its caller. A suspended coroutine can be resumed; to continue execution from the last suspend point or it can be destroyed. In the following example, we call function `f` (which may or may not be a; coroutine itself) that returns a handle to a suspended coroutine; (**coroutine handle**) that is used by `main` to resume the coroutine twice and; then destroy it:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.resume(ptr %hdl); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine frame:. In addition to the function stack frame which exists when a coroutine is; executing, there is an additional region of storage that contains objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:2203,Usability,resume,resume,2203,"objects that; keep the coroutine state when a coroutine is suspended. This region of storage; is called the **coroutine frame**. It is created when a coroutine is called; and destroyed when a coroutine either runs to completion or is destroyed; while suspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become the ""ramp function"",; the initial entrypoint of the coroutine, which executes until a suspend point; is first reached. The remainder of the original coroutine function is split; out into some number of ""resume functions"". Any state which must persist; across suspensions is stored in the coroutine frame. The resume functions; must somehow be able to handle either a ""normal"" resumption, which continues; the normal execution of the coroutine, or an ""abnormal"" resumption, which; must unwind the coroutine without attempting to suspend it. Switched-Resume Lowering; ------------------------. In LLVM's standard switched-resume lowering, signaled by the use of; `llvm.coro.id`, the coroutine frame is stored as part of a ""coroutine; object"" which represents a handle to a particular invocation of the; coroutine. All coroutine objects support a common ABI allowing certain; features to be used without knowing anything about the coroutine's; implementation:. - A coroutine object can be queried to see if it has reached completion; with `llvm.coro.done`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:2309,Usability,resume,resume,2309,"uspended. LLVM currently supports two styles of coroutine lowering. These styles; support substantially different sets of features, have substantially; different ABIs, and expect substantially different patterns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become the ""ramp function"",; the initial entrypoint of the coroutine, which executes until a suspend point; is first reached. The remainder of the original coroutine function is split; out into some number of ""resume functions"". Any state which must persist; across suspensions is stored in the coroutine frame. The resume functions; must somehow be able to handle either a ""normal"" resumption, which continues; the normal execution of the coroutine, or an ""abnormal"" resumption, which; must unwind the coroutine without attempting to suspend it. Switched-Resume Lowering; ------------------------. In LLVM's standard switched-resume lowering, signaled by the use of; `llvm.coro.id`, the coroutine frame is stored as part of a ""coroutine; object"" which represents a handle to a particular invocation of the; coroutine. All coroutine objects support a common ABI allowing certain; features to be used without knowing anything about the coroutine's; implementation:. - A coroutine object can be queried to see if it has reached completion; with `llvm.coro.done`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:2620,Usability,resume,resume,2620,"rns of frontend; code generation. However, the styles also have a great deal in common. In all cases, an LLVM coroutine is initially represented as an ordinary LLVM; function that has calls to `coroutine intrinsics`_ defining the structure of; the coroutine. The coroutine function is then, in the most general case,; rewritten by the coroutine lowering passes to become the ""ramp function"",; the initial entrypoint of the coroutine, which executes until a suspend point; is first reached. The remainder of the original coroutine function is split; out into some number of ""resume functions"". Any state which must persist; across suspensions is stored in the coroutine frame. The resume functions; must somehow be able to handle either a ""normal"" resumption, which continues; the normal execution of the coroutine, or an ""abnormal"" resumption, which; must unwind the coroutine without attempting to suspend it. Switched-Resume Lowering; ------------------------. In LLVM's standard switched-resume lowering, signaled by the use of; `llvm.coro.id`, the coroutine frame is stored as part of a ""coroutine; object"" which represents a handle to a particular invocation of the; coroutine. All coroutine objects support a common ABI allowing certain; features to be used without knowing anything about the coroutine's; implementation:. - A coroutine object can be queried to see if it has reached completion; with `llvm.coro.done`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:3082,Usability,resume,resumed,3082,"s first reached. The remainder of the original coroutine function is split; out into some number of ""resume functions"". Any state which must persist; across suspensions is stored in the coroutine frame. The resume functions; must somehow be able to handle either a ""normal"" resumption, which continues; the normal execution of the coroutine, or an ""abnormal"" resumption, which; must unwind the coroutine without attempting to suspend it. Switched-Resume Lowering; ------------------------. In LLVM's standard switched-resume lowering, signaled by the use of; `llvm.coro.id`, the coroutine frame is stored as part of a ""coroutine; object"" which represents a handle to a particular invocation of the; coroutine. All coroutine objects support a common ABI allowing certain; features to be used without knowing anything about the coroutine's; implementation:. - A coroutine object can be queried to see if it has reached completion; with `llvm.coro.done`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:3157,Usability,resume,resume,3157,"nction is split; out into some number of ""resume functions"". Any state which must persist; across suspensions is stored in the coroutine frame. The resume functions; must somehow be able to handle either a ""normal"" resumption, which continues; the normal execution of the coroutine, or an ""abnormal"" resumption, which; must unwind the coroutine without attempting to suspend it. Switched-Resume Lowering; ------------------------. In LLVM's standard switched-resume lowering, signaled by the use of; `llvm.coro.id`, the coroutine frame is stored as part of a ""coroutine; object"" which represents a handle to a particular invocation of the; coroutine. All coroutine objects support a common ABI allowing certain; features to be used without knowing anything about the coroutine's; implementation:. - A coroutine object can be queried to see if it has reached completion; with `llvm.coro.done`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:3991,Usability,resume,resume,3991,"ne`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4045,Usability,resume,resumed,4045,"ne`. - A coroutine object can be resumed normally if it has not already reached; completion with `llvm.coro.resume`. - A coroutine object can be destroyed, invalidating the coroutine object,; with `llvm.coro.destroy`. This must be done separately even if the; coroutine has reached completion normally. - ""Promise"" storage, which is known to have a certain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4283,Usability,resume,resume,4283,"rtain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4443,Usability,resume,resume,4443,"rtain size and alignment,; can be projected out of the coroutine object with `llvm.coro.promise`.; The coroutine implementation must have been compiled to define a promise; of the same size and alignment. In general, interacting with a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4581,Usability,resume,resume,4581,"th a coroutine object in any of these ways while; it is running has undefined behavior. The coroutine function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4749,Usability,resume,resume,4749,"e function is split into three functions, representing three; different ways that control can enter the coroutine:. 1. the ramp function that is initially invoked, which takes arbitrary; arguments and returns a pointer to the coroutine object;. 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:5200,Usability,resume,resume,5200,"inter to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the ramp function and then an arbitrary number of; these continuation functions, one for each suspend point. LLVM actually supports two closely-related returned-continuation; lowerings:. - In normal returned-continuation lowering, the coroutine may suspend; itself multiple times. This means that a continuation function; itself returns another continuation pointer, as well as a list of; yielded values. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:5712,Usability,resume,resumed,5712,"ed with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the ramp function and then an arbitrary number of; these continuation functions, one for each suspend point. LLVM actually supports two closely-related returned-continuation; lowerings:. - In normal returned-continuation lowering, the coroutine may suspend; itself multiple times. This means that a continuation function; itself returns another continuation pointer, as well as a list of; yielded values. The coroutine indicates that it has run to completion by returning; a null continuation pointer. Any yielded values will be `undef`; should be ignored. - In yield-once returned-continuation lowering, the coroutine must; suspend itself exactly once (or throw an exception). The ramp; function returns a continuation function pointer and yielded; values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:5723,Usability,simpl,simply,5723,"ed with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the ramp function and then an arbitrary number of; these continuation functions, one for each suspend point. LLVM actually supports two closely-related returned-continuation; lowerings:. - In normal returned-continuation lowering, the coroutine may suspend; itself multiple times. This means that a continuation function; itself returns another continuation pointer, as well as a list of; yielded values. The coroutine indicates that it has run to completion by returning; a null continuation pointer. Any yielded values will be `undef`; should be ignored. - In yield-once returned-continuation lowering, the coroutine must; suspend itself exactly once (or throw an exception). The ramp; function returns a continuation function pointer and yielded; values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:7294,Usability,resume,resumed,7294," to completion by returning; a null continuation pointer. Any yielded values will be `undef`; should be ignored. - In yield-once returned-continuation lowering, the coroutine must; suspend itself exactly once (or throw an exception). The ramp; function returns a continuation function pointer and yielded; values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buffer that is; passed to the `coro.id` intrinsic, which guarantees a certain size; and alignment statically. The same buffer must be passed to the; continuation function(s). The coroutine will allocate memory if the; buffer is insufficient, in which case it will need to store at; least that pointer in the buffer; therefore the buffer must always; be at least pointer-sized. How the coroutine uses the buffer may; vary between suspend points. In addition to the buffer pointer, continuation functions take an; argument indicating whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8555,Usability,resume,resume,8555,"his may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8605,Usability,resume,resume,8605,"applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8641,Usability,resume,resumed,8641,"nc-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; corou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8667,Usability,resume,resume,8667,"nc-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; corou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:8756,Usability,resume,resume,8756,"ering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to marshal arguments and return values of the; coroutine. Therefore an async coroutine returns `void`. .. code-block:: llvm. define swiftcc void @async_coroutine(ptr %async.ctxt, ptr, ptr) {; }. Values live across a suspend point need to be stored in the coroutine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:9244,Usability,resume,resume,9244,"ine frame to; be available in the continuation function. This frame is stored as a tail to the; `async context`. Every suspend point takes an `context projection function` argument which; describes how-to obtain the continuations `async context` and every suspend; point has an associated `resume function` denoted by the; `llvm.coro.async.resume` intrinsic. The coroutine is resumed by calling this; `resume function` passing the `async context` as the one of its arguments; argument. The `resume function` can restore its (the caller's) `async context`; by applying a `context projection function` that is provided by the frontend as; a parameter to the `llvm.coro.suspend.async` intrinsic. .. code-block:: c. // For example:; struct async_context {; struct async_context *caller_context;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:10067,Usability,resume,resume,10067,"text;; ...; }. char *context_projection_function(struct async_context *callee_ctxt) {; return callee_ctxt->caller_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3). Coroutines by Example; =====================. The examples below are all of switched-resume coroutines. Coroutine Representation; ------------------------. Let's look at an example of an LLVM coroutine with the behavior sketched; by the following pseudo-code. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend> // returns a coroutine handle on first sus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:10177,Usability,resume,resume,10177,"er_context;; }. .. code-block:: llvm. %resume_func_ptr = call ptr @llvm.coro.async.resume(); call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function. The frontend should provide a `async function pointer` struct associated with; each async coroutine by `llvm.coro.id.async`'s argument. The initial size and; alignment of the `async context` must be provided as arguments to the; `llvm.coro.id.async` intrinsic. Lowering will update the size entry with the; coroutine frame requirements. The frontend is responsible for allocating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3). Coroutines by Example; =====================. The examples below are all of switched-resume coroutines. Coroutine Representation; ------------------------. Let's look at an example of an LLVM coroutine with the behavior sketched; by the following pseudo-code. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend> // returns a coroutine handle on first suspend; }; }. This coroutine calls some function `print` with value `n` as an argument and; suspends execution. E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:10760,Usability,resume,resume,10760,"ating the; memory for the `async context` but can use the `async function pointer` struct; to obtain the required size. .. code-block:: c. struct async_function_pointer {; uint32_t relative_function_pointer_to_async_impl;; uint32_t context_size;; }. Lowering will split an async coroutine into a ramp function and one resume; function per suspend point. How control-flow is passed between caller, suspension point, and back to; resume function is left up to the frontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3). Coroutines by Example; =====================. The examples below are all of switched-resume coroutines. Coroutine Representation; ------------------------. Let's look at an example of an LLVM coroutine with the behavior sketched; by the following pseudo-code. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend> // returns a coroutine handle on first suspend; }; }. This coroutine calls some function `print` with value `n` as an argument and; suspends execution. Every time this coroutine resumes, it calls `print` again with an argument one bigger than the last time. This coroutine never completes by itself and must be destroyed explicitly. If we use this coroutine with; a `main` shown in the previous section. It will call `print` with values 4, 5; and 6 after which the coroutine will be destroyed. The LLVM IR for this coroutine looks like this:. .. code-block:: llvm. define ptr @f(i32 %n) presplitcoroutine {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %size = call i32 @llvm.coro.size.i32(); %alloc = call pt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:11186,Usability,resume,resumes,11186,"rontend. The suspend point takes a function and its arguments. The function is intended; to model the transfer to the callee function. It will be tail called by; lowering and therefore must have the same signature and calling convention as; the async coroutine. .. code-block:: llvm. call {ptr, ptr, ptr} (ptr, ptr, ...) @llvm.coro.suspend.async(; ptr %resume_func_ptr,; ptr %context_projection_function,; ptr %suspend_function,; ptr %arg1, ptr %arg2, i8 %arg3). Coroutines by Example; =====================. The examples below are all of switched-resume coroutines. Coroutine Representation; ------------------------. Let's look at an example of an LLVM coroutine with the behavior sketched; by the following pseudo-code. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend> // returns a coroutine handle on first suspend; }; }. This coroutine calls some function `print` with value `n` as an argument and; suspends execution. Every time this coroutine resumes, it calls `print` again with an argument one bigger than the last time. This coroutine never completes by itself and must be destroyed explicitly. If we use this coroutine with; a `main` shown in the previous section. It will call `print` with values 4, 5; and 6 after which the coroutine will be destroyed. The LLVM IR for this coroutine looks like this:. .. code-block:: llvm. define ptr @f(i32 %n) presplitcoroutine {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @malloc(i32 %size); %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); br label %loop; loop:; %n.val = phi i32 [ %n, %entry ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; call void @print(i32 %n.val); %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:13682,Usability,resume,resumed,13682,"ed if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-bloc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14377,Usability,resume,resume,14377,"n control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14425,Usability,resume,resume,14425,"ial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14467,Usability,resume,resume,14467," of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14679,Usability,resume,resume,14679,"the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15195,Usability,resume,resume,15195," back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular corout",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15493,Usability,resume,resume,15493,"ty cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15549,Usability,resume,resume,15549," compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15612,Usability,resume,resume,15612,"de-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15634,Usability,resume,resume,15634," = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15710,Usability,resume,resume,15710,"ion `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:18386,Usability,resume,resume,18386,"ation code:. .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); %need.dyn.free = icmp ne ptr %mem, null; br i1 %need.dyn.free, label %dyn.free, label %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:18533,Usability,resume,resume,18533,"eed.dyn.free, label %dyn.free, label %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:18569,Usability,resume,resume,18569,"bel %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:18922,Usability,resume,resume,18922,"main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:18996,Usability,resume,resume,18996,"ne that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19477,Usability,resume,resume,19477,"itch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19503,Usability,resume,resume,19503,"ume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, sett",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19764,Usability,resume,resume,19764,"anup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20047,Usability,resume,resume,20047," basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20273,Usability,resume,resume,20273,"dex = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20578,Usability,resume,resume,20578,"n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21059,Usability,resume,resume,21059,"uspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21213,Usability,resume,resume,21213," an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %save2 = call token @llvm.coro.save(ptr %hdl); call void @async_op2(ptr %hdl); %suspend2 = call i1 @llvm.coro.suspend(token %save2, i1 false); switch i8 %suspend2, label %suspend [i8 0, label %resume2; i8 1, label %cleanup]. .. _coroutine promise:. Coroutine Promise; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21318,Usability,resume,resume,21318," an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %save2 = call token @llvm.coro.save(ptr %hdl); call void @async_op2(ptr %hdl); %suspend2 = call i1 @llvm.coro.suspend(token %save2, i1 false); switch i8 %suspend2, label %suspend [i8 0, label %resume2; i8 1, label %cleanup]. .. _coroutine promise:. Coroutine Promise; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21604,Usability,resume,resume,21604,"state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %save2 = call token @llvm.coro.save(ptr %hdl); call void @async_op2(ptr %hdl); %suspend2 = call i1 @llvm.coro.suspend(token %save2, i1 false); switch i8 %suspend2, label %suspend [i8 0, label %resume2; i8 1, label %cleanup]. .. _coroutine promise:. Coroutine Promise; -----------------. A coroutine author or a frontend may designate a distinguished `alloca` that can; be used to communicate with the coroutine. This distinguished alloca is called; **coroutine promise** and is provided as the second parameter to the; `coro.id`_ intrinsic. The following coroutine designates a 32 bit integer `promise` and uses it to; st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21677,Usability,resume,resumed,21677,"state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %save2 = call token @llvm.coro.save(ptr %hdl); call void @async_op2(ptr %hdl); %suspend2 = call i1 @llvm.coro.suspend(token %save2, i1 false); switch i8 %suspend2, label %suspend [i8 0, label %resume2; i8 1, label %cleanup]. .. _coroutine promise:. Coroutine Promise; -----------------. A coroutine author or a frontend may designate a distinguished `alloca` that can; be used to communicate with the coroutine. This distinguished alloca is called; **coroutine promise** and is provided as the second parameter to the; `coro.id`_ intrinsic. The following coroutine designates a 32 bit integer `promise` and uses it to; st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:21701,Usability,resume,resume,21701,"state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should be ready for resumption prior to a call to; `async_op1` and `async_op2`. The `coro.save`_ intrinsic is used to indicate a; point when coroutine should be ready for resumption (namely, when a resume index; should be stored in the coroutine frame, so that it can be resumed at the; correct resume point):. .. code-block:: llvm. if.true:; %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]; if.false:; %save2 = call token @llvm.coro.save(ptr %hdl); call void @async_op2(ptr %hdl); %suspend2 = call i1 @llvm.coro.suspend(token %save2, i1 false); switch i8 %suspend2, label %suspend [i8 0, label %resume2; i8 1, label %cleanup]. .. _coroutine promise:. Coroutine Promise; -----------------. A coroutine author or a frontend may designate a distinguished `alloca` that can; be used to communicate with the coroutine. This distinguished alloca is called; **coroutine promise** and is provided as the second parameter to the; `coro.id`_ intrinsic. The following coroutine designates a 32 bit integer `promise` and uses it to; st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:23969,Usability,resume,resume,23969,"loc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is dest",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:24074,Usability,resume,resume,24074,"]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25228,Usability,resume,resume,25228,"r example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <des",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25279,Usability,resume,resume,25279,"r example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <des",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:25587,Usability,resume,resume,25587,"econd argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is destroying it via `coro.destroy`_ intrinsic. From the user perspective, the final suspend point represents an idea of a; coroutine reaching the end. From the compiler perspective, it is an optimization; opportunity for reducing number of resume points (and therefore switch cases) in; the resume function. The following is an example of a function that keeps resuming the coroutine; until the final suspend point is reached after which point the coroutine is; destroyed:. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); br label %while; while:; call void @llvm.coro.resume(ptr %hdl); %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:26593,Usability,resume,resume,26593," %done = call i1 @llvm.coro.done(ptr %hdl); br i1 %done, label %end, label %while; end:; call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. Usually, final suspend point is a frontend injected suspend point that does not; correspond to any explicitly authored suspend point of the high level language.; For example, for a Python generator that has only one suspend point:. .. code-block:: python. def coroutine(n):; for i in range(n):; yield i. Python frontend would inject two more suspend points, so that the actual code; looks like this:. .. code-block:: c. void* coroutine(int n) {; int current_value;; <designate current_value to be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function store",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27259,Usability,resume,resume,27259,"be coroutine promise>; <SUSPEND> // injected suspend point, so that the coroutine starts suspended; for (int i = 0; i < n; ++i) {; current_value = i; <SUSPEND>; // corresponds to ""yield i""; }; <SUSPEND final=true> // injected final suspend point; }. and python iterator `__next__` would look like:. .. code-block:: c++. int __next__(void* hdl) {; coro.resume(hdl);; if (coro.done(hdl)) throw StopIteration();; return *(int*)coro.promise(hdl, 4, false);; }. Intrinsics; ==========. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27715,Usability,resume,resume,27715,"=. Coroutine Manipulation Intrinsics; ---------------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27735,Usability,resume,resume,27735,"-------------------------. Intrinsics described in this section are used to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27825,Usability,resume,resume,27825,"ed to manipulate an existing; coroutine. They can be used in any function which happen to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27886,Usability,resume,resume,27886,"en to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27906,Usability,resume,resumes,27906,"en to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:27935,Usability,resume,resume,27935,"en to have a pointer; to a `coroutine frame`_ or a pointer to a `coroutine promise`_. .. _coro.destroy:. 'llvm.coro.destroy' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:28077,Usability,resume,resume,28077,":. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llvm.coro.promise' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare ptr @llvm.coro.promise(ptr <ptr>, i32 <alignment>, i1 <from>). Overview:; """""""""""""""""". The '``llvm.coro.promise``' intr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:28144,Usability,resume,resume,28144,":. declare void @llvm.coro.destroy(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.destroy``' intrinsic destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llvm.coro.promise' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare ptr @llvm.coro.promise(ptr <ptr>, i32 <alignment>, i1 <from>). Overview:; """""""""""""""""". The '``llvm.coro.promise``' intr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:28247,Usability,resume,resume,28247,"c destroys a suspended; switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a coroutine handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.destroy` intrinsic is replaced with a direct call to; the coroutine destroy function. Otherwise it is replaced with an indirect call; based on the function pointer for the destroy function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llvm.coro.promise' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare ptr @llvm.coro.promise(ptr <ptr>, i32 <alignment>, i1 <from>). Overview:; """""""""""""""""". The '``llvm.coro.promise``' intrinsic obtains a pointer to a; `coroutine promise`_ given a switched-resume coroutine handle and vice versa. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:28592,Usability,resume,resume,28592,"function stored in the coroutine; frame. Destroying a coroutine that is not suspended leads to undefined behavior. .. _coro.resume:. 'llvm.coro.resume' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare void @llvm.coro.resume(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.resume``' intrinsic resumes a suspended switched-resume coroutine. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". When possible, the `coro.resume` intrinsic is replaced with a direct call to the; coroutine resume function. Otherwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llvm.coro.promise' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare ptr @llvm.coro.promise(ptr <ptr>, i32 <alignment>, i1 <from>). Overview:; """""""""""""""""". The '``llvm.coro.promise``' intrinsic obtains a pointer to a; `coroutine promise`_ given a switched-resume coroutine handle and vice versa. Arguments:; """""""""""""""""""". The first argument is a handle to a coroutine if `from` is false. Otherwise,; it is a pointer to a coroutine promise. The second argument is an alignment requirements of the promise.; If a frontend designated `%promise = alloca i32` as a promise, the alignment; argument to `coro.promise` should be the alignment of `i32` on the target; plat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:29187,Usability,resume,resume,29187,"rwise it is replaced with an indirect call based; on the function pointer for the resume function stored in the coroutine frame.; Resuming a coroutine that is not suspended leads to undefined behavior. .. _coro.done:. 'llvm.coro.done' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare i1 @llvm.coro.done(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.done``' intrinsic checks whether a suspended; switched-resume coroutine is at the final suspend point or not. Arguments:; """""""""""""""""""". The argument is a handle to a suspended coroutine. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a `final suspend`_ point; or on a coroutine that is not suspended leads to undefined behavior. .. _coro.promise:. 'llvm.coro.promise' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ::. declare ptr @llvm.coro.promise(ptr <ptr>, i32 <alignment>, i1 <from>). Overview:; """""""""""""""""". The '``llvm.coro.promise``' intrinsic obtains a pointer to a; `coroutine promise`_ given a switched-resume coroutine handle and vice versa. Arguments:; """""""""""""""""""". The first argument is a handle to a coroutine if `from` is false. Otherwise,; it is a pointer to a coroutine promise. The second argument is an alignment requirements of the promise.; If a frontend designated `%promise = alloca i32` as a promise, the alignment; argument to `coro.promise` should be the alignment of `i32` on the target; platform. If a frontend designated `%promise = alloca i32, align 16` as a; promise, the alignment argument should be 16.; This argument only accepts constants. The third argument is a boolean indicating a direction of the transformation.; If `from` is true, the intrinsic returns a coroutine handle given a pointer; to a promise. If `from` is false, the intrinsics return a pointer to a promise; from a coroutine handle. This argument only accepts constants. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a coroutine promise; leads to undefined",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:31660,Usability,resume,resume,31660,".begin(token %id, ptr %alloc); ...; store i32 42, ptr %promise ; store something into the promise; ...; ret ptr %hdl; }. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4) ; starts the coroutine and returns its handle; %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val = load i32, ptr %promise.addr ; load a value from the promise; call void @print(i32 %val); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine intrinsics:. Coroutine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". The '``llvm.coro.align``' intrinsic returns the alignment of a `coroutine frame`_.; This is only supported for switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.align` intrinsic is lowered to a constant representing the alignment of; the coroutine frame. .. _coro.begin:. 'llvm.coro.begin' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.begin(token <id>, ptr <mem>). Overview:; """""""""""""""""". The '``llvm.coro.begin``' intrinsic returns an address of the coroutine frame. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:32136,Usability,resume,resume,32136,"outine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". The '``llvm.coro.align``' intrinsic returns the alignment of a `coroutine frame`_.; This is only supported for switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.align` intrinsic is lowered to a constant representing the alignment of; the coroutine frame. .. _coro.begin:. 'llvm.coro.begin' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.begin(token <id>, ptr <mem>). Overview:; """""""""""""""""". The '``llvm.coro.begin``' intrinsic returns an address of the coroutine frame. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:36021,Usability,resume,resumed,36021,"e first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. Semantics:; """""""""""""""""""". A frontend should emit at most one `coro.alloc` intrinsic per coroutine.; The intrinsic is used to suppress dynamic allocation of the coroutine frame; when possible. Example:; """""""""""""""". .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %dyn.alloc.required = call i1 @llvm.coro.alloc(token %id); br i1 %dyn.alloc.required, label %coro.alloc, label %coro.begin. coro.alloc:; %frame.size = call i32 @llvm.coro.size(); %alloc = call ptr @MyAlloc(i32 %frame.size); br label %coro.begin. coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %coro.alloc ]; %frame = call ptr @llvm.coro.begin(token %id, ptr %phi). .. _coro.noop:. 'llvm.coro.noop' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.noop(). Overview:; """""""""""""""""". The '``llvm.coro.noop``' intrinsic returns an address of the coroutine frame of; a coroutine that does nothing when resumed or destroyed. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to a private constant coroutine frame. The; resume and destroy handlers for this frame are empty functions that do nothing.; Note that in different translation units llvm.coro.noop may return different pointers. .. _coro.frame:. 'llvm.coro.frame' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.frame(). Overview:; """""""""""""""""". The '``llvm.coro.frame``' intrinsic returns an address of the coroutine frame of; the enclosing coroutine. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to the `coro.begin`_ instruction. This is; a frontend convenience intrinsic that makes it easier to refer to the; coroutine frame. .. _coro.id:. 'llvm.coro.id' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id(i32 <align>, ptr <promise>, ptr <coroaddr>,; ptr <f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:36176,Usability,resume,resume,36176,"ynamic allocation of the coroutine frame; when possible. Example:; """""""""""""""". .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %dyn.alloc.required = call i1 @llvm.coro.alloc(token %id); br i1 %dyn.alloc.required, label %coro.alloc, label %coro.begin. coro.alloc:; %frame.size = call i32 @llvm.coro.size(); %alloc = call ptr @MyAlloc(i32 %frame.size); br label %coro.begin. coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %coro.alloc ]; %frame = call ptr @llvm.coro.begin(token %id, ptr %phi). .. _coro.noop:. 'llvm.coro.noop' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.noop(). Overview:; """""""""""""""""". The '``llvm.coro.noop``' intrinsic returns an address of the coroutine frame of; a coroutine that does nothing when resumed or destroyed. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to a private constant coroutine frame. The; resume and destroy handlers for this frame are empty functions that do nothing.; Note that in different translation units llvm.coro.noop may return different pointers. .. _coro.frame:. 'llvm.coro.frame' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.frame(). Overview:; """""""""""""""""". The '``llvm.coro.frame``' intrinsic returns an address of the coroutine frame of; the enclosing coroutine. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to the `coro.begin`_ instruction. This is; a frontend convenience intrinsic that makes it easier to refer to the; coroutine frame. .. _coro.id:. 'llvm.coro.id' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id(i32 <align>, ptr <promise>, ptr <coroaddr>,; ptr <fnaddrs>). Overview:; """""""""""""""""". The '``llvm.coro.id``' intrinsic returns a token identifying a; switched-resume coroutine. Arguments:; """""""""""""""""""". The first argument provides information on the alignment of the memory returned; by ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:37087,Usability,resume,resume,37087,"None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to a private constant coroutine frame. The; resume and destroy handlers for this frame are empty functions that do nothing.; Note that in different translation units llvm.coro.noop may return different pointers. .. _coro.frame:. 'llvm.coro.frame' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.frame(). Overview:; """""""""""""""""". The '``llvm.coro.frame``' intrinsic returns an address of the coroutine frame of; the enclosing coroutine. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic is lowered to refer to the `coro.begin`_ instruction. This is; a frontend convenience intrinsic that makes it easier to refer to the; coroutine frame. .. _coro.id:. 'llvm.coro.id' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id(i32 <align>, ptr <promise>, ptr <coroaddr>,; ptr <fnaddrs>). Overview:; """""""""""""""""". The '``llvm.coro.id``' intrinsic returns a token identifying a; switched-resume coroutine. Arguments:; """""""""""""""""""". The first argument provides information on the alignment of the memory returned; by the allocation function and given to `coro.begin` by the first argument. If; this argument is 0, the memory is assumed to be aligned to 2 * sizeof(ptr).; This argument only accepts constants. The second argument, if not `null`, designates a particular alloca instruction; to be a `coroutine promise`_. The third argument is `null` coming out of the frontend. The CoroEarly pass sets; this argument to point to the function this coro.id belongs to. The fourth argument is `null` before coroutine is split, and later is replaced; to point to a private global constant array containing function pointers to; outlined resume and destroy parts of the coroutine. Semantics:; """""""""""""""""""". The purpose of this intrinsic is to tie together `coro.id`, `coro.alloc` and; `coro.begin` belonging to the same coroutine to prevent optimization passes from; duplicating an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:37827,Usability,resume,resume,37827,"at makes it easier to refer to the; coroutine frame. .. _coro.id:. 'llvm.coro.id' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id(i32 <align>, ptr <promise>, ptr <coroaddr>,; ptr <fnaddrs>). Overview:; """""""""""""""""". The '``llvm.coro.id``' intrinsic returns a token identifying a; switched-resume coroutine. Arguments:; """""""""""""""""""". The first argument provides information on the alignment of the memory returned; by the allocation function and given to `coro.begin` by the first argument. If; this argument is 0, the memory is assumed to be aligned to 2 * sizeof(ptr).; This argument only accepts constants. The second argument, if not `null`, designates a particular alloca instruction; to be a `coroutine promise`_. The third argument is `null` coming out of the frontend. The CoroEarly pass sets; this argument to point to the function this coro.id belongs to. The fourth argument is `null` before coroutine is split, and later is replaced; to point to a private global constant array containing function pointers to; outlined resume and destroy parts of the coroutine. Semantics:; """""""""""""""""""". The purpose of this intrinsic is to tie together `coro.id`, `coro.alloc` and; `coro.begin` belonging to the same coroutine to prevent optimization passes from; duplicating any of these instructions unless entire body of the coroutine is; duplicated. A frontend should emit exactly one `coro.id` intrinsic per coroutine. A frontend should emit function attribute `presplitcoroutine` for the coroutine. .. _coro.id.async:. 'llvm.coro.id.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.async(i32 <context size>, i32 <align>,; ptr <context arg>,; ptr <async function pointer>). Overview:; """""""""""""""""". The '``llvm.coro.id.async``' intrinsic returns a token identifying an async coroutine. Arguments:; """""""""""""""""""". The first argument provides the initial size of the `async context` as required; from the frontend. Lowering will add to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:42553,Usability,resume,resume,42553,"te `presplitcoroutine` for the coroutine. 'llvm.coro.id.retcon.once' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.retcon.once(i32 <size>, i32 <align>, ptr <buffer>,; ptr <prototype>,; ptr <alloc>, ptr <dealloc>). Overview:; """""""""""""""""". The '``llvm.coro.id.retcon.once``' intrinsic returns a token identifying a; unique-suspend returned-continuation coroutine. Arguments:; """""""""""""""""""". As for ``llvm.core.id.retcon``, except that the return type of the; continuation prototype must represent the normal return type of the continuation; (instead of matching the coroutine's return type). Semantics:; """""""""""""""""""". A frontend should emit function attribute `presplitcoroutine` for the coroutine. .. _coro.end:. 'llvm.coro.end' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end(ptr <handle>, i1 <unwind>, token <result.token>). Overview:; """""""""""""""""". The '``llvm.coro.end``' marks the point where execution of the resume part of; the coroutine should end and control should return to the caller. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. Non-trivial (non-none) token argument can only be specified for unique-suspend; returned-continuation coroutines where it must be a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:43555,Usability,resume,resume,43555,"ken>). Overview:; """""""""""""""""". The '``llvm.coro.end``' marks the point where execution of the resume part of; the coroutine should end and control should return to the caller. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. Non-trivial (non-none) token argument can only be specified for unique-suspend; returned-continuation coroutines where it must be a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:43907,Usability,resume,resume,43907,"riate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. Non-trivial (non-none) token argument can only be specified for unique-suspend; returned-continuation coroutines where it must be a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44146,Usability,resume,resume,44146,"can only be specified for unique-suspend; returned-continuation coroutines where it must be a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.va",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44233,Usability,resume,resume,44233,"e a token value produced by; '``llvm.coro.end.results``' intrinsic. Only none token is allowed for coro.end calls in unwind sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44297,Usability,resume,resume,44297,"sections. Semantics:; """"""""""""""""""""; The purpose of this intrinsic is to allow frontends to mark the cleanup and; other code that is only relevant during the initial invocation of the coroutine; and should not be present in resume and destroy parts. In returned-continuation lowering, ``llvm.coro.end`` fully destroys the; coroutine frame. If the second argument is `false`, it also returns from; the coroutine with a null continuation pointer, and the next instruction; will be unreachable. If the second argument is `true`, it falls through; so that the following logic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44887,Usability,resume,resume,44887,"ogic can resume unwinding. In a yield-once; coroutine, reaching a non-unwind ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bun",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44957,Usability,resume,resume,44957," ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` befor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:45175,Usability,resume,resume,45175,"is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` before; the `coro.end`_ intrinsic and will remove the rest of the block. In the unwind path (when the argument is `true`), `coro.end` will mark the coroutine; as done, making it undefined behavior to resume th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:45269,Usability,resume,resume,45269," of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` before; the `coro.end`_ intrinsic and will remove the rest of the block. In the unwind path (when the argument is `true`), `coro.end` will mark the coroutine; as done, making it undefined behavior to resume the coroutine again and causing ; `llvm.coro.done` to return `true`. This is not necessary in the normal path because; the coroutine will already be marked as done by the final suspend. The following ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:46170,Usability,resume,resume,46170,"al, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` before; the `coro.end`_ intrinsic and will remove the rest of the block. In the unwind path (when the argument is `true`), `coro.end` will mark the coroutine; as done, making it undefined behavior to resume the coroutine again and causing ; `llvm.coro.done` to return `true`. This is not necessary in the normal path because; the coroutine will already be marked as done by the final suspend. The following table summarizes the handling of `coro.end`_ intrinsic. +--------------------------+------------------------+---------------------------------+; | | In Start Function | In Resume/Destroy Functions |; +--------------------------+------------------------+---------------------------------+; |unwind=false | nothing |``ret void`` |; +------------+-------------+------------------------+---------------------------------+; | | WinEH | mark coroutine as done || ``cleanupret unwind to caller``|; | | | || mark coroutine done |; |unwind=true +-------------+------------------------+---------------------------------+; | | Landingpad | mark coroutine as done | mark coroutine done |; +------------+-------------+------------------------+---------------------------------+. .. _coro.end.re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:48552,Usability,resume,resume,48552,"ype of the continuation function is ``void`` there must be no; arguments. - if the return type of the continuation function is a ``struct``, the arguments; will be of element types of that ``struct`` in order;. - otherwise, it is just the return value of the continuation function. .. code-block:: llvm. define {ptr, ptr} @g(ptr %buffer, ptr %ptr, i8 %val) presplitcoroutine {; entry:; %id = call token @llvm.coro.id.retcon.once(i32 8, i32 8, ptr %buffer,; ptr @prototype,; ptr @allocate, ptr @deallocate); %hdl = call ptr @llvm.coro.begin(token %id, ptr null). ... cleanup:; %tok = call token (...) @llvm.coro.end.results(i8 %val); call i1 @llvm.coro.end(ptr %hdl, i1 0, token %tok); unreachable. ... declare i8 @prototype(ptr, i1 zeroext); . 'llvm.coro.end.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end.async(ptr <handle>, i1 <unwind>, ...). Overview:; """""""""""""""""". The '``llvm.coro.end.async``' marks the point where execution of the resume part; of the coroutine should end and control should return to the caller. As part of; its variable tail arguments this instruction allows to specify a function and; the function's arguments that are to be tail called as the last action before; returning. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. The third argument if present should specify a function to be called. If the third argument is present, the remaining arguments are the arguments to; the function call. .. code-block:: llvm. call i1 (ptr, i1, ...) @llvm.coro.end.async(; ptr %hdl, i1 0,; ptr @must_tail_call_return,; ptr %ctxt, ptr %task, pt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:49866,Usability,resume,resume,49866,"the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. The third argument if present should specify a function to be called. If the third argument is present, the remaining arguments are the arguments to; the function call. .. code-block:: llvm. call i1 (ptr, i1, ...) @llvm.coro.end.async(; ptr %hdl, i1 0,; ptr @must_tail_call_return,; ptr %ctxt, ptr %task, ptr %actor); unreachable. .. _coro.suspend:; .. _suspend points:. 'llvm.coro.suspend' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i8 @llvm.coro.suspend(token <save>, i1 <final>). Overview:; """""""""""""""""". The '``llvm.coro.suspend``' marks the point where execution of a; switched-resume coroutine is suspended and control is returned back; to the caller. Conditional branches consuming the result of this; intrinsic lead to basic blocks where coroutine should proceed when; suspended (-1), resumed (0) or destroyed (1). Arguments:; """""""""""""""""""". The first argument refers to a token of `coro.save` intrinsic that marks the; point when coroutine state is prepared for suspension. If `none` token is passed,; the intrinsic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:50076,Usability,resume,resumed,50076,"replace the null with an appropriate coroutine; handle value. The second argument should be `true` if this coro.end is in the block that is; part of the unwind sequence leaving the coroutine body due to an exception and; `false` otherwise. The third argument if present should specify a function to be called. If the third argument is present, the remaining arguments are the arguments to; the function call. .. code-block:: llvm. call i1 (ptr, i1, ...) @llvm.coro.end.async(; ptr %hdl, i1 0,; ptr @must_tail_call_return,; ptr %ctxt, ptr %task, ptr %actor); unreachable. .. _coro.suspend:; .. _suspend points:. 'llvm.coro.suspend' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i8 @llvm.coro.suspend(token <save>, i1 <final>). Overview:; """""""""""""""""". The '``llvm.coro.suspend``' marks the point where execution of a; switched-resume coroutine is suspended and control is returned back; to the caller. Conditional branches consuming the result of this; intrinsic lead to basic blocks where coroutine should proceed when; suspended (-1), resumed (0) or destroyed (1). Arguments:; """""""""""""""""""". The first argument refers to a token of `coro.save` intrinsic that marks the; point when coroutine state is prepared for suspension. If `none` token is passed,; the intrinsic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:50575,Usability,resume,resume,50575,"); unreachable. .. _coro.suspend:; .. _suspend points:. 'llvm.coro.suspend' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i8 @llvm.coro.suspend(token <save>, i1 <final>). Overview:; """""""""""""""""". The '``llvm.coro.suspend``' marks the point where execution of a; switched-resume coroutine is suspended and control is returned back; to the caller. Conditional branches consuming the result of this; intrinsic lead to basic blocks where coroutine should proceed when; suspended (-1), resumed (0) or destroyed (1). Arguments:; """""""""""""""""""". The first argument refers to a token of `coro.save` intrinsic that marks the; point when coroutine state is prepared for suspension. If `none` token is passed,; the intrinsic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:50828,Usability,resume,resume,50828,"o.suspend``' marks the point where execution of a; switched-resume coroutine is suspended and control is returned back; to the caller. Conditional branches consuming the result of this; intrinsic lead to basic blocks where coroutine should proceed when; suspended (-1), resumed (0) or destroyed (1). Arguments:; """""""""""""""""""". The first argument refers to a token of `coro.save` intrinsic that marks the; point when coroutine state is prepared for suspension. If `none` token is passed,; the intrinsic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51247,Usability,resume,resumed,51247," when coroutine state is prepared for suspension. If `none` token is passed,; the intrinsic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argume",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51265,Usability,resume,resume,51265,"insic behaves as if there were a `coro.save` immediately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:51344,Usability,resume,resumed,51344,"diately preceding; the `coro.suspend` intrinsic. The second argument indicates whether this suspension point is `final`_.; The second argument only accepts constants. If more than one suspend point is; designated as final, the resume and destroy branches should lead to the same; basic blocks. Example (normal suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %resume; i8 1, label %cleanup]. Example (final suspend point):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. while.end:; %s.final = call i8 @llvm.coro.suspend(token none, i1 true); switch i8 %s.final, label %suspend [i8 0, label %trap; i8 1, label %cleanup]; trap:; call void @llvm.trap(); unreachable. Semantics:; """""""""""""""""""". If a coroutine that was suspended at the suspend point marked by this intrinsic; is resumed via `coro.resume`_ the control will transfer to the basic block; of the 0-case. If it is resumed via `coro.destroy`_, it will proceed to the; basic block indicated by the 1-case. To suspend, coroutine proceed to the; default label. If suspend intrinsic is marked as final, it can consider the `true` branch; unreachable and can perform optimizations that can take advantage of that fact. .. _coro.save:. 'llvm.coro.save' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.save(ptr <handle>). Overview:; """""""""""""""""". The '``llvm.coro.save``' marks the point where a coroutine need to update its; state to prepare for resumption to be considered suspended (and thus eligible; for resumption). It is illegal to merge two '``llvm.coro.save``' calls unless their; '``llvm.coro.suspend``' users are also merged. So '``llvm.coro.save``' is currently; tagged with the `no_merge` function attribute. Arguments:; """""""""""""""""""". The first argument points to a coroutine handle of the enclosing coroutine. Semantics:; """""""""""""""""""". Whatever coroutine state changes are required to e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:53353,Usability,resume,resume,53353,"oroutine from the corresponding suspend point should be done at the point; of `coro.save` intrinsic. Example:; """""""""""""""". Separate save and suspend points are necessary when a coroutine is used to; represent an asynchronous control flow driven by callbacks representing; completions of asynchronous operations. In such a case, a coroutine should be ready for resumption prior to a call to; `async_op` function that may trigger resumption of a coroutine from the same or; a different thread possibly prior to `async_op` call returning control back; to the coroutine:. .. code-block:: llvm. %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]. .. _coro.suspend.async:. 'llvm.coro.suspend.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare {ptr, ptr, ptr} @llvm.coro.suspend.async(; ptr <resume function>,; ptr <context projection function>,; ... <function to call>; ... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:53719,Usability,resume,resume,53719,"for resumption prior to a call to; `async_op` function that may trigger resumption of a coroutine from the same or; a different thread possibly prior to `async_op` call returning control back; to the coroutine:. .. code-block:: llvm. %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]. .. _coro.suspend.async:. 'llvm.coro.suspend.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare {ptr, ptr, ptr} @llvm.coro.suspend.async(; ptr <resume function>,; ptr <context projection function>,; ... <function to call>; ... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resume function.; Execution is suspended at this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:53785,Usability,resume,resume,53785,"n that may trigger resumption of a coroutine from the same or; a different thread possibly prior to `async_op` call returning control back; to the coroutine:. .. code-block:: llvm. %save1 = call token @llvm.coro.save(ptr %hdl); call void @async_op1(ptr %hdl); %suspend1 = call i1 @llvm.coro.suspend(token %save1, i1 false); switch i8 %suspend1, label %suspend [i8 0, label %resume1; i8 1, label %cleanup]. .. _coro.suspend.async:. 'llvm.coro.suspend.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare {ptr, ptr, ptr} @llvm.coro.suspend.async(; ptr <resume function>,; ptr <context projection function>,; ... <function to call>; ... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resume function.; Execution is suspended at this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used to block inlining of the; async coroutine until after ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:54371,Usability,resume,resume,54371," ptr <resume function>,; ptr <context projection function>,; ... <function to call>; ... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resume function.; Execution is suspended at this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used to block inlining of the; async coroutine until after coroutine splitting. Arguments:; """""""""""""""""""". The first argument should be an async coroutine of type `void (ptr, ptr, ptr)`.; Lowering will replace this intrinsic with its coroutine function argument. .. _coro.suspend.retcon:. 'llvm.coro.suspend.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.suspend.retcon(...). Overview:; """""""""""""""""". The '``llvm.coro.suspend.retcon``' intrinsic marks the point where; execution of a returned-continuation coroutine is suspended and control; is returned back to the caller. `llvm.coro.susp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:54434,Usability,resume,resumed,54434,"... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resume function.; Execution is suspended at this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used to block inlining of the; async coroutine until after coroutine splitting. Arguments:; """""""""""""""""""". The first argument should be an async coroutine of type `void (ptr, ptr, ptr)`.; Lowering will replace this intrinsic with its coroutine function argument. .. _coro.suspend.retcon:. 'llvm.coro.suspend.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.suspend.retcon(...). Overview:; """""""""""""""""". The '``llvm.coro.suspend.retcon``' intrinsic marks the point where; execution of a returned-continuation coroutine is suspended and control; is returned back to the caller. `llvm.coro.suspend.retcon`` does not support separate save points;; they are not useful when the cont",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:54451,Usability,resume,resume,54451,"... <arguments to function>). Overview:; """""""""""""""""". The '``llvm.coro.suspend.async``' intrinsic marks the point where; execution of an async coroutine is suspended and control is passed to a callee. Arguments:; """""""""""""""""""". The first argument should be the result of the `llvm.coro.async.resume` intrinsic.; Lowering will replace this intrinsic with the resume function for this suspend; point. The second argument is the `context projection function`. It should describe; how-to restore the `async context` in the continuation function from the first; argument of the continuation function. Its type is `ptr (ptr)`. The third argument is the function that models transfer to the callee at the; suspend point. It should take 3 arguments. Lowering will `musttail` call this; function. The fourth to six argument are the arguments for the third argument. Semantics:; """""""""""""""""""". The result of the intrinsic are mapped to the arguments of the resume function.; Execution is suspended at this intrinsic and resumed when the resume function is; called. .. _coro.prepare.async:. 'llvm.coro.prepare.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.prepare.async(ptr <coroutine function>). Overview:; """""""""""""""""". The '``llvm.coro.prepare.async``' intrinsic is used to block inlining of the; async coroutine until after coroutine splitting. Arguments:; """""""""""""""""""". The first argument should be an async coroutine of type `void (ptr, ptr, ptr)`.; Lowering will replace this intrinsic with its coroutine function argument. .. _coro.suspend.retcon:. 'llvm.coro.suspend.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.suspend.retcon(...). Overview:; """""""""""""""""". The '``llvm.coro.suspend.retcon``' intrinsic marks the point where; execution of a returned-continuation coroutine is suspended and control; is returned back to the caller. `llvm.coro.suspend.retcon`` does not support separate save points;; they are not useful when the cont",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:55909,Usability,resume,resume,55909,"tr, ptr, ptr)`.; Lowering will replace this intrinsic with its coroutine function argument. .. _coro.suspend.retcon:. 'llvm.coro.suspend.retcon' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.suspend.retcon(...). Overview:; """""""""""""""""". The '``llvm.coro.suspend.retcon``' intrinsic marks the point where; execution of a returned-continuation coroutine is suspended and control; is returned back to the caller. `llvm.coro.suspend.retcon`` does not support separate save points;; they are not useful when the continuation function is not locally; accessible. That would be a more appropriate feature for a ``passcon``; lowering that is not yet implemented. Arguments:; """""""""""""""""""". The types of the arguments must exactly match the yielded-types sequence; of the coroutine. They will be turned into return values from the ramp; and continuation functions, along with the next continuation function. Semantics:; """""""""""""""""""". The result of the intrinsic indicates whether the coroutine should resume; abnormally (non-zero). In a normal coroutine, it is undefined behavior if the coroutine executes; a call to ``llvm.coro.suspend.retcon`` after resuming abnormally. In a yield-once coroutine, it is undefined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:56672,Usability,resume,resume,56672,"-types sequence; of the coroutine. They will be turned into return values from the ramp; and continuation functions, along with the next continuation function. Semantics:; """""""""""""""""""". The result of the intrinsic indicates whether the coroutine should resume; abnormally (non-zero). In a normal coroutine, it is undefined behavior if the coroutine executes; a call to ``llvm.coro.suspend.retcon`` after resuming abnormally. In a yield-once coroutine, it is undefined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume corou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:57110,Usability,resume,resume,57110,"ined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:57170,Usability,resume,resume,57170,"spend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:57646,Usability,resume,resume,57646,"uilds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metadata may be attached to an alloca instruction to; to signify that it shouldn't be promoted to the coroutine frame, useful for; filtering allocas out by the frontend when emitting internal control mechanisms.; Additionally, this metadata is only used as a flag, so the associated; node must be empty. .. code-block:: text. %__coro_gro = alloca %struct.GroType, align 1, !coro.outside.frame !0. ...; !0 = !{}. Areas Requiring Attention; =========================; #. When coro.suspend returns -1, the coroutine is suspended, and it's possible; that the coroutine has already been destroyed (hence the frame has been freed).; We cannot access anything on the frame on the suspend path.; However there is nothing that prevents the compiler from moving instructions; along that path (e.g. LICM), which can lead to use-after-free. At the moment; we disabled",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Coroutines.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:940,Availability,down,down,940,"le:: raw-html(raw); :format: html. =================================; LLVM Code Coverage Mapping Format; =================================. .. contents::; :local:. Introduction; ============. LLVM's code coverage mapping format is used to provide code coverage; analysis using LLVM's and Clang's instrumentation based profiling; (Clang's ``-fprofile-instr-generate`` option). This document is aimed at those who would like to know how LLVM's code coverage; mapping works under the hood. A prior knowledge of how Clang's profile guided; optimization works is useful, but not required. For those interested in using; LLVM to provide code coverage analysis for their own programs, see the `Clang; documentation <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`. We start by briefly describing LLVM's code coverage mapping format and the; way that Clang and LLVM's code coverage tool work with this format. After; the basics are down, more advanced features of the coverage mapping format; are discussed - such as the data structures, LLVM IR representation and; the binary encoding. High Level Overview; ===================. LLVM's code coverage mapping format is designed to be a self contained; data format that can be embedded into the LLVM IR and into object files.; It's described in this document as a **mapping** format because its goal is; to store the data that is required for a code coverage tool to map between; the specific source ranges in a file and the execution counts obtained; after running the instrumented version of the program. The mapping data is used in two places in the code coverage process:. 1. When clang compiles a source file with ``-fcoverage-mapping``, it; generates the mapping information that describes the mapping between the; source ranges and the profiling instrumentation counters.; This information gets embedded into the LLVM IR and conveniently; ends up in the final executable file when the program is linked. 2. It is also used by *llvm-cov* - the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:2533,Energy Efficiency,reduce,reduce,2533,"ge process:. 1. When clang compiles a source file with ``-fcoverage-mapping``, it; generates the mapping information that describes the mapping between the; source ranges and the profiling instrumentation counters.; This information gets embedded into the LLVM IR and conveniently; ends up in the final executable file when the program is linked. 2. It is also used by *llvm-cov* - the mapping information is extracted from an; object file and is used to associate the execution counts (the values of the; profile instrumentation counters), and the source ranges in a file.; After that, the tool is able to generate various code coverage reports; for the program. The coverage mapping format aims to be a ""universal format"" that would be; suitable for usage by any frontend, and not just by Clang. It also aims to; provide the frontend the possibility of generating the minimal coverage mapping; data in order to reduce the size of the IR and object files - for example,; instead of emitting mapping information for each statement in a function, the; frontend is allowed to group the statements with the same execution count into; regions of code, and emit the mapping information only for those regions. Advanced Concepts; =================. The remainder of this guide is meant to give you insight into the way the; coverage mapping format works. The coverage mapping format operates on a per-function level as the; profile instrumentation counters are associated with a specific function.; For each function that requires code coverage, the frontend has to create; coverage mapping data that can map between the source code ranges and; the profile instrumentation counters for that function. Mapping Region; --------------. The function's coverage mapping data contains an array of mapping regions.; A mapping region stores the `source code range`_ that is covered by this region,; the `file id <coverage file id_>`_, the `coverage mapping counter`_ and; the region's kind.; There are several kinds",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:15664,Energy Efficiency,reduce,reduce,15664," from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; Always 0. In prior versions, the length of the affixed string that contains the encoded coverage mapping data; i32 3, ; Coverage mapping format version; },; [32 x i8] c""..."" ; Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The first entry in the filename list is the compilation directory. When the; filename is relative, the compilation directory is combined with the relative; path to get an absolute path. This can reduce size by omitting the duplicate; prefix in filenames. There is one difference between versions 5 and 4:. * The notion of branch region has been introduced along with a corresponding; region kind. Branch regions encode two counters, one to track how many; times a ""true"" branch condition is taken, and one to track how many times a; ""false"" branch condition is taken. There are two differences between versions 4 and 3:. * Function records are now named symbols, and are marked *linkonce_odr*. This; allows linkers to merge duplicate function records. Merging of duplicate; *dummy* records (emitted for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:16328,Energy Efficiency,reduce,reduces,16328," Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The first entry in the filename list is the compilation directory. When the; filename is relative, the compilation directory is combined with the relative; path to get an absolute path. This can reduce size by omitting the duplicate; prefix in filenames. There is one difference between versions 5 and 4:. * The notion of branch region has been introduced along with a corresponding; region kind. Branch regions encode two counters, one to track how many; times a ""true"" branch condition is taken, and one to track how many times a; ""false"" branch condition is taken. There are two differences between versions 4 and 3:. * Function records are now named symbols, and are marked *linkonce_odr*. This; allows linkers to merge duplicate function records. Merging of duplicate; *dummy* records (emitted for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding for; column end locations was introduced to indicate gap regions. In version 1, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i8*, i32, i32, i64 } { i8* getelementptr inbounds ([3 x i8]* @__profn_foo, i32 0, i32 0), ; Function's name; i32 3, ; Function's name length; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash; }. In version 2, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i64, i32, i64 } {; i64 0x5cf8c24cdb18bdac, ; Function's name MD5; i32 9, ; Function's encoded coverage mapping d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:14123,Modifiability,variab,variable,14123,"span>; <span style='background-color:#4A789C'> </span><span style='background-color:#85C1F5'>printf(""Hello world!\n"")</span><span style='background-color:#4A789C'>; </span> <span class='c1'>// Unreachable region's counter is zero</span>; <span style='background-color:#4A789C'>}</span>; </pre>`. The zero counters allow the code coverage tool to display proper line execution; counts for the unreachable lines and highlight the unreachable code.; Without them, the tool would think that those lines and regions were still; executed, as it doesn't possess the frontend's knowledge. Note that branch regions are created to track branch conditions in the source; code and refer to two coverage mapping counters, one to track the number of; times the branch condition evaluated to ""true"", and one to track the number of; times the branch condition evaluated to ""false"". LLVM IR Representation; ======================. The coverage mapping data is stored in the LLVM IR using a global constant; structure variable called *__llvm_coverage_mapping* with the *IPSK_covmap*; section specifier (i.e. "".lcovmap$M"" on Windows and ""__llvm_covmap"" elsewhere). For example, lets consider a C file and how it gets compiled to LLVM:. .. _coverage mapping sample:. .. code-block:: c. int foo() {; return 42;; }; int bar() {; return 13;; }. The coverage mapping variable generated by Clang has 2 fields:. * Coverage mapping header. * An optionally compressed list of filenames present in the translation unit. The variable has 8-byte alignment because ld64 cannot always pack symbols from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:14467,Modifiability,variab,variable,14467,"proper line execution; counts for the unreachable lines and highlight the unreachable code.; Without them, the tool would think that those lines and regions were still; executed, as it doesn't possess the frontend's knowledge. Note that branch regions are created to track branch conditions in the source; code and refer to two coverage mapping counters, one to track the number of; times the branch condition evaluated to ""true"", and one to track the number of; times the branch condition evaluated to ""false"". LLVM IR Representation; ======================. The coverage mapping data is stored in the LLVM IR using a global constant; structure variable called *__llvm_coverage_mapping* with the *IPSK_covmap*; section specifier (i.e. "".lcovmap$M"" on Windows and ""__llvm_covmap"" elsewhere). For example, lets consider a C file and how it gets compiled to LLVM:. .. _coverage mapping sample:. .. code-block:: c. int foo() {; return 42;; }; int bar() {; return 13;; }. The coverage mapping variable generated by Clang has 2 fields:. * Coverage mapping header. * An optionally compressed list of filenames present in the translation unit. The variable has 8-byte alignment because ld64 cannot always pack symbols from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; Always 0. In prior versions, the length of the affixed string that contains the encoded coverage mapping data; i32 3, ; Coverage mapping format version; },; [32 x i8] c""..."" ; Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The firs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:14619,Modifiability,variab,variable,14619,"e. Note that branch regions are created to track branch conditions in the source; code and refer to two coverage mapping counters, one to track the number of; times the branch condition evaluated to ""true"", and one to track the number of; times the branch condition evaluated to ""false"". LLVM IR Representation; ======================. The coverage mapping data is stored in the LLVM IR using a global constant; structure variable called *__llvm_coverage_mapping* with the *IPSK_covmap*; section specifier (i.e. "".lcovmap$M"" on Windows and ""__llvm_covmap"" elsewhere). For example, lets consider a C file and how it gets compiled to LLVM:. .. _coverage mapping sample:. .. code-block:: c. int foo() {; return 42;; }; int bar() {; return 13;; }. The coverage mapping variable generated by Clang has 2 fields:. * Coverage mapping header. * An optionally compressed list of filenames present in the translation unit. The variable has 8-byte alignment because ld64 cannot always pack symbols from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; Always 0. In prior versions, the length of the affixed string that contains the encoded coverage mapping data; i32 3, ; Coverage mapping format version; },; [32 x i8] c""..."" ; Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The first entry in the filename list is the compilation directory. When the; filename is relative, the compilation directory is combined with the relative; path to get an absolute path. This can reduce size by omitting the duplicate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:22312,Modifiability,variab,variable-length,22312,"--------------------------------------------+; | ``0x02`` | The ending line of the first mapping region in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x02`` | The ending column of the first mapping region in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+. * The length of the substring that contains the encoded coverage mapping data; for the second function record is also 9. It's structured like the mapping data; for the first function record. * The two trailing bytes are zeroes and are used to pad the coverage mapping; data to give it the 8 byte alignment. Encoding; ========. The per-function coverage mapping data is encoded as a stream of bytes,; with a simple structure. The structure consists of the encoding; `types <cvmtypes_>`_ like variable-length unsigned integers, that; are used to encode `File ID Mapping`_, `Counter Expressions`_ and; the `Mapping Regions`_. The format of the structure follows:. ``[file id mapping, counter expressions, mapping regions]``. The translation unit filenames are encoded using the same encoding; `types <cvmtypes_>`_ as the per-function coverage mapping data, with the; following structure:. ``[numFilenames : LEB128, filename0 : string, filename1 : string, ...]``. .. _cvmtypes:. Types; -----. This section describes the basic types that are used by the encoding format; and can appear after ``:`` in the ``[foo : type]`` description. .. _LEB128:. LEB128; ^^^^^^. LEB128 is an unsigned integer value that is encoded using DWARF's LEB128; encoding, optimizing for the case where values are small; (1 byte for values less than 128). .. _CoverageStrings:. Strings; ^^^^^^^. ``[length : LEB128, characters...]``. String values are encoded with a `LEB value <LEB128_>`_ for the length; of the string and a sequence of bytes for its c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:541,Performance,optimiz,optimization,541,".. role:: raw-html(raw); :format: html. =================================; LLVM Code Coverage Mapping Format; =================================. .. contents::; :local:. Introduction; ============. LLVM's code coverage mapping format is used to provide code coverage; analysis using LLVM's and Clang's instrumentation based profiling; (Clang's ``-fprofile-instr-generate`` option). This document is aimed at those who would like to know how LLVM's code coverage; mapping works under the hood. A prior knowledge of how Clang's profile guided; optimization works is useful, but not required. For those interested in using; LLVM to provide code coverage analysis for their own programs, see the `Clang; documentation <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`. We start by briefly describing LLVM's code coverage mapping format and the; way that Clang and LLVM's code coverage tool work with this format. After; the basics are down, more advanced features of the coverage mapping format; are discussed - such as the data structures, LLVM IR representation and; the binary encoding. High Level Overview; ===================. LLVM's code coverage mapping format is designed to be a self contained; data format that can be embedded into the LLVM IR and into object files.; It's described in this document as a **mapping** format because its goal is; to store the data that is required for a code coverage tool to map between; the specific source ranges in a file and the execution counts obtained; after running the instrumented version of the program. The mapping data is used in two places in the code coverage process:. 1. When clang compiles a source file with ``-fcoverage-mapping``, it; generates the mapping information that describes the mapping between the; source ranges and the profiling instrumentation counters.; This information gets embedded into the LLVM IR and conveniently; ends up in the final executable file when the program is linked. 2. It is also used by *llvm-cov* -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:23064,Performance,optimiz,optimizing,23064,"o pad the coverage mapping; data to give it the 8 byte alignment. Encoding; ========. The per-function coverage mapping data is encoded as a stream of bytes,; with a simple structure. The structure consists of the encoding; `types <cvmtypes_>`_ like variable-length unsigned integers, that; are used to encode `File ID Mapping`_, `Counter Expressions`_ and; the `Mapping Regions`_. The format of the structure follows:. ``[file id mapping, counter expressions, mapping regions]``. The translation unit filenames are encoded using the same encoding; `types <cvmtypes_>`_ as the per-function coverage mapping data, with the; following structure:. ``[numFilenames : LEB128, filename0 : string, filename1 : string, ...]``. .. _cvmtypes:. Types; -----. This section describes the basic types that are used by the encoding format; and can appear after ``:`` in the ``[foo : type]`` description. .. _LEB128:. LEB128; ^^^^^^. LEB128 is an unsigned integer value that is encoded using DWARF's LEB128; encoding, optimizing for the case where values are small; (1 byte for values less than 128). .. _CoverageStrings:. Strings; ^^^^^^^. ``[length : LEB128, characters...]``. String values are encoded with a `LEB value <LEB128_>`_ for the length; of the string and a sequence of bytes for its characters. .. _file id mapping:. File ID Mapping; ---------------. ``[numIndices : LEB128, filenameIndex0 : LEB128, filenameIndex1 : LEB128, ...]``. File id mapping in a function's coverage mapping stream; contains the indices into the translation unit's filenames array. Counter; -------. ``[value : LEB128]``. A `coverage mapping counter`_ is stored in a single `LEB value <LEB128_>`_.; It is composed of two things --- the `tag <counter-tag_>`_; which is stored in the lowest 2 bits, and the `counter data`_ which is stored; in the remaining bits. .. _counter-tag:. Tag:; ^^^^. The counter's tag encodes the counter's kind; and, if the counter is an expression, the expression's kind.; The possible tag values are:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:17084,Security,hash,hash,17084,"nd one to track how many times a; ""false"" branch condition is taken. There are two differences between versions 4 and 3:. * Function records are now named symbols, and are marked *linkonce_odr*. This; allows linkers to merge duplicate function records. Merging of duplicate; *dummy* records (emitted for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding for; column end locations was introduced to indicate gap regions. In version 1, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i8*, i32, i32, i64 } { i8* getelementptr inbounds ([3 x i8]* @__profn_foo, i32 0, i32 0), ; Function's name; i32 3, ; Function's name length; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash; }. In version 2, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i64, i32, i64 } {; i64 0x5cf8c24cdb18bdac, ; Function's name MD5; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash. Coverage Mapping Header:; ------------------------. As shown above, the coverage mapping header has the following fields:. * The number of function records affixed to the coverage header. Always 0, but present for backwards compatibility. * The length of the string in the third field of *__llvm_coverage_mapping* that contains the encoded translation unit filenames. * The length of the string in the third field of *__llvm_coverage_mapping* that contains any encoded coverage mapping data affixed to the coverage header. Always 0, but present for backwards compatibility. * The format version. The current version",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:17347,Security,hash,hash,17347," for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding for; column end locations was introduced to indicate gap regions. In version 1, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i8*, i32, i32, i64 } { i8* getelementptr inbounds ([3 x i8]* @__profn_foo, i32 0, i32 0), ; Function's name; i32 3, ; Function's name length; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash; }. In version 2, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i64, i32, i64 } {; i64 0x5cf8c24cdb18bdac, ; Function's name MD5; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash. Coverage Mapping Header:; ------------------------. As shown above, the coverage mapping header has the following fields:. * The number of function records affixed to the coverage header. Always 0, but present for backwards compatibility. * The length of the string in the third field of *__llvm_coverage_mapping* that contains the encoded translation unit filenames. * The length of the string in the third field of *__llvm_coverage_mapping* that contains any encoded coverage mapping data affixed to the coverage header. Always 0, but present for backwards compatibility. * The format version. The current version is 6 (encoded as a 5). .. _function records:. Function record:; ----------------. A function record is a structure of the following type:. .. code-block:: llvm. { i64, i32, i64, i64, [? x i8] }. It contains the function name's MD5, the length of the encoded mapping data for; that function, the func",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:18286,Security,hash,hash,18286,"ded coverage mapping data string length; i64 0 ; Function's structural hash. Coverage Mapping Header:; ------------------------. As shown above, the coverage mapping header has the following fields:. * The number of function records affixed to the coverage header. Always 0, but present for backwards compatibility. * The length of the string in the third field of *__llvm_coverage_mapping* that contains the encoded translation unit filenames. * The length of the string in the third field of *__llvm_coverage_mapping* that contains any encoded coverage mapping data affixed to the coverage header. Always 0, but present for backwards compatibility. * The format version. The current version is 6 (encoded as a 5). .. _function records:. Function record:; ----------------. A function record is a structure of the following type:. .. code-block:: llvm. { i64, i32, i64, i64, [? x i8] }. It contains the function name's MD5, the length of the encoded mapping data for; that function, the function's structural hash value, the hash of the filenames; in the function's translation unit, and the encoded mapping data. Dissecting the sample:; ^^^^^^^^^^^^^^^^^^^^^^. Here's an overview of the encoded data that was stored in the; IR for the `coverage mapping sample`_ that was shown earlier:. * The IR contains the following string constant that represents the encoded; coverage mapping data for the sample translation unit:. .. code-block:: llvm. c""\01\15\1Dx\DA\13\D1\0F-N-*\D6/+\CE\D6/\C9-\D0O\CB\CF\D7K\06\00N+\07]"". * The string contains values that are encoded in the LEB128 format, which is; used throughout for storing integers. It also contains a compressed payload. * The first three LEB128-encoded numbers in the sample specify the number of; filenames, the length of the uncompressed filenames, and the length of the; compressed payload (or 0 if compression is disabled). In this sample, there; is 1 filename that is 21 bytes in length (uncompressed), and stored in 29; bytes (compressed). * T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:18302,Security,hash,hash,18302,"ded coverage mapping data string length; i64 0 ; Function's structural hash. Coverage Mapping Header:; ------------------------. As shown above, the coverage mapping header has the following fields:. * The number of function records affixed to the coverage header. Always 0, but present for backwards compatibility. * The length of the string in the third field of *__llvm_coverage_mapping* that contains the encoded translation unit filenames. * The length of the string in the third field of *__llvm_coverage_mapping* that contains any encoded coverage mapping data affixed to the coverage header. Always 0, but present for backwards compatibility. * The format version. The current version is 6 (encoded as a 5). .. _function records:. Function record:; ----------------. A function record is a structure of the following type:. .. code-block:: llvm. { i64, i32, i64, i64, [? x i8] }. It contains the function name's MD5, the length of the encoded mapping data for; that function, the function's structural hash value, the hash of the filenames; in the function's translation unit, and the encoded mapping data. Dissecting the sample:; ^^^^^^^^^^^^^^^^^^^^^^. Here's an overview of the encoded data that was stored in the; IR for the `coverage mapping sample`_ that was shown earlier:. * The IR contains the following string constant that represents the encoded; coverage mapping data for the sample translation unit:. .. code-block:: llvm. c""\01\15\1Dx\DA\13\D1\0F-N-*\D6/+\CE\D6/\C9-\D0O\CB\CF\D7K\06\00N+\07]"". * The string contains values that are encoded in the LEB128 format, which is; used throughout for storing integers. It also contains a compressed payload. * The first three LEB128-encoded numbers in the sample specify the number of; filenames, the length of the uncompressed filenames, and the length of the; compressed payload (or 0 if compression is disabled). In this sample, there; is 1 filename that is 21 bytes in length (uncompressed), and stored in 29; bytes (compressed). * T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:7677,Testability,log,logical,7677,"9C'>{ </span>; <span style='background-color:#4A789C'> #define MAX(x,y) </span><span style='background-color:#85C1F5'>((x) &gt; (y)? </span><span style='background-color:#F6D55D'>(x)</span><span style='background-color:#85C1F5'> : </span><span style='background-color:#F4BA70'>(y)</span><span style='background-color:#85C1F5'>)</span><span style='background-color:#4A789C'> </span>; <span style='background-color:#4A789C'> return </span><span style='background-color:#7FCA9F'>MAX</span><span style='background-color:#4A789C'>(x, 42); </span> <span class='c1'>// Expansion Region from 3:10 to 3:13</span>; <span style='background-color:#4A789C'>}</span>; </pre>`; * Branch regions associate instrumentable branch conditions in the source code; with a `coverage mapping counter`_ to track how many times an individual; condition evaluated to 'true' and another `coverage mapping counter`_ to; track how many times that condition evaluated to false. Instrumentable; branch conditions may comprise larger boolean expressions using boolean; logical operators. The 'true' and 'false' cases reflect unique branch paths; that can be traced back to the source code.; For example:. :raw-html:`<pre class='highlight' style='line-height:initial;'><span>int func(int x, int y) {; <span> if (<span style='background-color:#4A789C'>(x &gt; 1)</span> || <span style='background-color:#4A789C'>(y &gt; 3)</span>) {</span> <span class='c1'>// Branch Region from 3:6 to 3:12</span>; <span> </span><span class='c1'>// Branch Region from 3:17 to 3:23</span>; <span> printf(""%d\n"", x); </span>; <span> } else { </span>; <span> printf(""\n""); </span>; <span> }</span>; <span> return 0; </span>; <span>}</span>; </pre>`. * Decision regions associate multiple branch regions with a boolean; expression in the source code. This information also includes the number of; bitmap bytes needed to represent the expression's executed test vectors as; well as the total number of instrumentable branch conditions that comprise; the ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:8542,Testability,test,test,8542,"any times that condition evaluated to false. Instrumentable; branch conditions may comprise larger boolean expressions using boolean; logical operators. The 'true' and 'false' cases reflect unique branch paths; that can be traced back to the source code.; For example:. :raw-html:`<pre class='highlight' style='line-height:initial;'><span>int func(int x, int y) {; <span> if (<span style='background-color:#4A789C'>(x &gt; 1)</span> || <span style='background-color:#4A789C'>(y &gt; 3)</span>) {</span> <span class='c1'>// Branch Region from 3:6 to 3:12</span>; <span> </span><span class='c1'>// Branch Region from 3:17 to 3:23</span>; <span> printf(""%d\n"", x); </span>; <span> } else { </span>; <span> printf(""\n""); </span>; <span> }</span>; <span> return 0; </span>; <span>}</span>; </pre>`. * Decision regions associate multiple branch regions with a boolean; expression in the source code. This information also includes the number of; bitmap bytes needed to represent the expression's executed test vectors as; well as the total number of instrumentable branch conditions that comprise; the expression. Decision regions are used to visualize Modified; Condition/Decision Coverage (MC/DC) in *llvm-cov* for each boolean; expression. When decision regions are used, control flow IDs are assigned to; each associated branch region. One ID represents the current branch; condition, and two additional IDs represent the next branch condition in the; control flow given a true or false evaluation, respectively. This allows; *llvm-cov* to reconstruct the control flow around the conditions in order to; comprehend the full list of potential executable test vectors. .. _source code range:. Source Range:; ^^^^^^^^^^^^^. The source range record contains the starting and ending location of a certain; mapping region. Both locations include the line and the column numbers. .. _coverage file id:. File ID:; ^^^^^^^^. The file id an integer value that tells us; in which source file or macro expansion is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:9194,Testability,test,test,9194,"='c1'>// Branch Region from 3:17 to 3:23</span>; <span> printf(""%d\n"", x); </span>; <span> } else { </span>; <span> printf(""\n""); </span>; <span> }</span>; <span> return 0; </span>; <span>}</span>; </pre>`. * Decision regions associate multiple branch regions with a boolean; expression in the source code. This information also includes the number of; bitmap bytes needed to represent the expression's executed test vectors as; well as the total number of instrumentable branch conditions that comprise; the expression. Decision regions are used to visualize Modified; Condition/Decision Coverage (MC/DC) in *llvm-cov* for each boolean; expression. When decision regions are used, control flow IDs are assigned to; each associated branch region. One ID represents the current branch; condition, and two additional IDs represent the next branch condition in the; control flow given a true or false evaluation, respectively. This allows; *llvm-cov* to reconstruct the control flow around the conditions in order to; comprehend the full list of potential executable test vectors. .. _source code range:. Source Range:; ^^^^^^^^^^^^^. The source range record contains the starting and ending location of a certain; mapping region. Both locations include the line and the column numbers. .. _coverage file id:. File ID:; ^^^^^^^^. The file id an integer value that tells us; in which source file or macro expansion is this region located.; It enables Clang to produce mapping information for the code; defined inside macros, like this example demonstrates:. :raw-html:`<pre class='highlight' style='line-height:initial;'><span>void func(const char *str) </span><span style='background-color:#4A789C'>{ </span> <span class='c1'>// Code Region from 1:28 to 6:2 with file id 0</span>; <span style='background-color:#4A789C'> #define PUT </span><span style='background-color:#85C1F5'>printf(""%s\n"", str)</span><span style='background-color:#4A789C'> </span> <span class='c1'>// 2 Code Regions from 2:15 to 2:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:19949,Testability,test,test,19949,"ed in the LEB128 format, which is; used throughout for storing integers. It also contains a compressed payload. * The first three LEB128-encoded numbers in the sample specify the number of; filenames, the length of the uncompressed filenames, and the length of the; compressed payload (or 0 if compression is disabled). In this sample, there; is 1 filename that is 21 bytes in length (uncompressed), and stored in 29; bytes (compressed). * The coverage mapping from the first function record is encoded in this string:. .. code-block:: llvm. c""\01\00\00\01\01\01\0C\02\02"". This string consists of the following bytes:. +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x01`` | The number of file ids used by this function. There is only one file id used by the mapping data in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x00`` | An index into the filenames array which corresponds to the file ""/Users/alex/test.c"". |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x00`` | The number of counter expressions used by this function. This function doesn't use any expressions. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x01`` | The number of mapping regions that are stored in an array for the function's file id #0. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x01`` | The coverage mapping counter for the first region in this function. The value of 1 tells us that it's a coverage |; | | mapping counter that is a reference to the profile instrumentation counter with an index of 0. |; +----------+----",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:28133,Testability,test,testing,28133,"Start : LEB128, columnStart : LEB128, numLines : LEB128, columnEnd : LEB128]``. The source range record contains the following fields:. * *deltaLineStart*: The difference between the starting line of the; current mapping region and the starting line of the previous mapping region. If the current mapping region is the first region in the current; sub-array, then it stores the starting line of that region. * *columnStart*: The starting column of the mapping region. * *numLines*: The difference between the ending line and the starting line; of the current mapping region. * *columnEnd*: The ending column of the mapping region. If the high bit is set,; the current mapping region is a gap area. A count for a gap area is only used; as the line execution count if there are no other regions on a line. Testing Format; ==============. .. warning::; This section is for the LLVM developers who are working on ``llvm-cov`` only. ``llvm-cov`` uses a special file format (called ``.covmapping`` below) for; testing purposes. This format is private and should have no use for general; users. As a developer, you can get such files by the ``convert-for-testing``; subcommand of ``llvm-cov``. The structure of the ``.covmapping`` files follows:. ``[magicNumber : u64, version : u64, profileNames, coverageMapping, coverageRecords]``. Magic Number and Version; ------------------------. The magic is ``0x6d766f636d766c6c``, which is the ASCII string; ``llvmcovm`` in little-endian. There are two versions for now:. - Version1, encoded as ``0x6174616474736574`` (ASCII string ``testdata``).; - Version2, encoded as 1. The only difference between Version1 and Version2 is in the encoding of the; ``coverageMapping`` fields, which is explained later. Profile Names; -------------. ``profileNames``, ``coverageMapping`` and ``coverageRecords`` are 3 sections; extracted from the original binary file. ``profileNames`` encodes the size, address and the raw data of the section:. ``[profileNamesSize : LEB128, pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:28277,Testability,test,testing,28277,"* *deltaLineStart*: The difference between the starting line of the; current mapping region and the starting line of the previous mapping region. If the current mapping region is the first region in the current; sub-array, then it stores the starting line of that region. * *columnStart*: The starting column of the mapping region. * *numLines*: The difference between the ending line and the starting line; of the current mapping region. * *columnEnd*: The ending column of the mapping region. If the high bit is set,; the current mapping region is a gap area. A count for a gap area is only used; as the line execution count if there are no other regions on a line. Testing Format; ==============. .. warning::; This section is for the LLVM developers who are working on ``llvm-cov`` only. ``llvm-cov`` uses a special file format (called ``.covmapping`` below) for; testing purposes. This format is private and should have no use for general; users. As a developer, you can get such files by the ``convert-for-testing``; subcommand of ``llvm-cov``. The structure of the ``.covmapping`` files follows:. ``[magicNumber : u64, version : u64, profileNames, coverageMapping, coverageRecords]``. Magic Number and Version; ------------------------. The magic is ``0x6d766f636d766c6c``, which is the ASCII string; ``llvmcovm`` in little-endian. There are two versions for now:. - Version1, encoded as ``0x6174616474736574`` (ASCII string ``testdata``).; - Version2, encoded as 1. The only difference between Version1 and Version2 is in the encoding of the; ``coverageMapping`` fields, which is explained later. Profile Names; -------------. ``profileNames``, ``coverageMapping`` and ``coverageRecords`` are 3 sections; extracted from the original binary file. ``profileNames`` encodes the size, address and the raw data of the section:. ``[profileNamesSize : LEB128, profileNamesAddr : LEB128, profileNamesData : bytes]``. Coverage Mapping; ----------------. This field is padded with zero bytes to make it ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:28699,Testability,test,testdata,28699,"of the current mapping region. * *columnEnd*: The ending column of the mapping region. If the high bit is set,; the current mapping region is a gap area. A count for a gap area is only used; as the line execution count if there are no other regions on a line. Testing Format; ==============. .. warning::; This section is for the LLVM developers who are working on ``llvm-cov`` only. ``llvm-cov`` uses a special file format (called ``.covmapping`` below) for; testing purposes. This format is private and should have no use for general; users. As a developer, you can get such files by the ``convert-for-testing``; subcommand of ``llvm-cov``. The structure of the ``.covmapping`` files follows:. ``[magicNumber : u64, version : u64, profileNames, coverageMapping, coverageRecords]``. Magic Number and Version; ------------------------. The magic is ``0x6d766f636d766c6c``, which is the ASCII string; ``llvmcovm`` in little-endian. There are two versions for now:. - Version1, encoded as ``0x6174616474736574`` (ASCII string ``testdata``).; - Version2, encoded as 1. The only difference between Version1 and Version2 is in the encoding of the; ``coverageMapping`` fields, which is explained later. Profile Names; -------------. ``profileNames``, ``coverageMapping`` and ``coverageRecords`` are 3 sections; extracted from the original binary file. ``profileNames`` encodes the size, address and the raw data of the section:. ``[profileNamesSize : LEB128, profileNamesAddr : LEB128, profileNamesData : bytes]``. Coverage Mapping; ----------------. This field is padded with zero bytes to make it 8-byte aligned. ``coverageMapping`` contains the records of the source files. In version 1,; only one record is stored:. ``[padding : bytes, coverageMappingData : bytes]``. Version 2 relaxes this restriction by encoding the size of; ``coverageMappingData`` as a LEB128 number before the data:. ``[coverageMappingSize : LEB128, padding : bytes, coverageMappingData : bytes]``. The current version is 2. Covera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:533,Usability,guid,guided,533,".. role:: raw-html(raw); :format: html. =================================; LLVM Code Coverage Mapping Format; =================================. .. contents::; :local:. Introduction; ============. LLVM's code coverage mapping format is used to provide code coverage; analysis using LLVM's and Clang's instrumentation based profiling; (Clang's ``-fprofile-instr-generate`` option). This document is aimed at those who would like to know how LLVM's code coverage; mapping works under the hood. A prior knowledge of how Clang's profile guided; optimization works is useful, but not required. For those interested in using; LLVM to provide code coverage analysis for their own programs, see the `Clang; documentation <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`. We start by briefly describing LLVM's code coverage mapping format and the; way that Clang and LLVM's code coverage tool work with this format. After; the basics are down, more advanced features of the coverage mapping format; are discussed - such as the data structures, LLVM IR representation and; the binary encoding. High Level Overview; ===================. LLVM's code coverage mapping format is designed to be a self contained; data format that can be embedded into the LLVM IR and into object files.; It's described in this document as a **mapping** format because its goal is; to store the data that is required for a code coverage tool to map between; the specific source ranges in a file and the execution counts obtained; after running the instrumented version of the program. The mapping data is used in two places in the code coverage process:. 1. When clang compiles a source file with ``-fcoverage-mapping``, it; generates the mapping information that describes the mapping between the; source ranges and the profiling instrumentation counters.; This information gets embedded into the LLVM IR and conveniently; ends up in the final executable file when the program is linked. 2. It is also used by *llvm-cov* -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:2885,Usability,guid,guide,2885,"e final executable file when the program is linked. 2. It is also used by *llvm-cov* - the mapping information is extracted from an; object file and is used to associate the execution counts (the values of the; profile instrumentation counters), and the source ranges in a file.; After that, the tool is able to generate various code coverage reports; for the program. The coverage mapping format aims to be a ""universal format"" that would be; suitable for usage by any frontend, and not just by Clang. It also aims to; provide the frontend the possibility of generating the minimal coverage mapping; data in order to reduce the size of the IR and object files - for example,; instead of emitting mapping information for each statement in a function, the; frontend is allowed to group the statements with the same execution count into; regions of code, and emit the mapping information only for those regions. Advanced Concepts; =================. The remainder of this guide is meant to give you insight into the way the; coverage mapping format works. The coverage mapping format operates on a per-function level as the; profile instrumentation counters are associated with a specific function.; For each function that requires code coverage, the frontend has to create; coverage mapping data that can map between the source code ranges and; the profile instrumentation counters for that function. Mapping Region; --------------. The function's coverage mapping data contains an array of mapping regions.; A mapping region stores the `source code range`_ that is covered by this region,; the `file id <coverage file id_>`_, the `coverage mapping counter`_ and; the region's kind.; There are several kinds of mapping regions:. * Code regions associate portions of source code and `coverage mapping; counters`_. They make up the majority of the mapping regions. They are used; by the code coverage tool to compute the execution counts for lines,; highlight the regions of code that were never execute",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:22228,Usability,simpl,simple,22228,"ng column of the first mapping region in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x02`` | The ending line of the first mapping region in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+; | ``0x02`` | The ending column of the first mapping region in this function. |; +----------+-------------------------------------------------------------------------------------------------------------------------+. * The length of the substring that contains the encoded coverage mapping data; for the second function record is also 9. It's structured like the mapping data; for the first function record. * The two trailing bytes are zeroes and are used to pad the coverage mapping; data to give it the 8 byte alignment. Encoding; ========. The per-function coverage mapping data is encoded as a stream of bytes,; with a simple structure. The structure consists of the encoding; `types <cvmtypes_>`_ like variable-length unsigned integers, that; are used to encode `File ID Mapping`_, `Counter Expressions`_ and; the `Mapping Regions`_. The format of the structure follows:. ``[file id mapping, counter expressions, mapping regions]``. The translation unit filenames are encoded using the same encoding; `types <cvmtypes_>`_ as the per-function coverage mapping data, with the; following structure:. ``[numFilenames : LEB128, filename0 : string, filename1 : string, ...]``. .. _cvmtypes:. Types; -----. This section describes the basic types that are used by the encoding format; and can appear after ``:`` in the ``[foo : type]`` description. .. _LEB128:. LEB128; ^^^^^^. LEB128 is an unsigned integer value that is encoded using DWARF's LEB128; encoding, optimizing for the case where values are small; (1 byte for values less than 128). .. _CoverageStrings:. Strings; ^^^^^^^. ``[length",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CycleTerminology.rst:7395,Integrability,depend,depends,7395,"ny nesting of cycles discovered by the implementation-defined; DFS, consider the smallest cycle C which contains P. For the sake; of contradiction, assume that D is in C. Then the header H of C; cannot be in P, since the header of a cycle cannot be dominated by; any other node in the cycle. Thus, P is in the set (C-H), and there; must be a smaller cycle C' in C which also contains P, but that; contradicts how we chose C. 3. If a closed path P contains nodes U1 and U2 but not their; dominators D1 and D2 respectively, then there exists a cycle C that; contains U1 and U2 but neither of D1 and D2. **Proof:** From the above properties, each D1 and D2 separately; dominate every node in P. There exists a cycle C1 (respectively,; C2) that contains P but not D1 (respectively, D2). Either C1 and C2; are the same cycle, or one of them is nested inside the other.; Hence there is always a cycle that contains U1 and U2 but neither; of D1 and D2. .. _cycle-closed-path-header:. 4. In any cycle hierarchy, the header ``H`` of the smallest cycle; ``C`` containing a closed path ``P`` itself lies on ``P``. **Proof:** If ``H`` is not in ``P``, then there is a smaller cycle; ``C'`` in the set ``C - H`` containing ``P``, thus contradicting; the claim that ``C`` is the smallest such cycle. .. _cycle-reducible-headers:. Reducible Cycle Headers; =======================. Although the cycle hierarchy depends on the DFS chosen, reducible; cycles satisfy the following invariant:. If a reducible cycle ``C`` with header ``H`` is discovered in any; DFS, then there exists a cycle ``C'`` in every DFS with header; ``H``, that contains ``C``. **Proof:** For a closed path ``P`` in ``C`` that passes through ``H``,; every cycle hierarchy has a smallest cycle ``C'`` containing ``P`` and; whose header is in ``P``. Since ``H`` is the only entry to ``P``,; ``H`` must be the header of ``C'``. Since headers uniquely define; cycles, ``C'`` contains every such closed path ``P``, and hence ``C'``; contains ``C``.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CycleTerminology.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CycleTerminology.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CycleTerminology.rst:1267,Usability,simpl,simply,1267,"nction CFG or a subgraph of it, a *cycle*; is a maximal strongly connected region with at least one internal edge.; (Informational note --- The requirement for at least one internal edge; ensures that a single basic block is a cycle only if there is an edge; that goes back to the same basic block.); 2. A basic block in a cycle that can be reached from the entry of; the function along a path that does not visit any other basic block; in the cycle is called an *entry* of the cycle.; A cycle can have multiple entries.; 3. For a given depth-first search starting from the entry of the function, the; first node of a cycle to be visited is called the *header* of this cycle; with respect to this particular DFS. The header is always an entry node.; 4. In any depth-first search starting from the entry, the set of cycles; found in the CFG is the same. These are the *top-level cycles*; that do not themselves have a parent.; 5. The *child cycles* (or simply cycles) nested inside a cycle C with; header H are the cycles in the subgraph induced on the set of nodes (C - H).; C is said to be the *parent* of these cycles. Thus, cycles form an implementation-defined forest where each cycle C is; the parent of any child cycles nested inside C. The tree closely; follows the nesting of loops in the same function. The unique entry of; a reducible cycle (an LLVM loop) L dominates all its other nodes, and; is always chosen as the header of some cycle C regardless of the DFS; tree used. This cycle C is a superset of the loop L. For an; irreducible cycle, no one entry dominates the nodes of the cycle. One; of the entries is chosen as header of the cycle, in an; implementation-defined way. .. _cycle-irreducible:. A cycle is *irreducible* if it has multiple entries and it is; *reducible* otherwise. .. _cycle-parent-block:. A cycle C is said to be the *parent* of a basic block B if B occurs in; C but not in any child cycle of C. Then B is also said to be a *child*; of cycle C. .. _cycle-toplevel-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CycleTerminology.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CycleTerminology.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1437,Availability,avail,available,1437,"l>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1621,Deployability,release,release,1621,"bject files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1809,Deployability,release,release,1809,"ormation in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:380,Integrability,interface,interface,380,"=====================; Debugging JIT-ed Code; =====================. Background; ==========. Without special runtime support, debugging dynamically generated code can be; quite painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT comp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:594,Integrability,interface,interface,594,"=====================; Debugging JIT-ed Code; =====================. Background; ==========. Without special runtime support, debugging dynamically generated code can be; quite painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT comp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:539,Modifiability,plugin,plugin,539,"=====================; Debugging JIT-ed Code; =====================. Background; ==========. Without special runtime support, debugging dynamically generated code can be; quite painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT comp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1887,Modifiability,plugin,plugin,1887,"nerated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:3524,Modifiability,plugin,plugin,3524,"y following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 16 return -1;; 17 char firstletter = argv[1][0];; 18 int result = compute_factorial(firstletter - '0');; 19; 20 // Returned result is clipped at 255...; 21 return result;; 22 }. Here is a sample command line session that shows how to build and run this; code via ``lli`` inside LLDB:. .. code-block:: bash. > export BINPATH=/workspaces/llvm-project/build/bin; > $BINPATH/clang -g -S -emit-llvm --target=x86_64-unknown-unknown-elf showdebug.c; > lldb $BINPATH/lli; (lldb) target create ""/workspaces/llvm-project/build/bin/lli""; Current executable set to '/workspaces/llvm-project/build/bin/lli' (x86_64).; (lldb) settings set plugin.jit-loader.gdb.enable on; (lldb) b compute_factorial; Breakpoint 1: no locations (pending).; WARNING: Unable to resolve breakpoint to any actual locations.; (lldb) run --jit-kind=mcjit showdebug.ll 5; 1 location added to breakpoint 1; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 1.1; frame #0: 0x00007ffff7fd0007 JIT(0x45c2cb0)`compute_factorial(n=5) at showdebug.c:3:11; 1 int compute_factorial(int n); 2 {; -> 3 if (n <= 1); 4 return 1;; 5 int f = n;; 6 while (--n > 1); 7 f *= n;; (lldb) p n; (int) $0 = 5; (lldb) b showdebug.c:9; Breakpoint 2: where = JIT(0x45c2cb0)`compute_factorial + 60 at showdebug.c:9:1, address = 0x00007ffff7fd003c; (lldb) c; Process 21340 resuming; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 2.1; frame #0: 0x00007ffff7fd003c JIT(0x45c2cb0)`compute_factorial(n=1) at showdebug.c:9:1; 6 while (--n > 1); 7 f *= n;; 8 return f;; -> 9 }; 10; 11 int main(int argc, char** argv); 12 {; (lldb) p f; (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1183,Performance,load,loads,1183," painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1898,Performance,load,loader,1898," function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:3535,Performance,load,loader,3535,"code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 16 return -1;; 17 char firstletter = argv[1][0];; 18 int result = compute_factorial(firstletter - '0');; 19; 20 // Returned result is clipped at 255...; 21 return result;; 22 }. Here is a sample command line session that shows how to build and run this; code via ``lli`` inside LLDB:. .. code-block:: bash. > export BINPATH=/workspaces/llvm-project/build/bin; > $BINPATH/clang -g -S -emit-llvm --target=x86_64-unknown-unknown-elf showdebug.c; > lldb $BINPATH/lli; (lldb) target create ""/workspaces/llvm-project/build/bin/lli""; Current executable set to '/workspaces/llvm-project/build/bin/lli' (x86_64).; (lldb) settings set plugin.jit-loader.gdb.enable on; (lldb) b compute_factorial; Breakpoint 1: no locations (pending).; WARNING: Unable to resolve breakpoint to any actual locations.; (lldb) run --jit-kind=mcjit showdebug.ll 5; 1 location added to breakpoint 1; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 1.1; frame #0: 0x00007ffff7fd0007 JIT(0x45c2cb0)`compute_factorial(n=5) at showdebug.c:3:11; 1 int compute_factorial(int n); 2 {; -> 3 if (n <= 1); 4 return 1;; 5 int f = n;; 6 while (--n > 1); 7 f *= n;; (lldb) p n; (int) $0 = 5; (lldb) b showdebug.c:9; Breakpoint 2: where = JIT(0x45c2cb0)`compute_factorial + 60 at showdebug.c:9:1, address = 0x00007ffff7fd003c; (lldb) c; Process 21340 resuming; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 2.1; frame #0: 0x00007ffff7fd003c JIT(0x45c2cb0)`compute_factorial(n=1) at showdebug.c:9:1; 6 while (--n > 1); 7 f *= n;; 8 return f;; -> 9 }; 10; 11 int main(int argc, char** argv); 12 {; (lldb) p f; (int) $1 = 120; (lldb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1241,Usability,resume,resumes,1241," painful. Debuggers generally read debug information from object files on; disk, but for JITed code there is no such file to look for. In order to hand over the necessary debug info, `GDB established an; interface <https://sourceware.org/gdb/onlinedocs/gdb/JIT-Interface.html>`_; for registering JITed code with debuggers. LLDB implements it in the; JITLoaderGDB plugin. On the JIT side, LLVM MCJIT does implement the interface; for ELF object files. At a high level, whenever MCJIT generates new machine code, it does so in an; in-memory object file that contains the debug information in DWARF format.; MCJIT then adds this in-memory object file to a global list of dynamically; generated object files and calls a special function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:5301,Availability,error,error,5301,"changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10249,Availability,avail,available,10249,"code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12544,Availability,error,errors,12544,"ations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13123,Availability,avail,available,13123,"ef:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14416,Availability,failure,failure,14416,"ddressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14499,Availability,fault,fault,14499," should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17908,Availability,down,downstream,17908,"d be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is norm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17989,Availability,avail,available,17989," examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:20506,Availability,avail,available,20506," warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:27830,Availability,down,down,27830,"eries of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline merged into them periodically. If the branch; development and mainline development occur in the same pieces of code,; resolving merge conflicts can take a lot of time. #. Other people in the community tend to ignore work on branches. #. Huge changes (produced when a branch is merged back onto mainline) are; extremely difficult to `code review`_. #. Branches are not routinely tested by our nightly tester infrastructure. #. Changes developed as monolithic large changes often don't work until the; entire set of changes is done. Breaking it down into a set of smaller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28967,Availability,mainten,maintenance,28967,"roblems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34702,Availability,down,downsides,34702,"y changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34983,Availability,error,error,34983,"----------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <http",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35276,Availability,error,error,35276,"owing process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35421,Availability,error,error,35421,"ide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35439,Availability,error,error,35439,"ide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36688,Availability,down,downstream,36688,"e's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infras",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36958,Availability,avail,available,36958,"m.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infrastructure Working Group <mailto:iwg@llvm.org>`_. .. _new-llvm-components:. Introducing New Components into LLVM; ====================================. The LLVM community is a vibrant and exciting place to be, and we look to be; inclusive of new projects and foster new communities, and increase; collaboration across indust",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:37076,Availability,error,error,37076,"ations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infrastructure Working Group <mailto:iwg@llvm.org>`_. .. _new-llvm-components:. Introducing New Components into LLVM; ====================================. The LLVM community is a vibrant and exciting place to be, and we look to be; inclusive of new projects and foster new communities, and increase; collaboration across industry and academia. That said, we need to strike a balance between being inclusive of new ideas and; peopl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:38108,Availability,mainten,maintenance,38108,"nd the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infrastructure Working Group <mailto:iwg@llvm.org>`_. .. _new-llvm-components:. Introducing New Components into LLVM; ====================================. The LLVM community is a vibrant and exciting place to be, and we look to be; inclusive of new projects and foster new communities, and increase; collaboration across industry and academia. That said, we need to strike a balance between being inclusive of new ideas and; people and the cost of ongoing maintenance that new code requires. As such, we; have a general :doc:`support policy<SupportPolicy>` for introducing major new; components into the LLVM world, depending on the degree of detail and; responsibility required. *Core* projects need a higher degree of scrutiny; than *peripheral* projects, and the latter may have additional differences. However, this is really only intended to cover common cases; that we have seen arise: different situations are different, and we are open; to discussing unusual cases as well - just start an RFC thread on the; `LLVM Discourse forums`_. Adding a New Target; -------------------. LLVM is very receptive to new targets, even experimental ones, but a number of; problems can appear when adding new large portions of code, and back-ends are; normally added in bulk. New targets need the same level of support as other; *core* parts of the compiler, so they are covered in the *core tier* of our; :doc:`support policy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:39521,Availability,failure,failures,39521,"cases as well - just start an RFC thread on the; `LLVM Discourse forums`_. Adding a New Target; -------------------. LLVM is very receptive to new targets, even experimental ones, but a number of; problems can appear when adding new large portions of code, and back-ends are; normally added in bulk. New targets need the same level of support as other; *core* parts of the compiler, so they are covered in the *core tier* of our; :doc:`support policy<SupportPolicy>`. We have found that landing large pieces of new code and then trying to fix; emergent problems in-tree is problematic for a variety of reasons. For these; reasons, new targets are *always* added as *experimental* until they can be; proven stable, and later moved to non-experimental. The differences between both classes are:. * Experimental targets are not built by default (they need to be explicitly; enabled at CMake time). * Test failures, bugs, and build breakages that only appear when the; experimental target is enabled, caused by changes unrelated to the target, are; the responsibility of the community behind the target to fix. The basic rules for a back-end to be upstreamed in **experimental** mode are:. * Every target must have a :ref:`code owner<code owners>`. The `CODE_OWNERS.TXT`; file has to be updated as part of the first merge. The code owner makes sure; that changes to the target get reviewed and steers the overall effort. * There must be an active community behind the target. This community; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:40969,Availability,avail,available,40969,"ewed and steers the overall effort. * There must be an active community behind the target. This community; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41368,Availability,down,down,41368,"es, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41975,Availability,error,errors,41975,") or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:52428,Availability,down,down,52428,"ake at least 4-6 weeks. If you would like to contribute code; under a different license, please create a Phabricator review with the code; you want to contribute and email board@llvm.org requesting a review. If you have questions or comments about these topics, please ask on the; `LLVM Discourse forums`_. However,; please realize that most compiler developers are not lawyers, and therefore you; will not be getting official legal advice. Copyright; ---------. The LLVM project does not collect copyright assignments, which means that the; copyright for the code in the project is held by the respective contributors.; Because you (or your company); retain ownership of the code you contribute, you know it may only be used under; the terms of the open source license you contributed it under: the license for; your contributions cannot be changed in the future without your approval. Because the LLVM project does not require copyright assignments, changing the; LLVM license requires tracking down the; contributors to LLVM and getting them to agree that a license change is; acceptable for their contributions. We feel that a high burden for relicensing; is good for the project, because contributors do not have to fear that their; code will be used in a way with which they disagree. Relicensing; -----------. The last paragraph notwithstanding, the LLVM Project is in the middle of a large; effort to change licenses, which aims to solve several problems:. * The old licenses made it difficult to move code from (e.g.) the compiler to; runtime libraries, because runtime libraries used a different license from the; rest of the compiler.; * Some contributions were not submitted to LLVM due to concerns that; the patent grant required by the project was overly broad.; * The patent grant was unique to the LLVM Project, not written by a lawyer, and; was difficult to determine what protection was provided (if any). The scope of relicensing is all code that is considered part of the LLVM; pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:56418,Availability,avail,available,56418,"2.0 License ----. As an exception, if, as a result of your compiling your source code, portions; of this Software are embedded into an Object form of such source code, you; may redistribute such embedded portions in such Object form without complying; with the conditions of Sections 4(a), 4(b) and 4(d) of the License. In addition, if you combine or link compiled forms of this Software with; software that is licensed under the GPLv2 (""Combined Software"") and if a; court of competent jurisdiction determines that the patent provision (Section; 3), the indemnity provision (Section 9) or other Section of the License; conflicts with the conditions of the GPLv2, you may retroactively and; prospectively choose to deem waived or otherwise exclude such Section(s) of; the License, but only in their entirety and only with respect to the Combined; Software. We intend to keep LLVM perpetually open source and available under a permissive; license - this fosters the widest adoption of LLVM by; **allowing commercial products to be derived from LLVM** with few restrictions; and without a requirement for making any derived works also open source. In; particular, LLVM's license is not a ""copyleft"" license like the GPL. The ""Apache 2.0 License with LLVM exceptions"" allows you to:. * freely download and use LLVM (in whole or in part) for personal, internal, or; commercial purposes.; * include LLVM in packages or distributions you create.; * combine LLVM with code licensed under every other major open source; license (including BSD, MIT, GPLv2, GPLv3...).; * make changes to LLVM code without being required to contribute it back; to the project - contributions are appreciated though!. However, it imposes these limitations on you:. * You must retain the copyright notice if you redistribute LLVM: You cannot; strip the copyright headers off or replace them with your own.; * Binaries that include LLVM must reproduce the copyright notice (e.g. in an; included README file or in an ""About"" box), u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:56800,Availability,down,download,56800,", if you combine or link compiled forms of this Software with; software that is licensed under the GPLv2 (""Combined Software"") and if a; court of competent jurisdiction determines that the patent provision (Section; 3), the indemnity provision (Section 9) or other Section of the License; conflicts with the conditions of the GPLv2, you may retroactively and; prospectively choose to deem waived or otherwise exclude such Section(s) of; the License, but only in their entirety and only with respect to the Combined; Software. We intend to keep LLVM perpetually open source and available under a permissive; license - this fosters the widest adoption of LLVM by; **allowing commercial products to be derived from LLVM** with few restrictions; and without a requirement for making any derived works also open source. In; particular, LLVM's license is not a ""copyleft"" license like the GPL. The ""Apache 2.0 License with LLVM exceptions"" allows you to:. * freely download and use LLVM (in whole or in part) for personal, internal, or; commercial purposes.; * include LLVM in packages or distributions you create.; * combine LLVM with code licensed under every other major open source; license (including BSD, MIT, GPLv2, GPLv3...).; * make changes to LLVM code without being required to contribute it back; to the project - contributions are appreciated though!. However, it imposes these limitations on you:. * You must retain the copyright notice if you redistribute LLVM: You cannot; strip the copyright headers off or replace them with your own.; * Binaries that include LLVM must reproduce the copyright notice (e.g. in an; included README file or in an ""About"" box), unless the LLVM code was added as; a by-product of compilation. For example, if an LLVM runtime library like; compiler_rt or libc++ was automatically included into your application by the; compiler, you do not need to attribute it.; * You can't use our names to promote your products (LLVM derived or not) -; though you can make tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61124,Availability,avail,available,61124,"to the ASF are those you own or; have the right to license that read on your contribution or on the; combination of your contribution with the specific Apache product to which; you contributed as it existed at the time of your contribution. No additional; patent claims become licensed as a result of subsequent combinations of your; contribution with any other software. Note, however, that licensable patent; claims include those that you acquire in the future, as long as they read on; your original contribution as made at the original time. Once a patent claim; is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived fr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61232,Availability,avail,available,61232,"ith the specific Apache product to which; you contributed as it existed at the time of your contribution. No additional; patent claims become licensed as a result of subsequent combinations of your; contribution with any other software. Note, however, that licensable patent; claims include those that you acquire in the future, as long as they read on; your original contribution as made at the original time. Once a patent claim; is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived from LLVM** with few restrictions and without; a requirement for making any derived works also open source (i.e. LLVM's; license is not a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61505,Availability,avail,available,61505,"as long as they read on; your original contribution as made at the original time. Once a patent claim; is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived from LLVM** with few restrictions and without; a requirement for making any derived works also open source (i.e. LLVM's; license is not a ""copyleft"" license like the GPL). We suggest that you read the; `License <http://www.opensource.org/licenses/UoI-NCSA.php>`_ if further; clarification is needed. In addition to the UIUC license, the runtime library components of LLVM; (**compiler_rt, libc++, and libclc**) are also licensed under the `MIT License; <http://www.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61640,Availability,down,down,61640," is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived from LLVM** with few restrictions and without; a requirement for making any derived works also open source (i.e. LLVM's; license is not a ""copyleft"" license like the GPL). We suggest that you read the; `License <http://www.opensource.org/licenses/UoI-NCSA.php>`_ if further; clarification is needed. In addition to the UIUC license, the runtime library components of LLVM; (**compiler_rt, libc++, and libclc**) are also licensed under the `MIT License; <http://www.opensource.org/licenses/mit-license.php>`_, which does not contain; the binary redistribution clause. A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1102,Deployability,patch,patches,1102,"ent contains the LLVM Developer Policy which defines the project's; policy towards developers and their contributions. The intent of this policy is; to eliminate miscommunication, rework, and confusion that might arise from the; distributed nature of LLVM's development. By stating the policy in clear terms,; we hope each developer can know ahead of time what to expect when making LLVM; contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`Gi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1451,Deployability,patch,patches,1451,"contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. Yo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3718,Deployability,patch,patches,3718,"ts.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3804,Deployability,patch,patch,3804,"ing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3941,Deployability,patch,patch,3941," labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4044,Deployability,patch,patch,4044,"g issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Pleas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4165,Deployability,patch,patches,4165,"sue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4229,Deployability,patch,patches,4229,"stinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4314,Deployability,patch,patch,4314,"stinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4390,Deployability,patch,patch,4390,"re proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awarenes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4514,Deployability,patch,patches,4514,"LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4591,Deployability,patch,patches,4591,"LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:5715,Deployability,update,updated,5715,"ntribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6598,Deployability,release,release,6598," deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6617,Deployability,release,release,6617," updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6890,Deployability,release,release,6890,"urpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:7009,Deployability,release,release,7009,"en accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take adva",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:7320,Deployability,release,release,7320,"n do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take advantage of the fact that most people do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:8079,Deployability,patch,patches,8079,"the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take advantage of the fact that most people do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else will review it, allowing the patch to go unreviewed. To solve this; problem, we have a notion of an 'owner' for a piece of the code. The sole; responsibility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:8218,Deployability,patch,patches,8218,"). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take advantage of the fact that most people do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else will review it, allowing the patch to go unreviewed. To solve this; problem, we have a notion of an 'owner' for a piece of the code. The sole; responsibility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpecte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:8354,Deployability,patch,patch,8354,"). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the combination; of code review plus post-commit review for trusted maintainers. Having both is; a great way for the project to take advantage of the fact that most people do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else will review it, allowing the patch to go unreviewed. To solve this; problem, we have a notion of an 'owner' for a piece of the code. The sole; responsibility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpecte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9031,Deployability,patch,patches,9031,"le do; the right thing most of the time, and only commit patches without pre-commit; review when they are confident they are right. The trick to this is that the project has to guarantee that all patches that are; committed are reviewed after they go in: you don't want everyone to assume; someone else will review it, allowing the patch to go unreviewed. To solve this; problem, we have a notion of an 'owner' for a piece of the code. The sole; responsibility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10880,Deployability,release,release,10880,"en in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Cha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11074,Deployability,release,release,11074,"n; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11249,Deployability,release,release,11249,"are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11744,Deployability,release,release,11744,"rmance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11813,Deployability,release,release,11813," notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12221,Deployability,release,release,12221,"ant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17286,Deployability,patch,patch,17286,"ould be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17322,Deployability,patch,patch,17322,"ould be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17468,Deployability,patch,patch,17468,"ted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ---------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17617,Deployability,patch,patch,17617,"EV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:18888,Deployability,patch,patches,18888,"automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:18915,Deployability,patch,patch,18915,"a can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19045,Deployability,patch,patch,19045," such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19210,Deployability,patch,patch,19210,"n-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert som",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19502,Deployability,patch,patch,19502,"; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:20555,Deployability,patch,patch,20555," warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21113,Deployability,patch,patch,21113,"tabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21129,Deployability,patch,patches,21129,"tabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21222,Deployability,patch,patch,21222,"or themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21395,Deployability,patch,patch,21395,"; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21770,Deployability,patch,patch,21770,"istance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21957,Deployability,patch,patch,21957,"ge improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22103,Deployability,patch,patch,22103,"eing reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22268,Deployability,patch,patch,22268,"stomary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22310,Deployability,patch,patches,22310,"stomary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22821,Deployability,patch,patch,22821,"is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22857,Deployability,update,updated,22857,"is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23072,Deployability,patch,patches,23072," reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to requi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24333,Deployability,patch,patch,24333,"sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24443,Deployability,patch,patches,24443,"vm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24654,Deployability,patch,patches,24654,"ur behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subjec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25193,Deployability,patch,patches,25193,"ou are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25802,Deployability,patch,patches,25802," make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; together well and are as consistent as possible. If you plan to make a major; change to the way LLVM works or want to add a major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:27109,Deployability,patch,patches,27109,"post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; together well and are as consistent as possible. If you plan to make a major; change to the way LLVM works or want to add a major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the design of the new feature is finalized, the work itself should be done; as a series of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline merged into them periodically. If the branch; development and mainline development occur in the same pieces of code,; resolving merge conflicts can take a lot of time. #. Other people in the community tend to ignore work on branches. #. Huge changes (produced when a branch is merged back onto mainline) are; extremely difficult to `code review`_. #. Branches are not routinely tested by our nightly tester infrastructure. #. Changes developed as monolithic large changes often don't work until the; entire set of changes is done. Breaking it down into a set of smaller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:29667,Deployability,patch,patch,29667,"hange should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30250,Deployability,patch,patch,30250,"tion of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30470,Deployability,patch,patches,30470,"t making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30529,Deployability,patch,patch,30529,"t making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30679,Deployability,patch,patches,30679,"t making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30845,Deployability,patch,patch,30845,"rrect attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:31886,Deployability,release,release,31886,"appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32087,Deployability,release,releases,32087,"od was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32127,Deployability,release,releases,32127,"od was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32266,Deployability,upgrade,upgrade,32266,"ted processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32349,Deployability,upgrade,upgrades,32349,"bility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32429,Deployability,upgrade,upgrade,32429,"that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33089,Deployability,release,release,33089,"ile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33109,Deployability,patch,patches,33109,"ile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33227,Deployability,release,release,33227,"ile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33279,Deployability,release,release,33279,"ile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33373,Deployability,patch,patch,33373," dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the las",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33775,Deployability,release,release,33775,"ce and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34795,Deployability,update,update,34795," do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35250,Deployability,release,release,35250,"owing process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35335,Deployability,release,release-bound,35335,"e-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the thes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35461,Deployability,release,release,35461,"ide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35886,Deployability,continuous,continuous,35886,"nsition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35897,Deployability,integrat,integration,35897,"nsition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36073,Deployability,configurat,configurations,36073,"is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36269,Deployability,release,release,36269,"VM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st ste",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36304,Deployability,patch,patches,36304,"ound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36533,Deployability,patch,patch,36533,"ate the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36559,Deployability,configurat,configuration,36559,"ate the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:39902,Deployability,update,updated,39902," in bulk. New targets need the same level of support as other; *core* parts of the compiler, so they are covered in the *core tier* of our; :doc:`support policy<SupportPolicy>`. We have found that landing large pieces of new code and then trying to fix; emergent problems in-tree is problematic for a variety of reasons. For these; reasons, new targets are *always* added as *experimental* until they can be; proven stable, and later moved to non-experimental. The differences between both classes are:. * Experimental targets are not built by default (they need to be explicitly; enabled at CMake time). * Test failures, bugs, and build breakages that only appear when the; experimental target is enabled, caused by changes unrelated to the target, are; the responsibility of the community behind the target to fix. The basic rules for a back-end to be upstreamed in **experimental** mode are:. * Every target must have a :ref:`code owner<code owners>`. The `CODE_OWNERS.TXT`; file has to be updated as part of the first merge. The code owner makes sure; that changes to the target get reviewed and steers the overall effort. * There must be an active community behind the target. This community; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41452,Deployability,continuous,continuous,41452,"es, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41999,Deployability,configurat,configuration,41999,") or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:43672,Deployability,patch,patches,43672,"rage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:43759,Deployability,patch,patches,43759," necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:43914,Deployability,patch,patch,43914,"rom unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; ----",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44011,Deployability,patch,patches,44011,". Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-proje",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44117,Deployability,patch,patch,44117,"responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44235,Deployability,patch,patches,44235," Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44295,Deployability,patch,patches,44295," Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44497,Deployability,patch,patches,44497,"any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are great because they; allow atomic commits to the project, simplify CI, and make it easier for; subcommunities to collaborate. Like new targets, most projects already in the monorepo are considered to be in; th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:48700,Deployability,release,releases,48700,"e LLVM umbrella. Projects which can be considered for the LLVM incubator meet the following; criteria:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to the license, patent, and code of conduct policies laid out; in this developer policy document.; * Must have a documented charter and development plan, e.g. in the form of a; README file, mission statement, and/or manifesto.; * Should conform to coding standards, incremental development process, and; other expectations.; * Should have a sense of the community that it hopes to eventually foster, and; there should be interest from members with different affiliations /; organizations.; * Should have a feasible path to eventually graduate as a dedicated top-level; or sub-project within the `LLVM monorepo; <https://github.com/llvm/llvm-project>`_.; * Should include a notice (e.g. in the project README or web page) that the; project is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:49626,Deployability,integrat,integration,49626,"oject is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it is always; safe to ask on the `LLVM Discourse forums`_ about this. Suggested disclaimer for the project README and the main project web page:. ::. This project is participating in the LLVM Incubator process: as such, it is; not part of any official LLVM release. While incubation status is not; necessarily a reflection of the completeness or stability of the code, it; does indicate that the project is not yet endorsed as a component of LLVM. .. _copyright-license-patents:. Copyright, License, and Patents; ===============================. .. note::. This section",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:50328,Deployability,release,release,50328,"propriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it is always; safe to ask on the `LLVM Discourse forums`_ about this. Suggested disclaimer for the project README and the main project web page:. ::. This project is participating in the LLVM Incubator process: as such, it is; not part of any official LLVM release. While incubation status is not; necessarily a reflection of the completeness or stability of the code, it; does indicate that the project is not yet endorsed as a component of LLVM. .. _copyright-license-patents:. Copyright, License, and Patents; ===============================. .. note::. This section deals with legal matters but does not provide legal advice. We; are not lawyers --- please seek legal counsel from a licensed attorney. This section addresses the issues of copyright, license and patents for the LLVM; project. The copyright for the code is held by the contributors of; the code. The code is licensed under permissive `open source licensing terms`_,; namely the Apache-2.0 with LLVM-exception license, which includes a copyright; and `patent license`_. When you contribute code to the LLVM project, you; license it under these terms. In certain circumstances, code licensed under other licenses can be added; to the codeb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:61381,Deployability,release,released,61381,"; patent claims become licensed as a result of subsequent combinations of your; contribution with any other software. Note, however, that licensable patent; claims include those that you acquire in the future, as long as they read on; your original contribution as made at the original time. Once a patent claim; is subject to Apache's Grant of Patent License, it is licensed under the; terms of that Grant to the ASF and to recipients of any software distributed; by the ASF for any Apache software product whatsoever. .. _legacy:. Legacy License Structure; ------------------------. .. note::; The code base was previously licensed under the Terms described here.; We are in the middle of relicensing to a new approach (described above), but; until this effort is complete, the code is also still available under these; terms. Once we finish the relicensing project, new versions of the code will; not be available under these terms. However, nothing takes away your right; to use old versions under the licensing terms under which they were; originally released. We intend to keep LLVM perpetually open source and to use a permissive open; source license. The code in; LLVM is available under the `University of Illinois/NCSA Open Source License; <http://www.opensource.org/licenses/UoI-NCSA.php>`_, which boils down to; this:. * You can freely distribute LLVM.; * You must retain the copyright notice if you redistribute LLVM.; * Binaries derived from LLVM must reproduce the copyright notice (e.g. in an; included README file).; * You can't use our names to promote your LLVM derived products.; * There's no warranty on LLVM at all. We believe this fosters the widest adoption of LLVM because it **allows; commercial products to be derived from LLVM** with few restrictions and without; a requirement for making any derived works also open source (i.e. LLVM's; license is not a ""copyleft"" license like the GPL). We suggest that you read the; `License <http://www.opensource.org/licenses/UoI-NCSA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1584,Energy Efficiency,efficient,efficient,1584,"contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. Yo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3015,Energy Efficiency,monitor,monitor,3015,"le; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. You can also subscribe to the ""commits"" mailing list for a subproject you're interested in,; such as `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_, `cfe-commits; <http://lists.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9971,Energy Efficiency,reduce,reduced,9971," the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19378,Energy Efficiency,green,green,19378,"ions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28858,Energy Efficiency,reduce,reduces,28858,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41558,Energy Efficiency,adapt,adapted,41558," via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1484,Integrability,rout,routinely,1484,"contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. Yo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12855,Integrability,depend,depends,12855,"aking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14465,Integrability,message,messages,14465," should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14797,Integrability,message,messages,14797,"performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14815,Integrability,message,messages,14815,"regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14889,Integrability,message,messages,14889," `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; auth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15122,Integrability,message,message,15122," bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15554,Integrability,message,message,15554,"ommits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15593,Integrability,message,message,15593,"e; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17862,Integrability,message,message,17862,"d be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is norm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:18111,Integrability,message,message,18111,"ist. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21170,Integrability,message,message,21170,"or themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21697,Integrability,depend,dependencies,21697,"vert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the au",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22839,Integrability,message,message,22839,"is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25033,Integrability,message,message,25033,"so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25717,Integrability,depend,depending,25717,"nt changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; together well and are as consistent as possible. If you plan to make a major; change to the way LLVM works or want to add a major new",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:27655,Integrability,rout,routinely,27655," major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the design of the new feature is finalized, the work itself should be done; as a series of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline merged into them periodically. If the branch; development and mainline development occur in the same pieces of code,; resolving merge conflicts can take a lot of time. #. Other people in the community tend to ignore work on branches. #. Huge changes (produced when a branch is merged back onto mainline) are; extremely difficult to `code review`_. #. Branches are not routinely tested by our nightly tester infrastructure. #. Changes developed as monolithic large changes often don't work until the; entire set of changes is done. Breaking it down into a set of smaller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30365,Integrability,message,messages,30365,"tion of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:31197,Integrability,message,message,31197,"level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32788,Integrability,interface,interface,32788,"ed in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32840,Integrability,wrap,wraps,32840,"ed in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:35897,Integrability,integrat,integration,35897,"nsition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:37082,Integrability,message,message,37082,"ations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infrastructure Working Group <mailto:iwg@llvm.org>`_. .. _new-llvm-components:. Introducing New Components into LLVM; ====================================. The LLVM community is a vibrant and exciting place to be, and we look to be; inclusive of new projects and foster new communities, and increase; collaboration across industry and academia. That said, we need to strike a balance between being inclusive of new ideas and; peopl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:38268,Integrability,depend,depending,38268,". * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond or fix the worker, please escalate; to Galina Kostanova, the maintainer of the BuildBot master.; * 3rd step: If Galina could not help you, please escalate to the; `Infrastructure Working Group <mailto:iwg@llvm.org>`_. .. _new-llvm-components:. Introducing New Components into LLVM; ====================================. The LLVM community is a vibrant and exciting place to be, and we look to be; inclusive of new projects and foster new communities, and increase; collaboration across industry and academia. That said, we need to strike a balance between being inclusive of new ideas and; people and the cost of ongoing maintenance that new code requires. As such, we; have a general :doc:`support policy<SupportPolicy>` for introducing major new; components into the LLVM world, depending on the degree of detail and; responsibility required. *Core* projects need a higher degree of scrutiny; than *peripheral* projects, and the latter may have additional differences. However, this is really only intended to cover common cases; that we have seen arise: different situations are different, and we are open; to discussing unusual cases as well - just start an RFC thread on the; `LLVM Discourse forums`_. Adding a New Target; -------------------. LLVM is very receptive to new targets, even experimental ones, but a number of; problems can appear when adding new large portions of code, and back-ends are; normally added in bulk. New targets need the same level of support as other; *core* parts of the compiler, so they are covered in the *core tier* of our; :doc:`support policy<SupportPolicy>`. We have found that landing large pieces of new code and then trying to fix; emergent problems in-tree is problematic for a variety of reasons. For the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:46350,Integrability,depend,dependencies,46350,"y; allow atomic commits to the project, simplify CI, and make it easier for; subcommunities to collaborate. Like new targets, most projects already in the monorepo are considered to be in; the *core tier* of our :doc:`support policy<SupportPolicy>`. The burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, including established; code owners.; * Should have reasonable documentation about how it works, including a high; quality README file.; * Should have CI to catch breakage within the project itself or due to; underlying LLVM dependencies.; * Should have code free of issues the community finds contentious, or be on a; clear path to resolving them.; * Must be proposed through the LLVM RFC process, and have its addition approved; by the LLVM community - this ultimately mediates the resolution of the; ""should"" concerns above. If you have a project that you think would make sense to add to the LLVM; monorepo, please start an RFC topic on the `LLVM Discourse forums`_ to kick off; the discussion. This process can take some time and iteration - please dont; be discouraged or intimidated by that!. If you have an earlier stage project that you think is aligned with LLVM, please; see the ""Incubating New Projects"" section. Incubating New Projects; -----------------------. The burden to add a new project to the LLVM monorepo is intentionally very high,; but that can have a chilling effect on new and innovative projects. To help; foster these sorts of projects, LLVM supports an ""in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:46596,Integrability,mediat,mediates,46596,"he burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, including established; code owners.; * Should have reasonable documentation about how it works, including a high; quality README file.; * Should have CI to catch breakage within the project itself or due to; underlying LLVM dependencies.; * Should have code free of issues the community finds contentious, or be on a; clear path to resolving them.; * Must be proposed through the LLVM RFC process, and have its addition approved; by the LLVM community - this ultimately mediates the resolution of the; ""should"" concerns above. If you have a project that you think would make sense to add to the LLVM; monorepo, please start an RFC topic on the `LLVM Discourse forums`_ to kick off; the discussion. This process can take some time and iteration - please dont; be discouraged or intimidated by that!. If you have an earlier stage project that you think is aligned with LLVM, please; see the ""Incubating New Projects"" section. Incubating New Projects; -----------------------. The burden to add a new project to the LLVM monorepo is intentionally very high,; but that can have a chilling effect on new and innovative projects. To help; foster these sorts of projects, LLVM supports an ""incubator"" process that is; much easier to get started with. It provides space for potentially valuable,; new top-level and sub-projects to reach a critical mass before they have enough; code to prove their utility and grow a community. This also allows",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:48863,Integrability,mediat,mediates,48863,"oject to advance; compilers, languages, tools, runtimes, etc.; * Must conform to the license, patent, and code of conduct policies laid out; in this developer policy document.; * Must have a documented charter and development plan, e.g. in the form of a; README file, mission statement, and/or manifesto.; * Should conform to coding standards, incremental development process, and; other expectations.; * Should have a sense of the community that it hopes to eventually foster, and; there should be interest from members with different affiliations /; organizations.; * Should have a feasible path to eventually graduate as a dedicated top-level; or sub-project within the `LLVM monorepo; <https://github.com/llvm/llvm-project>`_.; * Should include a notice (e.g. in the project README or web page) that the; project is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:49231,Integrability,depend,dependencies,49231," foster, and; there should be interest from members with different affiliations /; organizations.; * Should have a feasible path to eventually graduate as a dedicated top-level; or sub-project within the `LLVM monorepo; <https://github.com/llvm/llvm-project>`_.; * Should include a notice (e.g. in the project README or web page) that the; project is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it is always; safe to ask on the `LLVM Discourse forums`_ about this. Suggested disclaimer for the project README and the main project web page:. ::. This project is participating in the LLVM Incubator process: as such, it is; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:49626,Integrability,integrat,integration,49626,"oject is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it is always; safe to ask on the `LLVM Discourse forums`_ about this. Suggested disclaimer for the project README and the main project web page:. ::. This project is participating in the LLVM Incubator process: as such, it is; not part of any official LLVM release. While incubation status is not; necessarily a reflection of the completeness or stability of the code, it; does indicate that the project is not yet endorsed as a component of LLVM. .. _copyright-license-patents:. Copyright, License, and Patents; ===============================. .. note::. This section",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3349,Modifiability,enhance,enhancements,3349,"tHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. You can also subscribe to the ""commits"" mailing list for a subproject you're interested in,; such as `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_, `cfe-commits; <http://lists.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33645,Modifiability,maintainab,maintainability,33645,"The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36073,Modifiability,config,configurations,36073,"is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36163,Modifiability,config,configured,36163,"don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36559,Modifiability,config,configuration,36559,"ate the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:40579,Modifiability,refactor,refactoring,40579,"hat only appear when the; experimental target is enabled, caused by changes unrelated to the target, are; the responsibility of the community behind the target to fix. The basic rules for a back-end to be upstreamed in **experimental** mode are:. * Every target must have a :ref:`code owner<code owners>`. The `CODE_OWNERS.TXT`; file has to be updated as part of the first merge. The code owner makes sure; that changes to the target get reviewed and steers the overall effort. * There must be an active community behind the target. This community; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41558,Modifiability,adapt,adapted,41558," via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41999,Modifiability,config,configuration,41999,") or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:54134,Modifiability,rewrite,rewrite,54134,"ome contributions were not submitted to LLVM due to concerns that; the patent grant required by the project was overly broad.; * The patent grant was unique to the LLVM Project, not written by a lawyer, and; was difficult to determine what protection was provided (if any). The scope of relicensing is all code that is considered part of the LLVM; project, including the main LLVM repository, runtime libraries (compiler_rt,; OpenMP, etc), Polly, and all other subprojects. There are a few exceptions:. * Code imported from other projects (e.g. Google Test, Autoconf, etc) will; remain as it is. This code isn't developed as part of the LLVM project, it; is used by LLVM.; * Some subprojects are impractical or uninteresting to relicense (e.g. llvm-gcc; and dragonegg). These will be split off from the LLVM project (e.g. to; separate GitHub projects), allowing interested people to continue their; development elsewhere. To relicense LLVM, we will be seeking approval from all of the copyright holders; of code in the repository, or potentially remove/rewrite code if we cannot.; This is a large; and challenging project which will take a significant amount of time to; complete. In the interim, **all contributions to the project will be made under; the terms of both the new license and the legacy license scheme** (each of which; is described below). The exception to this is the legacy patent grant, which; will not be required for new contributions. When all of the code in the project has been converted to the new license or; removed, we will drop the requirement to contribute under the legacy license.; This will achieve the goal of having; a single standardized license for the entire codebase. If you are a prior contributor to LLVM and have not done so already, please do; *TODO* to allow us to use your code. *Add a link to a separate page here, which; is probably a click through web form or something like that. Details to be; determined later*. .. _open source licensing terms:. New ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:5731,Performance,perform,performing,5731,"olicy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10718,Performance,perform,performance,10718," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:11544,Performance,optimiz,optimizations,11544,"(e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at le",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12271,Performance,perform,performing,12271,"ant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13647,Performance,perform,performance,13647,"xes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13706,Performance,perform,performance,13706," must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13797,Performance,perform,performance,13797,"vm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:16561,Performance,optimiz,optimization,16561,"nto title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-chang",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:31830,Performance,load,loading,31830,"ne sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ AP",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:45175,Performance,optimiz,optimizer,45175," show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are great because they; allow atomic commits to the project, simplify CI, and make it easier for; subcommunities to collaborate. Like new targets, most projects already in the monorepo are considered to be in; the *core tier* of our :doc:`support policy<SupportPolicy>`. The burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15251,Safety,avoid,avoid,15251,"eck the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-tog",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:26229,Safety,avoid,avoid,26229,"e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; together well and are as consistent as possible. If you plan to make a major; change to the way LLVM works or want to add a major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the design of the new feature is finalized, the work itself should be done; as a series of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:32397,Safety,safe,safe,32397,"that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34634,Safety,avoid,avoid,34634,"for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new feature",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:50085,Safety,safe,safe,50085,"ss; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it is always; safe to ask on the `LLVM Discourse forums`_ about this. Suggested disclaimer for the project README and the main project web page:. ::. This project is participating in the LLVM Incubator process: as such, it is; not part of any official LLVM release. While incubation status is not; necessarily a reflection of the completeness or stability of the code, it; does indicate that the project is not yet endorsed as a component of LLVM. .. _copyright-license-patents:. Copyright, License, and Patents; ===============================. .. note::. This section deals with legal matters but does not provide legal advice. We; are not lawyers --- please seek legal counsel from a licensed attorney. This section addresses the issues of copyright, license and patents for the LLVM; project. The copyright for the code is held by the contributors of; the code. The code is licensed under permissive `open source licensing terms`_,; namely the Apache-2.0 with LLVM-exception license, which includes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3639,Security,confidential,confidentiality,3639," in,; such as `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_, `cfe-commits; <http://lists.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:4541,Security,confidential,confidentiality,4541,"LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .. _code review:. Code Reviews; ------------. LLVM has a code-review policy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17352,Security,hash,hash,17352,"ould be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22129,Security,access,access,22129,"eing reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23001,Security,access,access,23001," reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to requi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23106,Security,access,access,23106,"have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediatel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23249,Security,access,access,23249,"ve about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23530,Security,access,access,23530,"ion point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23564,Security,access,access,23564,"If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples inclu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:23631,Security,access,access,23631,"If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples inclu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24191,Security,access,access,24191,"GitHub username. This is true; for former contributors with SVN access as well as new contributors. If; approved, a GitHub invitation will be sent to your GitHub account. In case you; don't get notification from GitHub, go to; `Invitation Link <https://github.com/orgs/llvm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25588,Security,access,access,25588,"ct you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with a post to the `LLVM Discourse forums`_, to the extent; possible. The reason for this is to:. #. keep the community informed about future changes to LLVM,. #. avoid duplication of effort by preventing multiple parties working on the; same thing and not knowing about it, and. #. ensure that any technical issues around the proposed work are discussed and; resolved before any significant work is done. The design of LLVM is carefully controlled to ensure that all the pieces fit; toge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:29723,Security,access,access,29723,"hange should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30567,Security,authoriz,authorized,30567,"t making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30646,Security,authoriz,authorized,30646,"t making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41075,Security,validat,validate,41075,"; will help maintain the target by providing buildbots, fixing; bugs, answering the LLVM community's questions and making sure the new; target doesn't break any of the other targets, or generic code. This; behavior is expected to continue throughout the lifetime of the; target's code. * The code must be free of contentious issues, for example, large; changes in how the IR behaves or should be formed by the front-ends,; unless agreed by the majority of the community via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:43495,Security,expose,expose,43495,"d policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchron",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6027,Testability,test,testing,6027,"s and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9477,Testability,test,testcase,9477,"bility of a code owner is to ensure that a commit to their area of the; code is appropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9546,Testability,test,test,9546,"ppropriately reviewed, either by themself or by someone else. The list; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9632,Testability,test,testcase,9632,"; of current code owners can be found in the file `CODE_OWNERS.TXT; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9681,Testability,test,test,9681,"T; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9716,Testability,test,test,9716,"T; <https://github.com/llvm/llvm-project/blob/main/llvm/CODE_OWNERS.TXT>`_ in the; root of the LLVM source tree. Note that code ownership is completely different than reviewers: anyone can; review a piece of code, and we welcome code review from anyone who is; interested. Code owners are the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10111,Testability,test,test,10111,"hat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10145,Testability,test,test,10145,"hat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10404,Testability,test,test,10404,"cial policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10467,Testability,test,test,10467,"; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10482,Testability,test,test,10482,"; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10534,Testability,test,tests,10534,"; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10561,Testability,test,test,10561," any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10600,Testability,benchmark,benchmarks,10600,"tting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10648,Testability,test,test,10648,"tting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10655,Testability,test,test,10655,"tting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10676,Testability,test,test,10676," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10736,Testability,test,testing,10736," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10772,Testability,test,testing,10772," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12639,Testability,test,testcase,12639,"I.; * Notifying users about a potentially disruptive change expected to be made in; a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major perfo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12740,Testability,test,test,12740,"a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness reg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12747,Testability,test,test,12747,"a future release, such as removal of a deprecated feature. In this case, the; release note should be added to a ``Potentially Breaking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness reg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12829,Testability,test,test,12829,"aking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:12959,Testability,test,testing,12959,"aking Changes`` section of; the notes with sufficient information and examples to demonstrate the; potential disruption. Additionally, any new entries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13022,Testability,test,test,13022,"ries to this section should be; announced in the `Announcements <https://discourse.llvm.org/c/announce/>`_; channel on Discourse. See :ref:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13094,Testability,test,test,13094,"ef:`breaking` for more details. Code reviewers are encouraged to request a release note if they think one is; warranted when performing a code review. Quality; -------. The minimum quality standards that any change must satisfy before being; committed to the main development branch are:. #. Code must adhere to the `LLVM Coding Standards <CodingStandards.html>`_. #. Code must compile cleanly (no errors, no warnings) on at least one platform. #. Bug fixes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13604,Testability,test,test,13604,"xes and new features should `include a testcase`_ so we know if the; fix/feature ever regresses in the future. #. Code must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14110,Testability,test,test,14110,"ce code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14177,Testability,test,testing,14177,"rmation rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14277,Testability,test,testers,14277,"cient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14969,Testability,log,logs,14969," `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; auth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:16469,Testability,log,log,16469,"getInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19652,Testability,test,test,19652," healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best ju",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21522,Testability,test,test,21522,"ailable, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21589,Testability,test,test,21589," return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:21673,Testability,test,test,21673,"vert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the au",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:22294,Testability,test,test,22294,"stomary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following along; is critical.; * It is not considered reasonable to revert without at least the promise to; provide a means for the patch author to debug the root issue. If a situation; arises where a public reproducer can not be shared for some reason (e.g.; requires hardware patch author doesn't have access to, sharp regression in; compile time of internal workload, etc.), the reverter is expected to be; proactive about working with the patch author to debug and test candidate; patches.; * Reverts should be reasonably timely. A change submitted two hours ago; can be reverted without prior discussion. A change submitted two years ago; should not be. Where exactly the transition point is is hard to say, but; it's probably in the handful of days in tree territory. If you are unsure,; we encourage you to reply to the commit thread, give the author a bit to; respond, and then proceed with the revert if the author doesn't seem to be; actively responding.; * When re-applying a reverted patch, the commit message should be updated to; indicate the problem that was addressed and how it was addressed. Obtaining Commit Access; -----------------------. We grant commit access to contributors with a track record of submitting high; quality patches. If you would like commit access, please send an email to; `Chris <mailto:clattner@llvm.org>`_ with your GitHub username. This is true; for former contributors with SVN access as ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:27665,Testability,test,tested,27665," major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the design of the new feature is finalized, the work itself should be done; as a series of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline merged into them periodically. If the branch; development and mainline development occur in the same pieces of code,; resolving merge conflicts can take a lot of time. #. Other people in the community tend to ignore work on branches. #. Huge changes (produced when a branch is merged back onto mainline) are; extremely difficult to `code review`_. #. Branches are not routinely tested by our nightly tester infrastructure. #. Changes developed as monolithic large changes often don't work until the; entire set of changes is done. Breaking it down into a set of smaller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:27687,Testability,test,tester,27687," major new extension, it is a good; idea to get consensus with the development community before you start working on; it. Once the design of the new feature is finalized, the work itself should be done; as a series of `incremental changes`_, not as a long-term development branch. .. _incremental changes:. Incremental Development; -----------------------. In the LLVM project, we do all significant changes as a series of incremental; patches. We have a strong dislike for huge changes or long-term development; branches. Long-term development branches have a number of drawbacks:. #. Branches must have mainline merged into them periodically. If the branch; development and mainline development occur in the same pieces of code,; resolving merge conflicts can take a lot of time. #. Other people in the community tend to ignore work on branches. #. Huge changes (produced when a branch is merged back onto mainline) are; extremely difficult to `code review`_. #. Branches are not routinely tested by our nightly tester infrastructure. #. Changes developed as monolithic large changes often don't work until the; entire set of changes is done. Breaking it down into a set of smaller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28809,Testability,log,logical,28809,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:29356,Testability,log,logically,29356," that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:31761,Testability,test,test,31761,"ant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33346,Testability,test,tests,33346," dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the las",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36326,Testability,test,tested,36326,"ound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36394,Testability,test,testing,36394,"ound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:36521,Testability,test,test,36521,"ate the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working with the CI system; --------------------------. The main continuous integration (CI) tool for the LLVM project is the; `LLVM Buildbot <https://lab.llvm.org/buildbot/>`_. It uses different *builders*; to cover a wide variety of sub-projects and configurations. The builds are; executed on different *workers*. Builders and workers are configured and; provided by community members. The Buildbot tracks the commits on the main branch and the release branches.; This means that patches are built and tested after they are merged to the these; branches (aka post-merge testing). This also means it's okay to break the build; occasionally, as it's unreasonable to expect contributors to build and test; their patch with every possible configuration. *If your commit broke the build:*. * Fix the build as soon as possible as this might block other contributors or; downstream users.; * If you need more time to analyze and fix the bug, please revert your change to; unblock others. *If someone else broke the build and this blocks your work*. * Comment on the code review in `GitHub <https://github.com/llvm/llvm-project/pulls>`_; (if available) or email the author, explain the problem and how this impacts; you. Add a link to the broken build and the error message so folks can; understand the problem.; * Revert the commit if this blocks your work, see revert_policy_ . *If a build/worker is permanently broken*. * 1st step: contact the owner of the worker. You can find the name and contact; information for the *Admin* of worker on the page of the build in the; *Worker* tab:. .. image:: buildbot_worker_contact.png. * 2nd step: If the owner does not respond o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41759,Testability,test,test,41759," policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41815,Testability,test,tests,41815," policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41938,Testability,test,test-suite,41938,") or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:42213,Testability,test,tests,42213,"to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:42652,Testability,test,test,42652,"ode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal of the target from the code base. * Degradation in support, documentation or test coverage will make the target as; nuisance to other targets and be considered a candidate for deprecation and; ultimately removed. In essence, these rules are necessary for targets to gain and retain their; status, but also markers to define bit-rot, and will be used to clean up the; tree from unmaintained targets. Those wishing to add a new target to LLVM must follow the procedure below:. 1. Read this section and make sure your target follows all requirements. For; minor issues, your community will be responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:44189,Testability,test,tests,44189,"responsible for making all necessary; adjustments soon after the initial merge.; 2. Send a request for comment (RFC) to the `LLVM Discourse forums`_ describing; your target and how it follows all the requirements and what work has been; done and will need to be done to accommodate the official target requirements.; Make sure to expose any and all controversial issues, changes needed in the; base code, table gen, etc.; 3. Once the response is positive, the LLVM community can start reviewing the; actual patches (but they can be prepared before, to support the RFC). Create; a sequence of N patches, numbered '1/N' to 'N/N' (make sure N is an actual; number, not the letter 'N'), that completes the basic structure of the target.; 4. The initial patch should add documentation, code owners and triple support in; clang and LLVM. The following patches add TableGen infrastructure to describe; the target and lower instructions to assembly. The final patch must show that; the target can lower correctly with extensive LIT tests (IR to MIR, MIR to; ASM, etc).; 5. Some patches may be approved before others, but only after *all* patches are; approved that the whole set can be merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:427,Usability,clear,clear,427,"=====================; LLVM Developer Policy; =====================. .. contents::; :local:. Introduction; ============. This document contains the LLVM Developer Policy which defines the project's; policy towards developers and their contributions. The intent of this policy is; to eliminate miscommunication, rework, and confusion that might arise from the; distributed nature of LLVM's development. By stating the policy in clear terms,; we hope each developer can know ahead of time what to expect when making LLVM; contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what oth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:761,Usability,simpl,simple,761,"=====================; LLVM Developer Policy; =====================. .. contents::; :local:. Introduction; ============. This document contains the LLVM Developer Policy which defines the project's; policy towards developers and their contributions. The intent of this policy is; to eliminate miscommunication, rework, and confusion that might arise from the; distributed nature of LLVM's development. By stating the policy in clear terms,; we hope each developer can know ahead of time what to expect when making LLVM; contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what oth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6035,Usability,feedback,feedback,6035,"s and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6837,Usability,learn,learn,6837,"urpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:14932,Usability,guid,guidelines,14932," `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; auth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15010,Usability,guid,guidelines,15010,"andled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:15519,Usability,guid,guidelines,15519,"ommits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is welcome to re-commit the change after the problem has; been fixed. .. _commit messages:. Commit messages; ---------------. Although we don't enforce the format of commit messages, we prefer that; you follow these guidelines to help review, search in logs, email formatting; and so on. These guidelines are very similar to rules used by other open source; projects. Most importantly, the contents of the message should be carefully written to; convey the rationale of the change (without delving too much in detail). It; also should avoid being vague or overly specific. For example, ""bits were not; set right"" will leave the reviewer wondering about which bits, and why they; weren't right, while ""Correctly set overflow bits in TargetInfo"" conveys almost; all there is to the change. Below are some guidelines about the format of the message itself:. * Separate the commit message into title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:17404,Usability,simpl,simple,17404,"d upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-change>`__.; If the patch fixes a bug in GitHub Issues, we encourage adding a reference to; the issue being closed, as described; `here <https://llvm.org/docs/BugLifeCycle.html#resolving-closing-bugs>`__. * It is also acceptable to add other metadata to the commit message to automate; processes, including for downstream consumers. This metadata can include; links to resources that are not available to the entire community. However,; such links and/or metadata should not be used in place of making the commit; message self-explanatory. Note that such non-public links should not be; included in the submitted code. For minor violations of these recommendations, the community normally favors; reminding the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19280,Usability,learn,learn,19280," the contributor of this policy over reverting. Minor corrections and; omissions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19842,Usability,feedback,feedback,19842,"nge?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19883,Usability,feedback,feedback,19883,"nge?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:20250,Usability,guid,guidelines,20250,"wn change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:20867,Usability,guid,guidelines,20867,">`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms differ from others;; we generally consider reverting a normal part of development. We don't; expect contributors to be always available, and the assurance that a; problematic patch will be reverted and we can return to it at our next; opportunity enables this. What are the expectations around a revert?. * Use your best judgment. If you're uncertain, please start an email on; the commit thread asking for assistance. We aren't trying to enumerate; every case, but rather give a set of guidelines.; * You should be sure that reverting the change improves the stability of tip; of tree. Sometimes reverting one change in a series can worsen things; instead of improving them. We expect reasonable judgment to ensure that; the proper patch or set of patches is being reverted.; * The commit message for the reverting commit should explain why patch; is being reverted.; * It is customary to respond to the original commit email mentioning the; revert. This serves as both a notice to the original author that their; patch was reverted, and helps others following llvm-commits track context.; * Ideally, you should have a publicly reproducible test case ready to share.; Where possible, we encourage sharing of test cases in commit threads, or; in PRs. We encourage the reverter to minimize the test case and to prune; dependencies where practical. This even applies when reverting your own; patch; documenting the reasons for others who might be following alo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24506,Usability,clear,clearly,24506,"ior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24543,Usability,simpl,simply,24543,"ior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:25048,Usability,clear,clearly,25048,"so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subject to `code review`_ (either before or; after they are committed, depending on the nature of the change). You are; encouraged to review other peoples' patches as well, but you aren't required; to do so. .. _discuss the change/gather consensus:. Making a Major Change; ---------------------. When a developer begins a major new project with the aim of contributing it back; to LLVM, they should inform the community with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28779,Usability,simpl,simplifies,28779,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28831,Usability,simpl,simplifies,28831,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28905,Usability,feedback,feedback,28905,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:30323,Usability,simpl,simple,30323,"tion of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is important to retain; correct attribution of contributions to their contributors. However, we do not; want the source code to be littered with random attributions ""this code written; by J. Random Hacker"" (this is noisy and distracting). In practice, the revision; control system keeps a perfect history of who changed what, and the CREDITS.txt; file describes higher-level contributions. If you commit a patch for someone; else, please follow the attribution of changes in the simple manner as outlined; by the `commit messages`_ section. Overall, please do not add contributor names; to the source code. Also, don't commit patches authored by others unless they have submitted the; patch to the project or you have been authorized to submit them on their behalf; (you work together and your company authorized you to contribute the patches,; etc.). The author should first submit them to the relevant project's commit; list, development list, or LLVM bug tracker component. If someone sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33661,Usability,feedback,feedback,33661,"The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:33802,Usability,clear,clear,33802,"ce and the; stability of the C++ API that it wraps. In practice, this means that things; like ""create debug info"" or ""create this type of instruction"" are likely to be; less stable than ""take this IR file and JIT it for my current machine"". * Release stability: We won't break the C API on the release branch with patches; that go on that branch, with the exception that we will fix an unintentional; C API break that will keep the release consistent with both the previous and; next release. * Testing: Patches to the C API are expected to come with tests just like any; other patch. * Including new things into the API: If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34374,Usability,guid,guideline,34374,": If an LLVM subcomponent has a C API already; included, then expanding that C API is acceptable. Adding C API for; subcomponents that don't currently have one needs to be discussed on the; `LLVM Discourse forums`_ for design and maintainability feedback prior to implementation. * Documentation: Any changes to the C API are required to be documented in the; release notes so that it's clear to external users who do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:34892,Usability,guid,guide,34892," do not follow the; project how the C API is changing and evolving. .. _toolchain:. Updating Toolchain Requirements; -------------------------------. We intend to require newer toolchains as time goes by. This means LLVM's; codebase can use newer versions of C++ as they get standardized. Requiring newer; toolchains to build LLVM can be painful for those building LLVM; therefore, it; will only be done through the following process:. * It is a general goal to support LLVM and GCC versions from the last 3 years; at a minimum. This time-based guideline is not strict: we may support much; older compilers, or decide to support fewer versions. * An RFC is sent to the `LLVM Discourse forums`_. - Detail upsides of the version increase (e.g. which newer C++ language or; library features LLVM should use; avoid miscompiles in particular compiler; versions, etc).; - Detail downsides on important platforms (e.g. Ubuntu LTS status). * Once the RFC reaches consensus, update the CMake toolchain version checks as; well as the :doc:`getting started<GettingStarted>` guide. This provides a; softer transition path for developers compiling LLVM, because the; error can be turned into a warning using a CMake flag. This is an important; step: LLVM still doesn't have code which requires the new toolchains, but it; soon will. If you compile LLVM but don't read the forums, we should; tell you!. * Ensure that at least one LLVM release has had this soft-error. Not all; developers compile LLVM top-of-tree. These release-bound developers should; also be told about upcoming changes. * Turn the soft-error into a hard-error after said LLVM release has branched. * Update the :doc:`coding standards<CodingStandards>` to allow the new; features we've explicitly approved in the RFC. * Start using the new features in LLVM's codebase. Here's a `sample RFC; <https://discourse.llvm.org/t/rfc-migrating-past-c-11/50943>`_ and the; `corresponding change <https://reviews.llvm.org/D57264>`_. .. _ci-usage:. Working ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:45351,Usability,simpl,simplify,45351,"merged in one go. This is to guarantee; that all changes are good as a single block.; 6. After the initial merge, the target community can stop numbering patches and; start working asynchronously on the target to complete support. They should; still seek review from those who helped them in the initial phase, to make; sure the progress is still consistent.; 7. Once all official requirements have been fulfilled (as above), the code owner; should request the target to be enabled by default by sending another RFC to; the `LLVM Discourse forums`_. Adding an Established Project To the LLVM Monorepo; --------------------------------------------------. The `LLVM monorepo <https://github.com/llvm/llvm-project>`_ is the centerpoint; of development in the LLVM world, and has all of the primary LLVM components,; including the LLVM optimizer and code generators, Clang, LLDB, etc. `Monorepos; in general <https://en.wikipedia.org/wiki/Monorepo>`_ are great because they; allow atomic commits to the project, simplify CI, and make it easier for; subcommunities to collaborate. Like new targets, most projects already in the monorepo are considered to be in; the *core tier* of our :doc:`support policy<SupportPolicy>`. The burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, including established; code owners.; * Should have reasonable documentation about how it works, including a high; quality README file.; * Should have CI to catch breakage within the project itself or due to; underlying",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:46444,Usability,clear,clear,46444," Like new targets, most projects already in the monorepo are considered to be in; the *core tier* of our :doc:`support policy<SupportPolicy>`. The burden to add; things to the LLVM monorepo needs to be very high - code that is added to this; repository is checked out by everyone in the community. As such, we hold; components to a high bar similar to ""official targets"", they:. * Must be generally aligned with the mission of the LLVM project to advance; compilers, languages, tools, runtimes, etc.; * Must conform to all of the policies laid out in this developer policy; document, including license, patent, coding standards, and code of conduct.; * Must have an active community that maintains the code, including established; code owners.; * Should have reasonable documentation about how it works, including a high; quality README file.; * Should have CI to catch breakage within the project itself or due to; underlying LLVM dependencies.; * Should have code free of issues the community finds contentious, or be on a; clear path to resolving them.; * Must be proposed through the LLVM RFC process, and have its addition approved; by the LLVM community - this ultimately mediates the resolution of the; ""should"" concerns above. If you have a project that you think would make sense to add to the LLVM; monorepo, please start an RFC topic on the `LLVM Discourse forums`_ to kick off; the discussion. This process can take some time and iteration - please dont; be discouraged or intimidated by that!. If you have an earlier stage project that you think is aligned with LLVM, please; see the ""Incubating New Projects"" section. Incubating New Projects; -----------------------. The burden to add a new project to the LLVM monorepo is intentionally very high,; but that can have a chilling effect on new and innovative projects. To help; foster these sorts of projects, LLVM supports an ""incubator"" process that is; much easier to get started with. It provides space for potentially valuable,; ne",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:49128,Usability,guid,guidelines,49128,"form of a; README file, mission statement, and/or manifesto.; * Should conform to coding standards, incremental development process, and; other expectations.; * Should have a sense of the community that it hopes to eventually foster, and; there should be interest from members with different affiliations /; organizations.; * Should have a feasible path to eventually graduate as a dedicated top-level; or sub-project within the `LLVM monorepo; <https://github.com/llvm/llvm-project>`_.; * Should include a notice (e.g. in the project README or web page) that the; project is in incubation status and is not included in LLVM releases (see; suggested wording below).; * Must be proposed through the LLVM RFC process, and have its addition; approved by the LLVM community - this ultimately mediates the resolution of; the ""should"" concerns above. That said, the project need not have any code to get started, and need not have; an established community at all! Furthermore, incubating projects may pass; through transient states that violate the ""Should"" guidelines above, or would; otherwise make them unsuitable for direct inclusion in the monorepo (e.g.; dependencies that have not yet been factored appropriately, leveraging; experimental components or APIs that are not yet upstream, etc). When approved, the llvm-admin group can grant the new project:; * A new repository in the LLVM Github Organization - but not the LLVM monorepo.; * New mailing list, discourse forum, and/or discord chat hosted with other LLVM; forums.; * Other infrastructure integration can be discussed on a case-by-case basis. Graduation to the mono-repo would follow existing processes and standards for; becoming a first-class part of the monorepo. Similarly, an incubating project; may be eventually retired, but no process has been established for that yet. If; and when this comes up, please start an RFC discussion on the `LLVM Discourse forums`_. This process is very new - please expect the details to change, it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:59147,Usability,guid,guidance,59147,"d users of the project. For more information about; the Apache 2.0 License, please see the `Apache License FAQ; <http://www.apache.org/foundation/license-faq.html>`_, maintained by the; Apache Project. .. _patent license:. Patents; -------. Section 3 of the Apache 2.0 license is a patent grant under which; contributors of code to the project contribute the rights to use any of; their patents that would otherwise be infringed by that code contribution; (protecting uses of that code). Further, the patent grant is revoked; from anyone who files a patent lawsuit about code in LLVM - this protects the; community by providing a ""patent commons"" for the code base and reducing the; odds of patent lawsuits in general. The license specifically scopes which patents are included with code; contributions. To help explain this, the `Apache License FAQ; <http://www.apache.org/foundation/license-faq.html>`_ explains this scope using; some questions and answers, which we reproduce here for your convenience (for; reference, the ""ASF"" is the Apache Software Foundation, the guidance still; holds though)::. Q1: If I own a patent and contribute to a Work, and, at the time my; contribution is included in that Work, none of my patent's claims are subject; to Apache's Grant of Patent License, is there a way any of those claims would; later become subject to the Grant of Patent License solely due to subsequent; contributions by other parties who are not licensees of that patent. A1: No. Q2: If at any time after my contribution, I am able to license other patent; claims that would have been subject to Apache's Grant of Patent License if; they were licensable by me at the time of my contribution, do those other; claims become subject to the Grant of Patent License?. A2: Yes. Q3: If I own or control a licensable patent and contribute code to a specific; Apache product, which of my patent claims are subject to Apache's Grant of; Patent License?. A3: The only patent claims that are licensed to th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:748,Deployability,release,release,748,"=================================; User Guide for the DirectX Target; =================================. .. warning::; Disclaimer: The DirectX backend is experimental and under active development.; It is not yet feature complete or ready to be used outside of experimental or; demonstration contexts. .. contents::; :local:. .. toctree::; :hidden:. Introduction; ============. The DirectX target implements the DirectX programmability interfaces. These; interfaces are documented in the `DirectX Specifications. <https://github.com/Microsoft/DirectX-Specs>`_. Initially the backend is aimed at supporting DirectX 12, and support for DirectX; 11 is planned at a later date. The DirectX backend is currently experimental and is not shipped with any; release builds of LLVM tools. To enable building the DirectX backend locally add; ``DirectX`` to the ``LLVM_EXPERIMENTAL_TARGETS_TO_BUILD`` CMake option. For more; information on building LLVM see the :doc:`CMake` documentation. .. _dx-target-triples:. Target Triples; ==============. At present the DirectX target only supports the ``dxil`` architecture, which; generates code for the; `DirectX Intermediate Language. <https://github.com/microsoft/DirectXShaderCompiler/blob/main/docs/DXIL.rst>`_. In addition to target architecture, the DirectX backend also needs to know the; target runtime version and pipeline stage. These are expressed using the OS and; Environment triple component. Presently the DirectX backend requires targeting the ``shadermodel`` OS, and; supports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``librar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:1354,Deployability,pipeline,pipeline,1354,"tents::; :local:. .. toctree::; :hidden:. Introduction; ============. The DirectX target implements the DirectX programmability interfaces. These; interfaces are documented in the `DirectX Specifications. <https://github.com/Microsoft/DirectX-Specs>`_. Initially the backend is aimed at supporting DirectX 12, and support for DirectX; 11 is planned at a later date. The DirectX backend is currently experimental and is not shipped with any; release builds of LLVM tools. To enable building the DirectX backend locally add; ``DirectX`` to the ``LLVM_EXPERIMENTAL_TARGETS_TO_BUILD`` CMake option. For more; information on building LLVM see the :doc:`CMake` documentation. .. _dx-target-triples:. Target Triples; ==============. At present the DirectX target only supports the ``dxil`` architecture, which; generates code for the; `DirectX Intermediate Language. <https://github.com/microsoft/DirectXShaderCompiler/blob/main/docs/DXIL.rst>`_. In addition to target architecture, the DirectX backend also needs to know the; target runtime version and pipeline stage. These are expressed using the OS and; Environment triple component. Presently the DirectX backend requires targeting the ``shadermodel`` OS, and; supports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``library`` Linkable ``dxil`` library; ``raygeneration`` Ray generation (ray tracing); ``intersection`` Ray intersection (ray tracing); ``anyhit`` Ray any collision (ray tracing); ``closesthit`` Ray closest collision (ray tracing); ``miss`` Ray miss (ray tracing); ``callable`` Callable shader (ray tracing); ``mesh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:435,Integrability,interface,interfaces,435,"=================================; User Guide for the DirectX Target; =================================. .. warning::; Disclaimer: The DirectX backend is experimental and under active development.; It is not yet feature complete or ready to be used outside of experimental or; demonstration contexts. .. contents::; :local:. .. toctree::; :hidden:. Introduction; ============. The DirectX target implements the DirectX programmability interfaces. These; interfaces are documented in the `DirectX Specifications. <https://github.com/Microsoft/DirectX-Specs>`_. Initially the backend is aimed at supporting DirectX 12, and support for DirectX; 11 is planned at a later date. The DirectX backend is currently experimental and is not shipped with any; release builds of LLVM tools. To enable building the DirectX backend locally add; ``DirectX`` to the ``LLVM_EXPERIMENTAL_TARGETS_TO_BUILD`` CMake option. For more; information on building LLVM see the :doc:`CMake` documentation. .. _dx-target-triples:. Target Triples; ==============. At present the DirectX target only supports the ``dxil`` architecture, which; generates code for the; `DirectX Intermediate Language. <https://github.com/microsoft/DirectXShaderCompiler/blob/main/docs/DXIL.rst>`_. In addition to target architecture, the DirectX backend also needs to know the; target runtime version and pipeline stage. These are expressed using the OS and; Environment triple component. Presently the DirectX backend requires targeting the ``shadermodel`` OS, and; supports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``librar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:454,Integrability,interface,interfaces,454,"=================================; User Guide for the DirectX Target; =================================. .. warning::; Disclaimer: The DirectX backend is experimental and under active development.; It is not yet feature complete or ready to be used outside of experimental or; demonstration contexts. .. contents::; :local:. .. toctree::; :hidden:. Introduction; ============. The DirectX target implements the DirectX programmability interfaces. These; interfaces are documented in the `DirectX Specifications. <https://github.com/Microsoft/DirectX-Specs>`_. Initially the backend is aimed at supporting DirectX 12, and support for DirectX; 11 is planned at a later date. The DirectX backend is currently experimental and is not shipped with any; release builds of LLVM tools. To enable building the DirectX backend locally add; ``DirectX`` to the ``LLVM_EXPERIMENTAL_TARGETS_TO_BUILD`` CMake option. For more; information on building LLVM see the :doc:`CMake` documentation. .. _dx-target-triples:. Target Triples; ==============. At present the DirectX target only supports the ``dxil`` architecture, which; generates code for the; `DirectX Intermediate Language. <https://github.com/microsoft/DirectXShaderCompiler/blob/main/docs/DXIL.rst>`_. In addition to target architecture, the DirectX backend also needs to know the; target runtime version and pipeline stage. These are expressed using the OS and; Environment triple component. Presently the DirectX backend requires targeting the ``shadermodel`` OS, and; supports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``librar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst:3321,Testability,test,testing,3321,"ports versions 6.0+ (at time of writing the latest announced version is 6.7). .. table:: DirectX Environments. ================== ========================================================; Environment Description; ================== ========================================================; ``pixel`` Pixel shader; ``vertex`` Vertex shader; ``geometry`` Geometry shader; ``hull`` Hull shader (tesselation); ``domain`` Domain shader (tesselation); ``compute`` Compute kernel; ``library`` Linkable ``dxil`` library; ``raygeneration`` Ray generation (ray tracing); ``intersection`` Ray intersection (ray tracing); ``anyhit`` Ray any collision (ray tracing); ``closesthit`` Ray closest collision (ray tracing); ``miss`` Ray miss (ray tracing); ``callable`` Callable shader (ray tracing); ``mesh`` Mesh shader; ``amplification`` Amplification shader; ================== ========================================================. Output Binaries; ===============. The DirectX runtime APIs read a file format based on the; `DirectX Specification. <https://github.com/Microsoft/DirectX-Specs>`_. In; different codebases the file format is referred to by different names; (specifically ``DXBC`` and ``DXILContainer``). Since the format is used to store; both ``DXBC`` and ``DXIL`` outputs, and the ultimate goal is to support both as; code generation targets in LLVM, the LLVM codebase uses a more neutral name,; ``DXContainer``. The ``DXContainer`` format is sparsely documented in the functional; specification, but a reference implementation exists in the; `DirectXShaderCompiler. <https://github.com/microsoft/DirectXShaderCompiler>`_. Support for generating ``DXContainer`` files in LLVM, is being added to the LLVM; MC layer for object streamers and writers, and to the Object and ObjectYAML; libraries for testing and object file tooling. For ``dxil`` targeting, bitcode emission into ``DXContainer`` files follows a; similar model to the ``-fembed-bitcode`` flag supported by clang for other; targets.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DirectXUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DirectXUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:2058,Availability,down,download,2058,"unning programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all; filesystem modifications, performed while building your image. When the build; process is finished, a diff between your image's final filesystem state and the; base image's filesystem is stored in the resulting image. Overview; ========; The ``llvm/utils/docker`` folder contains Dockerfiles and simple bash scripts to; serve as a basis for anyone who wants to create their own Docker image with; LLVM components, compiled from sources. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:1214,Deployability,release,releases,1214,"rces to build docker images with LLVM components in; ``llvm/utils/docker``. They can be used by anyone who wants to build the docker; images for their own use, or as a starting point for someone who wants to write; their own Dockerfiles. We currently provide Dockerfiles with ``debian10`` and ``nvidia-cuda`` base images.; We also provide an ``example`` image, which contains placeholders that one would need; to fill out in order to produce Dockerfiles for a new docker image. Why?; ----; Docker images provide a way to produce binary distributions of; software inside a controlled environment. Having Dockerfiles to builds docker images; inside LLVM repo makes them much more discoverable than putting them into any other; place. Docker basics; -------------; If you've never heard about Docker before, you might find this section helpful; to get a very basic explanation of it.; `Docker <https://www.docker.com/>`_ is a popular solution for running programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:1237,Deployability,deploy,deployed,1237,"rces to build docker images with LLVM components in; ``llvm/utils/docker``. They can be used by anyone who wants to build the docker; images for their own use, or as a starting point for someone who wants to write; their own Dockerfiles. We currently provide Dockerfiles with ``debian10`` and ``nvidia-cuda`` base images.; We also provide an ``example`` image, which contains placeholders that one would need; to fill out in order to produce Dockerfiles for a new docker image. Why?; ----; Docker images provide a way to produce binary distributions of; software inside a controlled environment. Having Dockerfiles to builds docker images; inside LLVM repo makes them much more discoverable than putting them into any other; place. Docker basics; -------------; If you've never heard about Docker before, you might find this section helpful; to get a very basic explanation of it.; `Docker <https://www.docker.com/>`_ is a popular solution for running programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:3851,Deployability,install,install-clang,3851," development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:3868,Deployability,install,install-clang-resource-headers,3868," development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4438,Deployability,install,install-clang,4438,"ery simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4462,Deployability,install,install-clang-resource-headers,4462,"ery simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4662,Deployability,install,install-clang,4662,"ery simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4676,Deployability,install,install-clang-resource-headers,4676,"ery simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5204,Deployability,install,installation,5204,"_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5273,Deployability,install,installation,5273,"ge2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5344,Deployability,install,installation,5344," 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5413,Deployability,install,installation,5413,"ang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker conta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5477,Deployability,install,installation,5477," \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5929,Deployability,install,installed,5929,"e; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:6724,Deployability,install,install,6724," that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7274,Deployability,install,install-clang,7274,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7291,Deployability,install,install-clang-resource-headers,7291,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7790,Deployability,install,installs,7790,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4201,Energy Efficiency,reduce,reduce,4201," the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:2890,Integrability,interface,interface,2890,"y contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all; filesystem modifications, performed while building your image. When the build; process is finished, a diff between your image's final filesystem state and the; base image's filesystem is stored in the resulting image. Overview; ========; The ``llvm/utils/docker`` folder contains Dockerfiles and simple bash scripts to; serve as a basis for anyone who wants to create their own Docker image with; LLVM components, compiled from sources. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DC",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:6768,Integrability,depend,dependencies,6768," that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7806,Integrability,depend,dependencies,7806,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:8123,Integrability,depend,dependencies,8123,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:2212,Performance,perform,performed,2212,"unning programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all; filesystem modifications, performed while building your image. When the build; process is finished, a diff between your image's final filesystem state and the; base image's filesystem is stored in the resulting image. Overview; ========; The ``llvm/utils/docker`` folder contains Dockerfiles and simple bash scripts to; serve as a basis for anyone who wants to create their own Docker image with; LLVM components, compiled from sources. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:5915,Security,access,access,5915,"e; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:6119,Security,access,access,6119,": posix; InstalledDir: /bin; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.8.4; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/bui",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:6392,Security,access,access,6392,"linux-gnu/4.9; Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9.2; Selected GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.9; Candidate multilib: .;@m64; Selected multilib: .;@m64. Which image should I choose?; ============================; We currently provide two images: Debian10-based and nvidia-cuda-based. They; differ in the base image that they use, i.e. they have a different set of; preinstalled binaries. Debian8 is very minimal, nvidia-cuda is larger, but has; preinstalled CUDA libraries and allows to access a GPU, installed on your; machine. If you need a minimal linux distribution with only clang and libstdc++ included,; you should try Debian10-based image. If you want to use CUDA libraries and have access to a GPU on your machine,; you should choose nvidia-cuda-based image and use `nvidia-docker; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7967,Security,access,accessible,7967,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:7986,Security,hash,hash,7986,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:8148,Security,access,accessible,8148,"r; <https://github.com/NVIDIA/nvidia-docker>`_ to run your docker containers. Note; that you don't need nvidia-docker to build the images, but you need it in order; to have an access to GPU from a docker container that is running the built; image. If you have a different use-case, you could create your own image based on; ``example/`` folder. Any docker image can be built and run using only the docker binary, i.e. you can; run debian10 build on Fedora or any other Linux distribution. You don't need to; install CMake, compilers or any other clang dependencies. It is all handled; during the build process inside Docker's isolated environment. Stable build; ============; If you want a somewhat recent and somewhat stable build, use the; ``branches/google/stable`` branch, i.e. the following command will produce a; Debian10-based image using the latest ``google/stable`` sources for you:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	-s debian10 --d clang-debian10 -t ""staging"" \; 	--branch branches/google/stable \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Minimizing docker image size; ============================; Due to how Docker's filesystem works, all intermediate writes are persisted in; the resulting image, even if they are removed in the following commands.; To minimize the resulting image size we use `multi-stage Docker builds; <https://docs.docker.com/develop/develop-images/multistage-build/>`_.; Internally Docker builds two images. The first image does all the work: installs; build dependencies, checks out LLVM source code, compiles LLVM, etc.; The first image is only used during build and does not have a descriptive name,; i.e. it is only accessible via the hash value after the build is finished.; The second image is our resulting image. It contains only the built binaries; and not any build dependencies. It is also accessible via a descriptive name; (specified by -d and -t flags).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:45,Usability,guid,guide,45,"=========================================; A guide to Dockerfiles for building LLVM; =========================================. Introduction; ============; You can find a number of sources to build docker images with LLVM components in; ``llvm/utils/docker``. They can be used by anyone who wants to build the docker; images for their own use, or as a starting point for someone who wants to write; their own Dockerfiles. We currently provide Dockerfiles with ``debian10`` and ``nvidia-cuda`` base images.; We also provide an ``example`` image, which contains placeholders that one would need; to fill out in order to produce Dockerfiles for a new docker image. Why?; ----; Docker images provide a way to produce binary distributions of; software inside a controlled environment. Having Dockerfiles to builds docker images; inside LLVM repo makes them much more discoverable than putting them into any other; place. Docker basics; -------------; If you've never heard about Docker before, you might find this section helpful; to get a very basic explanation of it.; `Docker <https://www.docker.com/>`_ is a popular solution for running programs in; an isolated and reproducible environment, especially to maintain releases for; software deployed to large distributed fleets.; It uses linux kernel namespaces and cgroups to provide a lightweight isolation; inside currently running linux kernel.; A single active instance of dockerized environment is called a *docker; container*.; A snapshot of a docker container filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:2482,Usability,simpl,simple,2482,"r filesystem is called a *docker image*.; One can start a container from a prebuilt docker image. Docker images are built from a so-called *Dockerfile*, a source file written in; a specialized language that defines instructions to be used when build; the docker image (see `official; documentation <https://docs.docker.com/engine/reference/builder/>`_ for more; details). A minimal Dockerfile typically contains a base image and a number; of RUN commands that have to be executed to build the image. When building a new; image, docker will first download your base image, mount its filesystem as; read-only and then add a writable overlay on top of it to keep track of all; filesystem modifications, performed while building your image. When the build; process is finished, a diff between your image's final filesystem state and the; base image's filesystem is stored in the resulting image. Overview; ========; The ``llvm/utils/docker`` folder contains Dockerfiles and simple bash scripts to; serve as a basis for anyone who wants to create their own Docker image with; LLVM components, compiled from sources. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:3570,Usability,simpl,simple,3570,"s. The sources are checked out from the; upstream git repository when building the image. The resulting image contains only the requested LLVM components and a few extra; packages to make the image minimally useful for C++ development, e.g. libstdc++; and binutils. The interface to run the build is ``build_docker_image.sh`` script. It accepts a; list of LLVM repositories to checkout and arguments for CMake invocation. If you want to write your own docker image, start with an ``example/`` subfolder.; It provides an incomplete Dockerfile with (very few) FIXMEs explaining the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Docker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:681,Availability,recover,recover,681,"==========================; Exception Handling in LLVM; ==========================. .. contents::; :local:. Introduction; ============. This document is the central repository for all information pertaining to; exception handling in LLVM. It describes the format that LLVM exception; handling information takes, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what exception handling information is used for in; C and C++. Itanium ABI Zero-cost Exception Handling; ----------------------------------------. Exception handling for most programming languages is designed to recover from; conditions that rarely occur during general use of an application. To that end,; exception handling should not interfere with the main flow of an application's; algorithm by performing checkpointing tasks, such as saving the current pc or; register state. The Itanium ABI Exception Handling Specification defines a methodology for; providing outlying data in the form of exception tables without inlining; speculative exception handling code in the flow of an application's main; algorithm. Thus, the specification is said to add ""zero-cost"" to the normal; execution of an application. A more complete description of the Itanium ABI exception handling runtime; support of can be found at `Itanium C++ ABI: Exception Handling; <http://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>`_. A description of the; exception frame format can be found at `Exception Frames; <http://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/ehframechpt.html>`_,; with details of the DWARF 4 specification at `DWARF 4 Standard; <http://dwarfstd.org/Dwarf4Std.php>`_. A description for the C++ exception; table formats can be found at `Exception Handling Tables; <http://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>`_. Setjmp/Longjmp Exception Handling; ---------------------------------. Setjmp/Lon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:880,Availability,checkpoint,checkpointing,880,"==========================; Exception Handling in LLVM; ==========================. .. contents::; :local:. Introduction; ============. This document is the central repository for all information pertaining to; exception handling in LLVM. It describes the format that LLVM exception; handling information takes, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what exception handling information is used for in; C and C++. Itanium ABI Zero-cost Exception Handling; ----------------------------------------. Exception handling for most programming languages is designed to recover from; conditions that rarely occur during general use of an application. To that end,; exception handling should not interfere with the main flow of an application's; algorithm by performing checkpointing tasks, such as saving the current pc or; register state. The Itanium ABI Exception Handling Specification defines a methodology for; providing outlying data in the form of exception tables without inlining; speculative exception handling code in the flow of an application's main; algorithm. Thus, the specification is said to add ""zero-cost"" to the normal; execution of an application. A more complete description of the Itanium ABI exception handling runtime; support of can be found at `Itanium C++ ABI: Exception Handling; <http://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>`_. A description of the; exception frame format can be found at `Exception Frames; <http://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/ehframechpt.html>`_,; with details of the DWARF 4 specification at `DWARF 4 Standard; <http://dwarfstd.org/Dwarf4Std.php>`_. A description for the C++ exception; table formats can be found at `Exception Handling Tables; <http://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>`_. Setjmp/Longjmp Exception Handling; ---------------------------------. Setjmp/Lon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:4365,Availability,error,error,4365,"te representation. It is not based on the; "":ref:`landingpad <i_landingpad>`"" instruction like the other two models, and is; described later in this document under :ref:`wineh`. Overview; --------. When an exception is thrown in LLVM code, the runtime does its best to find a; handler suited to processing the circumstance. The runtime first attempts to find an *exception frame* corresponding to the; function where the exception was thrown. If the programming language supports; exception handling (e.g. C++), the exception frame contains a reference to an; exception table describing how to process the exception. If the language does; not support exception handling (e.g. C), or if the exception needs to be; forwarded to a prior activation, the exception frame contains information about; how to unwind the current activation and restore the state of the prior; activation. This process is repeated until the exception is handled. If the; exception is not handled and no activations remain, then the application is; terminated with an appropriate error message. Because different programming languages have different behaviors when handling; exceptions, the exception handling ABI provides a mechanism for; supplying *personalities*. An exception handling personality is defined by; way of a *personality function* (e.g. ``__gxx_personality_v0`` in C++),; which receives the context of the exception, an *exception structure*; containing the exception object type and value, and a reference to the exception; table for the current function. The personality function for the current; compile unit is specified in a *common exception frame*. The organization of an exception table is language dependent. For C++, an; exception table is organized as a series of code ranges defining what to do if; an exception occurs in that range. Typically, the information associated with a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:6199,Availability,down,down,6199,"ith a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exception handling in terms of C++ examples. Throw; -----. Languages that support exception handling typically provide a ``throw``; operation to initiate the exception process. Internally, a ``throw`` operation; breaks down into two steps. #. A request is made to allocate exception space for an exception structure.; This structure needs to survive beyond the current activation. This structure; will contain the type and value of the object being thrown. #. A call is made to the runtime to raise the exception, passing the exception; structure as an argument. In C++, the allocation of the exception structure is done by the; ``__cxa_allocate_exception`` runtime function. The exception raising is handled; by ``__cxa_throw``. The type of the exception is represented using a C++ RTTI; structure. Try/Catch; ---------. A call within the scope of a *try* statement can potentially raise an; exception. In those circumstances, the LLVM C++ front-end replaces the call with; an ``invoke`` instruction. Unlike a call, the ``invoke`` has two potential; continuation points:. #. where to continue when the call succeeds as per normal, and. #. where to continue if the call raises an exception, either by a throw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:17081,Availability,avail,available,17081,"`` intrinsics are used internally within LLVM's; backend. Uses of them are generated by the backend's; ``SjLjEHPrepare`` pass. .. _llvm.eh.sjlj.setjmp:. ``llvm.eh.sjlj.setjmp``; ~~~~~~~~~~~~~~~~~~~~~~~. .. code-block:: text. i32 @llvm.eh.sjlj.setjmp(i8* %setjmp_buf). For SJLJ based exception handling, this intrinsic forces register saving for the; current function and stores the address of the following instruction for use as; a destination address by `llvm.eh.sjlj.longjmp`_. The buffer format and the; overall functioning of this intrinsic is compatible with the GCC; ``__builtin_setjmp`` implementation allowing code built with the clang and GCC; to interoperate. The single parameter is a pointer to a five word buffer in which the calling; context is saved. The front end places the frame pointer in the first word, and; the target implementation of this intrinsic should place the destination address; for a `llvm.eh.sjlj.longjmp`_ in the second word. The following three words are; available for use in a target-specific manner. .. _llvm.eh.sjlj.longjmp:. ``llvm.eh.sjlj.longjmp``; ~~~~~~~~~~~~~~~~~~~~~~~~. .. code-block:: llvm. void @llvm.eh.sjlj.longjmp(i8* %setjmp_buf). For SJLJ based exception handling, the ``llvm.eh.sjlj.longjmp`` intrinsic is; used to implement ``__builtin_longjmp()``. The single parameter is a pointer to; a buffer populated by `llvm.eh.sjlj.setjmp`_. The frame pointer and stack; pointer are restored from the buffer, then control is transferred to the; destination address. ``llvm.eh.sjlj.lsda``; ~~~~~~~~~~~~~~~~~~~~~. .. code-block:: llvm. i8* @llvm.eh.sjlj.lsda(). For SJLJ based exception handling, the ``llvm.eh.sjlj.lsda`` intrinsic returns; the address of the Language Specific Data Area (LSDA) for the current; function. The SJLJ front-end code stores this address in the exception handling; function context for use by the runtime. ``llvm.eh.sjlj.callsite``; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. code-block:: llvm. void @llvm.eh.sjlj.callsite(i32 %call_site",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:18744,Availability,down,down,18744,"sjlj.lsda`` intrinsic returns; the address of the Language Specific Data Area (LSDA) for the current; function. The SJLJ front-end code stores this address in the exception handling; function context for use by the runtime. ``llvm.eh.sjlj.callsite``; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. code-block:: llvm. void @llvm.eh.sjlj.callsite(i32 %call_site_num). For SJLJ based exception handling, the ``llvm.eh.sjlj.callsite`` intrinsic; identifies the callsite value associated with the following ``invoke``; instruction. This is used to ensure that landing pad entries in the LSDA are; generated in matching order. Asm Table Formats; =================. There are two tables that are used by the exception handling runtime to; determine which actions should be taken when an exception is thrown. Exception Handling Frame; ------------------------. An exception handling frame ``eh_frame`` is very similar to the unwind frame; used by DWARF debug info. The frame contains all the information necessary to; tear down the current frame and restore the state of the prior frame. There is; an exception handling frame for each function in a compile unit, plus a common; exception handling frame that defines information common to all functions in the; unit. The format of this call frame information (CFI) is often platform-dependent,; however. ARM, for example, defines their own format. Apple has their own compact; unwind info format. On Windows, another format is used for all architectures; since 32-bit x86. LLVM will emit whatever information is required by the; target. Exception Tables; ----------------. An exception table contains information about what actions to take when an; exception is thrown in a particular part of a function's code. This is typically; referred to as the language-specific data area (LSDA). The format of the LSDA; table is specific to the personality function, but the majority of personalities; out there use a variation of the tables consumed by ``__gxx_personality_v0``.; There ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:24283,Availability,fault,faulted,24283,"then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, or if code faulted; while accessing a particular memory address range. LLVM does not currently have; IR to represent filter expressions because it is difficult to represent their; control dependencies. Filter expressions run during the first phase of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the da",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:29386,Availability,recover,recover,29386,"d; br label %return. return: ; preds = %invoke.cont.3, %invoke.cont.2; %retval.0 = phi i32 [ 0, %invoke.cont.2 ], [ %3, %invoke.cont.3 ]; ret i32 %retval.0. lpad.cleanup: ; preds = %invoke.cont.2; %0 = cleanuppad within none []; call void @""??1Cleanup@@QEAA@XZ""(ptr nonnull %obj) nounwind; cleanupret from %0 unwind label %lpad.catch. lpad.catch: ; preds = %lpad.cleanup, %entry; %1 = catchswitch within none [label %catch.body] unwind label %lpad.terminate. catch.body: ; preds = %lpad.catch; %catch = catchpad within %1 [ptr @""??_R0H@8"", i32 0, ptr %e]; invoke void @""?may_throw@@YAXXZ""(); to label %invoke.cont.3 unwind label %lpad.terminate. invoke.cont.3: ; preds = %catch.body; %3 = load i32, ptr %e, align 4; catchret from %catch to label %return. lpad.terminate: ; preds = %catch.body, %lpad.catch; cleanuppad within none []; call void @""?terminate@@YAXXZ""(); unreachable; }. Funclet parent tokens; -----------------------. In order to produce tables for EH personalities that use funclets, it is; necessary to recover the nesting that was present in the source. This funclet; parent relationship is encoded in the IR using tokens produced by the new ""pad""; instructions. The token operand of a ""pad"" or ""ret"" instruction indicates which; funclet it is in, or ""none"" if it is not nested within another funclet. The ``catchpad`` and ``cleanuppad`` instructions establish new funclets, and; their tokens are consumed by other ""pad"" instructions to establish membership.; The ``catchswitch`` instruction does not create a funclet, but it produces a; token that is always consumed by its immediate successor ``catchpad``; instructions. This ensures that every catch handler modelled by a ``catchpad``; belongs to exactly one ``catchswitch``, which models the dispatch point after a; C++ try. Here is an example of what this nesting looks like using some hypothetical; C++ code:. .. code-block:: c. void f() {; try {; throw;; } catch (...) {; try {; throw;; } catch (...) {; }; }; }. .. code-block:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14649,Deployability,update,update,14649,"e. Note that the most general form of a ``landingpad``; instruction can have any number of catch, cleanup, and filter clauses (though; having more than one cleanup is pointless). The LLVM C++ front-end can generate; such ``landingpad`` instructions due to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions, LLVM uses several; intrinsic functions (name prefixed with ``llvm.eh``) to provide exception; handling information at various points in generated code. .. _llvm.eh.typeid.for:. ``llvm.eh.typeid.for``; ----------------------. .. code-block:: llvm. i32 @llvm.eh.typeid.for(i8* %type_info). This intrinsic returns the type info index in the exception table of the current; function. This value can be used to compare against the result of; ``landingpad`` instruction. The single argument is a refe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:21125,Deployability,release,release,21125,"ting with exceptions on Windows is significantly more complicated than; on Itanium C++ ABI platforms. The fundamental difference between the two models; is that Itanium EH is designed around the idea of ""successive unwinding,"" while; Windows EH is not. Under Itanium, throwing an exception typically involves allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:6244,Energy Efficiency,allocate,allocate,6244,"nfo*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exception handling in terms of C++ examples. Throw; -----. Languages that support exception handling typically provide a ``throw``; operation to initiate the exception process. Internally, a ``throw`` operation; breaks down into two steps. #. A request is made to allocate exception space for an exception structure.; This structure needs to survive beyond the current activation. This structure; will contain the type and value of the object being thrown. #. A call is made to the runtime to raise the exception, passing the exception; structure as an argument. In C++, the allocation of the exception structure is done by the; ``__cxa_allocate_exception`` runtime function. The exception raising is handled; by ``__cxa_throw``. The type of the exception is represented using a C++ RTTI; structure. Try/Catch; ---------. A call within the scope of a *try* statement can potentially raise an; exception. In those circumstances, the LLVM C++ front-end replaces the call with; an ``invoke`` instruction. Unlike a call, the ``invoke`` has two potential; continuation points:. #. where to continue when the call succeeds as per normal, and. #. where to continue if the call raises an exception, either by a throw or the; unwinding of a throw. The term used to define the place where ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:20841,Energy Efficiency,allocate,allocated,20841,".. _wineh:. Exception Handling using the Windows Runtime; =================================================. Background on Windows exceptions; ---------------------------------. Interacting with exceptions on Windows is significantly more complicated than; on Itanium C++ ABI platforms. The fundamental difference between the two models; is that Itanium EH is designed around the idea of ""successive unwinding,"" while; Windows EH is not. Under Itanium, throwing an exception typically involves allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:21388,Energy Efficiency,allocate,allocated,21388,"s allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implem",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22606,Energy Efficiency,allocate,allocated,22606,"LLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22865,Energy Efficiency,allocate,allocated,22865,"ersonalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:4371,Integrability,message,message,4371,"te representation. It is not based on the; "":ref:`landingpad <i_landingpad>`"" instruction like the other two models, and is; described later in this document under :ref:`wineh`. Overview; --------. When an exception is thrown in LLVM code, the runtime does its best to find a; handler suited to processing the circumstance. The runtime first attempts to find an *exception frame* corresponding to the; function where the exception was thrown. If the programming language supports; exception handling (e.g. C++), the exception frame contains a reference to an; exception table describing how to process the exception. If the language does; not support exception handling (e.g. C), or if the exception needs to be; forwarded to a prior activation, the exception frame contains information about; how to unwind the current activation and restore the state of the prior; activation. This process is repeated until the exception is handled. If the; exception is not handled and no activations remain, then the application is; terminated with an appropriate error message. Because different programming languages have different behaviors when handling; exceptions, the exception handling ABI provides a mechanism for; supplying *personalities*. An exception handling personality is defined by; way of a *personality function* (e.g. ``__gxx_personality_v0`` in C++),; which receives the context of the exception, an *exception structure*; containing the exception object type and value, and a reference to the exception; table for the current function. The personality function for the current; compile unit is specified in a *common exception frame*. The organization of an exception table is language dependent. For C++, an; exception table is organized as a series of code ranges defining what to do if; an exception occurs in that range. Typically, the information associated with a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:5009,Integrability,depend,dependent,5009," C), or if the exception needs to be; forwarded to a prior activation, the exception frame contains information about; how to unwind the current activation and restore the state of the prior; activation. This process is repeated until the exception is handled. If the; exception is not handled and no activations remain, then the application is; terminated with an appropriate error message. Because different programming languages have different behaviors when handling; exceptions, the exception handling ABI provides a mechanism for; supplying *personalities*. An exception handling personality is defined by; way of a *personality function* (e.g. ``__gxx_personality_v0`` in C++),; which receives the context of the exception, an *exception structure*; containing the exception object type and value, and a reference to the exception; table for the current function. The personality function for the current; compile unit is specified in a *common exception frame*. The organization of an exception table is language dependent. For C++, an; exception table is organized as a series of code ranges defining what to do if; an exception occurs in that range. Typically, the information associated with a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exceptio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:19053,Integrability,depend,dependent,19053,"de-block:: llvm. void @llvm.eh.sjlj.callsite(i32 %call_site_num). For SJLJ based exception handling, the ``llvm.eh.sjlj.callsite`` intrinsic; identifies the callsite value associated with the following ``invoke``; instruction. This is used to ensure that landing pad entries in the LSDA are; generated in matching order. Asm Table Formats; =================. There are two tables that are used by the exception handling runtime to; determine which actions should be taken when an exception is thrown. Exception Handling Frame; ------------------------. An exception handling frame ``eh_frame`` is very similar to the unwind frame; used by DWARF debug info. The frame contains all the information necessary to; tear down the current frame and restore the state of the prior frame. There is; an exception handling frame for each function in a compile unit, plus a common; exception handling frame that defines information common to all functions in the; unit. The format of this call frame information (CFI) is often platform-dependent,; however. ARM, for example, defines their own format. Apple has their own compact; unwind info format. On Windows, another format is used for all architectures; since 32-bit x86. LLVM will emit whatever information is required by the; target. Exception Tables; ----------------. An exception table contains information about what actions to take when an; exception is thrown in a particular part of a function's code. This is typically; referred to as the language-specific data area (LSDA). The format of the LSDA; table is specific to the personality function, but the majority of personalities; out there use a variation of the tables consumed by ``__gxx_personality_v0``.; There is one exception table per function, except leaf functions and functions; that have calls only to non-throwing functions. They do not need an exception; table. .. _wineh:. Exception Handling using the Windows Runtime; =================================================. Background on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:21673,Integrability,rout,routine,21673,"ns to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22350,Integrability,depend,depending,22350,"ly described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:24460,Integrability,depend,dependencies,24460,"mpatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, or if code faulted; while accessing a particular memory address range. LLVM does not currently have; IR to represent filter expressions because it is difficult to represent their; control dependencies. Filter expressions run during the first phase of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the data; required by the personality, so long as it uses the familiar core EH actions:; catch, cleanup, and terminate. However, the new instructions are hard to m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22438,Modifiability,variab,variables,22438,"`. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22555,Modifiability,variab,variables,22555,"LLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:24743,Modifiability,variab,variables,24743," this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, or if code faulted; while accessing a particular memory address range. LLVM does not currently have; IR to represent filter expressions because it is difficult to represent their; control dependencies. Filter expressions run during the first phase of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the data; required by the personality, so long as it uses the familiar core EH actions:; catch, cleanup, and terminate. However, the new instructions are hard to modify; without knowing details of the EH personality. While they can be used to; represent Itanium EH, the landingpad model is strictly better for optimization; purposes. The following new instructions are considered ""exception handling pads"", in that; they must be the first non-phi instruction of a basic block that may be the; unwind destination of an EH flow edge:; `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:869,Performance,perform,performing,869,"==========================; Exception Handling in LLVM; ==========================. .. contents::; :local:. Introduction; ============. This document is the central repository for all information pertaining to; exception handling in LLVM. It describes the format that LLVM exception; handling information takes, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what exception handling information is used for in; C and C++. Itanium ABI Zero-cost Exception Handling; ----------------------------------------. Exception handling for most programming languages is designed to recover from; conditions that rarely occur during general use of an application. To that end,; exception handling should not interfere with the main flow of an application's; algorithm by performing checkpointing tasks, such as saving the current pc or; register state. The Itanium ABI Exception Handling Specification defines a methodology for; providing outlying data in the form of exception tables without inlining; speculative exception handling code in the flow of an application's main; algorithm. Thus, the specification is said to add ""zero-cost"" to the normal; execution of an application. A more complete description of the Itanium ABI exception handling runtime; support of can be found at `Itanium C++ ABI: Exception Handling; <http://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>`_. A description of the; exception frame format can be found at `Exception Frames; <http://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/ehframechpt.html>`_,; with details of the DWARF 4 specification at `DWARF 4 Standard; <http://dwarfstd.org/Dwarf4Std.php>`_. A description for the C++ exception; table formats can be found at `Exception Handling Tables; <http://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>`_. Setjmp/Longjmp Exception Handling; ---------------------------------. Setjmp/Lon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14219,Performance,perform,perform,14219,"n. To represent this, a top level landing pad may exist to; filter out invalid types. To express this in LLVM code the :ref:`i_landingpad`; will have a filter clause. The clause consists of an array of type infos.; ``landingpad`` will return a negative value; if the exception does not match any of the type infos. If no match is found then; a call to ``__cxa_call_unexpected`` should be made, otherwise; ``_Unwind_Resume``. Each of these functions requires a reference to the; exception structure. Note that the most general form of a ``landingpad``; instruction can have any number of catch, cleanup, and filter clauses (though; having more than one cleanup is pointless). The LLVM C++ front-end can generate; such ``landingpad`` instructions due to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:25555,Performance,optimiz,optimization,25555," of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the data; required by the personality, so long as it uses the familiar core EH actions:; catch, cleanup, and terminate. However, the new instructions are hard to modify; without knowing details of the EH personality. While they can be used to; represent Itanium EH, the landingpad model is strictly better for optimization; purposes. The following new instructions are considered ""exception handling pads"", in that; they must be the first non-phi instruction of a basic block that may be the; unwind destination of an EH flow edge:; ``catchswitch``, ``catchpad``, and ``cleanuppad``.; As with landingpads, when entering a try scope, if the; frontend encounters a call site that may throw an exception, it should emit an; invoke that unwinds to a ``catchswitch`` block. Similarly, inside the scope of a; C++ object with a destructor, invokes should unwind to a ``cleanuppad``. New instructions are also used to mark the points where control is transferred; out of a catch/cleanup handler (which will correspond to exits from the; generated funclet). A catch handler which reaches its end by normal execution; executes a ``catchret`` instruction, which is a terminator indicating where in; the function control is returned to. A cleanup handler which reaches its end; by normal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:29056,Performance,load,load,29056,"ptr nonnull %obj); to label %invoke.cont unwind label %lpad.catch. invoke.cont: ; preds = %entry; invoke void @""?may_throw@@YAXXZ""(); to label %invoke.cont.2 unwind label %lpad.cleanup. invoke.cont.2: ; preds = %invoke.cont; call void @""??_DCleanup@@QEAA@XZ""(ptr nonnull %obj) nounwind; br label %return. return: ; preds = %invoke.cont.3, %invoke.cont.2; %retval.0 = phi i32 [ 0, %invoke.cont.2 ], [ %3, %invoke.cont.3 ]; ret i32 %retval.0. lpad.cleanup: ; preds = %invoke.cont.2; %0 = cleanuppad within none []; call void @""??1Cleanup@@QEAA@XZ""(ptr nonnull %obj) nounwind; cleanupret from %0 unwind label %lpad.catch. lpad.catch: ; preds = %lpad.cleanup, %entry; %1 = catchswitch within none [label %catch.body] unwind label %lpad.terminate. catch.body: ; preds = %lpad.catch; %catch = catchpad within %1 [ptr @""??_R0H@8"", i32 0, ptr %e]; invoke void @""?may_throw@@YAXXZ""(); to label %invoke.cont.3 unwind label %lpad.terminate. invoke.cont.3: ; preds = %catch.body; %3 = load i32, ptr %e, align 4; catchret from %catch to label %return. lpad.terminate: ; preds = %catch.body, %lpad.catch; cleanuppad within none []; call void @""?terminate@@YAXXZ""(); unreachable; }. Funclet parent tokens; -----------------------. In order to produce tables for EH personalities that use funclets, it is; necessary to recover the nesting that was present in the source. This funclet; parent relationship is encoded in the IR using tokens produced by the new ""pad""; instructions. The token operand of a ""pad"" or ""ret"" instruction indicates which; funclet it is in, or ""none"" if it is not nested within another funclet. The ``catchpad`` and ``cleanuppad`` instructions establish new funclets, and; their tokens are consumed by other ""pad"" instructions to establish membership.; The ``catchswitch`` instruction does not create a funclet, but it produces a; token that is always consumed by its immediate successor ``catchpad``; instructions. This ensures that every catch handler modelled by a ``catchpad``; belongs to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:681,Safety,recover,recover,681,"==========================; Exception Handling in LLVM; ==========================. .. contents::; :local:. Introduction; ============. This document is the central repository for all information pertaining to; exception handling in LLVM. It describes the format that LLVM exception; handling information takes, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what exception handling information is used for in; C and C++. Itanium ABI Zero-cost Exception Handling; ----------------------------------------. Exception handling for most programming languages is designed to recover from; conditions that rarely occur during general use of an application. To that end,; exception handling should not interfere with the main flow of an application's; algorithm by performing checkpointing tasks, such as saving the current pc or; register state. The Itanium ABI Exception Handling Specification defines a methodology for; providing outlying data in the form of exception tables without inlining; speculative exception handling code in the flow of an application's main; algorithm. Thus, the specification is said to add ""zero-cost"" to the normal; execution of an application. A more complete description of the Itanium ABI exception handling runtime; support of can be found at `Itanium C++ ABI: Exception Handling; <http://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html>`_. A description of the; exception frame format can be found at `Exception Frames; <http://refspecs.linuxfoundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/ehframechpt.html>`_,; with details of the DWARF 4 specification at `DWARF 4 Standard; <http://dwarfstd.org/Dwarf4Std.php>`_. A description for the C++ exception; table formats can be found at `Exception Handling Tables; <http://itanium-cxx-abi.github.io/cxx-abi/exceptions.pdf>`_. Setjmp/Longjmp Exception Handling; ---------------------------------. Setjmp/Lon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:10679,Safety,abort,aborting,10679,"uivalent to ""``catch i8* null``"",; because ``filter`` and ``catch`` produce negative and positive selector; values respectively.). - ``cleanup``. - This clause means that the landingpad should always be entered. - C++ front-ends use this for calling objects' destructors. - When this clause is matched, the selector value will be zero. - The runtime may treat ""``cleanup``"" differently from ""``catch <type>; null``"". In C++, if an unhandled exception occurs, the language runtime will call; ``std::terminate()``, but it is implementation-defined whether the runtime; unwinds the stack and calls object destructors first. For example, the GNU; C++ unwinder does not call object destructors when an unhandled exception; occurs. The reason for this is to improve debuggability: it ensures that; ``std::terminate()`` is called from the context of the ``throw``, so that; this context is not lost by unwinding the stack. A runtime will typically; implement this by searching for a matching non-``cleanup`` clause, and; aborting if it does not find one, before entering any landingpad blocks. Once the landing pad has the type info selector, the code branches to the code; for the first catch. The catch then checks the value of the type info selector; against the index of type info for that catch. Since the type info index is not; known until all the type infos have been gathered in the backend, the catch code; must call the `llvm.eh.typeid.for`_ intrinsic to determine the index for a given; type info. If the catch fails to match the selector then control is passed on to; the next catch. Finally, the entry and exit of catch code is bracketed with calls to; ``__cxa_begin_catch`` and ``__cxa_end_catch``. * ``__cxa_begin_catch`` takes an exception structure reference as an argument; and returns the value of the exception object. * ``__cxa_end_catch`` takes no arguments. This function:. #. Locates the most recently caught exception and decrements its handler; count,. #. Removes the exception fro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:29386,Safety,recover,recover,29386,"d; br label %return. return: ; preds = %invoke.cont.3, %invoke.cont.2; %retval.0 = phi i32 [ 0, %invoke.cont.2 ], [ %3, %invoke.cont.3 ]; ret i32 %retval.0. lpad.cleanup: ; preds = %invoke.cont.2; %0 = cleanuppad within none []; call void @""??1Cleanup@@QEAA@XZ""(ptr nonnull %obj) nounwind; cleanupret from %0 unwind label %lpad.catch. lpad.catch: ; preds = %lpad.cleanup, %entry; %1 = catchswitch within none [label %catch.body] unwind label %lpad.terminate. catch.body: ; preds = %lpad.catch; %catch = catchpad within %1 [ptr @""??_R0H@8"", i32 0, ptr %e]; invoke void @""?may_throw@@YAXXZ""(); to label %invoke.cont.3 unwind label %lpad.terminate. invoke.cont.3: ; preds = %catch.body; %3 = load i32, ptr %e, align 4; catchret from %catch to label %return. lpad.terminate: ; preds = %catch.body, %lpad.catch; cleanuppad within none []; call void @""?terminate@@YAXXZ""(); unreachable; }. Funclet parent tokens; -----------------------. In order to produce tables for EH personalities that use funclets, it is; necessary to recover the nesting that was present in the source. This funclet; parent relationship is encoded in the IR using tokens produced by the new ""pad""; instructions. The token operand of a ""pad"" or ""ret"" instruction indicates which; funclet it is in, or ""none"" if it is not nested within another funclet. The ``catchpad`` and ``cleanuppad`` instructions establish new funclets, and; their tokens are consumed by other ""pad"" instructions to establish membership.; The ``catchswitch`` instruction does not create a funclet, but it produces a; token that is always consumed by its immediate successor ``catchpad``; instructions. This ensures that every catch handler modelled by a ``catchpad``; belongs to exactly one ``catchswitch``, which models the dispatch point after a; C++ try. Here is an example of what this nesting looks like using some hypothetical; C++ code:. .. code-block:: c. void f() {; try {; throw;; } catch (...) {; try {; throw;; } catch (...) {; }; }; }. .. code-block:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22422,Security,access,accessing,22422,"`. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:24298,Security,access,accessing,24298,"then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, or if code faulted; while accessing a particular memory address range. LLVM does not currently have; IR to represent filter expressions because it is difficult to represent their; control dependencies. Filter expressions run during the first phase of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the da",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:24796,Security,access,accessed,24796," this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, or if code faulted; while accessing a particular memory address range. LLVM does not currently have; IR to represent filter expressions because it is difficult to represent their; control dependencies. Filter expressions run during the first phase of EH,; before cleanups run, making it very difficult to build a faithful control flow; graph. For now, the new EH instructions cannot represent SEH filter; expressions, and frontends must outline them ahead of time. Local variables of; the parent function can be escaped and accessed using the ``llvm.localescape``; and ``llvm.localrecover`` intrinsics. New exception handling instructions; ------------------------------------. The primary design goal of the new EH instructions is to support funclet; generation while preserving information about the CFG so that SSA formation; still works. As a secondary goal, they are designed to be generic across MSVC; and Itanium C++ exceptions. They make very few assumptions about the data; required by the personality, so long as it uses the familiar core EH actions:; catch, cleanup, and terminate. However, the new instructions are hard to modify; without knowing details of the EH personality. While they can be used to; represent Itanium EH, the landingpad model is strictly better for optimization; purposes. The following new instructions are considered ""exception handling pads"", in that; they must be the first non-phi instruction of a basic block that may be the; unwind destination of an EH flow edge:; `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:8190,Testability,test,tested,8190," throw. The term used to define the place where an ``invoke`` continues after an; exception is called a *landing pad*. LLVM landing pads are conceptually; alternative function entry points where an exception structure reference and a; type info index are passed in as arguments. The landing pad saves the exception; structure reference and then proceeds to select the catch block that corresponds; to the type info of the exception object. The LLVM :ref:`i_landingpad` is used to convey information about the landing; pad to the back end. For C++, the ``landingpad`` instruction returns a pointer; and integer pair corresponding to the pointer to the *exception structure* and; the *selector value* respectively. The ``landingpad`` instruction looks for a reference to the personality; function to be used for this ``try``/``catch`` sequence in the parent; function's attribute list. The instruction contains a list of *cleanup*,; *catch*, and *filter* clauses. The exception is tested against the clauses; sequentially from first to last. The clauses have the following meanings:. - ``catch <type> @ExcType``. - This clause means that the landingpad block should be entered if the; exception being thrown is of type ``@ExcType`` or a subtype of; ``@ExcType``. For C++, ``@ExcType`` is a pointer to the ``std::type_info``; object (an RTTI object) representing the C++ exception type. - If ``@ExcType`` is ``null``, any exception matches, so the landingpad; should always be entered. This is used for C++ catch-all blocks (""``catch; (...)``""). - When this clause is matched, the selector value will be equal to the value; returned by ""``@llvm.eh.typeid.for(i8* @ExcType)``"". This will always be a; positive value. - ``filter <type> [<type> @ExcType1, ..., <type> @ExcTypeN]``. - This clause means that the landingpad should be entered if the exception; being thrown does *not* match any of the types in the list (which, for C++,; are again specified as ``std::type_info`` pointers). - C++ front-ends u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14903,Testability,test,test,14903,"e to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions, LLVM uses several; intrinsic functions (name prefixed with ``llvm.eh``) to provide exception; handling information at various points in generated code. .. _llvm.eh.typeid.for:. ``llvm.eh.typeid.for``; ----------------------. .. code-block:: llvm. i32 @llvm.eh.typeid.for(i8* %type_info). This intrinsic returns the type info index in the exception table of the current; function. This value can be used to compare against the result of; ``landingpad`` instruction. The single argument is a reference to a type info. Uses of this intrinsic are generated by the C++ front-end. .. _llvm.eh.exceptionpointer:. ``llvm.eh.exceptionpointer``; ----------------------------. .. code-block:: text. i8 addrspace(N)* @llvm.eh.padparam.pNi8(token %catchpad). ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:5525,Usability,resume,resumes,5525," is defined by; way of a *personality function* (e.g. ``__gxx_personality_v0`` in C++),; which receives the context of the exception, an *exception structure*; containing the exception object type and value, and a reference to the exception; table for the current function. The personality function for the current; compile unit is specified in a *common exception frame*. The organization of an exception table is language dependent. For C++, an; exception table is organized as a series of code ranges defining what to do if; an exception occurs in that range. Typically, the information associated with a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exception handling in terms of C++ examples. Throw; -----. Languages that support exception handling typically provide a ``throw``; operation to initiate the exception process. Internally, a ``throw`` operation; breaks down into two steps. #. A request is made to allocate exception space for an exception structure.; This structure needs to survive beyond the current activation. This structure; will contain the type and value of the object being thrown. #. A call is made to the runtime to raise the exception, passing the exception; structure as an argument. In C++, the allocation of the exception st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:12913,Usability,resume,resume,12913," A cleanup is extra code which needs to be run as part of unwinding a scope. C++; destructors are a typical example, but other languages and language extensions; provide a variety of different kinds of cleanups. In general, a landing pad may; need to run arbitrary amounts of cleanup code before actually entering a catch; block. To indicate the presence of cleanups, a :ref:`i_landingpad` should have; a *cleanup* clause. Otherwise, the unwinder will not stop at the landing pad if; there are no catches or filters that require it to. .. note::. Do not allow a new exception to propagate out of the execution of a; cleanup. This can corrupt the internal state of the unwinder. Different; languages describe different high-level semantics for these situations: for; example, C++ requires that the process be terminated, whereas Ada cancels both; exceptions and throws a third. When all cleanups are finished, if the exception is not handled by the current; function, resume unwinding by calling the :ref:`resume instruction <i_resume>`,; passing in the result of the ``landingpad`` instruction for the original; landing pad. Throw Filters; -------------. Prior to C++17, C++ allowed the specification of which exception types may be; thrown from a function. To represent this, a top level landing pad may exist to; filter out invalid types. To express this in LLVM code the :ref:`i_landingpad`; will have a filter clause. The clause consists of an array of type infos.; ``landingpad`` will return a negative value; if the exception does not match any of the type infos. If no match is found then; a call to ``__cxa_call_unexpected`` should be made, otherwise; ``_Unwind_Resume``. Each of these functions requires a reference to the; exception structure. Note that the most general form of a ``landingpad``; instruction can have any number of catch, cleanup, and filter clauses (though; having more than one cleanup is pointless). The LLVM C++ front-end can generate; such ``landingpad`` instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:12951,Usability,resume,resume,12951," A cleanup is extra code which needs to be run as part of unwinding a scope. C++; destructors are a typical example, but other languages and language extensions; provide a variety of different kinds of cleanups. In general, a landing pad may; need to run arbitrary amounts of cleanup code before actually entering a catch; block. To indicate the presence of cleanups, a :ref:`i_landingpad` should have; a *cleanup* clause. Otherwise, the unwinder will not stop at the landing pad if; there are no catches or filters that require it to. .. note::. Do not allow a new exception to propagate out of the execution of a; cleanup. This can corrupt the internal state of the unwinder. Different; languages describe different high-level semantics for these situations: for; example, C++ requires that the process be terminated, whereas Ada cancels both; exceptions and throws a third. When all cleanups are finished, if the exception is not handled by the current; function, resume unwinding by calling the :ref:`resume instruction <i_resume>`,; passing in the result of the ``landingpad`` instruction for the original; landing pad. Throw Filters; -------------. Prior to C++17, C++ allowed the specification of which exception types may be; thrown from a function. To represent this, a top level landing pad may exist to; filter out invalid types. To express this in LLVM code the :ref:`i_landingpad`; will have a filter clause. The clause consists of an array of type infos.; ``landingpad`` will return a negative value; if the exception does not match any of the type infos. If no match is found then; a call to ``__cxa_call_unexpected`` should be made, otherwise; ``_Unwind_Resume``. Each of these functions requires a reference to the; exception structure. Note that the most general form of a ``landingpad``; instruction can have any number of catch, cleanup, and filter clauses (though; having more than one cleanup is pointless). The LLVM C++ front-end can generate; such ``landingpad`` instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14959,Usability,resume,resume,14959,"e to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions, LLVM uses several; intrinsic functions (name prefixed with ``llvm.eh``) to provide exception; handling information at various points in generated code. .. _llvm.eh.typeid.for:. ``llvm.eh.typeid.for``; ----------------------. .. code-block:: llvm. i32 @llvm.eh.typeid.for(i8* %type_info). This intrinsic returns the type info index in the exception table of the current; function. This value can be used to compare against the result of; ``landingpad`` instruction. The single argument is a reference to a type info. Uses of this intrinsic are generated by the C++ front-end. .. _llvm.eh.exceptionpointer:. ``llvm.eh.exceptionpointer``; ----------------------------. .. code-block:: text. i8 addrspace(N)* @llvm.eh.padparam.pNi8(token %catchpad). ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14999,Usability,resume,resume,14999,"e to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions, LLVM uses several; intrinsic functions (name prefixed with ``llvm.eh``) to provide exception; handling information at various points in generated code. .. _llvm.eh.typeid.for:. ``llvm.eh.typeid.for``; ----------------------. .. code-block:: llvm. i32 @llvm.eh.typeid.for(i8* %type_info). This intrinsic returns the type info index in the exception table of the current; function. This value can be used to compare against the result of; ``landingpad`` instruction. The single argument is a reference to a type info. Uses of this intrinsic are generated by the C++ front-end. .. _llvm.eh.exceptionpointer:. ``llvm.eh.exceptionpointer``; ----------------------------. .. code-block:: text. i8 addrspace(N)* @llvm.eh.padparam.pNi8(token %catchpad). ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:15180,Usability,resume,resume,15180,"y will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions, LLVM uses several; intrinsic functions (name prefixed with ``llvm.eh``) to provide exception; handling information at various points in generated code. .. _llvm.eh.typeid.for:. ``llvm.eh.typeid.for``; ----------------------. .. code-block:: llvm. i32 @llvm.eh.typeid.for(i8* %type_info). This intrinsic returns the type info index in the exception table of the current; function. This value can be used to compare against the result of; ``landingpad`` instruction. The single argument is a reference to a type info. Uses of this intrinsic are generated by the C++ front-end. .. _llvm.eh.exceptionpointer:. ``llvm.eh.exceptionpointer``; ----------------------------. .. code-block:: text. i8 addrspace(N)* @llvm.eh.padparam.pNi8(token %catchpad). This intrinsic retrieves a pointer to the exception caught by the given; ``catchpad``. SJLJ Intrinsics; ---------------. The ``llvm.eh.sjlj`` intrinsics are used internally within LLVM's; backend. Uses of them are generated by the backend's; ``SjLjEHPrepa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:20708,Usability,resume,resumes,20708," is one exception table per function, except leaf functions and functions; that have calls only to non-throwing functions. They do not need an exception; table. .. _wineh:. Exception Handling using the Windows Runtime; =================================================. Background on Windows exceptions; ---------------------------------. Interacting with exceptions on Windows is significantly more complicated than; on Itanium C++ ABI platforms. The fundamental difference between the two models; is that Itanium EH is designed around the idea of ""successive unwinding,"" while; Windows EH is not. Under Itanium, throwing an exception typically involves allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; Ther",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:21149,Usability,resume,resume,21149,"ting with exceptions on Windows is significantly more complicated than; on Itanium C++ ABI platforms. The fundamental difference between the two models; is that Itanium EH is designed around the idea of ""successive unwinding,"" while; Windows EH is not. Under Itanium, throwing an exception typically involves allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:23291,Usability,resume,resume,23291,"t either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressions; -----------------------. The SEH personality functions also use funclets to implement filter expressions,; which allow executing arbitrary user code to decide which exceptions to catch.; Filter expressions should not be confused with the ``filter`` clause of the LLVM; ``landingpad`` instruction. Typically filter expressions are used to determine; if the exception came from a particular DLL or code region, o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:27083,Usability,resume,resume,27083,"cleanuppad``. New instructions are also used to mark the points where control is transferred; out of a catch/cleanup handler (which will correspond to exits from the; generated funclet). A catch handler which reaches its end by normal execution; executes a ``catchret`` instruction, which is a terminator indicating where in; the function control is returned to. A cleanup handler which reaches its end; by normal execution executes a ``cleanupret`` instruction, which is a terminator; indicating where the active exception will unwind to next. Each of these new EH pad instructions has a way to identify which action should; be considered after this action. The ``catchswitch`` instruction is a terminator; and has an unwind destination operand analogous to the unwind destination of an; invoke. The ``cleanuppad`` instruction is not; a terminator, so the unwind destination is stored on the ``cleanupret``; instruction instead. Successfully executing a catch handler should resume; normal control flow, so neither ``catchpad`` nor ``catchret`` instructions can; unwind. All of these ""unwind edges"" may refer to a basic block that contains an; EH pad instruction, or they may unwind to the caller. Unwinding to the caller; has roughly the same semantics as the ``resume`` instruction in the landingpad; model. When inlining through an invoke, instructions that unwind to the caller; are hooked up to unwind to the unwind destination of the call site. Putting things together, here is a hypothetical lowering of some C++ that uses; all of the new IR instructions:. .. code-block:: c. struct Cleanup {; Cleanup();; ~Cleanup();; int m;; };; void may_throw();; int f() noexcept {; try {; Cleanup obj;; may_throw();; } catch (int e) {; may_throw();; return e;; }; return 0;; }. .. code-block:: text. define i32 @f() nounwind personality ptr @__CxxFrameHandler3 {; entry:; %obj = alloca %struct.Cleanup, align 4; %e = alloca i32, align 4; %call = invoke ptr @""??0Cleanup@@QEAA@XZ""(ptr nonnull %obj); to la",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:27371,Usability,resume,resume,27371," a ``catchret`` instruction, which is a terminator indicating where in; the function control is returned to. A cleanup handler which reaches its end; by normal execution executes a ``cleanupret`` instruction, which is a terminator; indicating where the active exception will unwind to next. Each of these new EH pad instructions has a way to identify which action should; be considered after this action. The ``catchswitch`` instruction is a terminator; and has an unwind destination operand analogous to the unwind destination of an; invoke. The ``cleanuppad`` instruction is not; a terminator, so the unwind destination is stored on the ``cleanupret``; instruction instead. Successfully executing a catch handler should resume; normal control flow, so neither ``catchpad`` nor ``catchret`` instructions can; unwind. All of these ""unwind edges"" may refer to a basic block that contains an; EH pad instruction, or they may unwind to the caller. Unwinding to the caller; has roughly the same semantics as the ``resume`` instruction in the landingpad; model. When inlining through an invoke, instructions that unwind to the caller; are hooked up to unwind to the unwind destination of the call site. Putting things together, here is a hypothetical lowering of some C++ that uses; all of the new IR instructions:. .. code-block:: c. struct Cleanup {; Cleanup();; ~Cleanup();; int m;; };; void may_throw();; int f() noexcept {; try {; Cleanup obj;; may_throw();; } catch (int e) {; may_throw();; return e;; }; return 0;; }. .. code-block:: text. define i32 @f() nounwind personality ptr @__CxxFrameHandler3 {; entry:; %obj = alloca %struct.Cleanup, align 4; %e = alloca i32, align 4; %call = invoke ptr @""??0Cleanup@@QEAA@XZ""(ptr nonnull %obj); to label %invoke.cont unwind label %lpad.catch. invoke.cont: ; preds = %entry; invoke void @""?may_throw@@YAXXZ""(); to label %invoke.cont.2 unwind label %lpad.cleanup. invoke.cont.2: ; preds = %invoke.cont; call void @""??_DCleanup@@QEAA@XZ""(ptr nonnull %obj) n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:36266,Usability,undo,undocumented,36266,"Lowering``'s ``emitPrologue``, you have to emit `CFI; directives <https://sourceware.org/binutils/docs/as/CFI-directives.html>`_; to specify how to calculate the CFA (Canonical Frame Address) and how register; is restored from the address pointed by the CFA with an offset. The assembler; is instructed by CFI directives to build ``.eh_frame`` section, which is used; by th unwinder to unwind stack during exception handling. * ``getExceptionPointerRegister`` and ``getExceptionSelectorRegister``. ``TargetLowering`` must implement both functions. The *personality function*; passes the *exception structure* (a pointer) and *selector value* (an integer); to the landing pad through the registers specified by ``getExceptionPointerRegister``; and ``getExceptionSelectorRegister`` respectively. On most platforms, they; will be GPRs and will be the same as the ones specified in the calling convention. * ``EH_RETURN``. The ISD node represents the undocumented GCC extension ``__builtin_eh_return (offset, handler)``,; which adjusts the stack by offset and then jumps to the handler. ``__builtin_eh_return``; is used in GCC unwinder (`libgcc <https://gcc.gnu.org/onlinedocs/gccint/Libgcc.html>`_),; but not in LLVM unwinder (`libunwind <https://clang.llvm.org/docs/Toolchain.html#unwind-library>`_).; If you are on the top of ``libgcc`` and have particular requirement on your target,; you have to handle ``EH_RETURN`` in ``TargetLowering``. If you don't leverage the existing runtime (``libstdc++`` and ``libgcc``),; you have to take a look on `libc++ <https://libcxx.llvm.org/>`_ and; `libunwind <https://clang.llvm.org/docs/Toolchain.html#unwind-library>`_; to see what have to be done there. For ``libunwind``, you have to do the following. * ``__libunwind_config.h``. Define macros for your target. * ``include/libunwind.h``. Define enum for the target registers. * ``src/Registers.hpp``. Define ``Registers`` class for your target, implement setter and getter functions. * ``src/UnwindCursor.hpp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:906,Deployability,update,update,906,"============================================================; Extending LLVM: Adding instructions, intrinsics, types, etc.; ============================================================. Introduction and Warning; ========================. During the course of using LLVM, you may wish to customize it for your research; project or for experimentation. At this point, you may realize that you need to; add something to LLVM, whether it be a new fundamental type, a new intrinsic; function, or a whole new instruction. When you come to this realization, stop and think. Do you really need to extend; LLVM? Is it a new fundamental capability that LLVM does not support at its; current incarnation or can it be synthesized from already pre-existing LLVM; elements? If you are not sure, ask on the `LLVM forums; <https://discourse.llvm.org>`_. The reason is that; extending LLVM will get involved as you need to update all the different passes; that you intend to use with your extension, and there are ``many`` LLVM analyses; and transformations, so it may be quite a bit of work. Adding an `intrinsic function`_ is far easier than adding an; instruction, and is transparent to optimization passes. If your added; functionality can be expressed as a function call, an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:9819,Deployability,install,installations,9819,"ib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/Bitcode/Writer/BitcodeWriter.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/IR/Instruction.cpp``:. add a case for how your instruction will be printed out to assembly. #. ``llvm/lib/IR/Instructions.cpp``:. implement the class you defined in ``llvm/include/llvm/Instructions.h``. #. Test your instruction. #. ``llvm/lib/Target/*``:. add support for your instruction to code generators, or add a lowering pass. #. ``llvm/test/*``:. add your test cases to the test suite. Also, you need to implement (or modify) any analyses or passes that you want to; understand this new instruction. Adding a new type; =================. .. warning::. Adding new types changes the bitcode format, and will break compatibility with; currently-existing LLVM installations. Only add new types if it is absolutely; necessary. Adding a fundamental type; -------------------------. #. ``llvm/include/llvm/IR/Type.h``:. add enum for the new type; add static ``Type*`` for this type. #. ``llvm/lib/IR/Type.cpp`` and ``llvm/lib/CodeGen/ValueTypes.cpp``:. add mapping from ``TypeID`` => ``Type*``; initialize the static ``Type*``. #. ``llvm/include/llvm-c/Core.h`` and ``llvm/lib/IR/Core.cpp``:. add enum ``LLVMTypeKind`` and modify; ``LLVMTypeKind LLVMGetTypeKind(LLVMTypeRef Ty)`` for the new type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add ability to parse in the type from text assembly. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add a token for that type. #. ``llvm/lib/Bitcode/Writer/BitcodeWriter.cpp``:. modify ``void ModuleBitcodeWriter::writeTypeTable()`` to serialize your type. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. modify ``Error BitcodeReader::parseTypeTableBody()`` to read your data type. #.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:589,Modifiability,extend,extend,589,"============================================================; Extending LLVM: Adding instructions, intrinsics, types, etc.; ============================================================. Introduction and Warning; ========================. During the course of using LLVM, you may wish to customize it for your research; project or for experimentation. At this point, you may realize that you need to; add something to LLVM, whether it be a new fundamental type, a new intrinsic; function, or a whole new instruction. When you come to this realization, stop and think. Do you really need to extend; LLVM? Is it a new fundamental capability that LLVM does not support at its; current incarnation or can it be synthesized from already pre-existing LLVM; elements? If you are not sure, ask on the `LLVM forums; <https://discourse.llvm.org>`_. The reason is that; extending LLVM will get involved as you need to update all the different passes; that you intend to use with your extension, and there are ``many`` LLVM analyses; and transformations, so it may be quite a bit of work. Adding an `intrinsic function`_ is far easier than adding an; instruction, and is transparent to optimization passes. If your added; functionality can be expressed as a function call, an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:858,Modifiability,extend,extending,858,"============================================================; Extending LLVM: Adding instructions, intrinsics, types, etc.; ============================================================. Introduction and Warning; ========================. During the course of using LLVM, you may wish to customize it for your research; project or for experimentation. At this point, you may realize that you need to; add something to LLVM, whether it be a new fundamental type, a new intrinsic; function, or a whole new instruction. When you come to this realization, stop and think. Do you really need to extend; LLVM? Is it a new fundamental capability that LLVM does not support at its; current incarnation or can it be synthesized from already pre-existing LLVM; elements? If you are not sure, ask on the `LLVM forums; <https://discourse.llvm.org>`_. The reason is that; extending LLVM will get involved as you need to update all the different passes; that you intend to use with your extension, and there are ``many`` LLVM analyses; and transformations, so it may be quite a bit of work. Adding an `intrinsic function`_ is far easier than adding an; instruction, and is transparent to optimization passes. If your added; functionality can be expressed as a function call, an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:1173,Performance,optimiz,optimization,1173,"==================================================. Introduction and Warning; ========================. During the course of using LLVM, you may wish to customize it for your research; project or for experimentation. At this point, you may realize that you need to; add something to LLVM, whether it be a new fundamental type, a new intrinsic; function, or a whole new instruction. When you come to this realization, stop and think. Do you really need to extend; LLVM? Is it a new fundamental capability that LLVM does not support at its; current incarnation or can it be synthesized from already pre-existing LLVM; elements? If you are not sure, ask on the `LLVM forums; <https://discourse.llvm.org>`_. The reason is that; extending LLVM will get involved as you need to update all the different passes; that you intend to use with your extension, and there are ``many`` LLVM analyses; and transformations, so it may be quite a bit of work. Adding an `intrinsic function`_ is far easier than adding an; instruction, and is transparent to optimization passes. If your added; functionality can be expressed as a function call, an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2250,Performance,optimiz,optimization,2250," an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:3775,Performance,perform,perform,3775,"m/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer representation) or capture more; complicated behavior in a single node (rotate). #. ``include/llvm/CodeGen/ISDOpcodes.h``:. Add an enum value for the new SelectionDAG node. #. ``lib/CodeGen/SelectionDAG/SelectionDAG.cpp``:. Add code to print the node to ``getOperationName``. If your new node can be; evaluated at compile time when given constant arguments (such as an add of a; constant with another constant), find the ``getNode`` method that takes the; appropriate number of arguments, and add a case for your node to the switch; statement that performs constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:4393,Performance,perform,performs,4393,"examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer representation) or capture more; complicated behavior in a single node (rotate). #. ``include/llvm/CodeGen/ISDOpcodes.h``:. Add an enum value for the new SelectionDAG node. #. ``lib/CodeGen/SelectionDAG/SelectionDAG.cpp``:. Add code to print the node to ``getOperationName``. If your new node can be; evaluated at compile time when given constant arguments (such as an add of a; constant with another constant), find the ``getNode`` method that takes the; appropriate number of arguments, and add a case for your node to the switch; statement that performs constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may suppo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5489,Performance,perform,perform,5489," constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5675,Performance,perform,performs,5675,"se statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSRL`` are good starting places. #. ``lib/Target/PowerPC/PPCISelLowering.cpp``:. Each target has an implementation of the ``TargetLowering`` class, usually in; its own file (although some targets include it in the same file as the; DAGToDAGISel). The default behavior for a target is to assum",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5913,Performance,perform,perform,5913,"onDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSRL`` are good starting places. #. ``lib/Target/PowerPC/PPCISelLowering.cpp``:. Each target has an implementation of the ``TargetLowering`` class, usually in; its own file (although some targets include it in the same file as the; DAGToDAGISel). The default behavior for a target is to assume that your new; node is legal for all types that are legal for that target. If this target; does not natively support your node, then tell the target to either Promote; it (if it is supported at a larger type) or Expand it. This will caus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2222,Security,access,access,2222," an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2817,Testability,test,test,2817,"ns to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2832,Testability,test,test,2832,"sic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer represent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2852,Testability,test,test,2852,"sic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer represent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2870,Testability,test,test,2870,"sic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer represent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:7960,Testability,test,test,7960,"p`` above to decompose your new node into other; legal nodes for this target. #. ``include/llvm/Target/TargetSelectionDAG.td``:. Most current targets supported by LLVM generate code using the DAGToDAG; method, where SelectionDAG nodes are pattern matched to target-specific; nodes, which represent individual instructions. In order for the targets to; match an instruction to your new node, you must add a def for that node to; the list in this file, with the appropriate type constraints. Look at; ``add``, ``bswap``, and ``fadd`` for examples. #. ``lib/Target/PowerPC/PPCInstrInfo.td``:. Each target has a tablegen file that describes the target's instruction set.; For targets that use the DAGToDAG instruction selection framework, add a; pattern for your new node that uses one or more target nodes. Documentation; for this is a bit sparse right now, but there are several decent examples.; See the patterns for ``rotl`` in ``PPCInstrInfo.td``. #. TODO: document complex patterns. #. ``llvm/test/CodeGen/*``:. Add test cases for your new node to the test suite.; ``llvm/test/CodeGen/X86/bswap.ll`` is a good example. Adding a new instruction; ========================. .. warning::. Adding instructions changes the bitcode format, and it will take some effort; to maintain compatibility with the previous version. Only add an instruction; if it is absolutely necessary. #. ``llvm/include/llvm/IR/Instruction.def``:. add a number for your instruction and an enum name. #. ``llvm/include/llvm/IR/Instructions.h``:. add a definition for the class that will represent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:7983,Testability,test,test,7983,"to other; legal nodes for this target. #. ``include/llvm/Target/TargetSelectionDAG.td``:. Most current targets supported by LLVM generate code using the DAGToDAG; method, where SelectionDAG nodes are pattern matched to target-specific; nodes, which represent individual instructions. In order for the targets to; match an instruction to your new node, you must add a def for that node to; the list in this file, with the appropriate type constraints. Look at; ``add``, ``bswap``, and ``fadd`` for examples. #. ``lib/Target/PowerPC/PPCInstrInfo.td``:. Each target has a tablegen file that describes the target's instruction set.; For targets that use the DAGToDAG instruction selection framework, add a; pattern for your new node that uses one or more target nodes. Documentation; for this is a bit sparse right now, but there are several decent examples.; See the patterns for ``rotl`` in ``PPCInstrInfo.td``. #. TODO: document complex patterns. #. ``llvm/test/CodeGen/*``:. Add test cases for your new node to the test suite.; ``llvm/test/CodeGen/X86/bswap.ll`` is a good example. Adding a new instruction; ========================. .. warning::. Adding instructions changes the bitcode format, and it will take some effort; to maintain compatibility with the previous version. Only add an instruction; if it is absolutely necessary. #. ``llvm/include/llvm/IR/Instruction.def``:. add a number for your instruction and an enum name. #. ``llvm/include/llvm/IR/Instructions.h``:. add a definition for the class that will represent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:8019,Testability,test,test,8019,"to other; legal nodes for this target. #. ``include/llvm/Target/TargetSelectionDAG.td``:. Most current targets supported by LLVM generate code using the DAGToDAG; method, where SelectionDAG nodes are pattern matched to target-specific; nodes, which represent individual instructions. In order for the targets to; match an instruction to your new node, you must add a def for that node to; the list in this file, with the appropriate type constraints. Look at; ``add``, ``bswap``, and ``fadd`` for examples. #. ``lib/Target/PowerPC/PPCInstrInfo.td``:. Each target has a tablegen file that describes the target's instruction set.; For targets that use the DAGToDAG instruction selection framework, add a; pattern for your new node that uses one or more target nodes. Documentation; for this is a bit sparse right now, but there are several decent examples.; See the patterns for ``rotl`` in ``PPCInstrInfo.td``. #. TODO: document complex patterns. #. ``llvm/test/CodeGen/*``:. Add test cases for your new node to the test suite.; ``llvm/test/CodeGen/X86/bswap.ll`` is a good example. Adding a new instruction; ========================. .. warning::. Adding instructions changes the bitcode format, and it will take some effort; to maintain compatibility with the previous version. Only add an instruction; if it is absolutely necessary. #. ``llvm/include/llvm/IR/Instruction.def``:. add a number for your instruction and an enum name. #. ``llvm/include/llvm/IR/Instructions.h``:. add a definition for the class that will represent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:8039,Testability,test,test,8039,"``include/llvm/Target/TargetSelectionDAG.td``:. Most current targets supported by LLVM generate code using the DAGToDAG; method, where SelectionDAG nodes are pattern matched to target-specific; nodes, which represent individual instructions. In order for the targets to; match an instruction to your new node, you must add a def for that node to; the list in this file, with the appropriate type constraints. Look at; ``add``, ``bswap``, and ``fadd`` for examples. #. ``lib/Target/PowerPC/PPCInstrInfo.td``:. Each target has a tablegen file that describes the target's instruction set.; For targets that use the DAGToDAG instruction selection framework, add a; pattern for your new node that uses one or more target nodes. Documentation; for this is a bit sparse right now, but there are several decent examples.; See the patterns for ``rotl`` in ``PPCInstrInfo.td``. #. TODO: document complex patterns. #. ``llvm/test/CodeGen/*``:. Add test cases for your new node to the test suite.; ``llvm/test/CodeGen/X86/bswap.ll`` is a good example. Adding a new instruction; ========================. .. warning::. Adding instructions changes the bitcode format, and it will take some effort; to maintain compatibility with the previous version. Only add an instruction; if it is absolutely necessary. #. ``llvm/include/llvm/IR/Instruction.def``:. add a number for your instruction and an enum name. #. ``llvm/include/llvm/IR/Instructions.h``:. add a definition for the class that will represent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/Bitcode/Write",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:9499,Testability,test,test,9499,"or the class that will represent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/Bitcode/Writer/BitcodeWriter.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/IR/Instruction.cpp``:. add a case for how your instruction will be printed out to assembly. #. ``llvm/lib/IR/Instructions.cpp``:. implement the class you defined in ``llvm/include/llvm/Instructions.h``. #. Test your instruction. #. ``llvm/lib/Target/*``:. add support for your instruction to code generators, or add a lowering pass. #. ``llvm/test/*``:. add your test cases to the test suite. Also, you need to implement (or modify) any analyses or passes that you want to; understand this new instruction. Adding a new type; =================. .. warning::. Adding new types changes the bitcode format, and will break compatibility with; currently-existing LLVM installations. Only add new types if it is absolutely; necessary. Adding a fundamental type; -------------------------. #. ``llvm/include/llvm/IR/Type.h``:. add enum for the new type; add static ``Type*`` for this type. #. ``llvm/lib/IR/Type.cpp`` and ``llvm/lib/CodeGen/ValueTypes.cpp``:. add mapping from ``TypeID`` => ``Type*``; initialize the static ``Type*``. #. ``llvm/include/llvm-c/Core.h`` and ``llvm/lib/IR/Core.cpp``:. add enum ``LLVMTypeKind`` and modify; ``LLVMTypeKind LLVMGetTypeKind(LLVMTypeRef Ty)`` for the new type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add ability to parse in the type from text assembly. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add a token ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:9519,Testability,test,test,9519,"sent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/Bitcode/Writer/BitcodeWriter.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/IR/Instruction.cpp``:. add a case for how your instruction will be printed out to assembly. #. ``llvm/lib/IR/Instructions.cpp``:. implement the class you defined in ``llvm/include/llvm/Instructions.h``. #. Test your instruction. #. ``llvm/lib/Target/*``:. add support for your instruction to code generators, or add a lowering pass. #. ``llvm/test/*``:. add your test cases to the test suite. Also, you need to implement (or modify) any analyses or passes that you want to; understand this new instruction. Adding a new type; =================. .. warning::. Adding new types changes the bitcode format, and will break compatibility with; currently-existing LLVM installations. Only add new types if it is absolutely; necessary. Adding a fundamental type; -------------------------. #. ``llvm/include/llvm/IR/Type.h``:. add enum for the new type; add static ``Type*`` for this type. #. ``llvm/lib/IR/Type.cpp`` and ``llvm/lib/CodeGen/ValueTypes.cpp``:. add mapping from ``TypeID`` => ``Type*``; initialize the static ``Type*``. #. ``llvm/include/llvm-c/Core.h`` and ``llvm/lib/IR/Core.cpp``:. add enum ``LLVMTypeKind`` and modify; ``LLVMTypeKind LLVMGetTypeKind(LLVMTypeRef Ty)`` for the new type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add ability to parse in the type from text assembly. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add a token for that type. #. ``llvm/lib/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:9537,Testability,test,test,9537,"sent your instruction. #. ``llvm/include/llvm/IR/InstVisitor.h``:. add a prototype for a visitor to your new instruction type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add a new token to parse your instruction from assembly text file. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add the grammar on how your instruction can be read and what it will; construct as a result. #. ``llvm/lib/Bitcode/Reader/BitcodeReader.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/Bitcode/Writer/BitcodeWriter.cpp``:. add a case for your instruction and how it will be parsed from bitcode. #. ``llvm/lib/IR/Instruction.cpp``:. add a case for how your instruction will be printed out to assembly. #. ``llvm/lib/IR/Instructions.cpp``:. implement the class you defined in ``llvm/include/llvm/Instructions.h``. #. Test your instruction. #. ``llvm/lib/Target/*``:. add support for your instruction to code generators, or add a lowering pass. #. ``llvm/test/*``:. add your test cases to the test suite. Also, you need to implement (or modify) any analyses or passes that you want to; understand this new instruction. Adding a new type; =================. .. warning::. Adding new types changes the bitcode format, and will break compatibility with; currently-existing LLVM installations. Only add new types if it is absolutely; necessary. Adding a fundamental type; -------------------------. #. ``llvm/include/llvm/IR/Type.h``:. add enum for the new type; add static ``Type*`` for this type. #. ``llvm/lib/IR/Type.cpp`` and ``llvm/lib/CodeGen/ValueTypes.cpp``:. add mapping from ``TypeID`` => ``Type*``; initialize the static ``Type*``. #. ``llvm/include/llvm-c/Core.h`` and ``llvm/lib/IR/Core.cpp``:. add enum ``LLVMTypeKind`` and modify; ``LLVMTypeKind LLVMGetTypeKind(LLVMTypeRef Ty)`` for the new type. #. ``llvm/lib/AsmParser/LLLexer.cpp``:. add ability to parse in the type from text assembly. #. ``llvm/lib/AsmParser/LLParser.cpp``:. add a token for that type. #. ``llvm/lib/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5092,Usability,simpl,simpler,5092,"electionDAG.cpp``:. Add code to print the node to ``getOperationName``. If your new node can be; evaluated at compile time when given constant arguments (such as an add of a; constant with another constant), find the ``getNode`` method that takes the; appropriate number of arguments, and add a case for your node to the switch; statement that performs constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to suppor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:6345,Usability,simpl,simple,6345,"need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSRL`` are good starting places. #. ``lib/Target/PowerPC/PPCISelLowering.cpp``:. Each target has an implementation of the ``TargetLowering`` class, usually in; its own file (although some targets include it in the same file as the; DAGToDAGISel). The default behavior for a target is to assume that your new; node is legal for all types that are legal for that target. If this target; does not natively support your node, then tell the target to either Promote; it (if it is supported at a larger type) or Expand it. This will cause the; code you wrote in ``LegalizeOp`` above to decompose your new node into other; legal nodes for this target. #. ``include/llvm/Target/TargetSelectionDAG.td``:. Most current targets supported by LLVM generate code using the DAGToDAG; method, where SelectionDAG nodes are pattern matched to target-specific; nodes, which represent individual instructions. In order for the targets to; match an instruction to your new node, you must add ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:1927,Availability,error,error,1927,"; ``IMAGE_REL_AMD64_ADDR32NB`` (64-bit). .. code-block:: text. .text; fun:; mov foo@IMGREL(%ebx, %ecx, 4), %eax. .section .pdata; .long fun@IMGREL; .long (fun@imgrel + 0x3F); .long $unwind$fun@imgrel. **.secrel32** generates a relocation that corresponds to the COFF relocation; types ``IMAGE_REL_I386_SECREL`` (32-bit) or ``IMAGE_REL_AMD64_SECREL`` (64-bit). **.secidx** relocation generates an index of the section that contains; the target. It corresponds to the COFF relocation types; ``IMAGE_REL_I386_SECTION`` (32-bit) or ``IMAGE_REL_AMD64_SECTION`` (64-bit). .. code-block:: none. .section .debug$S,""rn""; .long 4; .long 242; .long 40; .secrel32 _function_name + 0; .secidx _function_name; ... ``.linkonce`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:. ``.linkonce [ comdat type ]``. Supported COMDAT types:. ``discard``; Discards duplicate sections with the same COMDAT symbol. This is the default; if no type is specified. ``one_only``; If the symbol is defined multiple times, the linker issues an error. ``same_size``; Duplicates are discarded, but the linker issues an error if any have; different sizes. ``same_contents``; Duplicates are discarded, but the linker issues an error if any duplicates; do not have exactly the same content. ``largest``; Links the largest section from among the duplicates. ``newest``; Links the newest section from among the duplicates. .. code-block:: gas. .section .text$foo; .linkonce; ... ``.section`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. MC supports passing the information in ``.linkonce`` at the end of; ``.section``. For example, these two codes are equivalent. .. code-block:: gas. .section secName, ""dr"", discard, ""Symbol1""; .globl Symbol1; Symbol1:; .long 1. .. code-block:: gas. .section secName, ""dr""; .linkonce discard; .globl Symbol1; Symbol1:; .long 1. Note that in the combined form the COMDAT symbol is explicit. This; extension exists to support multiple sections with the same name ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:2000,Availability,error,error,2000,"bx, %ecx, 4), %eax. .section .pdata; .long fun@IMGREL; .long (fun@imgrel + 0x3F); .long $unwind$fun@imgrel. **.secrel32** generates a relocation that corresponds to the COFF relocation; types ``IMAGE_REL_I386_SECREL`` (32-bit) or ``IMAGE_REL_AMD64_SECREL`` (64-bit). **.secidx** relocation generates an index of the section that contains; the target. It corresponds to the COFF relocation types; ``IMAGE_REL_I386_SECTION`` (32-bit) or ``IMAGE_REL_AMD64_SECTION`` (64-bit). .. code-block:: none. .section .debug$S,""rn""; .long 4; .long 242; .long 40; .secrel32 _function_name + 0; .secidx _function_name; ... ``.linkonce`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:. ``.linkonce [ comdat type ]``. Supported COMDAT types:. ``discard``; Discards duplicate sections with the same COMDAT symbol. This is the default; if no type is specified. ``one_only``; If the symbol is defined multiple times, the linker issues an error. ``same_size``; Duplicates are discarded, but the linker issues an error if any have; different sizes. ``same_contents``; Duplicates are discarded, but the linker issues an error if any duplicates; do not have exactly the same content. ``largest``; Links the largest section from among the duplicates. ``newest``; Links the newest section from among the duplicates. .. code-block:: gas. .section .text$foo; .linkonce; ... ``.section`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. MC supports passing the information in ``.linkonce`` at the end of; ``.section``. For example, these two codes are equivalent. .. code-block:: gas. .section secName, ""dr"", discard, ""Symbol1""; .globl Symbol1; Symbol1:; .long 1. .. code-block:: gas. .section secName, ""dr""; .linkonce discard; .globl Symbol1; Symbol1:; .long 1. Note that in the combined form the COMDAT symbol is explicit. This; extension exists to support multiple sections with the same name in; different COMDATs:. .. code-block:: gas. .section secName, ""dr"", discard, ""Symbol1""; .gl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:2106,Availability,error,error,2106,"32** generates a relocation that corresponds to the COFF relocation; types ``IMAGE_REL_I386_SECREL`` (32-bit) or ``IMAGE_REL_AMD64_SECREL`` (64-bit). **.secidx** relocation generates an index of the section that contains; the target. It corresponds to the COFF relocation types; ``IMAGE_REL_I386_SECTION`` (32-bit) or ``IMAGE_REL_AMD64_SECTION`` (64-bit). .. code-block:: none. .section .debug$S,""rn""; .long 4; .long 242; .long 40; .secrel32 _function_name + 0; .secidx _function_name; ... ``.linkonce`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:. ``.linkonce [ comdat type ]``. Supported COMDAT types:. ``discard``; Discards duplicate sections with the same COMDAT symbol. This is the default; if no type is specified. ``one_only``; If the symbol is defined multiple times, the linker issues an error. ``same_size``; Duplicates are discarded, but the linker issues an error if any have; different sizes. ``same_contents``; Duplicates are discarded, but the linker issues an error if any duplicates; do not have exactly the same content. ``largest``; Links the largest section from among the duplicates. ``newest``; Links the newest section from among the duplicates. .. code-block:: gas. .section .text$foo; .linkonce; ... ``.section`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. MC supports passing the information in ``.linkonce`` at the end of; ``.section``. For example, these two codes are equivalent. .. code-block:: gas. .section secName, ""dr"", discard, ""Symbol1""; .globl Symbol1; Symbol1:; .long 1. .. code-block:: gas. .section secName, ""dr""; .linkonce discard; .globl Symbol1; Symbol1:; .long 1. Note that in the combined form the COMDAT symbol is explicit. This; extension exists to support multiple sections with the same name in; different COMDATs:. .. code-block:: gas. .section secName, ""dr"", discard, ""Symbol1""; .globl Symbol1; Symbol1:; .long 1. .section secName, ""dr"", discard, ""Symbol2""; .globl Symbol2; Symbol2:; .long 1. In addi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:6597,Availability,error,error,6597,"_LINK_ORDER. If it is present, a symbol; must be given that identifies the section to be placed is the; .sh_link. .. code-block:: gas. .section .foo,""a"",@progbits; .Ltmp:; .section .bar,""ao"",@progbits,.Ltmp. which is equivalent to just. .. code-block:: gas. .section .foo,""a"",@progbits; .section .bar,""ao"",@progbits,.foo. ``.linker-options`` Section (linker options); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In order to support passing linker options from the frontend to the linker, a; special section of type ``SHT_LLVM_LINKER_OPTIONS`` (usually named; ``.linker-options`` though the name is not significant as it is identified by; the type). The contents of this section is a simple pair-wise encoding of; directives for consideration by the linker. The strings are encoded as standard; null-terminated UTF-8 strings. They are emitted inline to avoid having the; linker traverse the object file for retrieving the value. The linker is; permitted to not honour the option and instead provide a warning/error to the; user that the requested option was not honoured. The section has type ``SHT_LLVM_LINKER_OPTIONS`` and has the ``SHF_EXCLUDE``; flag to ensure that the section is treated as opaque by linkers which do not; support the feature and will not be emitted into the final linked binary. This would be equivalent to the follow raw assembly:. .. code-block:: gas. .section "".linker-options"",""e"",@llvm_linker_options; .asciz ""option 1""; .asciz ""value 1""; .asciz ""option 2""; .asciz ""value 2"". The following directives are specified:. - lib. The parameter identifies a library to be linked against. The library will; be looked up in the default and any specified library search paths; (specified to this point). - libpath. The parameter identifies an additional library search path to be considered; when looking up libraries after the inclusion of this option. ``SHT_LLVM_DEPENDENT_LIBRARIES`` Section (Dependent Libraries); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:9158,Availability,error,error,9158,"n is used to pass a call graph profile to the linker which can be; used to optimize the placement of sections. It contains a sequence of; (from symbol, to symbol, weight) tuples. It shall have a type of ``SHT_LLVM_CALL_GRAPH_PROFILE`` (0x6fff4c02), shall; have the ``SHF_EXCLUDE`` flag set, the ``sh_link`` member shall hold the section; header index of the associated symbol table, and shall have a ``sh_entsize`` of; 16. It should be named ``.llvm.call-graph-profile``. The contents of the section shall be a sequence of ``Elf_CGProfile`` entries. .. code-block:: c. typedef struct {; Elf_Word cgp_from;; Elf_Word cgp_to;; Elf_Xword cgp_weight;; } Elf_CGProfile;. cgp_from; The symbol index of the source of the edge. cgp_to; The symbol index of the destination of the edge. cgp_weight; The weight of the edge. This is represented in assembly as:. .. code-block:: gas. .cg_profile from, to, 42. ``.cg_profile`` directives are processed at the end of the file. It is an error; if either ``from`` or ``to`` are undefined temporary symbols. If either symbol; is a temporary symbol, then the section symbol is used instead. If either; symbol is undefined, then that symbol is defined as if ``.weak symbol`` has been; written at the end of the file. This forces the symbol to show up in the symbol; table. ``SHT_LLVM_ADDRSIG`` Section (address-significance table); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to mark symbols as address-significant, i.e. the address; of the symbol is used in a comparison or leaks outside the translation unit. It; has the same meaning as the absence of the LLVM attributes ``unnamed_addr``; and ``local_unnamed_addr``. Any sections referred to by symbols that are not marked as address-significant; in any object file may be safely merged by a linker without breaking the; address uniqueness guarantee provided by the C and C++ language standards. The contents of the section are a sequence of ULEB128-encoded integers; referring to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:14940,Availability,mask,mask,14940,"s called as taken; from a PGO profile. This will always be zero if PGO was not used or the; function was not encountered in the profile. #. Basic Block Frequencies - Encoded as raw block frequency value taken from; MBFI analysis. This value is an integer that encodes the relative frequency; compared to the entry block. More information can be found in; 'llvm/Support/BlockFrequency.h'. #. Branch Probabilities - Encoded as raw numerator for branch probability; taken from MBPI analysis. This value is the numerator for a fixed point ratio; defined in 'llvm/Support/BranchProbability.h'. It indicates the probability; that the block is followed by a given successor block during execution. This extra data requires version 2 or above. This is necessary since successors; of basic blocks won't know their index but will know their BB ID. Example of BBAddrMap with PGO data:. .. code-block:: gas. .section "".llvm_bb_addr_map"","""",@llvm_bb_addr_map; .byte 2 # version number; .byte 7 # feature byte - PGO analyses enabled mask; .quad .Lfunc_begin0 # address of the function; .uleb128 4 # number of basic blocks; # BB record for BB_0; .uleb128 0 # BB_0 BB ID; .uleb128 .Lfunc_begin0-.Lfunc_begin0 # BB_0 offset relative to function entry (always zero); .uleb128 .LBB_END0_0-.Lfunc_begin0 # BB_0 size; .byte 0x18 # BB_0 metadata (multiple successors); # BB record for BB_1; .uleb128 1 # BB_1 BB ID; .uleb128 .LBB0_1-.LBB_END0_0 # BB_1 offset relative to the end of last block (BB_0).; .uleb128 .LBB_END0_1-.LBB0_1 # BB_1 size; .byte 0x0 # BB_1 metadata (two successors); # BB record for BB_2; .uleb128 2 # BB_2 BB ID; .uleb128 .LBB0_2-.LBB_END1_0 # BB_2 offset relative to the end of last block (BB_1).; .uleb128 .LBB_END0_2-.LBB0_2 # BB_2 size; .byte 0x0 # BB_2 metadata (one successor); # BB record for BB_3; .uleb128 3 # BB_3 BB ID; .uleb128 .LBB0_3-.LBB_END0_2 # BB_3 offset relative to the end of last block (BB_2).; .uleb128 .LBB_END0_3-.LBB0_3 # BB_3 size; .byte 0x0 # BB_3 metadata (zero successor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:21391,Modifiability,extend,extended,21391,"apEnd* options may be repeated as needed. Syntax:; ``.cv_def_range`` *RangeStart RangeEnd* [ *GapStart GapEnd* ] ``,`` *bytes*. ``.cv_stringtable`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``.cv_filechecksums`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``.cv_filechecksumoffset`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_filechecksumoffset`` *FileNumber*. ``.cv_fpo_data`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_fpo_data`` *procsym*. Target Specific Behaviour; =========================. X86; ---. Relocations; ^^^^^^^^^^^. **@ABS8** can be applied to symbols which appear as immediate operands to; instructions that have an 8-bit immediate form for that operand. It causes; the assembler to use the 8-bit form and an 8-bit relocation (e.g. ``R_386_8``; or ``R_X86_64_8``) for the symbol. For example:. .. code-block:: gas. cmpq $foo@ABS8, %rdi. This causes the assembler to select the form of the 64-bit ``cmpq`` instruction; that takes an 8-bit immediate operand that is sign extended to 64 bits, as; opposed to ``cmpq $foo, %rdi`` which takes a 32-bit immediate operand. This; is also not the same as ``cmpb $foo, %dil``, which is an 8-bit comparison. **@GOTPCREL_NORELAX** can be used in place of ``@GOTPCREL`` to guarantee that; the assembler emits an ``R_X86_64_GOTPCREL`` relocation instead of a relaxable; ``R_X86_64[_REX]_GOTPCRELX`` relocation. Windows on ARM; --------------. Stack Probe Emission; ^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2012) emits stack probes; in the following fashion:. .. code-block:: gas. movw r4, #constant; bl __chkstk; sub.w sp, sp, r4. However, this has the limitation of 32 MiB (16MiB). In order to accommodate; larger binaries, LLVM supports the use of ``-mcmodel=large`` to allow a 4GiB; range via a slight deviation. It will generate an indirect jump as follows:. .. code-block:: gas. movw r4, #constant; movw r12, :lower16:__chkstk; movt r12, :upper16:__chkstk; blx r12; sub.w sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:22582,Modifiability,extend,extends,22582,"d in place of ``@GOTPCREL`` to guarantee that; the assembler emits an ``R_X86_64_GOTPCREL`` relocation instead of a relaxable; ``R_X86_64[_REX]_GOTPCRELX`` relocation. Windows on ARM; --------------. Stack Probe Emission; ^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2012) emits stack probes; in the following fashion:. .. code-block:: gas. movw r4, #constant; bl __chkstk; sub.w sp, sp, r4. However, this has the limitation of 32 MiB (16MiB). In order to accommodate; larger binaries, LLVM supports the use of ``-mcmodel=large`` to allow a 4GiB; range via a slight deviation. It will generate an indirect jump as follows:. .. code-block:: gas. movw r4, #constant; movw r12, :lower16:__chkstk; movt r12, :upper16:__chkstk; blx r12; sub.w sp, sp, r4. Variable Length Arrays; ^^^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2012) does not permit the; emission of Variable Length Arrays (VLAs). The Windows ARM Itanium ABI extends the base ABI by adding support for emitting; a dynamic stack allocation. When emitting a variable stack allocation, a call; to ``__chkstk`` is emitted unconditionally to ensure that guard pages are setup; properly. The emission of this stack probe emission is handled similar to the; standard stack probe emission. The MSVC environment does not emit code for VLAs currently. Windows on ARM64; ----------------. Stack Probe Emission; ^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2017) emits stack probes; in the following fashion:. .. code-block:: gas. mov x15, #constant; bl __chkstk; sub sp, sp, x15, lsl #4. However, this has the limitation of 256 MiB (128MiB). In order to accommodate; larger binaries, LLVM supports the use of ``-mcmodel=large`` to allow a 8GiB; (4GiB) range via a slight deviation. It will generate an indirect jump as; follows:. .. code-block:: gas. mov x15, #constant; adrp x16, __chkstk; add x16, x16, :lo12:__chkstk; blr x16; sub sp, sp, x15, lsl #4. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:22679,Modifiability,variab,variable,22679,"d in place of ``@GOTPCREL`` to guarantee that; the assembler emits an ``R_X86_64_GOTPCREL`` relocation instead of a relaxable; ``R_X86_64[_REX]_GOTPCRELX`` relocation. Windows on ARM; --------------. Stack Probe Emission; ^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2012) emits stack probes; in the following fashion:. .. code-block:: gas. movw r4, #constant; bl __chkstk; sub.w sp, sp, r4. However, this has the limitation of 32 MiB (16MiB). In order to accommodate; larger binaries, LLVM supports the use of ``-mcmodel=large`` to allow a 4GiB; range via a slight deviation. It will generate an indirect jump as follows:. .. code-block:: gas. movw r4, #constant; movw r12, :lower16:__chkstk; movt r12, :upper16:__chkstk; blx r12; sub.w sp, sp, r4. Variable Length Arrays; ^^^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2012) does not permit the; emission of Variable Length Arrays (VLAs). The Windows ARM Itanium ABI extends the base ABI by adding support for emitting; a dynamic stack allocation. When emitting a variable stack allocation, a call; to ``__chkstk`` is emitted unconditionally to ensure that guard pages are setup; properly. The emission of this stack probe emission is handled similar to the; standard stack probe emission. The MSVC environment does not emit code for VLAs currently. Windows on ARM64; ----------------. Stack Probe Emission; ^^^^^^^^^^^^^^^^^^^^. The reference implementation (Microsoft Visual Studio 2017) emits stack probes; in the following fashion:. .. code-block:: gas. mov x15, #constant; bl __chkstk; sub sp, sp, x15, lsl #4. However, this has the limitation of 256 MiB (128MiB). In order to accommodate; larger binaries, LLVM supports the use of ``-mcmodel=large`` to allow a 8GiB; (4GiB) range via a slight deviation. It will generate an indirect jump as; follows:. .. code-block:: gas. mov x15, #constant; adrp x16, __chkstk; add x16, x16, :lo12:__chkstk; blr x16; sub sp, sp, x15, lsl #4. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:4025,Performance,load,loaded,4025,"ol2""; .globl Symbol2; Symbol2:; .long 1. In addition to the types allowed with ``.linkonce``, ``.section`` also accepts; ``associative``. The meaning is that the section is linked if a certain other; COMDAT section is linked. This other section is indicated by the comdat symbol; in this directive. It can be any symbol defined in the associated section, but; is usually the associated section's comdat. The following restrictions apply to the associated section:. 1. It must be a COMDAT section.; 2. It cannot be another associative COMDAT section. In the following example the symbol ``sym`` is the comdat symbol of ``.foo``; and ``.bar`` is associated to ``.foo``. .. code-block:: gas. 	.section	.foo,""bw"",discard, ""sym""; 	.section	.bar,""rd"",associative, ""sym"". MC supports these flags in the COFF ``.section`` directive:. - ``b``: BSS section (``IMAGE_SCN_CNT_INITIALIZED_DATA``); - ``d``: Data section (``IMAGE_SCN_CNT_UNINITIALIZED_DATA``); - ``n``: Section is not loaded (``IMAGE_SCN_LNK_REMOVE``); - ``r``: Read-only; - ``s``: Shared section; - ``w``: Writable; - ``x``: Executable section; - ``y``: Not readable; - ``D``: Discardable (``IMAGE_SCN_MEM_DISCARDABLE``). These flags are all compatible with gas, with the exception of the ``D`` flag,; which gnu as does not support. For gas compatibility, sections with a name; starting with "".debug"" are implicitly discardable. ARM64/COFF-Dependent; --------------------. Relocations; ^^^^^^^^^^^. The following additional symbol variants are supported:. **:secrel_lo12:** generates a relocation that corresponds to the COFF relocation; types ``IMAGE_REL_ARM64_SECREL_LOW12A`` or ``IMAGE_REL_ARM64_SECREL_LOW12L``. **:secrel_hi12:** generates a relocation that corresponds to the COFF relocation; type ``IMAGE_REL_ARM64_SECREL_HIGH12A``. .. code-block:: gas. add x0, x0, :secrel_hi12:symbol; ldr x0, [x0, :secrel_lo12:symbol]. add x1, x1, :secrel_hi12:symbol; add x1, x1, :secrel_lo12:symbol; ... ELF-Dependent; -------------. ``.section`` Direc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:8262,Performance,optimiz,optimize,8262,"efault and any specified library search paths; (specified to this point). - libpath. The parameter identifies an additional library search path to be considered; when looking up libraries after the inclusion of this option. ``SHT_LLVM_DEPENDENT_LIBRARIES`` Section (Dependent Libraries); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section contains strings specifying libraries to be added to the link by; the linker. The section should be consumed by the linker and not written to the output. The strings are encoded as standard null-terminated UTF-8 strings. For example:. .. code-block:: gas. .section "".deplibs"",""MS"",@llvm_dependent_libraries,1; .asciz ""library specifier 1""; .asciz ""library specifier 2"". The interpretation of the library specifiers is defined by the consuming linker. ``SHT_LLVM_CALL_GRAPH_PROFILE`` Section (Call Graph Profile); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to pass a call graph profile to the linker which can be; used to optimize the placement of sections. It contains a sequence of; (from symbol, to symbol, weight) tuples. It shall have a type of ``SHT_LLVM_CALL_GRAPH_PROFILE`` (0x6fff4c02), shall; have the ``SHF_EXCLUDE`` flag set, the ``sh_link`` member shall hold the section; header index of the associated symbol table, and shall have a ``sh_entsize`` of; 16. It should be named ``.llvm.call-graph-profile``. The contents of the section shall be a sequence of ``Elf_CGProfile`` entries. .. code-block:: c. typedef struct {; Elf_Word cgp_from;; Elf_Word cgp_to;; Elf_Xword cgp_weight;; } Elf_CGProfile;. cgp_from; The symbol index of the source of the edge. cgp_to; The symbol index of the destination of the edge. cgp_weight; The weight of the edge. This is represented in assembly as:. .. code-block:: gas. .cg_profile from, to, 42. ``.cg_profile`` directives are processed at the end of the file. It is an error; if either ``from`` or ``to`` are undefined temporary symbols. If either",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:17899,Performance,perform,perform,17899," probabilities); .uleb128 2 # BB_1 successor 1 BB ID (only enabled with branch probabilities); .uleb128 0x11111111 # BB_1 successor 1 branch probability (only enabled with branch probabilities); .uleb128 3 # BB_1 successor 2 BB ID (only enabled with branch probabilities); .uleb128 0x11111111 # BB_1 successor 2 branch probability (only enabled with branch probabilities); # PGO data record for BB_2; .uleb128 18 # BB_2 basic block frequency (only when enabled); .uleb128 1 # BB_2 successors count (only enabled with branch probabilities); .uleb128 3 # BB_2 successor 1 BB ID (only enabled with branch probabilities); .uleb128 0xffffffff # BB_2 successor 1 branch probability (only enabled with branch probabilities); # PGO data record for BB_3; .uleb128 1000 # BB_3 basic block frequency (only when enabled); .uleb128 0 # BB_3 successors count (only enabled with branch probabilities). ``SHT_LLVM_OFFLOADING`` Section (offloading data); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores the binary data used to perform offloading device linking; and execution, creating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:18598,Performance,perform,perform,18598," with branch probabilities); # PGO data record for BB_3; .uleb128 1000 # BB_3 basic block frequency (only when enabled); .uleb128 0 # BB_3 successors count (only enabled with branch probabilities). ``SHT_LLVM_OFFLOADING`` Section (offloading data); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores the binary data used to perform offloading device linking; and execution, creating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ``.cv_file`` Directive; ^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_file`` *FileNumber FileName* [ *checksum* ] [ *checksumkind* ]. ``.cv_func_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Syntax:; ``.cv_func_id`` *FunctionId*. ``.cv_inline_site_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Includes; ``inlined at`` source location information for use in the line table of the; caller, whether the caller is a real function or another inlined call site. Syntax:; ``.cv_inline_site_id`` *FunctionId* ``within`` *Function* ``inlined_at`` *FileNumber Line* [ *Column* ]. ``.cv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:6441,Safety,avoid,avoid,6441,"the resulting object at all. It is just used; in the assembler to differentiate the sections. The 'o' flag is mapped to SHF_LINK_ORDER. If it is present, a symbol; must be given that identifies the section to be placed is the; .sh_link. .. code-block:: gas. .section .foo,""a"",@progbits; .Ltmp:; .section .bar,""ao"",@progbits,.Ltmp. which is equivalent to just. .. code-block:: gas. .section .foo,""a"",@progbits; .section .bar,""ao"",@progbits,.foo. ``.linker-options`` Section (linker options); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In order to support passing linker options from the frontend to the linker, a; special section of type ``SHT_LLVM_LINKER_OPTIONS`` (usually named; ``.linker-options`` though the name is not significant as it is identified by; the type). The contents of this section is a simple pair-wise encoding of; directives for consideration by the linker. The strings are encoded as standard; null-terminated UTF-8 strings. They are emitted inline to avoid having the; linker traverse the object file for retrieving the value. The linker is; permitted to not honour the option and instead provide a warning/error to the; user that the requested option was not honoured. The section has type ``SHT_LLVM_LINKER_OPTIONS`` and has the ``SHF_EXCLUDE``; flag to ensure that the section is treated as opaque by linkers which do not; support the feature and will not be emitted into the final linked binary. This would be equivalent to the follow raw assembly:. .. code-block:: gas. .section "".linker-options"",""e"",@llvm_linker_options; .asciz ""option 1""; .asciz ""value 1""; .asciz ""option 2""; .asciz ""value 2"". The following directives are specified:. - lib. The parameter identifies a library to be linked against. The library will; be looked up in the default and any specified library search paths; (specified to this point). - libpath. The parameter identifies an additional library search path to be considered; when looking up libraries after the inclusion of this option. ``SHT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:9979,Safety,safe,safely,9979," of the edge. This is represented in assembly as:. .. code-block:: gas. .cg_profile from, to, 42. ``.cg_profile`` directives are processed at the end of the file. It is an error; if either ``from`` or ``to`` are undefined temporary symbols. If either symbol; is a temporary symbol, then the section symbol is used instead. If either; symbol is undefined, then that symbol is defined as if ``.weak symbol`` has been; written at the end of the file. This forces the symbol to show up in the symbol; table. ``SHT_LLVM_ADDRSIG`` Section (address-significance table); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to mark symbols as address-significant, i.e. the address; of the symbol is used in a comparison or leaks outside the translation unit. It; has the same meaning as the absence of the LLVM attributes ``unnamed_addr``; and ``local_unnamed_addr``. Any sections referred to by symbols that are not marked as address-significant; in any object file may be safely merged by a linker without breaking the; address uniqueness guarantee provided by the C and C++ language standards. The contents of the section are a sequence of ULEB128-encoded integers; referring to the symbol table indexes of the address-significant symbols. There are two associated assembly directives:. .. code-block:: gas. .addrsig. This instructs the assembler to emit an address-significance table. Without; this directive, all symbols are considered address-significant. .. code-block:: gas. .addrsig_sym sym. If ``sym`` is not otherwise referenced or defined anywhere else in the file,; this directive is a no-op. Otherwise, mark ``sym`` as address-significant. ``SHT_LLVM_SYMPART`` Section (symbol partition specification); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This section is used to mark symbols with the `partition`_ that they; belong to. An ``.llvm_sympart`` section consists of a null-terminated string; specifying the name of the partition followed by a rel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:18952,Security,checksum,checksum,18952,"reating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ``.cv_file`` Directive; ^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_file`` *FileNumber FileName* [ *checksum* ] [ *checksumkind* ]. ``.cv_func_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Syntax:; ``.cv_func_id`` *FunctionId*. ``.cv_inline_site_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Includes; ``inlined at`` source location information for use in the line table of the; caller, whether the caller is a real function or another inlined call site. Syntax:; ``.cv_inline_site_id`` *FunctionId* ``within`` *Function* ``inlined_at`` *FileNumber Line* [ *Column* ]. ``.cv_loc`` Directive; ^^^^^^^^^^^^^^^^^^^^^; The first number is a file number, must have been previously assigned with a; ``.file`` directive, the second number is the line number and optionally the; third number is a column position (zero if not specified). The remaining; optional items are ``.loc`` sub-directives. Syntax:; ``.cv_loc`` *FunctionId FileNumber* [ *Line* ] [ *Column* ] [ *prologue_end* ] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:18967,Security,checksum,checksumkind,18967,"reating a fat binary. This section is emitted during compilation; of offloading languages such as OpenMP or CUDA. If the data is intended to be; used by the device linker only, it should use the ``SHF_EXCLUDE`` flag so it is; automatically stripped from the final executable or shared library. The binary data stored in this section conforms to a custom binary format used; for storing offloading metadata. This format is effectively a string table; containing metadata accompanied by a device image. ``SHT_LLVM_LTO`` Section (LLVM bitcode for fat LTO); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; This section stores LLVM bitcode used to perform regular LTO or ThinLTO at link; time. This section is generated when the compiler enables fat LTO. This section; has the ``SHF_EXCLUDE`` flag so that it is stripped from the final executable; or shared library. CodeView-Dependent; ------------------. ``.cv_file`` Directive; ^^^^^^^^^^^^^^^^^^^^^^; Syntax:; ``.cv_file`` *FileNumber FileName* [ *checksum* ] [ *checksumkind* ]. ``.cv_func_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Syntax:; ``.cv_func_id`` *FunctionId*. ``.cv_inline_site_id`` Directive; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Introduces a function ID that can be used with ``.cv_loc``. Includes; ``inlined at`` source location information for use in the line table of the; caller, whether the caller is a real function or another inlined call site. Syntax:; ``.cv_inline_site_id`` *FunctionId* ``within`` *Function* ``inlined_at`` *FileNumber Line* [ *Column* ]. ``.cv_loc`` Directive; ^^^^^^^^^^^^^^^^^^^^^; The first number is a file number, must have been previously assigned with a; ``.file`` directive, the second number is the line number and optionally the; third number is a column position (zero if not specified). The remaining; optional items are ``.loc`` sub-directives. Syntax:; ``.cv_loc`` *FunctionId FileNumber* [ *Line* ] [ *Column* ] [ *prologue_end* ] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:6272,Usability,simpl,simple,6272,"ctions named ``.text``. .. code-block:: gas. 	.section	.text,""ax"",@progbits,unique,1; nop. 	.section	.text,""ax"",@progbits,unique,2; nop. The unique number is not present in the resulting object at all. It is just used; in the assembler to differentiate the sections. The 'o' flag is mapped to SHF_LINK_ORDER. If it is present, a symbol; must be given that identifies the section to be placed is the; .sh_link. .. code-block:: gas. .section .foo,""a"",@progbits; .Ltmp:; .section .bar,""ao"",@progbits,.Ltmp. which is equivalent to just. .. code-block:: gas. .section .foo,""a"",@progbits; .section .bar,""ao"",@progbits,.foo. ``.linker-options`` Section (linker options); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In order to support passing linker options from the frontend to the linker, a; special section of type ``SHT_LLVM_LINKER_OPTIONS`` (usually named; ``.linker-options`` though the name is not significant as it is identified by; the type). The contents of this section is a simple pair-wise encoding of; directives for consideration by the linker. The strings are encoded as standard; null-terminated UTF-8 strings. They are emitted inline to avoid having the; linker traverse the object file for retrieving the value. The linker is; permitted to not honour the option and instead provide a warning/error to the; user that the requested option was not honoured. The section has type ``SHT_LLVM_LINKER_OPTIONS`` and has the ``SHF_EXCLUDE``; flag to ensure that the section is treated as opaque by linkers which do not; support the feature and will not be emitted into the final linked binary. This would be equivalent to the follow raw assembly:. .. code-block:: gas. .section "".linker-options"",""e"",@llvm_linker_options; .asciz ""option 1""; .asciz ""value 1""; .asciz ""option 2""; .asciz ""value 2"". The following directives are specified:. - lib. The parameter identifies a library to be linked against. The library will; be looked up in the default and any specified library search paths; (specifi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Extensions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:2973,Availability,avail,available,2973,"*is* the add instruction. The; ""assignment"" doesn't explicitly ""store"" anything to any ""virtual register"";; the ""``=``"" is more like the mathematical sense of equality. Longer explanation: In order to generate a textual representation of the; IR, some kind of name has to be given to each instruction so that other; instructions can textually reference it. However, the isomorphic in-memory; representation that you manipulate from C++ has no such restriction since; instructions can simply keep pointers to any other ``Value``'s that they; reference. In fact, the names of dummy numbered temporaries like ``%1`` are; not explicitly represented in the in-memory representation at all (see; ``Value::getName()``). Source Languages; ================. What source languages are supported?; ------------------------------------. LLVM currently has full support for C and C++ source languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3879,Energy Efficiency,adapt,adapts,3879,"ny other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:4313,Energy Efficiency,efficient,efficient,4313,"mpiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in this regard. What support is there for a higher level source language constructs for building a compiler?; --------------------------------------------------------------------------------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3108,Integrability,interface,interface,3108,"structions can textually reference it. However, the isomorphic in-memory; representation that you manipulate from C++ has no such restriction since; instructions can simply keep pointers to any other ``Value``'s that they; reference. In fact, the names of dummy numbered temporaries like ``%1`` are; not explicitly represented in the in-memory representation at all (see; ``Value::getName()``). Source Languages; ================. What source languages are supported?; ------------------------------------. LLVM currently has full support for C and C++ source languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's nati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3700,Integrability,interface,interface,3700,". Source Languages; ================. What source languages are supported?; ------------------------------------. LLVM currently has full support for C and C++ source languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:4794,Integrability,interface,interface,4794,"t a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in this regard. What support is there for a higher level source language constructs for building a compiler?; --------------------------------------------------------------------------------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities for lexical nor semantic analysis. I don't understand the ``GetElementPtr`` instruction. Help!; -----------------------------------------------------------; See `The Often Misunderstood GEP Instruction <GetElementPtr.html>`_. Using the C and C++ Front Ends; ==============================. Can I compile C or C++ code to platform-independent LLVM bitcode?; -----------------------------------------------------------------; No. C and C++ are inherently platform-dependent languages. The most obvious; example of t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:5793,Integrability,depend,dependent,5793,"r. The C interface was designed to require very little memory; management, and so is straightforward in this regard. What support is there for a higher level source language constructs for building a compiler?; --------------------------------------------------------------------------------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities for lexical nor semantic analysis. I don't understand the ``GetElementPtr`` instruction. Help!; -----------------------------------------------------------; See `The Often Misunderstood GEP Instruction <GetElementPtr.html>`_. Using the C and C++ Front Ends; ==============================. Can I compile C or C++ code to platform-independent LLVM bitcode?; -----------------------------------------------------------------; No. C and C++ are inherently platform-dependent languages. The most obvious; example of this is the preprocessor. A very common way that C code is made; portable is by using the preprocessor to include platform-specific code. In; practice, information about other platforms is lost after preprocessing, so; the result is inherently dependent on the platform that the preprocessing was; targeting. Another example is ``sizeof``. It's common for ``sizeof(long)`` to vary; between platforms. In most C front-ends, ``sizeof`` is expanded to a; constant immediately, thus hard-wiring a platform-specific detail. Also, since many platforms define their ABIs in terms of C, and since LLVM is; lower-level than C, front-ends currently must emit platform-specific IR in; order to have the result conform to the platform ABI. Questions about code generated by the demo page; ===============================================. What is this ``llvm.global_ctors`` and ``_GLOBAL__I_a...`` stuff that happens when I ``#include <iostream>``?; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:6087,Integrability,depend,dependent,6087,"-----------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities for lexical nor semantic analysis. I don't understand the ``GetElementPtr`` instruction. Help!; -----------------------------------------------------------; See `The Often Misunderstood GEP Instruction <GetElementPtr.html>`_. Using the C and C++ Front Ends; ==============================. Can I compile C or C++ code to platform-independent LLVM bitcode?; -----------------------------------------------------------------; No. C and C++ are inherently platform-dependent languages. The most obvious; example of this is the preprocessor. A very common way that C code is made; portable is by using the preprocessor to include platform-specific code. In; practice, information about other platforms is lost after preprocessing, so; the result is inherently dependent on the platform that the preprocessing was; targeting. Another example is ``sizeof``. It's common for ``sizeof(long)`` to vary; between platforms. In most C front-ends, ``sizeof`` is expanded to a; constant immediately, thus hard-wiring a platform-specific detail. Also, since many platforms define their ABIs in terms of C, and since LLVM is; lower-level than C, front-ends currently must emit platform-specific IR in; order to have the result conform to the platform ABI. Questions about code generated by the demo page; ===============================================. What is this ``llvm.global_ctors`` and ``_GLOBAL__I_a...`` stuff that happens when I ``#include <iostream>``?; -------------------------------------------------------------------------------------------------------------; If you ``#include`` the ``<iostream>`` header into a C++ translation unit,; the file will probably use the ``std::cin``/``std::cout``/... global objects.; However, C++ does no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:1063,Modifiability,portab,portable,1063,"===. Can I modify LLVM source code and redistribute the modified source?; -------------------------------------------------------------------; Yes. The modified source distribution must retain the copyright notice and; follow the conditions listed in the `Apache License v2.0 with LLVM Exceptions; <https://github.com/llvm/llvm-project/blob/main/llvm/LICENSE.TXT>`_. Can I modify the LLVM source code and redistribute binaries or other tools based on it, without redistributing the source?; --------------------------------------------------------------------------------------------------------------------------; Yes. This is why we distribute LLVM under a less restrictive license than GPL,; as explained in the first question above. Source Code; ===========. In what language is LLVM written?; ---------------------------------; All of the LLVM tools and libraries are written in C++ with extensive use of; the STL. How portable is the LLVM source code?; -------------------------------------; The LLVM source code should be portable to most modern Unix-like operating; systems. LLVM also has excellent support on Windows systems.; Most of the code is written in standard C++ with operating system; services abstracted to a support library. The tools required to build and; test LLVM have been ported to a plethora of platforms. What API do I use to store a value to one of the virtual registers in LLVM IR's SSA representation?; ---------------------------------------------------------------------------------------------------. In short: you can't. It's actually kind of a silly question once you grok; what's going on. Basically, in code like:. .. code-block:: llvm. %result = add i32 %foo, %bar. , ``%result`` is just a name given to the ``Value`` of the ``add``; instruction. In other words, ``%result`` *is* the add instruction. The; ""assignment"" doesn't explicitly ""store"" anything to any ""virtual register"";; the ""``=``"" is more like the mathematical sense of equality. Longer explanation",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:1168,Modifiability,portab,portable,1168,"===. Can I modify LLVM source code and redistribute the modified source?; -------------------------------------------------------------------; Yes. The modified source distribution must retain the copyright notice and; follow the conditions listed in the `Apache License v2.0 with LLVM Exceptions; <https://github.com/llvm/llvm-project/blob/main/llvm/LICENSE.TXT>`_. Can I modify the LLVM source code and redistribute binaries or other tools based on it, without redistributing the source?; --------------------------------------------------------------------------------------------------------------------------; Yes. This is why we distribute LLVM under a less restrictive license than GPL,; as explained in the first question above. Source Code; ===========. In what language is LLVM written?; ---------------------------------; All of the LLVM tools and libraries are written in C++ with extensive use of; the STL. How portable is the LLVM source code?; -------------------------------------; The LLVM source code should be portable to most modern Unix-like operating; systems. LLVM also has excellent support on Windows systems.; Most of the code is written in standard C++ with operating system; services abstracted to a support library. The tools required to build and; test LLVM have been ported to a plethora of platforms. What API do I use to store a value to one of the virtual registers in LLVM IR's SSA representation?; ---------------------------------------------------------------------------------------------------. In short: you can't. It's actually kind of a silly question once you grok; what's going on. Basically, in code like:. .. code-block:: llvm. %result = add i32 %foo, %bar. , ``%result`` is just a name given to the ``Value`` of the ``add``; instruction. In other words, ``%result`` *is* the add instruction. The; ""assignment"" doesn't explicitly ""store"" anything to any ""virtual register"";; the ""``=``"" is more like the mathematical sense of equality. Longer explanation",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3879,Modifiability,adapt,adapts,3879,"ny other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:5908,Modifiability,portab,portable,5908,"for a higher level source language constructs for building a compiler?; --------------------------------------------------------------------------------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities for lexical nor semantic analysis. I don't understand the ``GetElementPtr`` instruction. Help!; -----------------------------------------------------------; See `The Often Misunderstood GEP Instruction <GetElementPtr.html>`_. Using the C and C++ Front Ends; ==============================. Can I compile C or C++ code to platform-independent LLVM bitcode?; -----------------------------------------------------------------; No. C and C++ are inherently platform-dependent languages. The most obvious; example of this is the preprocessor. A very common way that C code is made; portable is by using the preprocessor to include platform-specific code. In; practice, information about other platforms is lost after preprocessing, so; the result is inherently dependent on the platform that the preprocessing was; targeting. Another example is ``sizeof``. It's common for ``sizeof(long)`` to vary; between platforms. In most C front-ends, ``sizeof`` is expanded to a; constant immediately, thus hard-wiring a platform-specific detail. Also, since many platforms define their ABIs in terms of C, and since LLVM is; lower-level than C, front-ends currently must emit platform-specific IR in; order to have the result conform to the platform ABI. Questions about code generated by the demo page; ===============================================. What is this ``llvm.global_ctors`` and ``_GLOBAL__I_a...`` stuff that happens when I ``#include <iostream>``?; -------------------------------------------------------------------------------------------------------------; If you ``#include`` the ``<iostre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8473,Modifiability,variab,variable,8473," a static object that gets created in every translation; unit that includes ``<iostream>``. This object has a static constructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8583,Modifiability,variab,variables,8583,"tructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8827,Modifiability,variab,variable,8827,"nderstand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to the function. For; example, this code:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; call void @foo(); ret void; }. Is optimized to:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; unreachable; }. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3143,Performance,optimiz,optimizers,3143,"structions can textually reference it. However, the isomorphic in-memory; representation that you manipulate from C++ has no such restriction since; instructions can simply keep pointers to any other ``Value``'s that they; reference. In fact, the names of dummy numbered temporaries like ``%1`` are; not explicitly represented in the in-memory representation at all (see; ``Value::getName()``). Source Languages; ================. What source languages are supported?; ------------------------------------. LLVM currently has full support for C and C++ source languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's nati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3818,Performance,optimiz,optimization,3818,"ce languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8200,Performance,optimiz,optimizers,8200,"``std::cout``, for example, the object would not necessarily be; automatically initialized before your use. To make ``std::cout`` and friends work correctly in these scenarios, the STL; that we use declares a static object that gets created in every translation; unit that includes ``<iostream>``. This object has a static constructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; --------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8520,Performance,optimiz,optimizer,8520,"tructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:9698,Performance,optimiz,optimized,9698,"-----; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to the function. For; example, this code:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; call void @foo(); ret void; }. Is optimized to:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; unreachable; }. ... with ""``opt -instcombine -simplifycfg``"". This often bites people because; ""all their code disappears"". Setting the calling convention on the caller and; callee is required for indirect calls to work, so people often ask why not; make the verifier reject this sort of thing. The answer is that this code has undefined behavior, but it is not illegal.; If we made it illegal, then every transformation that could potentially create; this would have to ensure that it doesn't, and there is valid code that can; create this sort of construct (in dead code). The sorts of things that can; cause this to happen are fairly contrived, but we still need to accept them.; Here's an example:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define internal void @bar(void()* %FP, i1 %cond) {; br i1 %cond, label %T, label %F; T:; call void %FP(); ret void; F:; call fastcc void ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:1417,Testability,test,test,1417,"ceptions; <https://github.com/llvm/llvm-project/blob/main/llvm/LICENSE.TXT>`_. Can I modify the LLVM source code and redistribute binaries or other tools based on it, without redistributing the source?; --------------------------------------------------------------------------------------------------------------------------; Yes. This is why we distribute LLVM under a less restrictive license than GPL,; as explained in the first question above. Source Code; ===========. In what language is LLVM written?; ---------------------------------; All of the LLVM tools and libraries are written in C++ with extensive use of; the STL. How portable is the LLVM source code?; -------------------------------------; The LLVM source code should be portable to most modern Unix-like operating; systems. LLVM also has excellent support on Windows systems.; Most of the code is written in standard C++ with operating system; services abstracted to a support library. The tools required to build and; test LLVM have been ported to a plethora of platforms. What API do I use to store a value to one of the virtual registers in LLVM IR's SSA representation?; ---------------------------------------------------------------------------------------------------. In short: you can't. It's actually kind of a silly question once you grok; what's going on. Basically, in code like:. .. code-block:: llvm. %result = add i32 %foo, %bar. , ``%result`` is just a name given to the ``Value`` of the ``add``; instruction. In other words, ``%result`` *is* the add instruction. The; ""assignment"" doesn't explicitly ""store"" anything to any ""virtual register"";; the ""``=``"" is more like the mathematical sense of equality. Longer explanation: In order to generate a textual representation of the; IR, some kind of name has to be given to each instruction so that other; instructions can textually reference it. However, the isomorphic in-memory; representation that you manipulate from C++ has no such restriction since; instruc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:10736,Testability,test,test,10736,"id @foo(); ret void; }. Is optimized to:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; unreachable; }. ... with ""``opt -instcombine -simplifycfg``"". This often bites people because; ""all their code disappears"". Setting the calling convention on the caller and; callee is required for indirect calls to work, so people often ask why not; make the verifier reject this sort of thing. The answer is that this code has undefined behavior, but it is not illegal.; If we made it illegal, then every transformation that could potentially create; this would have to ensure that it doesn't, and there is valid code that can; create this sort of construct (in dead code). The sorts of things that can; cause this to happen are fairly contrived, but we still need to accept them.; Here's an example:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define internal void @bar(void()* %FP, i1 %cond) {; br i1 %cond, label %T, label %F; T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code el",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:10839,Testability,test,test,10839,"ppears"". Setting the calling convention on the caller and; callee is required for indirect calls to work, so people often ask why not; make the verifier reject this sort of thing. The answer is that this code has undefined behavior, but it is not illegal.; If we made it illegal, then every transformation that could potentially create; this would have to ensure that it doesn't, and there is valid code that can; create this sort of construct (in dead code). The sorts of things that can; cause this to happen are fairly contrived, but we still need to accept them.; Here's an example:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define internal void @bar(void()* %FP, i1 %cond) {; br i1 %cond, label %T, label %F; T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:11235,Testability,test,test,11235,"entially create; this would have to ensure that it doesn't, and there is valid code that can; create this sort of construct (in dead code). The sorts of things that can; cause this to happen are fairly contrived, but we still need to accept them.; Here's an example:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define internal void @bar(void()* %FP, i1 %cond) {; br i1 %cond, label %T, label %F; T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:11771,Testability,test,test,11771,"T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call as unreachable. However, since; ``instcombine``/``simplifycfg`` turns the undefined call into unreachable, we; end up with a branch on a condition that goes to unreachable: a branch to; unreachable can never happen, so ""``-inline -instcombine -simplifycfg``"" is; able to produce:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test(i1 %X) {; F.i:; call fastcc void @foo(); ret void; }; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:11889,Testability,test,test,11889,"T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call as unreachable. However, since; ``instcombine``/``simplifycfg`` turns the undefined call into unreachable, we; end up with a branch on a condition that goes to unreachable: a branch to; unreachable can never happen, so ""``-inline -instcombine -simplifycfg``"" is; able to produce:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test(i1 %X) {; F.i:; call fastcc void @foo(); ret void; }; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:12592,Testability,test,test,12592,"T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call as unreachable. However, since; ``instcombine``/``simplifycfg`` turns the undefined call into unreachable, we; end up with a branch on a condition that goes to unreachable: a branch to; unreachable can never happen, so ""``-inline -instcombine -simplifycfg``"" is; able to produce:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test(i1 %X) {; F.i:; call fastcc void @foo(); ret void; }; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:2437,Usability,simpl,simply,2437,"build and; test LLVM have been ported to a plethora of platforms. What API do I use to store a value to one of the virtual registers in LLVM IR's SSA representation?; ---------------------------------------------------------------------------------------------------. In short: you can't. It's actually kind of a silly question once you grok; what's going on. Basically, in code like:. .. code-block:: llvm. %result = add i32 %foo, %bar. , ``%result`` is just a name given to the ``Value`` of the ``add``; instruction. In other words, ``%result`` *is* the add instruction. The; ""assignment"" doesn't explicitly ""store"" anything to any ""virtual register"";; the ""``=``"" is more like the mathematical sense of equality. Longer explanation: In order to generate a textual representation of the; IR, some kind of name has to be given to each instruction so that other; instructions can textually reference it. However, the isomorphic in-memory; representation that you manipulate from C++ has no such restriction since; instructions can simply keep pointers to any other ``Value``'s that they; reference. In fact, the names of dummy numbered temporaries like ``%1`` are; not explicitly represented in the in-memory representation at all (see; ``Value::getName()``). Source Languages; ================. What source languages are supported?; ------------------------------------. LLVM currently has full support for C and C++ source languages through; `Clang <https://clang.llvm.org/>`_. Many other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:9046,Usability,simpl,simplifycfg,9046,"ted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to the function. For; example, this code:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; call void @foo(); ret void; }. Is optimized to:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; unreachable; }. ... with ""``opt -instcombine -simplifycfg``"". This often bites people because; ""all their code disappears"". Setting the calling convention on the caller and; callee is required for indirect calls to work, so people often ask why not; make the verifier reject this sort of thing. The answer is that this code has undefined behavior, but it is not illegal.; If we made it illegal, then every transformation that could potentially create; this would have to ensure that it do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:9845,Usability,simpl,simplifycfg,9845,"ore you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to the function. For; example, this code:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; call void @foo(); ret void; }. Is optimized to:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @bar() {; unreachable; }. ... with ""``opt -instcombine -simplifycfg``"". This often bites people because; ""all their code disappears"". Setting the calling convention on the caller and; callee is required for indirect calls to work, so people often ask why not; make the verifier reject this sort of thing. The answer is that this code has undefined behavior, but it is not illegal.; If we made it illegal, then every transformation that could potentially create; this would have to ensure that it doesn't, and there is valid code that can; create this sort of construct (in dead code). The sorts of things that can; cause this to happen are fairly contrived, but we still need to accept them.; Here's an example:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define internal void @bar(void()* %FP, i1 %cond) {; br i1 %cond, label %T, label %F; T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, """,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:12284,Usability,simpl,simplifycfg,12284,"T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call as unreachable. However, since; ``instcombine``/``simplifycfg`` turns the undefined call into unreachable, we; end up with a branch on a condition that goes to unreachable: a branch to; unreachable can never happen, so ""``-inline -instcombine -simplifycfg``"" is; able to produce:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test(i1 %X) {; F.i:; call fastcc void @foo(); ret void; }; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:12478,Usability,simpl,simplifycfg,12478,"T:; call void %FP(); ret void; F:; call fastcc void %FP(); ret void; }; define void @test() {; %X = or i1 false, false; call void @bar(void()* @foo, i1 %X); ret void; }. In this example, ""test"" always passes ``@foo``/``false`` into ``bar``, which; ensures that it is dynamically called with the right calling conv (thus, the; code is perfectly well defined). If you run this through the inliner, you; get this (the explicit ""or"" is there so that the inliner doesn't dead code; eliminate a bunch of stuff):. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test() {; %X = or i1 false, false; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. Here you can see that the inlining pass made an undefined call to ``@foo``; with the wrong calling convention. We really don't want to make the inliner; have to know about this sort of thing, so it needs to be valid code. In this; case, dead code elimination can trivially remove the undefined code. However,; if ``%X`` was an input argument to ``@test``, the inliner would produce this:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }. define void @test(i1 %X) {; br i1 %X, label %T.i, label %F.i; T.i:; call void @foo(); br label %bar.exit; F.i:; call fastcc void @foo(); br label %bar.exit; bar.exit:; ret void; }. The interesting thing about this is that ``%X`` *must* be false for the; code to be well-defined, but no amount of dead code elimination will be able; to delete the broken call as unreachable. However, since; ``instcombine``/``simplifycfg`` turns the undefined call into unreachable, we; end up with a branch on a condition that goes to unreachable: a branch to; unreachable can never happen, so ""``-inline -instcombine -simplifycfg``"" is; able to produce:. .. code-block:: llvm. define fastcc void @foo() {; ret void; }; define void @test(i1 %X) {; F.i:; call fastcc void @foo(); ret void; }; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FAQ.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:486,Availability,avail,available,486,"===================; FatLTO; ===================; .. contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:873,Deployability,pipeline,pipeline,873,"===================; FatLTO; ===================; .. contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:919,Deployability,pipeline,pipeline,919,"===================; FatLTO; ===================; .. contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1080,Deployability,pipeline,pipeline,1080,"contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``Em",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1212,Deployability,pipeline,pipelines,1212,"R in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1488,Deployability,pipeline,pipelines,1488,"s, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't pl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:2471,Modifiability,extend,extending,2471,"in)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't planned for now. .. NOTE; For standard linking the fat object files should be usable by any; linker capable of using ELF objects, since the ``.llvm.lto`` section is; marked ``SHF_EXCLUDE``. Supported File Formats; ----------------------. The current implementation only supports ELF files. At time of writing, it is; unclear if it will be useful to support other object file formats like ``COFF``; or ``Mach-O``. Usage; =====. Clang users can specify ``-ffat-lto-objects`` with ``-flto`` or ``-flto=thin``.; Without the ``-flto`` option, ``-ffat-lto-objects`` has no effect. Compile an object file using FatLTO:. .. code-block:: console. $ clang -flto -ffat-lto-objects example.c -c -o example.o. Link using the object code from the fat object without LTO. This turns; ``-ffat-lto-objects`` into a no-op, when ``-fno-lto`` is specified:. .. code-block:: console. $ clang -fno-lto -ffat-lto-objects -fuse-ld=lld example.o. Alternatively, you can omit any references to L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1029,Performance,optimiz,optimizing,1029,"contents::; :local:; :depth: 2. .. toctree::; :maxdepth: 1. Introduction; ============. FatLTO objects are a special type of `fat object file; <https://en.wikipedia.org/wiki/Fat_binary>`_ that contain LTO compatible IR in; addition to generated object code, instead of containing object code for; multiple target architectures. This allows users to defer the choice of whether; to use LTO or not to link-time, and has been a feature available in other; compilers, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``Em",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1619,Performance,optimiz,optimization,1619,"s, like `GCC; <https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html>`_, for some time. Under FatLTO the compiler can emit standard object files which contain both the; machine code in the ``.text`` section and LLVM bitcode in the ``.llvm.lto``; section. Overview; ========. Within LLVM, FatLTO is supported by choosing the ``FatLTODefaultPipeline``.; This pipeline will:. #) Run the pre-link (Thin)LTO pipeline on the current module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't pl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:1917,Performance,perform,performance,1917,"urrent module.; #) Embed the pre-link bitcode in a special ``.llvm.lto`` section.; #) Finish optimizing the module using the ModuleOptimization pipeline.; #) Emit the object file, including the new ``.llvm.lto`` section. .. NOTE. Previously, we conservatively ran independent pipelines on separate copies; of the LLVM module to generate the bitcode section and the object code,; which happen to be identical to those used outside of FatLTO. While that; resulted in compiled artifacts that were identical to those produced by the; default and (Thin)LTO pipelines, module cloning led to some cases of; miscompilation, and we have moved away from trying to keep bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't planned for now. .. NOTE; For standard linking the fat object files should be usable by any; linker capable of using ELF objects, since the ``.llvm.lto`` section is; marked ``SHF_EXCLUDE``. Supported File Formats; ----------------------. The current implementation only supports ELF files. At time of writing, it is; unclear if it will be useful to support other object file formats like ``COFF``; or ``Mach-O``. Usage; =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst:2590,Usability,usab,usable,2590,"p bitcode; generation and optimization completely disjoint. Bit-for-bit compatibility is not (and never was) a guarantee, and we reserve; the right to change this at any time. Explicitly, users should not rely on; the produced bitcode or object code to match their non-LTO counterparts; precisely. They will exhibit similar performance characteristics, but may; not be bit-for-bit the same. Internally, the ``.llvm.lto`` section is created by running the; ``EmbedBitcodePass`` after the ``ThinLTOPreLinkDefaultPipeline``. This pass is; responsible for emitting the ``.llvm.lto`` section. Afterwards, the; ``ThinLTODefaultPipeline`` runs and the compiler can emit the fat object file. Limitations; ===========. Linkers; -------. Currently, using LTO with LLVM fat lto objects is supported by LLD and by the; GNU linkers via :doc:`GoldPlugin`. This may change in the future, but; extending support to other linkers isn't planned for now. .. NOTE; For standard linking the fat object files should be usable by any; linker capable of using ELF objects, since the ``.llvm.lto`` section is; marked ``SHF_EXCLUDE``. Supported File Formats; ----------------------. The current implementation only supports ELF files. At time of writing, it is; unclear if it will be useful to support other object file formats like ``COFF``; or ``Mach-O``. Usage; =====. Clang users can specify ``-ffat-lto-objects`` with ``-flto`` or ``-flto=thin``.; Without the ``-flto`` option, ``-ffat-lto-objects`` has no effect. Compile an object file using FatLTO:. .. code-block:: console. $ clang -flto -ffat-lto-objects example.c -c -o example.o. Link using the object code from the fat object without LTO. This turns; ``-ffat-lto-objects`` into a no-op, when ``-fno-lto`` is specified:. .. code-block:: console. $ clang -fno-lto -ffat-lto-objects -fuse-ld=lld example.o. Alternatively, you can omit any references to LTO with fat objects and retain standard linker behavior:. .. code-block:: console. $ clang -fuse-ld=lld example.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FatLTO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FatLTO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:511,Availability,fault,fault,511,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:517,Availability,reliab,reliably,517,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:562,Availability,recover,recovering,562,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:586,Availability,fault,fault,586,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1165,Availability,fault,fault,1165,"tion; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; check",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1732,Availability,fault,fault,1732," the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1764,Availability,fault,faults,1764,"ption`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1820,Availability,fault,fault,1820," In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1890,Availability,fault,fault,1890,"e in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1966,Availability,fault,fault,1966,"lded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3297,Availability,fault,faulting,3297,"l = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3431,Availability,fault,fault,3431,"is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are considered as candidates for; conversion into implicit null checks. (Note that while we could deal with (1) using profiling data, dealing; with (2) requires some informat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3994,Availability,fault,fault,3994,". !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are considered as candidates for; conversion into implicit null checks. (Note that while we could deal with (1) using profiling data, dealing; with (2) requires some information not present in branch profiles.); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3594,Deployability,patch,patching,3594,". !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are considered as candidates for; conversion into implicit null checks. (Note that while we could deal with (1) using profiling data, dealing; with (2) requires some information not present in branch profiles.); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1833,Performance,load,load,1833," In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1915,Performance,load,load,1915,"e in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:2350,Performance,load,load,2350,"ed (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:2497,Performance,load,loading,2497,"ress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:2614,Performance,load,load,2614,": FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3198,Performance,optimiz,optimization,3198,"l = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3233,Performance,perform,performance,3233,"l = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:241,Safety,safe,safety,241,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:460,Safety,safe,safety,460,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:562,Safety,recover,recovering,562,"==============================; FaultMaps and implicit checks; ==============================. .. contents::; :local:; :depth: 2. Motivation; ==========. Code generated by managed language runtimes tend to have checks that; are required for safety but never fail in practice. In such cases, it; is profitable to make the non-failing case cheaper even if it makes; the failing case significantly more expensive. This asymmetry can be; exploited by folding such safety checks into operations that can be; made to fault reliably if the check would have failed, and recovering; from such a fault by using a signal handler. For example, Java requires null checks on objects before they are read; from or written to. If the object is ``null`` then a; ``NullPointerException`` has to be thrown, interrupting normal; execution. In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FaultMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6876,Availability,error,error,6876,"----------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:9657,Availability,avail,available,9657,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:9753,Availability,avail,available,9753,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3432,Deployability,pipeline,pipeline,3432,"; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3966,Deployability,configurat,configurations,3966,"ry name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--fuzzer-args``, and any ``llc`` flags must use two dashes. For; example, to fuzz the AArch64 assembler you might use the following command:. .. code-block:: console. llvm-mc-fuzzer --triple=aarch64-linux-gnu --fuzzer-args -max_len=4. This scheme will likely change in the future. llvm-mc-disassemble-fuzzer; --------------------------. A |generic fuzzer| that fuzzes the MC layer's disassemblers by treating inputs; as assembled binary data. Note that this fuzzer has an unusual command line interface which is not fully; compat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6964,Deployability,install,installed,6964,"fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8918,Deployability,continuous,continuously,8918,"zers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:4322,Integrability,interface,interface,4322,"-------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--fuzzer-args``, and any ``llc`` flags must use two dashes. For; example, to fuzz the AArch64 assembler you might use the following command:. .. code-block:: console. llvm-mc-fuzzer --triple=aarch64-linux-gnu --fuzzer-args -max_len=4. This scheme will likely change in the future. llvm-mc-disassemble-fuzzer; --------------------------. A |generic fuzzer| that fuzzes the MC layer's disassemblers by treating inputs; as assembled binary data. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. See the notes above about; ``llvm-mc-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:4931,Integrability,interface,interface,4931,"ents in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--fuzzer-args``, and any ``llc`` flags must use two dashes. For; example, to fuzz the AArch64 assembler you might use the following command:. .. code-block:: console. llvm-mc-fuzzer --triple=aarch64-linux-gnu --fuzzer-args -max_len=4. This scheme will likely change in the future. llvm-mc-disassemble-fuzzer; --------------------------. A |generic fuzzer| that fuzzes the MC layer's disassemblers by treating inputs; as assembled binary data. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. See the notes above about; ``llvm-mc-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb-target-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and uses them to; create a target in lldb. Mutators and Input Generators; =============================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6106,Integrability,protocol,protocols,6106,"c-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb-target-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and uses them to; create a target in lldb. Mutators and Input Generators; =============================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6950,Integrability,depend,dependencies,6950,"fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:9739,Integrability,interface,interface,9739,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3966,Modifiability,config,configurations,3966,"ry name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--fuzzer-args``, and any ``llc`` flags must use two dashes. For; example, to fuzz the AArch64 assembler you might use the following command:. .. code-block:: console. llvm-mc-fuzzer --triple=aarch64-linux-gnu --fuzzer-args -max_len=4. This scheme will likely change in the future. llvm-mc-disassemble-fuzzer; --------------------------. A |generic fuzzer| that fuzzes the MC layer's disassemblers by treating inputs; as assembled binary data. Note that this fuzzer has an unusual command line interface which is not fully; compat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6021,Modifiability,layers,layers,6021,"c-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb-target-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and uses them to; create a target in lldb. Mutators and Input Generators; =============================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6548,Modifiability,layers,layers,6548,"======================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; ---------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:7021,Modifiability,config,configuring,7021,"fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:10037,Modifiability,config,config,10037,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:1013,Performance,optimiz,optimization,1013,"================================; Fuzzing LLVM libraries and tools; ================================. .. contents::; :local:; :depth: 2. Introduction; ============. The LLVM tree includes a number of fuzzers for various components. These are; built on top of :doc:`LibFuzzer <LibFuzzer>`. In order to build and run these; fuzzers, see :ref:`building-fuzzers`. Available Fuzzers; =================. clang-fuzzer; ------------. A |generic fuzzer| that tries to compile textual input as C++ code. Some of the; bugs this fuzzer has reported are `on bugzilla`__ and `on OSS Fuzz's; tracker`__. __ https://llvm.org/pr23057; __ https://bugs.chromium.org/p/oss-fuzz/issues/list?q=proj-llvm+clang-fuzzer. clang-proto-fuzzer; ------------------. A |protobuf fuzzer| that compiles valid C++ programs generated from a protobuf; class that describes a subset of the C++ language. This fuzzer accepts clang command line options after `ignore_remaining_args=1`.; For example, the following command will fuzz clang with a higher optimization; level:. .. code-block:: shell. % bin/clang-proto-fuzzer <corpus-dir> -ignore_remaining_args=1 -O3. clang-format-fuzzer; -------------------. A |generic fuzzer| that runs clang-format_ on C++ text fragments. Some of the; bugs this fuzzer has reported are `on bugzilla`__; and `on OSS Fuzz's tracker`__. .. _clang-format: https://clang.llvm.org/docs/ClangFormat.html; __ https://llvm.org/pr23052; __ https://bugs.chromium.org/p/oss-fuzz/issues/list?q=proj-llvm+clang-format-fuzzer. llvm-as-fuzzer; --------------. A |generic fuzzer| that tries to parse text as :doc:`LLVM assembly <LangRef>`.; Some of the bugs this fuzzer has reported are `on bugzilla`__. __ https://llvm.org/pr24639. llvm-dwarfdump-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and runs; :doc:`llvm-dwarfdump <CommandGuide/llvm-dwarfdump>` on them. Some of the bugs; this fuzzer has reported are `on OSS Fuzz's tracker`__. __ https://bugs.chromium.org/p/oss-fuzz/i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3056,Performance,optimiz,optimization,3056,"----------. A |generic fuzzer| for the Itanium demangler used in various LLVM tools. We've; fuzzed __cxa_demangle to death, why not fuzz LLVM's implementation of the same; function!. llvm-isel-fuzzer; ----------------. A |LLVM IR fuzzer| aimed at finding bugs in instruction selection. This fuzzer accepts flags after `ignore_remaining_args=1`. The flags match; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzze",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3386,Performance,optimiz,optimization,3386,"zzer accepts flags after `ignore_remaining_args=1`. The flags match; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:3419,Performance,optimiz,optimization,3419,"; those of :doc:`llc <CommandGuide/llc>` and the triple is required. For example,; the following command would fuzz AArch64 with :doc:`GlobalISel/index`:. .. code-block:: shell. % bin/llvm-isel-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple aarch64 -global-isel -O0. Some flags can also be specified in the binary name itself in order to support; OSS Fuzz, which has trouble with required arguments. To do this, you can copy; or move ``llvm-isel-fuzzer`` to ``llvm-isel-fuzzer--x-y-z``, separating options; from the binary name using ""--"". The valid options are architecture names; (``aarch64``, ``x86_64``), optimization levels (``O0``, ``O2``), or specific; keywords, like ``gisel`` for enabling global instruction selection. In this; mode, the same example could be run like so:. .. code-block:: shell. % bin/llvm-isel-fuzzer--aarch64-O0-gisel <corpus-dir>. llvm-opt-fuzzer; ---------------. A |LLVM IR fuzzer| aimed at finding bugs in optimization passes. It receives optimization pipeline and runs it for each fuzzer input. Interface of this fuzzer almost directly mirrors ``llvm-isel-fuzzer``. Both; ``mtriple`` and ``passes`` arguments are required. Passes are specified in a; format suitable for the new pass manager. You can find some documentation about; this format in the doxygen for ``PassBuilder::parsePassPipeline``. .. code-block:: shell. % bin/llvm-opt-fuzzer <corpus-dir> -ignore_remaining_args=1 -mtriple x86_64 -passes instcombine. Similarly to the ``llvm-isel-fuzzer`` arguments in some predefined configurations; might be embedded directly into the binary file name:. .. code-block:: shell. % bin/llvm-opt-fuzzer--x86_64-instcombine <corpus-dir>. llvm-mc-assemble-fuzzer; -----------------------. A |generic fuzzer| that fuzzes the MC layer's assemblers by treating inputs as; target specific assembly. Note that this fuzzer has an unusual command line interface which is not fully; compatible with all of libFuzzer's features. Fuzzer arguments must be passed; after ``--f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6502,Performance,perform,perform,6502,"======================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; ---------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6750,Performance,perform,perform,6750,"----------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the build; with :doc:`CMake <CMake>`. For example, `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8546,Safety,avoid,avoid,8546,"------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8115,Security,sanitiz,sanitizer,8115," `clang-proto-fuzzer`_ can be enabled by; adding ``-DCLANG_ENABLE_PROTO_FUZZER=ON`` to the flags described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `O",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8189,Security,sanitiz,sanitizer,8189,"described in; :ref:`building-fuzzers`. The only in-tree fuzzer that uses ``libprotobuf-mutator`` today is; `clang-proto-fuzzer`_. .. _libprotobuf-mutator: https://github.com/google/libprotobuf-mutator; .. _protobuf: https://github.com/google/protobuf. .. _fuzzing-llvm-ir:. Structured Fuzzing of LLVM IR; -----------------------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8478,Security,sanitiz,sanitizers,8478,"------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8565,Security,sanitiz,sanitizers,8565,"------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8592,Security,sanitiz,sanitizers,8592,"------------. We also use a more direct form of structured fuzzing for fuzzers that take; :doc:`LLVM IR <LangRef>` as input. This is achieved through the ``FuzzMutate``; library, which was `discussed at EuroLLVM 2017`_. The ``FuzzMutate`` library is used to structurally fuzz backends in; `llvm-isel-fuzzer`_. .. _discussed at EuroLLVM 2017: https://www.youtube.com/watch?v=UBbQ_s6hNgg. Building and Running; ====================. .. _building-fuzzers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:6058,Testability,test,testing,6058,"c-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb-target-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and uses them to; create a target in lldb. Mutators and Input Generators; =============================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you need `protobuf`_ and its dependencies; installed, and you need to specify some extra flags when configuring the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:9955,Testability,test,tested,9955,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:10329,Testability,test,testing,10329,"SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be built and tested when not built against libFuzzer. There is also some handling of the CMake config for fuzzers, where you should; use the ``add_llvm_fuzzer`` to set up fuzzer targets. This function works; similarly to functions such as ``add_llvm_tool``, but they take care of linking; to LibFuzzer when appropriate and can be passed the ``DUMMY_MAIN`` argument to; enable standalone testing.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:5892,Usability,simpl,simply,5892," line interface which is not fully; compatible with all of libFuzzer's features. See the notes above about; ``llvm-mc-assemble-fuzzer`` for details. .. |generic fuzzer| replace:: :ref:`generic fuzzer <fuzzing-llvm-generic>`; .. |protobuf fuzzer|; replace:: :ref:`libprotobuf-mutator based fuzzer <fuzzing-llvm-protobuf>`; .. |LLVM IR fuzzer|; replace:: :ref:`structured LLVM IR fuzzer <fuzzing-llvm-ir>`. lldb-target-fuzzer; ---------------------. A |generic fuzzer| that interprets inputs as object files and uses them to; create a target in lldb. Mutators and Input Generators; =============================. The inputs for a fuzz target are generated via random mutations of a; :ref:`corpus <libfuzzer-corpus>`. There are a few options for the kinds of; mutations that a fuzzer in LLVM might want. .. _fuzzing-llvm-generic:. Generic Random Fuzzing; ----------------------. The most basic form of input mutation is to use the built in mutators of; LibFuzzer. These simply treat the input corpus as a bag of bits and make random; mutations. This type of fuzzer is good for stressing the surface layers of a; program, and is good at testing things like lexers, parsers, or binary; protocols. Some of the in-tree fuzzers that use this type of mutator are `clang-fuzzer`_,; `clang-format-fuzzer`_, `llvm-as-fuzzer`_, `llvm-dwarfdump-fuzzer`_,; `llvm-mc-assemble-fuzzer`_, and `llvm-mc-disassemble-fuzzer`_. .. _fuzzing-llvm-protobuf:. Structured Fuzzing using ``libprotobuf-mutator``; ------------------------------------------------. We can use libprotobuf-mutator_ in order to perform structured fuzzing and; stress deeper layers of programs. This works by defining a protobuf class that; translates arbitrary data into structurally interesting input. Specifically, we; use this to work with a subset of the C++ language and perform mutations that; produce valid C++ programs in order to exercise parts of clang that are more; interesting than parser error handling. To build this kind of fuzzer you n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:2621,Availability,avail,available,2621," LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.statepoint`` relocation sequence. Don't forget to create a root for each intermediate value that is generated when; evaluating an expression. In ``h(f(), g())``, the result of ``f()`` could; easily be collected if evaluating ``g()`` triggers a collection. Finally, you need to link your runtime library with the generated program; executable (for a static compiler) or ensure the appropriate symbols are; available for the runtime linker (for a JIT compiler). Introduction; ============. What is Garbage Collection?; ---------------------------. Garbage collection is a widely used technique that frees the programmer from; having to know the lifetimes of heap objects, making software easier to produce; and maintain. Many programming languages rely on garbage collection for; automatic memory management. There are two primary forms of garbage collection:; conservative and accurate. Conservative garbage collection often does not require any special support from; either the language or the compiler: it can handle non-type-safe programming; languages (such as C/C++) and does not require any special information from the; compiler. The `Boehm collector; <https://hboehm.info/gc/>`__ is an example of a; state-of-the-art conservative collector. Accurate garbage collection requires the ability to identify all pointers in the; program at run-time (which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4543,Availability,degraded,degraded,4543,"identify all pointers in the; program at run-time (which requires that the source-language be type-safe in; most cases). Identifying pointers at run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected lan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:9149,Availability,error,error,9149," in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This page <Statepoints>` contains detailed documentation for; ``gc.statepoint``. Using ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcroot(i8** ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:13241,Availability,toler,tolerable,13241,"oca %Object*. ;; Tell LLVM that the stack space is a stack root.; ;; Java has type-tags on objects, so we pass null as metadata.; %tmp = bitcast %Object** %X to i8**; call void @llvm.gcroot(i8** %tmp, i8* null); ... ;; ""CodeBlock"" is the block corresponding to the start; ;; of the scope above.; CodeBlock:; ;; Java null-initializes pointers.; store %Object* null, %Object** %X. ... ;; As the pointer goes out of scope, store a null value into; ;; it, to indicate that the value is no longer live.; store %Object* null, %Object** %X; ... Reading and writing references in the heap; ------------------------------------------. Some collectors need to be informed when the mutator (the program that needs; garbage collection) either reads a pointer from or writes a pointer to a field; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that needs to; be executed is usually quite small and not on the critical path of any; computation, so the overall performance impact of the barrier is tolerable. Barriers often require access to the *object pointer* rather than the *derived; pointer* (which is a pointer to the field within the object). Accordingly,; these intrinsics take both pointers as separate arguments for completeness. In; this snippet, ``%object`` is the object pointer, and ``%derived`` is the derived; pointer:. .. code-block:: llvm. ;; An array type.; %class.Array = type { %class.Object, i32, [0 x %class.Object*] }; ... ;; Load the object pointer from a gcroot.; %object = load %class.Array** %object_addr. ;; Compute the derived pointer.; %derived = getelementptr %object, i32 0, i32 2, i32 %n. LLVM does not enforce this relationship between the object and derived pointer; (although a particular :ref:`collector strategy <plugin>` might). However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25760,Availability,avail,available,25760,""");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental | threaded | concurrent |; | | | stack | | sweep | | | | |; +============+======+========+==========+=======+=========+=============+==========+============+; | stack map | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | initialize | |v| | |x| | |x| | |x| | |x| | |x| | |x| | |x| |; | roots | | | | | | | | |; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:29883,Availability,avail,available,29883,"--+; | *assembly* | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *JIT* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | *obj* | NO | | | **?** | **?** | **?** | **?** | **?** |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | live | NO | | | **?** | **?** | **?** | **?** | **?** |; | analysis | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | register | NO | | | **?** | **?** | **?** | **?** | **?** |; | map | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | \* Derived pointers only pose a hazard to copying collections. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **?** denotes a feature which could be utilized if available. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+. To be clear, the collection techniques above are defined as:. Shadow Stack; The mutator carefully maintains a linked list of stack roots. Reference Counting; The mutator maintains a reference count for each object and frees an object; when its count falls to zero. Mark-Sweep; When the heap is exhausted, the collector marks reachable objects starting; from the roots, then deallocates unreachable objects in a sweep phase. Copying; As reachability analysis proceeds, the collector copies objects from one heap; area to another, compacting them in the process. Copying collectors enable; highly efficient ""bump pointer"" allocation and can improve locality of; reference. Incremental; (Including generational collectors.) Incremental collectors generally have all; the properties of a copying collector (regardless ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:180,Deployability,integrat,integrate,180,"=====================================; Garbage Collection with LLVM; =====================================. .. contents::; :local:. Abstract; ========. This document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4653,Deployability,update,update,4653,"run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6792,Deployability,update,update,6792,"runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:7703,Deployability,integrat,integrate,7703,"erences within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8975,Deployability,patch,patching,8975,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:17351,Deployability,integrat,integrate,17351,"son02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meaningful code.). .. code-block:: c++. /// The map for a single function's stack frame. One of these is; /// compiled as constant data into the executable for each function.; ///; /// Storage of metadata values is elided if the %metadata parameter to; /// @llvm.gcroot is null.; struct FrameMap {; int32_t NumRoots; //< Number of roots in stack frame.; int32_t NumMeta; //< Number of metadata entries. May be < NumRoots.; const void *Meta[0]; //< Metadata for each root.; };. /// A link in the dynamic shadow stack. One of these is embedded in; /// the stack frame of each function on the call stack.; struct StackEntry {; StackEntry *Next; //< Link to next stack entry (the caller's).; const FrameMap *Map; //< Pointer to constant FrameMap.; void *Roots[0]; //< Stack roots (in-plac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:22115,Deployability,patch,patched,22115,"he; `CoreCLR <https://github.com/dotnet/coreclr>`__ runtime. Support for this GC strategy is a work in progress. This strategy will; differ from; :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifyin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:22165,Deployability,patch,patched,22165," :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:34940,Deployability,patch,patchable,34940,"`null``; upon entry to the function. Support for this mode in code generation is; largely a legacy detail to keep old collector implementations working. Custom lowering of intrinsics; ------------------------------. For GCs which use barriers or unusual treatment of stack roots, the; implementor is responsibly for providing a custom pass to lower the; intrinsics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such a pass is the ShadowStackGC and it's; ShadowStackGCLowering pass. There is currently no way to register such a custom lowering pass; without building a custom copy of LLVM. .. _safe-points:. Generating safe points; -----------------------. LLVM provides support for associating stackmaps with the return address of; a call. Any loop or return safepoints required by a given collector design; can be modeled via calls to runtime routines, or potentially patchable call; sequences. Using gcroot, all call instructions are inferred to be possible; safepoints and will thus have an associated stackmap. .. _assembly:. Emitting assembly code: ``GCMetadataPrinter``; ---------------------------------------------. LLVM allows a plugin to print arbitrary assembly code before and after the rest; of a module's assembly code. At the end of the module, the GC can compile the; LLVM stack map into assembly code. (At the beginning, this information is not; yet computed.). Since AsmWriter and CodeGen are separate components of LLVM, a separate abstract; base class and registry is provided for printing assembly code, the; ``GCMetadaPrinter`` and ``GCMetadataPrinterRegistry``. The AsmWriter will look; for such a subclass if the ``GCStrategy`` sets ``UsesMetadata``:. .. code-block:: c++. MyGC::MyGC() {; UsesMetadata = true;; }. This separation allows JIT-only clients to be smaller. Note that LLVM does not ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:7281,Energy Efficiency,allocate,allocate,7281," The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:12089,Energy Efficiency,allocate,allocate,12089,"lloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also important to mark intermediate values with ``llvm.gcroot``. For; example, consider ``h(f(), g())``. Beware leaking the result of ``f()`` in the; case that ``g()`` triggers a collection. Note, that stack variables must be; initialized and marked with ``llvm.gcroot`` in function's prologue. The ``%metadata`` argument can be used to avoid requiring heap objects to have; 'isa' pointers or tag bits. [Appel89_, Goldberg91_, Tolmach94_] If specified,; its value will be tracked along with the location of the pointer in the stack; frame. Consider the following fragment of Java code:. .. code-block:: java. {; Object X; // A null-initialized reference to an object; ...; }. This block (which may be located in the middle of a function or in a loop nest),; could be compiled to this LLVM code:. .. code-block:: llvm. Entry:; ;; In the entry block for the function, allocate the; ;; stack space for X, which is an LLVM pointer.; %X = alloca %Object*. ;; Tell LLVM that the stack space is a stack root.; ;; Java has type-tags on objects, so we pass null as metadata.; %tmp = bitcast %Object** %X to i8**; call void @llvm.gcroot(i8** %tmp, i8* null); ... ;; ""CodeBlock"" is the block corresponding to the start; ;; of the scope above.; CodeBlock:; ;; Java null-initializes pointers.; store %Object* null, %Object** %X. ... ;; As the pointer goes out of scope, store a null value into; ;; it, to indicate that the value is no longer live.; store %Object* null, %Object** %X; ... Reading and writing references in the heap; ------------------------------------------. Some collectors need to be informed when the mutator (the program that needs; garbage collection) either reads a pointer from or writes a pointer to a field; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:30591,Energy Efficiency,efficient,efficient,30591,"-+---------+-------------+----------+------------+; | \* Derived pointers only pose a hazard to copying collections. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **?** denotes a feature which could be utilized if available. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+. To be clear, the collection techniques above are defined as:. Shadow Stack; The mutator carefully maintains a linked list of stack roots. Reference Counting; The mutator maintains a reference count for each object and frees an object; when its count falls to zero. Mark-Sweep; When the heap is exhausted, the collector marks reachable objects starting; from the roots, then deallocates unreachable objects in a sweep phase. Copying; As reachability analysis proceeds, the collector copies objects from one heap; area to another, compacting them in the process. Copying collectors enable; highly efficient ""bump pointer"" allocation and can improve locality of; reference. Incremental; (Including generational collectors.) Incremental collectors generally have all; the properties of a copying collector (regardless of whether the mature heap; is compacting), but bring the added complexity of requiring write barriers. Threaded; Denotes a multithreaded mutator; the collector must still stop the mutator; (""stop the world"") before beginning reachability analysis. Stopping a; multithreaded mutator is a complicated problem. It generally requires highly; platform-specific code in the runtime, and the production of carefully; designed machine code at safe points. Concurrent; In this technique, the mutator and the collector run concurrently, with the; goal of eliminating pause times. In a *cooperative* collector, the mutator; further aids with collection should a pause occur, allowing collection to take; advantage of multiprocessor hosts. The ""stop the world"" problem of threaded; collectors is generally still ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:180,Integrability,integrat,integrate,180,"=====================================; Garbage Collection with LLVM; =====================================. .. contents::; :local:. Abstract; ========. This document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1352,Integrability,rout,routines,1352,"==========. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.statepoint`` relocation sequence. Don't forget to create a root for each intermediate value that is generated when; evaluating an expression. In ``h(f(),",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1506,Integrability,interface,interface,1506,"s, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.statepoint`` relocation sequence. Don't forget to create a root for each intermediate value that is generated when; evaluating an expression. In ``h(f(), g())``, the result of ``f()`` could; easily be collected if evaluating ``g()`` triggers a collec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4923,Integrability,interface,interfaces,4923,"it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; saf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6147,Integrability,interface,interface,6147,"bage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are add",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6471,Integrability,interface,interface,6471," class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:7635,Integrability,interface,interface,7635,"s within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:7703,Integrability,integrat,integrate,7703,"erences within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8052,Integrability,interface,interface,8052,"re additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; ge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:17351,Integrability,integrat,integrate,17351,"son02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meaningful code.). .. code-block:: c++. /// The map for a single function's stack frame. One of these is; /// compiled as constant data into the executable for each function.; ///; /// Storage of metadata values is elided if the %metadata parameter to; /// @llvm.gcroot is null.; struct FrameMap {; int32_t NumRoots; //< Number of roots in stack frame.; int32_t NumMeta; //< Number of metadata entries. May be < NumRoots.; const void *Meta[0]; //< Metadata for each root.; };. /// A link in the dynamic shadow stack. One of these is embedded in; /// the stack frame of each function on the call stack.; struct StackEntry {; StackEntry *Next; //< Link to next stack entry (the caller's).; const FrameMap *Map; //< Pointer to constant FrameMap.; void *Roots[0]; //< Stack roots (in-plac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:24267,Integrability,interface,interface,24267," defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRAR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:34915,Integrability,rout,routines,34915,"`null``; upon entry to the function. Support for this mode in code generation is; largely a legacy detail to keep old collector implementations working. Custom lowering of intrinsics; ------------------------------. For GCs which use barriers or unusual treatment of stack roots, the; implementor is responsibly for providing a custom pass to lower the; intrinsics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such a pass is the ShadowStackGC and it's; ShadowStackGCLowering pass. There is currently no way to register such a custom lowering pass; without building a custom copy of LLVM. .. _safe-points:. Generating safe points; -----------------------. LLVM provides support for associating stackmaps with the return address of; a call. Any loop or return safepoints required by a given collector design; can be modeled via calls to runtime routines, or potentially patchable call; sequences. Using gcroot, all call instructions are inferred to be possible; safepoints and will thus have an associated stackmap. .. _assembly:. Emitting assembly code: ``GCMetadataPrinter``; ---------------------------------------------. LLVM allows a plugin to print arbitrary assembly code before and after the rest; of a module's assembly code. At the end of the module, the GC can compile the; LLVM stack map into assembly code. (At the beginning, this information is not; yet computed.). Since AsmWriter and CodeGen are separate components of LLVM, a separate abstract; base class and registry is provided for printing assembly code, the; ``GCMetadaPrinter`` and ``GCMetadataPrinterRegistry``. The AsmWriter will look; for such a subclass if the ``GCStrategy`` sets ``UsesMetadata``:. .. code-block:: c++. MyGC::MyGC() {; UsesMetadata = true;; }. This separation allows JIT-only clients to be smaller. Note that LLVM does not ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:506,Modifiability,plugin,plugin,506,"=====================================; Garbage Collection with LLVM; =====================================. .. contents::; :local:. Abstract; ========. This document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:3741,Modifiability,variab,variables,3741,"?; ---------------------------. Garbage collection is a widely used technique that frees the programmer from; having to know the lifetimes of heap objects, making software easier to produce; and maintain. Many programming languages rely on garbage collection for; automatic memory management. There are two primary forms of garbage collection:; conservative and accurate. Conservative garbage collection often does not require any special support from; either the language or the compiler: it can handle non-type-safe programming; languages (such as C/C++) and does not require any special information from the; compiler. The `Boehm collector; <https://hboehm.info/gc/>`__ is an example of a; state-of-the-art conservative collector. Accurate garbage collection requires the ability to identify all pointers in the; program at run-time (which requires that the source-language be type-safe in; most cases). Identifying pointers at run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effect",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:5994,Modifiability,extend,extend,5994,"bage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are add",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6059,Modifiability,plugin,plugins,6059,"bage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are add",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6068,Modifiability,plugin,plugin,6068,"bage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are add",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:6415,Modifiability,flexible,flexible,6415,"erative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8439,Modifiability,plugin,plugin,8439," with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8951,Modifiability,plugin,plugin,8951,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:9673,Modifiability,plugin,plugin,9673,"e is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This page <Statepoints>` contains detailed documentation for; ``gc.statepoint``. Using ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcroot(i8** %ptrloc, i8* %metadata). The ``llvm.gcroot`` intrinsic is used to inform LLVM that a stack variable; references an object on the heap and is to be tracked for garbage collection.; The exact impact on generated code is specified by the Function's selected; :ref:`GC strategy <plugin>`. All calls to ``llvm.gcroot`` **must** reside; inside the first basic block. The first argument **must** be a value referring to an alloca instruction or a; bitcast of an alloca. The second contains a pointer to metadata that s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:10220,Modifiability,variab,variable,10220,"ograms that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This page <Statepoints>` contains detailed documentation for; ``gc.statepoint``. Using ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcroot(i8** %ptrloc, i8* %metadata). The ``llvm.gcroot`` intrinsic is used to inform LLVM that a stack variable; references an object on the heap and is to be tracked for garbage collection.; The exact impact on generated code is specified by the Function's selected; :ref:`GC strategy <plugin>`. All calls to ``llvm.gcroot`` **must** reside; inside the first basic block. The first argument **must** be a value referring to an alloca instruction or a; bitcast of an alloca. The second contains a pointer to metadata that should be; associated with the pointer, and **must** be a constant or global value; address. If your target collector uses tags, use a null pointer for metadata. A compiler which performs manual SSA construction **must** ensure that SSA; values representing GC references are stored in to the alloca passed to the; respective ``gcroot`` before every call site and reloaded after every call.; A compiler which uses mem2reg to raise imperative code using ``alloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also importan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:10404,Modifiability,plugin,plugin,10404,"--------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This page <Statepoints>` contains detailed documentation for; ``gc.statepoint``. Using ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcroot(i8** %ptrloc, i8* %metadata). The ``llvm.gcroot`` intrinsic is used to inform LLVM that a stack variable; references an object on the heap and is to be tracked for garbage collection.; The exact impact on generated code is specified by the Function's selected; :ref:`GC strategy <plugin>`. All calls to ``llvm.gcroot`` **must** reside; inside the first basic block. The first argument **must** be a value referring to an alloca instruction or a; bitcast of an alloca. The second contains a pointer to metadata that should be; associated with the pointer, and **must** be a constant or global value; address. If your target collector uses tags, use a null pointer for metadata. A compiler which performs manual SSA construction **must** ensure that SSA; values representing GC references are stored in to the alloca passed to the; respective ``gcroot`` before every call site and reloaded after every call.; A compiler which uses mem2reg to raise imperative code using ``alloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also important to mark intermediate values with ``llvm.gcroot``. For; example, consider ``h(f(), g())``. Beware leaking the result of ``f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:11169,Modifiability,variab,variables,11169," is used to inform LLVM that a stack variable; references an object on the heap and is to be tracked for garbage collection.; The exact impact on generated code is specified by the Function's selected; :ref:`GC strategy <plugin>`. All calls to ``llvm.gcroot`` **must** reside; inside the first basic block. The first argument **must** be a value referring to an alloca instruction or a; bitcast of an alloca. The second contains a pointer to metadata that should be; associated with the pointer, and **must** be a constant or global value; address. If your target collector uses tags, use a null pointer for metadata. A compiler which performs manual SSA construction **must** ensure that SSA; values representing GC references are stored in to the alloca passed to the; respective ``gcroot`` before every call site and reloaded after every call.; A compiler which uses mem2reg to raise imperative code using ``alloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also important to mark intermediate values with ``llvm.gcroot``. For; example, consider ``h(f(), g())``. Beware leaking the result of ``f()`` in the; case that ``g()`` triggers a collection. Note, that stack variables must be; initialized and marked with ``llvm.gcroot`` in function's prologue. The ``%metadata`` argument can be used to avoid requiring heap objects to have; 'isa' pointers or tag bits. [Appel89_, Goldberg91_, Tolmach94_] If specified,; its value will be tracked along with the location of the pointer in the stack; frame. Consider the following fragment of Java code:. .. code-block:: java. {; Object X; // A null-initialized reference to an object; ...; }. This block (which may be located in the middle of a function or in a loop nest),; could be compiled to this LLVM code:. .. code-block:: llvm. Entry:; ;; In the entry block for the function, allocate the; ;; stack space for X, which is an LLVM pointer.; %X = alloca %Object*. ;; Tell L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:11431,Modifiability,variab,variables,11431,"** reside; inside the first basic block. The first argument **must** be a value referring to an alloca instruction or a; bitcast of an alloca. The second contains a pointer to metadata that should be; associated with the pointer, and **must** be a constant or global value; address. If your target collector uses tags, use a null pointer for metadata. A compiler which performs manual SSA construction **must** ensure that SSA; values representing GC references are stored in to the alloca passed to the; respective ``gcroot`` before every call site and reloaded after every call.; A compiler which uses mem2reg to raise imperative code using ``alloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also important to mark intermediate values with ``llvm.gcroot``. For; example, consider ``h(f(), g())``. Beware leaking the result of ``f()`` in the; case that ``g()`` triggers a collection. Note, that stack variables must be; initialized and marked with ``llvm.gcroot`` in function's prologue. The ``%metadata`` argument can be used to avoid requiring heap objects to have; 'isa' pointers or tag bits. [Appel89_, Goldberg91_, Tolmach94_] If specified,; its value will be tracked along with the location of the pointer in the stack; frame. Consider the following fragment of Java code:. .. code-block:: java. {; Object X; // A null-initialized reference to an object; ...; }. This block (which may be located in the middle of a function or in a loop nest),; could be compiled to this LLVM code:. .. code-block:: llvm. Entry:; ;; In the entry block for the function, allocate the; ;; stack space for X, which is an LLVM pointer.; %X = alloca %Object*. ;; Tell LLVM that the stack space is a stack root.; ;; Java has type-tags on objects, so we pass null as metadata.; %tmp = bitcast %Object** %X to i8**; call void @llvm.gcroot(i8** %tmp, i8* null); ... ;; ""CodeBlock"" is the block corresponding to the start; ;; of the scope a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:13996,Modifiability,plugin,plugin,13996,"eld; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that needs to; be executed is usually quite small and not on the critical path of any; computation, so the overall performance impact of the barrier is tolerable. Barriers often require access to the *object pointer* rather than the *derived; pointer* (which is a pointer to the field within the object). Accordingly,; these intrinsics take both pointers as separate arguments for completeness. In; this snippet, ``%object`` is the object pointer, and ``%derived`` is the derived; pointer:. .. code-block:: llvm. ;; An array type.; %class.Array = type { %class.Object, i32, [0 x %class.Object*] }; ... ;; Load the object pointer from a gcroot.; %object = load %class.Array** %object_addr. ;; Compute the derived pointer.; %derived = getelementptr %object, i32 0, i32 2, i32 %n. LLVM does not enforce this relationship between the object and derived pointer; (although a particular :ref:`collector strategy <plugin>` might). However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require the corresponding barrier. The GC strategy used with such a collector; should replace the intrinsic calls with the corresponding ``load`` or; ``store`` instruction if they are used. One known deficiency with the current design is that the barrier intrinsics do; not include the size or alignment of the underlying operation performed. It is; currently assumed that the operation is of pointer size and the alignment is; assumed to be the target machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* %value, i8* %object, i8** %derived). For write barriers, LLVM provides the ``llvm.gcwrite`` intrinsic function. It; has exactly the same semantics as a non-volatile ``store`` to the derived; poin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:15050,Modifiability,plugin,plugin,15050,". However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require the corresponding barrier. The GC strategy used with such a collector; should replace the intrinsic calls with the corresponding ``load`` or; ``store`` instruction if they are used. One known deficiency with the current design is that the barrier intrinsics do; not include the size or alignment of the underlying operation performed. It is; currently assumed that the operation is of pointer size and the alignment is; assumed to be the target machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* %value, i8* %object, i8** %derived). For write barriers, LLVM provides the ``llvm.gcwrite`` intrinsic function. It; has exactly the same semantics as a non-volatile ``store`` to the derived; pointer (the third argument). The exact code generated is specified by the; Function's selected :ref:`GC strategy <plugin>`. Many important algorithms require write barriers, including generational and; concurrent collectors. Additionally, write barriers could be used to implement; reference counting. Read barrier: ``llvm.gcread``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. i8* @llvm.gcread(i8* %object, i8** %derived). For read barriers, LLVM provides the ``llvm.gcread`` intrinsic function. It has; exactly the same semantics as a non-volatile ``load`` from the derived pointer; (the second argument). The exact code generated is specified by the Function's; selected :ref:`GC strategy <plugin>`. Read barriers are needed by fewer algorithms than write barriers, and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:15637,Modifiability,plugin,plugin,15637,"arget machine's default alignment. Write barrier: ``llvm.gcwrite``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.gcwrite(i8* %value, i8* %object, i8** %derived). For write barriers, LLVM provides the ``llvm.gcwrite`` intrinsic function. It; has exactly the same semantics as a non-volatile ``store`` to the derived; pointer (the third argument). The exact code generated is specified by the; Function's selected :ref:`GC strategy <plugin>`. Many important algorithms require write barriers, including generational and; concurrent collectors. Additionally, write barriers could be used to implement; reference counting. Read barrier: ``llvm.gcread``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. i8* @llvm.gcread(i8* %object, i8** %derived). For read barriers, LLVM provides the ``llvm.gcread`` intrinsic function. It has; exactly the same semantics as a non-volatile ``load`` from the derived pointer; (the second argument). The exact code generated is specified by the Function's; selected :ref:`GC strategy <plugin>`. Read barriers are needed by fewer algorithms than write barriers, and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:16512,Modifiability,portab,portability,16512,"the second argument). The exact code generated is specified by the Function's; selected :ref:`GC strategy <plugin>`. Read barriers are needed by fewer algorithms than write barriers, and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meani",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:16723,Modifiability,portab,portability,16723," and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meaningful code.). .. code-block:: c++. /// The map for a single function's stack frame. One of these is; /// compiled as constant data into the executable for each function.; ///; /// S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:16903,Modifiability,plugin,plugin,16903,"rieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meaningful code.). .. code-block:: c++. /// The map for a single function's stack frame. One of these is; /// compiled as constant data into the executable for each function.; ///; /// Storage of metadata values is elided if the %metadata parameter to; /// @llvm.gcroot is null.; struct FrameMap {; int32_t NumRoots; //< Number of roots in stack frame.; int32_t NumMeta; //< Number of metadata entries. May be < Num",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:16911,Modifiability,plugin,plugin,16911,"rieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meaningful code.). .. code-block:: c++. /// The map for a single function's stack frame. One of these is; /// compiled as constant data into the executable for each function.; ///; /// Storage of metadata values is elided if the %metadata parameter to; /// @llvm.gcroot is null.; struct FrameMap {; int32_t NumRoots; //< Number of roots in stack frame.; int32_t NumMeta; //< Number of metadata entries. May be < Num",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:19687,Modifiability,plugin,plugin,19687,"each GC root on the stack.; /// root and meta are exactly the values passed to; /// @llvm.gcroot.; ///; /// Visitor could be a function to recursively mark live objects. Or it; /// might copy them to another heap or generation.; ///; /// @param Visitor A function to invoke for every GC root on the stack.; void visitGCRoots(void (*Visitor)(void **Root, const void *Meta)) {; for (StackEntry *R = llvm_gc_root_chain; R; R = R->Next) {; unsigned i = 0;. // For roots [0, NumMeta), the metadata pointer is in the FrameMap.; for (unsigned e = R->Map->NumMeta; i != e; ++i); Visitor(&R->Roots[i], R->Map->Meta[i]);. // For roots [NumMeta, NumRoots), the metadata pointer is null.; for (unsigned e = R->Map->NumRoots; i != e; ++i); Visitor(&R->Roots[i], NULL);; }; }. The 'Erlang' and 'Ocaml' GCs; -----------------------------. LLVM ships with two example collectors which leverage the ``gcroot``; mechanisms. To our knowledge, these are not actually used by any language; runtime, but they do provide a reasonable starting point for someone interested; in writing an ``gcroot`` compatible GC plugin. In particular, these are the; only in tree examples of how to produce a custom binary stack map format using; a ``gcroot`` strategy. As there names imply, the binary format produced is intended to model that; used by the Erlang and OCaml compilers respectively. .. _statepoint_example_gc:. The Statepoint Example GC; -------------------------. .. code-block:: c++. F.setGC(""statepoint-example"");. This GC provides an example of how one might use the infrastructure provided; by ``gc.statepoint``. This example GC is compatible with the; :ref:`PlaceSafepoints` and :ref:`RewriteStatepointsForGC` utility passes; which simplify ``gc.statepoint`` sequence insertion. If you need to build a; custom GC strategy around the ``gc.statepoints`` mechanisms, it is recommended; that you use this one as a starting point. This GC strategy does not support read or write barriers. As a result, these; intrinsics are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:21908,Modifiability,plugin,plugin,21908," The CoreCLR GC; -------------------------. .. code-block:: c++. F.setGC(""coreclr"");. This GC leverages the ``gc.statepoint`` mechanism to support the; `CoreCLR <https://github.com/dotnet/coreclr>`__ runtime. Support for this GC strategy is a work in progress. This strategy will; differ from; :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack craw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:21934,Modifiability,plugin,plugins,21934,"he; `CoreCLR <https://github.com/dotnet/coreclr>`__ runtime. Support for this GC strategy is a work in progress. This strategy will; differ from; :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifyin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:22248,Modifiability,extend,extend,22248,"inters of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:23078,Modifiability,variab,variables,23078,"ring pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage col",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:23383,Modifiability,plugin,plugin,23383,"ould be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:23591,Modifiability,plugin,plugin,23591,"ation; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack crawler to discover functions on the call stack, and enumerate the; references listed in the stack map for each call site. #. A mechanism for identifying references in global locations (e.g. global; variables). #. If you collector requires them, an LLVM IR implementation of your collectors; load and store barriers. Note that since many collectors don't require; barriers at all, LLVM defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:24195,Modifiability,plugin,plugin,24195," defaults to lowering such barriers to normal loads; and stores unless you arrange otherwise. Implementing a collector plugin; -------------------------------. User code specifies which GC code generation to use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRAR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:24478,Modifiability,plugin,plugin,24478,"o use with the ``gc`` function; attribute or, equivalently, with the ``setGC`` method of ``Function``. To implement a GC plugin, it is necessary to subclass ``llvm::GCStrategy``,; which can be accomplished in a few lines of boilerplate code. LLVM's; infrastructure provides access to several important algorithms. For an; uncontroversial collector, all that remains may be to compile LLVM's computed; stack map to assembly code (using the binary representation expected by the; runtime library). This can be accomplished in about 100 lines of code. This is not the appropriate place to implement a garbage collected heap or a; garbage collector itself. That code should exist in the language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-spec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25167,Modifiability,plugin,plugin,25167,"language's runtime; library. The compiler plugin is responsible for generating code which conforms; to the binary interface defined by library, most essentially the :ref:`stack map; <stack-map>`. To subclass ``llvm::GCStrategy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25343,Modifiability,plugin,plugin,25343,"tegy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25658,Modifiability,plugin,plugin,25658,"MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental | threaded | concurrent |; | | | stack | | sweep | | | | |; +============+======+========+==========+=======+=========+=============+==========+============+; | stack map | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+---",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25872,Modifiability,plugin,plugin,25872,"m.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental | threaded | concurrent |; | | | stack | | sweep | | | | |; +============+======+========+==========+=======+=========+=============+==========+============+; | stack map | |v| | | | |x| | |x| | |x| | |x| | |x| |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | initialize | |v| | |x| | |x| | |x| | |x| | |x| | |x| | |x| |; | roots | | | | | | | | |; +------------+------+--------+----------+-------+---------+-------------+---",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:31865,Modifiability,extend,extend,31865," of whether the mature heap; is compacting), but bring the added complexity of requiring write barriers. Threaded; Denotes a multithreaded mutator; the collector must still stop the mutator; (""stop the world"") before beginning reachability analysis. Stopping a; multithreaded mutator is a complicated problem. It generally requires highly; platform-specific code in the runtime, and the production of carefully; designed machine code at safe points. Concurrent; In this technique, the mutator and the collector run concurrently, with the; goal of eliminating pause times. In a *cooperative* collector, the mutator; further aids with collection should a pause occur, allowing collection to take; advantage of multiprocessor hosts. The ""stop the world"" problem of threaded; collectors is generally still present to a limited extent. Sophisticated; marking algorithms are necessary. Read barriers may be necessary. As the matrix indicates, LLVM's garbage collection infrastructure is already; suitable for a wide variety of collectors, but does not currently extend to; multithreaded programs. This will be added in the future as there is; interest. .. _stack-map:. Computing stack maps; --------------------. LLVM automatically computes a stack map. One of the most important features; of a ``GCStrategy`` is to compile this information into the executable in; the binary representation expected by the runtime library. The stack map consists of the location and identity of each GC root in the; each function in the module. For each root:. * ``RootNum``: The index of the root. * ``StackOffset``: The offset of the object relative to the frame pointer. * ``RootMetadata``: The value passed as the ``%metadata`` parameter to the; ``@llvm.gcroot`` intrinsic. Also, for the function as a whole:. * ``getFrameSize()``: The overall size of the function's initial stack frame,; not accounting for any dynamic allocation. * ``roots_size()``: The count of roots in the function. To access the stack map, use ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:33473,Modifiability,plugin,plugins,33473,"alue passed as the ``%metadata`` parameter to the; ``@llvm.gcroot`` intrinsic. Also, for the function as a whole:. * ``getFrameSize()``: The overall size of the function's initial stack frame,; not accounting for any dynamic allocation. * ``roots_size()``: The count of roots in the function. To access the stack map, use ``GCFunctionMetadata::roots_begin()`` and; -``end()`` from the :ref:`GCMetadataPrinter <assembly>`:. .. code-block:: c++. for (iterator I = begin(), E = end(); I != E; ++I) {; GCFunctionInfo *FI = *I;; unsigned FrameSize = FI->getFrameSize();; size_t RootCount = FI->roots_size();. for (GCFunctionInfo::roots_iterator RI = FI->roots_begin(),; RE = FI->roots_end();; RI != RE; ++RI) {; int RootNum = RI->Num;; int RootStackOffset = RI->StackOffset;; Constant *RootMetadata = RI->Metadata;; }; }. If the ``llvm.gcroot`` intrinsic is eliminated before code generation by a; custom lowering pass, LLVM will compute an empty stack map. This may be useful; for collector plugins which implement reference counting or a shadow stack. .. _init-roots:. Initializing roots to null; ---------------------------. It is recommended that frontends initialize roots explicitly to avoid; potentially confusing the optimizer. This prevents the GC from visiting; uninitialized pointers, which will almost certainly cause it to crash. As a fallback, LLVM will automatically initialize each root to ``null``; upon entry to the function. Support for this mode in code generation is; largely a legacy detail to keep old collector implementations working. Custom lowering of intrinsics; ------------------------------. For GCs which use barriers or unusual treatment of stack roots, the; implementor is responsibly for providing a custom pass to lower the; intrinsics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:35209,Modifiability,plugin,plugin,35209,"ics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such a pass is the ShadowStackGC and it's; ShadowStackGCLowering pass. There is currently no way to register such a custom lowering pass; without building a custom copy of LLVM. .. _safe-points:. Generating safe points; -----------------------. LLVM provides support for associating stackmaps with the return address of; a call. Any loop or return safepoints required by a given collector design; can be modeled via calls to runtime routines, or potentially patchable call; sequences. Using gcroot, all call instructions are inferred to be possible; safepoints and will thus have an associated stackmap. .. _assembly:. Emitting assembly code: ``GCMetadataPrinter``; ---------------------------------------------. LLVM allows a plugin to print arbitrary assembly code before and after the rest; of a module's assembly code. At the end of the module, the GC can compile the; LLVM stack map into assembly code. (At the beginning, this information is not; yet computed.). Since AsmWriter and CodeGen are separate components of LLVM, a separate abstract; base class and registry is provided for printing assembly code, the; ``GCMetadaPrinter`` and ``GCMetadataPrinterRegistry``. The AsmWriter will look; for such a subclass if the ``GCStrategy`` sets ``UsesMetadata``:. .. code-block:: c++. MyGC::MyGC() {; UsesMetadata = true;; }. This separation allows JIT-only clients to be smaller. Note that LLVM does not currently have analogous APIs to support code generation; in the JIT, nor using the object writers. .. code-block:: c++. // lib/MyGC/MyGCPrinter.cpp - Example LLVM GC printer. #include ""llvm/CodeGen/GCMetadataPrinter.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGCPrinter : public GCMetadataPrinter",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:36499,Modifiability,portab,portable,36499,"arate components of LLVM, a separate abstract; base class and registry is provided for printing assembly code, the; ``GCMetadaPrinter`` and ``GCMetadataPrinterRegistry``. The AsmWriter will look; for such a subclass if the ``GCStrategy`` sets ``UsesMetadata``:. .. code-block:: c++. MyGC::MyGC() {; UsesMetadata = true;; }. This separation allows JIT-only clients to be smaller. Note that LLVM does not currently have analogous APIs to support code generation; in the JIT, nor using the object writers. .. code-block:: c++. // lib/MyGC/MyGCPrinter.cpp - Example LLVM GC printer. #include ""llvm/CodeGen/GCMetadataPrinter.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGCPrinter : public GCMetadataPrinter {; public:; virtual void beginAssembly(AsmPrinter &AP);. virtual void finishAssembly(AsmPrinter &AP);; };. GCMetadataPrinterRegistry::Add<MyGCPrinter>; X(""mygc"", ""My bespoke garbage collector."");; }. The collector should use ``AsmPrinter`` to print portable assembly code. The; collector itself contains the stack map for the entire module, and may access; the ``GCFunctionInfo`` using its own ``begin()`` and ``end()`` methods. Here's; a realistic example:. .. code-block:: c++. #include ""llvm/CodeGen/AsmPrinter.h""; #include ""llvm/IR/Function.h""; #include ""llvm/IR/DataLayout.h""; #include ""llvm/Target/TargetAsmInfo.h""; #include ""llvm/Target/TargetMachine.h"". void MyGCPrinter::beginAssembly(AsmPrinter &AP) {; // Nothing to do.; }. void MyGCPrinter::finishAssembly(AsmPrinter &AP) {; MCStreamer &OS = AP.OutStreamer;; unsigned IntPtrSize = AP.getPointerSize();. // Put this in the data section.; OS.switchSection(AP.getObjFileLowering().getDataSection());. // For each function...; for (iterator FI = begin(), FE = end(); FI != FE; ++FI) {; GCFunctionInfo &MD = **FI;. // A compact GC layout. Emit this data structure:; //; // struct {; // int32_t PointCount;; // void *SafePointAddress[PointCount];; // int32_t StackFrameSize; // in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:497,Performance,load,loadable,497,"=====================================; Garbage Collection with LLVM; =====================================. .. contents::; :local:. Abstract; ========. This document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1155,Performance,load,load,1155,"is document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplishe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1224,Performance,load,load,1224," language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4559,Performance,optimiz,optimization,4559,"identify all pointers in the; program at run-time (which requires that the source-language be type-safe in; most cases). Identifying pointers at run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected lan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4702,Performance,optimiz,optimizations,4702,"run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst
